{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Monday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (25 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "\n",
        "(3) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(4) Collect all the information of the 904 narrators in the Densho Digital Repository.\n",
        "\n",
        "(5)**Collect a total of 10000 reviews** of the top 100 most popular software from G2 and Capterra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jDyTKYs-yGit"
      },
      "outputs": [],
      "source": [
        "# importing the data library\n",
        "import requests\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "772xKr0LEZuM",
        "outputId": "e09c252e-4e22-471e-cb56-7b108c48cb30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " An effective approach is proposed to evaluate the service life reliability of a multi-physics coupling structure of an insulated gate bipolar transistor (IGBT) module. The node-based smoothed finite element method with stabilization terms is firstly employed to construct an electrical-thermal-mechanical (ETM) coupling structure of the IGBT module, based on which the multi-physics responses can be accurately calculated to predict the service life of the IGBT module. By using the high-quality sample data obtained through the ETM coupling model, a Monte Carlo based active learning Kriging metamodel (AK-MCS) is developed to assess the service life reliability of the IGBT module, which can greatly reduce the computational cost needed by the surrogate model construction and reliability analysis. Numerical results show that the proposed ETM coupling structure can produce high-quality sample data of the IGBT dynamics and the AK-MCS machine learning technique can accurately estimate the service life reliability of the IGBT module.\n",
            "----------------------------------------\n",
            "Title: Matrix Factorization-based Technique for Drug Repurposing Predictions\n",
            "Abstract: Classical drug design methodologies are hugely costly and time-consuming, with approximately 85% of the new proposed molecules failing in the first three phases of the FDA drug approval process. Thus, strategies to find alternative indications for already approved drugs that leverage computational methods are of crucial relevance. We previously demonstrated the efficacy of the Non-negative Matrix Tri-Factorization, a method that allows exploiting both data integration and machine learning, to infer novel indications for approved drugs. In this work, we present an innovative enhancement of the NMTF method that consists of a shortest-path evaluation of drug-protein pairs using the protein-to-protein interaction network. This approach allows inferring novel protein targets that were never considered as drug targets before, increasing the information fed to the NMTF method. Indeed, this novel advance enables the investigation of drug-centric predictions, simultaneously identifying therapeutic classes, protein targets and diseases associated with a particular drug. To test our methodology, we applied the NMTF and shortest-path enhancement methods to an outdated collection of data and compared the predictions against the most updated version, obtaining very good performance, with an Average Precision Score of 0.82. The data enhancement strategy allowed increasing the number of putative protein targets from 3,691 to 15,295, while the predictive performance of the method is slightly increased. Finally, we also validated our top-scored predictions according to the literature, finding relevant confirmation of predicted interactions between drugs and protein targets, as well as of predicted annotations between drugs and both therapeutic classes and diseases.\n",
            "----------------------------------------\n",
            "Title: Use of flipped classroom in the marketing career during the educational process on financial mathematics\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Facial Emotion Recognition – A gift for the visionless\n",
            "Abstract: — Most of the mundane activities these days are automated. There are others, which do not have a fixed pattern. For instance, recognition of emotions of an individual given the facial expressions. Using the Machine Learning concepts, a model is trained with various facial images having varied expressions, of single and multiple individuals. In the current work, face detection and emotion recognition is carried out at real time even when an individual is on the move. The findings of the paper can be useful in identifying missing individual, helping individuals in emotional distress. It can also help the visionless analyze the mood of the person with whom he is interacting. The name of the individual whose identity is verified is also verbally provided as an assistance to the impaired. Various face recognition algorithms and the relative comparison and analysis is also brought out usic plays an essential role in the well-being of many people. It can be therapeutic, motivational and can even unite people.\n",
            "----------------------------------------\n",
            "Title: Improving The Detection of Plagiarism in Scientific Articles Using Machine Learning Approaches\n",
            "Abstract: . One of the modern problems that occur in the current research and publication process is the duplication of the results of other people's research that is presented again by other parties. With the ease of the resources obtained, the more open the opportunity to bring up a problem called Plagiarism. This is attempted to be completed by the computer system with new approaches to detect and predict the existence of plagiarism in research automatically. In this article, approaches and methods for detecting plagiarism use machine learning techniques, where machine learning is empowered to become an algorithm as construction and evaluation in detecting plagiarism. Technically, this algorithm will compare and analyze the compatibility of words and sentences in documents with other document databases so that the analysis becomes an evaluation material, prediction, and determination that the document is plagiarism or not. The purpose of this study is to protect intellectual property and ideas, as well as the results to improve better performance and level of accuracy in detecting plagiarism.\n",
            "----------------------------------------\n",
            "Title: Application of Machine Learning Methods in Baikal-GVD: Background Noise Rejection and Selection of Neutrino-Induced Events\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Stellar Abundances to Predict Exoplanet Host Stars\n",
            "Abstract: Introduction: Since the initial discovery of the “planet-metallicity” relationship for giant planets, as popularized by Fischer & Valenti [1] the iron content within a star, or the [Fe/H] ratio, has been used as a proxy for the overall metallicity of the star. While it has been assumed that the abundances of other important bio-essential elements, such as C, O, Si, and Mg, have been consistent with the Fe-trends in giant planet hosting stars, these results have not been seen despite a variety of studies over the last ~10 years. Additionally, there has not been any detected correlation between stellar abundances and smaller, terrestrial planets. Despite the huge number of exoplanetary detections from the Kepler mission, the traditional radial velocity and transiting detection techniques only utilize the physical properties of the stellar system. Here we take advantage of the host’s stellar abundances in order to statistically examine any possible dependence of the occurrence of exoplanets to the chemistry of the star. We used the Hypatia Catalog [2, 3] as a large sample of non-Fe abundances for stars that do and do not have detected exoplanets. We produced a target list of possible planet-hosting stars that have a high probability of hosting a detectable exoplanet. Hypatia Catalog: The Hypatia Catalog is a database of stellar abundances which includes +65 elements and species within >6000 FGK-stars that are less than 150 pc from the Sun. Hypatia was compiled from over 200 literature sources such that the data were homogenized to the same solar scale. The median value was used during those instances where multiple literature values existed for the same element in the same star. Hypatia currently contains stellar abundances for +300 exoplanet host stars. Supervised Machine Learning: When comparing non-Fe element ratios in stars with and without planets, the standard method has looked at individual elements between the two groups. However, by employing the award-winning supervised machine learning algorithm XGBoost [4], we are able to analyze the elements as an ensemble in a way that is very similar to the Netflix movie recommendation algorithm. For example, after watching a number of movies, Netflix is able to assess that you enjoy a particular genre of movies. It then applies this information to the back catalog of movies that you haven’t watched and makes recommendations, with listed probabilitoes, that you will like the movie.\n",
            "----------------------------------------\n",
            "Title: AMELIORATION OF MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE IN MEDICAL MANAGEMENT (A CASE STUDY ON THE PANDEMIC OF COVID 19 CASES IN ASIA)\n",
            "Abstract: Machine learning is seeing increasingly utilized in medical management for different reasons: tremendous sums of information are being captured and made accessible carefully; handling of vast sums of information has gotten to be cost-effective due to the expanded computing control presently accessible at reasonable costs; and different open source systems, toolkits, and libraries are accessible that can be utilized to construct and execute ML applications. Particularly in healthcare, ML has driven to energizing modern improvements that may rethink COVID-19 treatment and vaccination within a long time to come. With modern occurrences of the brand modern coronavirus clutter, COVID-19, creating day through the day, it is common to compare the unused affliction to other flare-ups in current history. Machine learning can offer assistance to anticipate three sorts of restorative dangers - disease, seriousness, and result. Whereas it is still it is early for COVID-19 with machine learning, but early applications seem promising.  Machine learning is utilized when a computer has been instructed to recognize designs by giving it with information and a calculation to assist get it that information. This method of learning from the information is called training and the yield that we accomplish is through testing. Machine learning-based robotic surgery is changing the way surgery is performed nowadays. Machine learning in healthcare is getting to be more broadly utilized and is making a difference in patients and clinicians in numerous diverse ways. Cybersecurity and protection are major concerns and open challenges in healthcare which are yet to be addressed.\n",
            "----------------------------------------\n",
            "Title: The CLaC Discourse Parser at CoNLL-2016\n",
            "Abstract: This paper describes our submission \"CLaC\" to the CoNLL-2016 shared task on shallow discourse parsing. We used two complementary approaches for the task. A standard machine learning approach for the parsing of explicit relations, and a deep learning approach for non-explicit relations. Overall, our parser achieves an F1-score of 0.2106 on the identification of discourse relations (0.3110 for explicit relations and 0.1219 for non-explicit relations) on the blind CoNLL-2016 test set.\n",
            "----------------------------------------\n",
            "Title: Review on machine and deep learning models for the detection and prediction of Coronavirus\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Spatial localisation and sensing in two dimensions via metasurfaces\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: ANALYSIS OF THE METHODS AND SPECIFIC OF THE FIELD TRIAL DATA DIGITALIZATION AS THE BASIS OF FARMING MANAGEMENT\n",
            "Abstract: The purpose of the study. The topic of crop management, which is largely determined by modern digitalization processes, is relevant and is in the center of attention of both specialists and experts in the field of agriculture and in the field of computer technology, because the production of products of the agricultural sector plays a vital role in the world economy. Considering that traditional field data processing methods are unable to meet the ever-growing needs of agricultural producers at the new stage of agricultural development and are a serious obstacle to obtaining the necessary information, the purpose of the article is to conduct a critical review and analysis of publications on the digitization of field research databases in order to develop and adopt effective management decisions in crop production. Research methods. Research was conducted using generally accepted scientific methods: abstract-logical; analysis and synthesis; induction and deduction; expert evaluations. Research results. The conducted analysis made it possible to determine that the level of development of agricultural enterprises currently largely depends on modern digital technologies, the implementation of which involves a change in the general paradigm of production process management and allows commodity producers to act accordingly to increase production volumes. It has been proven that along with updating the material and technical component, the priority of production is the intellectualization of production and management activities based on digitization. Conclusion. In order to benefit from the ever-increasing amount of data that comes from numerous sources of digital transformation, despite the fact that the vast majority of farmers and agricultural producers are not experts in this field and are unable to fully understand the basic laws of the algorithms being created, the scientific and methodological approach to increase the effectiveness of machine learning for automatic recognition of agricultural crops, detection of diseases and weeds, forecasting of yield and quality of the crop, management of water resources and soil can be useful for agricultural enterprises of many countries of the world. Key words: machine learning, precision farming, productivity, soil conditions, water resources.\n",
            "----------------------------------------\n",
            "Title: Fraud Detection in Banking: A Machine Learning Approach using Credit Card Transaction Data\n",
            "Abstract: Financial fraud poses a significant threat to the banking industry, with fraudsters continually evolving their tactics to exploit vulnerabilities. This paper investigates the efficacy of various machine learning algorithms for fraud detection using the Credit Card Fraud dataset from Kaggle. The paper explores Decision Tree, K-Nearest Neighbors (KNN), Logistic Regression, Support Vector Machine (SVM), Random Forest, and XGBoost algorithms. The study analyzes the performance of these models and discusses their real-time implementation in banking systems. Furthermore, we outline potential future directions to enhance fraud detection capabilities.\n",
            "----------------------------------------\n",
            "Title: Speaking with machines: interacting with bots for language teaching and\n",
            " learning\n",
            "Abstract: This piece explores technologies for freer communication with machines, i.e. bots (chatbots or conversational agents), rather than the concept of speaking to machines, such as Intelligent Assistants (IA) like Alexa. Bots are computer programmes which simulate natural intelligent communication using text or speech technologies. The first chatbot claimed to pass the Turing Test (a test to identify whether a computer is intelligent), ELIZA, was created by Joseph Weizenbaum in 1966 to imitate a psychotherapist. More recently, interest in chatbots appears to have shifted from whether they can be perceived as human to their ability to imitate natural conversations to achieve specific purposes and provide efficient customer services.\n",
            "----------------------------------------\n",
            "Title: A Survey on the Use of Data Points in IDS Research\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Polysaccharides and Composite Adsorbents in the Spotlight for Effective Agrochemical Residue Removal from Water\n",
            "Abstract: Agrochemical residues, including pesticides and herbicides, pose significant environmental and health risks when present in water sources. Conventional water treatment methods often fall short in effectively removing these persistent pollutants, necessitating innovative solutions. This review explores the use of polysaccharides and composite adsorbents as sustainable alternatives for agrochemical residue removal from water. Biopolymers such as chitosan, alginate, and cellulose are highlighted for their biodegradability, biocompatibility, and ability to be functionalized for enhanced adsorption performance. Recent advances in the development of composite materials incorporating nanomaterials, such as graphene, oxide, and metal oxides, have shown significant promise in enhancing the efficiency and selectivity of agrochemical adsorption. The review also addresses the fundamental mechanism of adsorption, such as electrostatic interactions, hydrogen bonding, and hydrophobic forces, that contribute to the effectiveness of these materials. Challenges associated with scalability, regeneration, and real-world applications are discussed, as well as future opportunities for integrating emerging technologies like 3D printing and machine learning into adsorbent design. Overall, polysaccharides and composites offer a promising pathway toward achieving efficient and sustainable agrochemical residue removal, with ongoing research needed to overcome current limitations and optimize their practical application in water treatment.\n",
            "----------------------------------------\n",
            "Title: An investigation on annular cartilage samples for post-mortem interval estimation using Fourier transform infrared spectroscopy\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A novel technique based on the improved firefly algorithm coupled with extreme learning machine (ELM-IFF) for predicting the thermal conductivity of soil\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: DiffPhysiNet: A Bearing Diagnostic Framework Based on Physics-Driven Diffusion Network for Unseen Working Conditions\n",
            "Abstract: Fault diagnosis is essential to ensure bearing safety in industrial applications. Many existing diagnostic methods require large scales of data from a full range of working conditions. However, the structure and working conditions differences between machines lead to significant variation in data distribution, making it difficult to diagnostic with unseen samples. To handle this situation, an unknown condition diagnosis Framework (UCDF) based on physics-driven diffusion network (DiffPhysiNet) is proposed, effectively integrating the generation capability of the diffusion model and learning from the working conditional encoding (WCE). Specifically, signals under limited working conditions are gradually convert to noise through a forward noising process. Then, DiffPhysiNet reconstructs signals from the noise by a reverse denoising process. In addition, a physics-driven UNet (Physi-UNet) structure is designed to extract WCE for noise level prediction during the reverse process. Moreover, an Unsupervised Clustering Filter (UCFilter) is constructed to select signals with high quality after generation. Signals under unknown working condition can be generated with certain WCE. Ultimately, extensive experiments on two bearing datasets (SDUST and PU) validate the effectiveness of our method compared with the state-of-the-art baselines and the ablution test confirms the significant role of Physi-UNet and UCFilter.\n",
            "----------------------------------------\n",
            "Title: Estimating Flyrock Distance Induced Due to Mine Blasting by Extreme Learning Machine Coupled with an Equilibrium Optimizer\n",
            "Abstract: Blasting is essential for breaking hard rock in opencast mines and tunneling projects. It creates an adverse impact on flyrock. Thus, it is essential to forecast flyrock to minimize the environmental effects. The objective of this study is to forecast/estimate the amount of flyrock produced during blasting by applying three creative composite intelligent models: equilibrium optimizer-coupled extreme learning machine (EO-ELM), particle swarm optimization-based extreme learning machine (PSO-ELM), and particle swarm optimization-artificial neural network (PSO-ANN). To obtain a successful conclusion, we considered 114 blasting data parameters consisting of eight inputs (hole diameter, burden, stemming length, rock density, charge-per-meter, powder factor (PF), blastability index (BI), and weathering index), and one output parameter (flyrock distance). We then compared the results of different models using seven different performance indices. Every predictive model accomplished the results comparable with the measured values of flyrock. To show the effectiveness of the developed EO-ELM, the result from each model run 10-times is compared. The average result shows that the EO-ELM model in testing (R2 = 0.97, RMSE = 32.14, MAE = 19.78, MAPE = 20.37, NSE = 0.93, VAF = 93.97, A20 = 0.57) achieved a better performance as compared to the PSO-ANN model (R2 = 0.87, RMSE = 64.44, MAE = 36.02, MAPE = 29.96, NSE = 0.72, VAF = 74.72, A20 = 0.33) and PSO-ELM model (R2 = 0.88, RMSE = 48.55, MAE = 26.97, MAPE = 26.71, NSE = 0.84, VAF = 84.84, A20 = 0.51). Further, a non-parametric test is performed to assess the performance of these three models developed. It shows that the EO-ELM performed better in the prediction of flyrock compared to PSO-ELM and PSO-ANN. We did sensitivity analysis by introducing a new parameter, WI. Input parameters, PF and BI, showed the highest sensitivity with 0.98 each.\n",
            "----------------------------------------\n",
            "Title: Maintaining proper health records improves machine learning predictions for novel 2019-nCoV\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: P10.13.A DEMOCRATIZING QUALITY: A STRATEGY TO MAKE LEVEL OF EVIDENCE ASSESSMENTS QUICK, EASY, AND ACCESSIBLE TO ALL\n",
            "Abstract: \n",
            " \n",
            " \n",
            " Advances in clinical care depend decisively on evidence from high-quality clinical trials. EANO and other international societies have established systematic and transparent methodologies for assessing the quality of clinical trials, but the process is time-consuming and challenging to master. Using advanced computational strategies, we have developed three novel models—an Excel-based calculator, a machine learning (ML) model, and a permutation-based decision tree—designed to facilitate this assessment and make it easily accessible to clinicians and researchers.\n",
            " \n",
            " \n",
            " \n",
            " A PRISMA-compliant literature review was conducted to identify all therapeutic human trials involving adult neuro-oncology patients published in the last 12 months in high-impact journals. Articles fulfilling pre-specified inclusion and exclusion criteria were selected and a level of evidence was assigned independently by two investigators, with differences resolved by consensus. Simultaneously, an advanced ML model was created, employing a Support Vector Machine (SVM) algorithm renowned for its efficacy in classification tasks. The SVM model was configured with a 0.2 train-test split to validate its predictive accuracy and recursive feature elimination to evaluate the significance of input features, confirming their equal importance. Additionally, a permutation-based decision tree was developed, where a collaborative team analyzed all possible permutations of questionnaire responses to assign explicit quality ratings through a data-driven decision framework. Finally, an Excel-based tool was developed to calculate the level of evidence. The results of all four assessment strategies were statistically compared.\n",
            " \n",
            " \n",
            " \n",
            " The ML model was developed and trained on a dataset of 225 categorized research papers and achieved a classification accuracy of 97%. The permutation-based decision tree tool was designed to map all possible questionnaire response permutations to specific trial quality levels, with 11,521 independently graded permutation response pathways. The Excel-based tool was programmed to use a phrase-matching algorithm to identify an evidence level based on a user’s provided answers. The permutation and Excel-based strategies provided excellent classification accuracy but were inferior to the ML model. As we will demonstrate, all three models were easy to use and provided rapid and reliable levels of evidence assessments.\n",
            " \n",
            " \n",
            " \n",
            " By providing open access to these tools to clinicians and researchers and making the level of evidence assessments efficient, consistent, and transparent, we hope to democratize the ability to evaluate published trials, thereby improving the quality of clinical care. We also hope that clinical researchers will utilize these tools to enhance the quality of their clinical trials at the design stage.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Research and Design of a Key Technology for Accelerating Convolution Computation for FPGA-Based CNN\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Investigation and Evaluation of a Zero Input Tracking Analyzer (ZITA)\n",
            "Abstract: Abstract : This study was designed to evaluate a psychomotor testing instrument known as the ZITA (Zero Input Tracking Analyzer). This instrument was being considered as a prediction device in the selection of applicants for the U. S. Navy aircrew training program. Analysis of the data obtained from six subjects (all U. S. Navy pilots) over 26 hours of testing, showed the machine capable of consistent results in distinguishing between subjects with respect to this particular psychomotor task. A major disadvantage of the ZITA that became apparent was the amount of time (approximately 2 hours) required before learning curves were leveled out and the rate at which different individuals develop their learning curve.\n",
            "----------------------------------------\n",
            "Title: The field terrain recognition based on extreme learning machine using wavelet features\n",
            "Abstract: Feature extraction and classification algorithm is important to determine the accuracy of classification. The terrain recognition of a legged robot has higher requirements on real-time classification. Considering the traditional training methods is difficult to meet the requirements, this paper applies the extreme learning machine using wavelet features to terrain recognition. The experimental results show that recognition rate of the extreme learning algorithm is 96.78%, which is 30.89% and 20.45% higher than BP and SVM algorithm respectively. Hence, the proposed method in this paper has obvious advantages over traditional algorithm in parameter selection and learning speed.\n",
            "----------------------------------------\n",
            "Title: Sentinel 3 OLCI and Machine Learning for Cyanobacteria Bloom Detection Over Small Inland Water Target\n",
            "Abstract: High nutrient input agricultural practices and nutrient enrichment have been identified as the main factors driving cyanobacterial harmful algal blooms (cyanoHABs) formation in Uruguay. Current agricultural practices are already inflicting significant harm on aquatic ecosystems and human well-being, with future forecasts indicating a worsening of these trends. Thus, real-time detection of cyanoHABs in inland freshwater ecosystems is imperative for mitigating potential threats. Conventional cyanobacteria detection models often entail intricate procedures, necessitating the integration of biophysical, chemical, or on-site DNA sequencing measurements. Leveraging satellite imagery offers a cost-effective means to pinpoint cyanoHAB occurrences across extensive spatial and temporal scales. Within the European Space Agency's (ESA) satellite fleet, the Sentinel 3 satellites equipped with the Ocean and Land Color Instrument (OLCI) present a notable resource. In this study, we employed the cyanoHAB detection algorithm, Maximum peak-height (MPH), on OLCI data from the Laguna del Sauce lagoon to establish a baseline detection accuracy of 85%. The success of MPH's tree-like algorithm encouraged us to use machine learning classification algorithms based on decision trees to improve detection accuracy. The XGBoost classification model outperformed the other models by achieving an accuracy of 92%.\n",
            "----------------------------------------\n",
            "Title: Data mining Classification Techniques for Intrusion Detection System\n",
            "Abstract: In today’s contemporary era detection of network attacks has become the need of the hour due to increasing network traffic over the network. Data mining technique plays a vital role in searching network attacks and anomalies. These techniques help in selecting and refining useful and relevant information from large data sets. Data mining technique helps in classify relevant data for Intrusion Detection System. Intrusion Detection system generates alarms for the network traffic about the foreign invasions in the system. In the following paper we have used data mining classification techniques for intrusion detection in order to build a safe network. Random tree, Naive Bayes, J48 and Random forest machine learning classifier are used for classification. Comparison based on parameters like data accuracy, finding useful patterns, extracts useful information between the techniques.\n",
            "----------------------------------------\n",
            "Title: Prediction of North Atlantic Oscillation Index with Convolutional LSTM Based on Ensemble Empirical Mode Decomposition\n",
            "Abstract: The North Atlantic Oscillation (NAO) is the most significant mode of the atmosphere in the North Atlantic, and it plays an important role in regulating the local weather and climate and even those of the entire Northern Hemisphere. Therefore, it is vital to predict NAO events. Since the NAO event can be quantified by the NAO index, an effective neural network model EEMD-ConvLSTM, which is based on Convolutional Long Short-Term Memory (ConvLSTM) with Ensemble Empirical Mode Decomposition (EEMD), is proposed for NAO index prediction in this paper. EEMD is applied to preprocess NAO index data, which are issued by the National Oceanic and Atmospheric Administration (NOAA), and NAO index data are decomposed into several Intrinsic Mode Functions (IMFs). After being filtered by the energy threshold, the remaining IMFs are used to reconstruct new NAO index data as the input of ConvLSTM. In order to evaluate the performance of EEMD-ConvLSTM, six methods were selected as the benchmark, which included traditional models, machine learning algorithms, and other deep neural networks. Furthermore, we forecast the NAO index with EEMD-ConvLSTM and the Rolling Forecast (RF) and compared the results with those of Global Forecast System (GFS) and the averaging of 11 Medium Range Forecast (MRF) model ensemble members (ENSM) provided by the NOAA Climate Prediction Center. The experimental results show that EEMD-ConvLSTM not only has the highest reliability from evaluation metrics, but also can better capture the variation trend of the NAO index data.\n",
            "----------------------------------------\n",
            "Title: Usability of Artificial Intelligence in Cyber Security\n",
            "Abstract: The Internet of Things is getting increasingly intelligent and sophisticated. The use of smart devices is rapidly expanding. Artificial intelligence and machine learning are being integrated into IoT applications, resulting in competitive benefits such as increased operational productivity. Large businesses have been purchasing smaller start-ups that have been working at the intersection of artificial intelligence and the Internet of Things over the past decade. In addition, leading IoT service providers are increasingly offering advanced AI features including machine-based learning analytics. We evaluated various papers relevant to the application of artificial intelligence in cyber-security in this report.\n",
            "----------------------------------------\n",
            "Title: Tumor Microenvironment, Radiology, and Artificial Intelligence: Should We Consider Tumor Periphery?\n",
            "Abstract: The tumor microenvironment (TME) consists of cellular and noncellular components which enable the tumor to interact with its surroundings and plays an important role in the tumor progression and how the immune system reacts to the malignancy. In the present study, we investigate the diagnostic potential of the TME in differentiating benign and malignant lesions using image quantification and machine learning.\n",
            "----------------------------------------\n",
            "Title: FLoX: Federated Learning with FaaS at the Edge\n",
            "Abstract: Federated learning (FL) is a technique for distributed machine learning that enables the use of siloed and distributed data. With FL, individual machine learning models are trained separately and then only model parameters (e.g., weights in a neural network) are shared and aggregated to create a global model, allowing data to remain in its original environment. While many applications can benefit from FL, existing frameworks are incomplete, cumbersome, and environment-dependent. To address these issues, we present FLoX, an FL framework built on the funcX federated serverless computing platform. FLoX decouples FL model training/inference from infrastructure management and thus enables users to easily deploy FL models on one or more remote computers with a single line of Python code. We evaluate FLoX using three benchmark datasets deployed on ten heterogeneous and distributed compute endpoints. We show that FLoX incurs minimal overhead, especially with respect to the large communication overheads between endpoints for data transfer. We show how balancing the number of samples and epochs with respect to the capacities of participating endpoints can significantly reduce training time with minimal reduction in accuracy. Finally, we show that global models consistently outperform any single model on average by 8%.\n",
            "----------------------------------------\n",
            "Title: Polygalic acid inhibits african swine fever virus polymerase activity: findings from machine learning and in vitro testing\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Bayesian optimization for materials design\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Nearest Charging Station Identification for EV Using Machine Learning Techniques\n",
            "Abstract: As the call for electric cars (EVs) continues to surge, making sure efficient access to charging infrastructure will become paramount for encouraging their large adoption. The research addresses the urgent undertaking of optimising EV charging infrastructure by means of predicting EV charging requirements and recommending the nearest charging stations based totally on the car's charging functionality. The work goal is to expand a predictive approach that anticipates EV charging requirements and guides users to the most suitable charging stations. The approach utilizes number of object mastering algorithms, which include Decision Tree Regression, K-Nearest Neighbours Regression, and Support Vector Regression, trained on real-local charging station records from Bangalore. These techniques are designed to estimate charging points at various geographic locations, empowering EV customers to make informed choices based on their instant charging requirements. The research demonstrates the software of each set of rules in exactly predicting charging points and identifying the most suitable charging stations. Beyond Bangalore, the proposed technique can be adapted to benefit other cities and regions, contributing to sustainable transportation, and expediting the transition to electric mobility.\n",
            "----------------------------------------\n",
            "Title: Tightening the Evaluation of PAC Bounds Using Formal Verification Results\n",
            "Abstract: Probably Approximately Correct (PAC) bounds are widely used to derive probabilistic guarantees for the generalisation of machine learning models. They highlight the components of the model which contribute to its generalisation capacity. However, current state-of-the-art results are loose in approximating the generalisation capacity of deployed machine learning models. Consequently, while PAC bounds are theoretically useful, their applicability for evaluating a model's generalisation property in a given operational design domain is limited. The underlying classical theory is supported by the idea that bounds can be tightened when the number of test points available to the user to evaluate the model increases. Yet, in the case of neural networks, the number of test points required to obtain bounds of interest is often impractical even for small problems. In this paper, we take the novel approach of using the formal verification of neural systems to inform the evaluation of PAC bounds. Rather than using pointwise information obtained from repeated tests, we use verification results on regions around test points. We show that conditioning existing bounds on verification results leads to a tightening proportional to the underlying probability mass of the verified region.\n",
            "----------------------------------------\n",
            "Title: RakshaNet: URL - Aware Malicious Website Classifier\n",
            "Abstract: Software revolution has resulted in a hyperbolic increase in internet browsing, making internet security a vital issue. Most naive users typically visit unknown websites, and due to their lack of awareness and software proficiency, malicious websites pose a significant threat to their data and security. This paper proposes a classification algorithm that determines whether a website is malicious or benign based on its application layer and network layer features. These features are extracted from the header and body of the HTTP/HTTPS request/response of a website, upon which the ML algorithm acts to determine whether the website is malicious. The client-server data can be intercepted using a proxy service, such as the Squid proxy, and the ML classifier runs as part of the Internet Content Adaptation Protocol (ICAP). If a website is determined as potentially malicious, the user shall be notified immediately and redirected back to the previous benign webpage. The URL parameters extracted include the Server name, DNS query time, TCP details, etc., which are chosen after extensive study of the contribution of these features (importance) to the classification. The study is performed on the decision tree and random forest supervised machine learning algorithms, and it is observed that the random forest algorithm is the most suitable ML classification methodology, achieving a test accuracy of 92%. The classification performance is visualized with the help of the confusion matrix and receiver operating characteristics curve (ROC), with an area under the curve (AUC) of 84%. Thus, this paper proposes an end-to-end software that utilises the random forest algorithm for the classification of websites as malicious or benign, and preempt users from accessing harmful websites.\n",
            "----------------------------------------\n",
            "Title: Efficient and Accurate Simulations of Vibrational and Electronic Spectra with Symmetry-Preserving Neural Network Models for Tensorial Properties.\n",
            "Abstract: Machine learning has revolutionized the high-dimensional representations for molecular properties such as potential energy. However, there are scarce machine learning models targeting tensorial properties, which are rotationally covariant. Here, we propose tensorial neural network (NN) models to learn both tensorial response and transition properties in which atomic coordinate vectors are multiplied with scalar NN outputs or their derivatives to preserve the rotationally covariant symmetry. This strategy keeps structural descriptors symmetry invariant so that the resulting tensorial NN models are as efficient as their scalar counterparts. We validate the performance and universality of this approach by learning response properties of water oligomers and liquid water and transition dipole moment of a model structural unit of proteins. Machine-learned tensorial models have enabled efficient simulations of vibrational spectra of liquid water and ultraviolet spectra of realistic proteins, promising feasible and accurate spectroscopic simulations for biomolecules and materials.\n",
            "----------------------------------------\n",
            "Title: Kernel-based data transformation model for nonlinear classification of symbolic data\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Guarantees for Self-Play in Multiplayer Games via Polymatrix Decomposability\n",
            "Abstract: Self-play is a technique for machine learning in multi-agent systems where a learning algorithm learns by interacting with copies of itself. Self-play is useful for generating large quantities of data for learning, but has the drawback that the agents the learner will face post-training may have dramatically different behavior than the learner came to expect by interacting with itself. For the special case of two-player constant-sum games, self-play that reaches Nash equilibrium is guaranteed to produce strategies that perform well against any post-training opponent; however, no such guarantee exists for multiplayer games. We show that in games that approximately decompose into a set of two-player constant-sum games (called constant-sum polymatrix games) where global $\\epsilon$-Nash equilibria are boundedly far from Nash equilibria in each subgame (called subgame stability), any no-external-regret algorithm that learns by self-play will produce a strategy with bounded vulnerability. For the first time, our results identify a structural property of multiplayer games that enable performance guarantees for the strategies produced by a broad class of self-play algorithms. We demonstrate our findings through experiments on Leduc poker.\n",
            "----------------------------------------\n",
            "Title: Torque ripple reduction in Permanent Magnet Synchronous Machines using angle-based iterative learning control\n",
            "Abstract: Permanent Magnet Synchronous Machines (PMSM) are used in many applications, particularly in high-performance drive systems. However, one inherent problem of PMSM is its parasitic undesired torque ripple, which reduces the PMSM performances. Several kinds of parasitic torque ripples are periodic functions of the rotor position. To reduce them, a method called Iterative Learning Control (ILC) seems well suited, but is efficient for only one constant speed chosen by the designer (and all the integer multiples of this speed). To design a solution for a varying speed, an ILC variant named angle-based ILC is proposed, which no longer uses time as the reference, but the angular position. This angle-based ILC can simply be implemented and does not require a heavy computational load. Simulations of a PMSM variable speed drive system and experiments have been done to assess the performances of the proposed technique.\n",
            "----------------------------------------\n",
            "Title: Combining hypothesis-driven ECG indices with machine learning improves ventricular arrhythmic risk prediction in a low-risk population\n",
            "Abstract: \n",
            " \n",
            " \n",
            " Life-threatening ventricular arrhythmias (LTVA) are a leading cause of mortality, but early identification of high-risk individuals remains a major challenge. An ECG index, TMV (T-wave morphology variations), predicts LTVA in 51,794 individuals without known cardiovascular disease from the UK Biobank (UKB) within a 10-year follow up (cohort 1), with an area under the ROC curve (AUC) of 0.558 and a hazard ratio (HR) of 1.57. Machine learning on the ECG has shown a high accuracy in detecting patients with cardiovascular disease, but its LTVA predictive value in a low-risk population and comparisons with hypothesis-driven risk markers, like TMV, is unknown.\n",
            " \n",
            " \n",
            " \n",
            " We tested the LTVA predictive value of a score combining a multi-layer convolutional neural network (CNN) model and TMV in individuals without known cardiovascular disease.\n",
            " \n",
            " \n",
            " \n",
            " Using UKB we split the individuals from cohort 1 into training (90%) and internal test (10%) sets (Figure 1). In the training set, we applied 10-fold cross validation to train a multi-layer CNN with an attention layer, where the input was a 15-second ECG at rest (lead I), and the output was occurrence (or not) of LTVA within a 10-year follow-up. We used 10-second ECG data (lead I) from an independent cohort of 32,209 individuals without cardiovascular disease from UKB (cohort 2) as an external test set (median follow-up was 3.4 years), where we also calculated TMV. We next combined them into a score (weighted by their relative contribution to LTVA in a logistic regression). The AUC, and Cox regression HRs were calculated to estimate the performance of the CNN, TMV and the combined score.\n",
            " \n",
            " \n",
            " \n",
            " In cohort 1, 217 subjects had a LTVA during the follow-up period. In the internal test set, the AUC of the CNN was 0.707. In the external test set (60 LTVA events during the follow-up period), the CNN’s prediction and TMV led to AUCs of 0.610 and 0.604, respectively. Interestingly, the CNN’s prediction and TMV were not correlated (ρ = 0.005), and the combined score led to an AUC of 0.627. We set a threshold at the score value that maximised sensitivity and specificity, and survival analyses showed a HR of 3.007 (P < 0.0001) for individuals in the score+ (score > threshold) versus those in the score- (score < threshold) group, after adjusting for age and gender (Figure 2). The continuous score also predicted LTVA independently from age and gender.\n",
            " \n",
            " \n",
            " \n",
            " A CNN-based model predicts LTVA in a low-risk population independently from TMV, a strong ECG risk predictor derived from knowledge on the underlying electrophysiology. When TMV and the CNN are combined into a score, the LTVA risk stratification improves, independently from age and gender. Our findings support the combination of hypothesis-based risk markers and CNN approaches to optimise LTVA prediction in a low-risk population.Study designSurvival curves\n",
            "\n",
            "----------------------------------------\n",
            "Title: Combining Long-Term Recurrent Convolutional and Graph Convolutional Networks to Detect Phishing Sites Using URL and HTML\n",
            "Abstract: Phishing, a well-known cyber-attack practice has gained significant research attention in the cyber-security domain for the last two decades due to its dynamic attacking strategies. Although different solutions have been exercised against phishing, phishing attacks have dramatically increased in the past few years. Recent studies have shown that machine learning has become prominent in the present anti-phishing context, and the techniques like deep learning have extensively improved anti-phishing tools’ detection ability. This paper proposes PhishDet, a new way of detecting phishing websites through Long-term Recurrent Convolutional Network and Graph Convolutional Network using URL and HTML features. PhishDet is the first of its kind, which uses the powerful analysis and processing capabilities of Graph Neural Network in the anti-phishing domain and recorded 96.42% detection accuracy, with a 0.036 false-negative rate. It is effective against zero-day attacks, and the average detection time which is 1.8 seconds could also be considered realistic. The feature selection of PhishDet is automatic and occurs inside the system, as PhishDet gradually learns URLs and HTML content features to handle constantly changing phishing attacks. This has outperformed similar solutions by achieving a 99.53% f1-score with a public benchmark dataset. However, PhishDet requires periodic retraining to maintain its performance over time. If such retraining could be facilitated, PhishDet could fight against phishers for a more extended period to safeguard Internet users from this Internet threat.\n",
            "----------------------------------------\n",
            "Title: Review Paper on Facial Expression Based Music Recommendation System\n",
            "Abstract: Music plays an important role in one's life, the tone of music helps to heal the pain and it also helps to enjoy moments. We have different song lists depending upon the mood. But there are no such tools that can be used as an emotion-based music player that detects the emotion of the person and plays music according to the mood. The proposed system is Emotion Based Music Player using Python and Machine Learning.\n",
            "----------------------------------------\n",
            "Title: Assessing the Value of eBay Listing Features\n",
            "Abstract: We used machine learning to access the value of additional features sellers can use to highlight their eBay item listings. The set of features a user can add to their listing includes subtitles, extra photos, a pop up photo view of an item, a ―listing designer‖, and a bold listing of their item in search results. As eBay fixes the costs for these features, we implemented a price-prediction scheme to determine which listing features add most value to an item and identified the relative importance of specific features in price determination. Motivation\n",
            "----------------------------------------\n",
            "Title: Facial Emotion Recognition Using Conventional Machine Learning and Deep Learning Methods: Current Achievements, Analysis and Remaining Challenges\n",
            "Abstract: Facial emotion recognition (FER) is an emerging and significant research area in the pattern recognition domain. In daily life, the role of non-verbal communication is significant, and in overall communication, its involvement is around 55% to 93%. Facial emotion analysis is efficiently used in surveillance videos, expression analysis, gesture recognition, smart homes, computer games, depression treatment, patient monitoring, anxiety, detecting lies, psychoanalysis, paralinguistic communication, detecting operator fatigue and robotics. In this paper, we present a detailed review on FER. The literature is collected from different reputable research published during the current decade. This review is based on conventional machine learning (ML) and various deep learning (DL) approaches. Further, different FER datasets for evaluation metrics that are publicly available are discussed and compared with benchmark results. This paper provides a holistic review of FER using traditional ML and DL methods to highlight the future gap in this domain for new researchers. Finally, this review work is a guidebook and very helpful for young researchers in the FER area, providing a general understating and basic knowledge of the current state-of-the-art methods, and to experienced researchers looking for productive directions for future work.\n",
            "----------------------------------------\n",
            "Title: Hybrid blockchain-enabled secure microservices fabric for decentralized multi-domain avionics systems\n",
            "Abstract: Advancement in artificial intelligence (AI) and machine learning (ML), dynamic data driven application systems (DDDAS), and hierarchical cloud-fog-edge computing paradigm provide opportunities for enhancing multi-domain systems performance. As one example that represents multi-domain scenario, a “fly-by-feel” system utilizes DDDAS framework to support autonomous operations and improve maneuverability, safety and fuel efficiency. The DDDAS “fly-by-feel\" avionics system can enhance multi-domain coordination to support domain specific operations. However, conventional enabling technologies rely on a centralized manner for data aggregation, sharing and security policy enforcement, and it incurs critical issues related to bottleneck of performance, data provenance and consistency. Inspired by the containerized microservices and blockchain technology, this paper introduces BLEM, a hybrid BLockchain-Enabled secure Microservices fabric to support decentralized, secure and efficient data fusion\n",
            "----------------------------------------\n",
            "Title: Artificial Intelligence (AI) Powered Matchmaker: Finding Your Ideal Vendor Every Time\n",
            "Abstract: In today’s fast-paced business environment, the ability to quickly and accurately identify suitable vendors is crucial for maintaining competitive advantage. Traditional vendor selection processes can be time-consuming and prone to errors, leading to suboptimal partnerships. This paper explores an AI-powered approach to vendor matchmaking, leveraging machine learning algorithms and big data analytics to enhance decision-making accuracy and efficiency. The proposed method involves a comprehensive analysis of historical vendor performance data using advanced machine learning models to evaluate vendors based on multiple criteria, including performance history, cost-effectiveness, and compliance with regulatory standards. Tools such as Python for data processing, sci-kit-learn for model development, and Matplotlib for data visualization were utilized. The dataset, spanning five years and including data on over 500 vendors, was sourced from internal business records and external market intelligence. Our findings suggest that AI-powered matchmaking significantly improves the quality of vendor selection, reducing both time and cost while increasing overall satisfaction and performance. The study underscores the transformative potential of AI in streamlining business operations and fostering strategic partnerships.\n",
            "----------------------------------------\n",
            "Title: Enhancing residential demand response through dynamic pricing forecasting\n",
            "Abstract: This study rigorously investigates the impact of demand response mechanisms in daily household operations, leveraging smart devices driven by dynamic pricing. It introduces a machine learning framework tailored for real-time predictive capabilities. The main objective is to enhance user convenience, optimize appliance management, and reduce electricity expenses by analyzing market prices. The focal point lies in monitoring and utilizing essential and non-essential devices, responsive to real-time fluctuations in grid prices throughout the day. This approach involves systematic data collection for training sophisticated models, particularly using Long Short-Term Memory (LSTM) networks. The performance of the adopted machine learning model is validated and evaluated for its ability to regulate device usage in dynamic grid pricing scenarios. Eventually, this study aims to establish a responsive and energy-efficient residential ecosystem, aligning with contemporary demands for sustainable living through cost analysis.\n",
            "----------------------------------------\n",
            "Title: Automatic Detection and Classification of Rock Microstructures through Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A systematic review and meta-analysis of groundwater level forecasting with machine learning techniques: Current status and future directions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Towards the ultimate differential SMEFT analysis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine learning for tackling microbiota data and infection complications in immunocompromised patients with cancer\n",
            "Abstract: In the last two decades, overall cancer survival has improved steadily in most developed countries; however, cancer still constitutes a significant public health problem and is the second leading cause of death worldwide [1]. Infectious complications represent an important cause of morbidity and mortality in patients with cancer, particularly in those with haematological malignancies or in haematopoietic stem cell transplantation recipients [2]. A severely impaired immune function (especially neutropenia) and the disruption of natural anatomical barriers such as the skin and mucosal surfaces, as a result of the intensive cytotoxic chemotherapy and immunosuppressive drugs, facilitate the passage of colonizing bacteria and fungi from the body niches into bloodstream, which ultimately leads to severe infectious complications. Other factors that promote the bloodstream dissemination of pathogens in these patients include the need for prolonged hospitalization, intensive care admission, as well as the extensive use of invasive procedures. The administration of empirical antibiotics has been the standard of care for chemotherapy-treated cancer patients with fever and severe neutropenia since the beginning of the 1960s, when bacterial bloodstream infections emerged as a prominent cause of death in these patients. While this approach has effectively reduced the burden of infection and saved innumerable lives, the use of multiple antibiotics decreases the commensal microbial diversity and consequently results in the profound disruption of the gut microbiota, which further increases the risk of developing bloodstream infections in patients with cancer [2]. Consequently, antibiotics that destroy the gut microbiota deplete the colonization resistance against pathogens and ultimately promote the growth of pathogenic microbial species such as Clostridium difficile (C. difficile), Candida albicans, Pseudomonas aeruginosa and other intestinal pathogens [2]. In addition, the prolonged use of broad-spectrum antibiotics has resulted in the emergence and dissemination of multidrug-resistant (MDR) pathogens, including extended-spectrum beta-lactamase-producing Escherichia coli, methicillin-resistant coagulasenegative staphylococci, vancomycin-resistant enterococci and MDR Pseudomonas aeruginosa [2].\n",
            "----------------------------------------\n",
            "Title: Crops Classification Using Machine Learning And Google Earth Engine\n",
            "Abstract: The primary objective of this study was to address the critical challenge of obtaining accurate information regarding the spatial distribution and classification of crops in agricultural areas. The aim was to enhance agricultural decision-making and management, especially in regions with limited water resources, where crop productivity and sustainability are crucial for achieving food security and sustainable development. To achieve this objective, this study utilized machine-learning classification algorithms in conjunction with Landsat and Sentinel satellite imagery. The classification of different crops was based on Normalized Difference Vegetation Index (NDVI) phenology . The classification process and post-processing were conducted using the Google Earth Engine (GEE) platform , as well as utilizing Python, and scikit-learn library. Ground-truth data provided by local experts, along with the EUROMAP 2018 dataset in South Spain, were used to label the classification results . The findings of this study demonstrated a classification accuracy of 72% for certain crop types, indicating significant implications for sustainable agricultural practices and land use planning.\n",
            "----------------------------------------\n",
            "Title: Computer-Aided Detection (CADe) and Segmentation Methods for Breast Cancer Using Magnetic Resonance Imaging (MRI).\n",
            "Abstract: Breast cancer continues to be a major health concern, and early detection is vital for enhancing survival rates. Magnetic resonance imaging (MRI) is a key tool due to its substantial sensitivity for invasive breast cancers. Computer-aided detection (CADe) systems enhance the effectiveness of MRI by identifying potential lesions, aiding radiologists in focusing on areas of interest, extracting quantitative features, and integrating with computer-aided diagnosis (CADx) pipelines. This review aims to provide a comprehensive overview of the current state of CADe systems in breast MRI, focusing on the technical details of pipelines and segmentation models including classical intensity-based methods, supervised and unsupervised machine learning (ML) approaches, and the latest deep learning (DL) architectures. It highlights recent advancements from traditional algorithms to sophisticated DL models such as U-Nets, emphasizing CADe implementation of multi-parametric MRI acquisitions. Despite these advancements, CADe systems face challenges like variable false-positive and negative rates, complexity in interpreting extensive imaging data, variability in system performance, and lack of large-scale studies and multicentric models, limiting the generalizability and suitability for clinical implementation. Technical issues, including image artefacts and the need for reproducible and explainable detection algorithms, remain significant hurdles. Future directions emphasize developing more robust and generalizable algorithms, integrating explainable AI to improve transparency and trust among clinicians, developing multi-purpose AI systems, and incorporating large language models to enhance diagnostic reporting and patient management. Additionally, efforts to standardize and streamline MRI protocols aim to increase accessibility and reduce costs, optimizing the use of CADe systems in clinical practice. LEVEL OF EVIDENCE: NA TECHNICAL EFFICACY: Stage 2.\n",
            "----------------------------------------\n",
            "Title: Analysis of the Composition of Ancient Glass and Its Identification Based on the Daen-LR, ARIMA-LSTM and MLR Combined Process\n",
            "Abstract: The glass relics are precious material evidence of the early trade and cultural exchange between the East and the West. To explore the cultural differences and trade development between early China and foreign countries, it is extremely important to classify glass cultural relics. Despite their similar appearances, Chinese glass contains more lead, while foreign glass contains more potassium. In view of this, this paper proposes a joint Daen-LR, ARIMA-LSTM, and MLR machine learning algorithm (JMLA) for the analysis and identification of the chemical composition of ancient glass. We separate the sampling points of ancient glass into two systems: lead-barium glass and high-potassium glass. Firstly, an improved logistic regression model based on a double adaptive elastic network (Daen-LR) is used to select variables with both Oracle and adaptive classification characteristics. Secondly, the ARIMA-LSTM model was used to establish the correlation curve of chemical composition before and after weathering and to predict the change in chemical composition with weathering. Thirdly, combining the data processed by the above two methods, a multiple linear regression model (MLR) is used to classify unknown glass products. It was shown that the sample obtained by this processing method has a very good fit. In comparison with other similar types of models like Decision Trees (DT), Random Forests (RF), Support Vector Machines (SVM), and Random Forests based on classification and regression trees (CART-RF), the classification accuracy of JMLA is 97.9% on the train set. The accuracy rate on the test set reached 97.6%. The results of the research demonstrate that JMLA can improve the accuracy of the glass type classification problem, greatly enhance the research efficiency of archaeological staff, and gain a more reliable result.\n",
            "----------------------------------------\n",
            "Title: Towards Inherently Interpretable Machine Learning for Healthcare\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Thermomechanical Properties of Transition Metal Dichalcogenides Predicted by a Machine Learning Parameterized Force Field.\n",
            "Abstract: The mechanical and thermal properties of transition metal dichalcogenides (TMDs) are directly relevant to their applications in electronics, thermoelectric devices, and heat management systems. In this study, we use a machine learning (ML) approach to parametrize molecular dynamics (MD) force fields to predict the mechanical and thermal transport properties of a library of monolayered TMDs (MoS2, MoTe2, WSe2, WS2, and ReS2). The ML-trained force fields were then employed in equilibrium MD simulations to calculate the lattice thermal conductivities of the foregoing TMDs and to investigate how they are affected by small and large mechanical strains. Furthermore, using nonequilibrium MD, we studied thermal transport across grain boundaries. The presented approach provides a fast albeit accurate methodology to compute both mechanical and thermal properties of TMDs, especially for relatively large systems and spatially complex structures, where density functional theory computational cost is prohibitive.\n",
            "----------------------------------------\n",
            "Title: A Resource Utilization Prediction Model for Cloud Data Centers Using Evolutionary Algorithms and Machine Learning Techniques\n",
            "Abstract: Cloud computing has revolutionized the modes of computing. With huge success and diverse benefits, the paradigm faces several challenges as well. Power consumption, dynamic resource scaling, and over- and under-provisioning issues are challenges for the cloud computing paradigm. The research has been carried out in cloud computing for resource utilization prediction to overcome over- and under-provisioning issues. Over-provisioning of resources consumes more energy and leads to high costs. However, under-provisioning induces Service Level Agreement (SLA) violation and Quality of Service (QoS) degradation. Most of the existing mechanisms focus on single resource utilization prediction, such as memory, CPU, storage, network, or servers allocated to cloud applications but overlook the correlation among resources. This research focuses on multi-resource utilization prediction using Functional Link Neural Network (FLNN) with hybrid Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The proposed technique is evaluated on Google cluster traces data. Experimental results show that the proposed model yields better accuracy as compared to traditional techniques.\n",
            "----------------------------------------\n",
            "Title: Chemistry-informed machine learning: Using chemical property features to improve gas classification performance\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Transfer Learning for sEMG-based Hand Gesture Classification using Deep Learning in a Master- Slave Architecture\n",
            "Abstract: Recent advancements in diagnostic learning and development of gesture-based human machine interfaces have driven surface electromyography (sEMG) towards significant importance. Analysis of hand gestures requires an accurate assessment of sEMG signals. The proposed work presents a novel sequential master-slave architecture consisting of deep neural networks (DNNs) for classification of signs from the Indian sign language using signals recorded from multiple sEMG channels. The performance of the master-slave network is augmented by leveraging additional synthetic feature data generated by long short term memory networks. Performance of the proposed network is compared to that of a conventional DNN prior to and after the addition of synthetic data. Up to 14% improvement is observed in the conventional DNN and up to 9% improvement in master-slave network on addition of synthetic data with an average accuracy value of 93.5% asserting the suitability of the proposed approach.\n",
            "----------------------------------------\n",
            "Title: Legal Issues of Copyright Objects Processing by AI Systems in the Process of Machine Learning\n",
            "Abstract: The research paper analyses the legal aspects of copyright objects processing by AI systems, including the legality of automated analysis of text and data in digital form — TDM (text and data mining) and machine learning. The research paper examines: the grounds for qualifying such processing as copyright infringement and certain obstacles to the full protection of copyright (including Big Data, being a subject of processing by AI systems). The paper proposes the adoption of certain public law principles of copyright objects processing by artificial intelligent systems, in particular: the principle of limited purpose, according to which the processing of works should be carried out exclusively for the purposes established by the operator of the artificial intellectual system; the principle of limited storage, which involves storing personal data (in a form accessible to identify the subjects of this data) no longer than required in-order to achieve the stated processing purposes; the principle of transparent reporting — reporting on the quantity and quality of processed data sets, accessible to any person, regardless of interest.\n",
            "----------------------------------------\n",
            "Title: A Novel Context-Sensitive SVM for Classification of Remote Sensing Images\n",
            "Abstract: In this paper, a novel context-sensitive classification technique based on Support Vector Machines (CS-SVM) is proposed. This technique aims at exploiting the promising SVM method for classification of 2-D (or n-D) scenes by considering the spatial-context information of the pixel to be analyzed. In greater detail, the proposed architecture properly exploits the spatial-context information for: i) increasing the robustness of the learning procedure of SVMs to the noise present in the training set (mislabeled training samples); ii) regularizing the classification maps. The first property is achieved by introducing a context-sensitive term in the objective function to be minimized for defining the decision hyperplane in the SVM kernel space. The second property is obtained including in the classification procedure of a generic pattern the information of neighboring pixels. Experiments carried out on very high geometrical resolution images confirm the validity of the proposed technique.\n",
            "----------------------------------------\n",
            "Title: Tensor Networks for Dimensionality Reduction and Large-scale Optimization: Part 1 Low-Rank Tensor Decompositions\n",
            "Abstract: Modern applications in engineering and data science are increasinglybased on multidimensional data of exceedingly high volume, variety,and structural richness. However, standard machine learning algorithmstypically scale exponentially with data volume and complexityof cross-modal couplings - the so called curse of dimensionality -which is prohibitive to the analysis of large-scale, multi-modal andmulti-relational datasets. Given that such data are often efficientlyrepresented as multiway arrays or tensors, it is therefore timely andvaluable for the multidisciplinary machine learning and data analyticcommunities to review low-rank tensor decompositions and tensor networksas emerging tools for dimensionality reduction and large scaleoptimization problems. Our particular emphasis is on elucidating that,by virtue of the underlying low-rank approximations, tensor networkshave the ability to alleviate the curse of dimensionality in a numberof applied areas. In Part 1 of this monograph we provide innovativesolutions to low-rank tensor network decompositions and easy to interpretgraphical representations of the mathematical operations ontensor networks. Such a conceptual insight allows for seamless migrationof ideas from the flat-view matrices to tensor network operationsand vice versa, and provides a platform for further developments, practicalapplications, and non-Euclidean extensions. It also permits theintroduction of various tensor network operations without an explicitnotion of mathematical expressions, which may be beneficial for manyresearch communities that do not directly rely on multilinear algebra.Our focus is on the Tucker and tensor train TT decompositions andtheir extensions, and on demonstrating the ability of tensor networksto provide linearly or even super-linearly e.g., logarithmically scalablesolutions, as illustrated in detail in Part 2 of this monograph.\n",
            "----------------------------------------\n",
            "Title: Comparison on Image to Image Translation Algorithms\n",
            "Abstract: Image to image translation(I2I) is one of the important parts in computer vision area. It includes lots of applications in this time. GAN provides basic theory for this problem which is an advanced method of machine learning area. The structure of GAN contains two main parts: Generator and Discriminator. This new method developed the performance of I2I problem. In this paper, five papers of I2I area using GAN method have been summarized including a paper about cGAN and a paper about cycle GAN. The rest three paper is about unsupervised learning. These five papers used different method based on GAN algorithm and can be used on different problems. Finally, there are still some problems cannot be solved in this area, this paper also discuss which problem could be development in the future.\n",
            "----------------------------------------\n",
            "Title: Machine learning based canine posture estimation using inertial data\n",
            "Abstract: The aim of this study was to design a new canine posture estimation system specifically for working dogs. The system was composed of Inertial Measurement Units (IMUs) that are commercially available, and a supervised learning algorithm which was developed for different behaviours. Three IMUs, each containing a 3-axis accelerometer, gyroscope, and magnetometer, were attached to the dogs’ chest, back, and neck. To build and test the model, data were collected during a video-recorded behaviour test where the trainee assistance dogs performed static postures (standing, sitting, lying down) and dynamic activities (walking, body shake). Advanced feature extraction techniques were employed for the first time in this field, including statistical, temporal, and spectral methods. The most important features for posture prediction were chosen using Select K Best with ANOVA F-value. The individual contributions of each IMU, sensor, and feature type were analysed using Select K Best scores and Random Forest feature importance. Results showed that the back and chest IMUs were more important than the neck IMU, and the accelerometers were more important than the gyroscopes. The addition of IMUs to the chest and back of dog harnesses is recommended to improve performance. Additionally, statistical and temporal feature domains were more important than spectral feature domains. Three novel cascade arrangements of Random Forest and Isolation Forest were fitted to the dataset. The best classifier achieved an f1-macro of 0.83 and an f1-weighted of 0.90 for the prediction of the five postures, demonstrating a better performance than previous studies. These results were attributed to the data collection methodology (number of subjects and observations, multiple IMUs, use of common working dog breeds) and novel machine learning techniques (advanced feature extraction, feature selection and modelling arrangements) employed. The dataset and code used are publicly available on Mendeley Data and GitHub, respectively.\n",
            "----------------------------------------\n",
            "Title: Neural networks empowered: a machine learning-enabled, Gyro mmID for enhanced virtual reality and motion tracking applications\n",
            "Abstract: \n",
            " With the emerging developments in millimeter-wave/5G technologies, the potential for wireless Internet of things devices to achieve widespread sensing, precise localization, and high data-rate communication systems becomes increasingly viable. The surge in interest surrounding virtual reality (VR) and augmented reality (AR) technologies is attributed to the vast array of applications they enable, ranging from surgical training to motion capture and daily interactions in VR spaces. To further elevate the user experience, and real-time and accurate orientation detection of the user, the authors proposes the utilization of a frequency-modulated continuous-wave (FMCW) radar system coupled with an ultra-low-power, sticker-like millimeter-wave identification (mmID). The mmID features four backscattering elements, multiplexed in amplitude, frequency, and spatial domains. This design utilizes the training of a supervised learning classification convolutional neural network, enabling accurate real-time three-axis orientation detection of the user. The proposed orientation detection system exhibits exceptional performance, achieving a noteworthy accuracy of 90.58% over three axes at a distance of 8 m. This high accuracy underscores the precision of the orientation detection system, particularly tailored for medium-range VR/AR applications. The integration of the FMCW-based mmID system with machine learning proves to be a promising advancement, contributing to the seamless and immersive interaction within virtual and augmented environments.\n",
            "----------------------------------------\n",
            "Title: Human activity classification using simulated micro-Dopplers and time-frequency analysis in conjunction with machine learning algorithm\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine learning approach to gait deviation prediction based on isokinetic data acquired from biometric sensors.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Financial Distress Prediction Based on Multiple Feature Subsets Ensembles\n",
            "Abstract: In order to predict financial distress effectively,This paper constructs base classifiers by integrating multiple learning algorithms such as support vector machine,multi-discriminant analysis,Logistic regression,and CART with multiple feature selection methods including t test,one way ANOVA,stepwise discriminant analysis,stepwise Logistic regression and neighborhood rough sets.And then it proposes a multiple feature subsets ensembles,which select its base classifiers using an accuracy-guided forward search and post-pruning strategy.This method does not need to calculate the diversity among the base classifiers. Firstly it implements the forward search based on the principle of maximizing the system prediction accuracy,and then chooses the combing system with the highest accuracy or a satisfied one as the final result.Using Chinese listed companies' real data as our sample data and 10 fold Cross-Validation as an assessment,an empirical study is carried out.By comparing the experiment result with the individual best base classifier and within its inside components,it indicates that this method can improve the prediction accuracy significantly and provide more flexibility to financial distress prediction.\n",
            "----------------------------------------\n",
            "Title: Validating an iOS-based Rhythmic Auditory Cueing Evaluation (iRACE) for Parkinson's Disease\n",
            "Abstract: Movement disorders such as Parkinson's disease (PD) will affect a rapidly growing segment of the population as society continues to age. Rhythmic Auditory Cueing (RAC) is a well-supported evidence-based intervention for the treatment of gait impairments in PD. RAC interventions have not been widely adopted, however, due to limitations in access to personnel, technological, and financial resources. To help \"scale up\" RAC for wider distribution, we have developed an iOS-based Rhythmic Auditory Cueing Evaluation (iRACE) mobile application to deliver RAC and assess motor performance in PD patients. The touchscreen of the mobile device is used to assess motor timing during index finger tapping, and the device's built-in tri-axial accelerometer and gyroscope to assess step time and step length during walking. Novel machine learning-based gait analysis algorithms have been developed for iRACE, including heel strike detection, step length quantification, and left-versus-right foot identification. The concurrent validity of iRACE was assessed using a clinic-standard instrumented walking mat and a pair of force-sensing resistor sensors. Results from 10 PD patients reveal that iRACE has low error rates (<±1.0%) across a set of four clinically relevant outcome measures, indicating a potentially useful clinical tool.\n",
            "----------------------------------------\n",
            "Title: Towards efﬁcient Bayesian Optimization for Big Data\n",
            "Abstract: We present a new Bayesian optimization method, environmental entropy search (EnvES), suited for optimizing the hyperparameters of machine learning algorithms on large datasets. EnvES executes fast algorithm runs on subsets of the data and probabilistically extrapolates their performance to reason about performance on the entire dataset. It considers the dataset size as an additional degree of freedom to choose freely at each step of the optimization, and sets it adaptively to trade off expected information gain about the location of the best conﬁgura-tion vs. expected time spent. We empirically evaluate EnvES for optimizing the hyperparameters of a support vector machine, showing that extrapolating performance from small to large datasets can yield a considerable speedup over standard Bayesian optimization methods.\n",
            "----------------------------------------\n",
            "Title: Cervical Cancer Diagnostics Healthcare System Using Hybrid Object Detection Adversarial Networks\n",
            "Abstract: Cervical cancer is one of the common cancers among women and it causes significant mortality in many developing countries. Diagnosis of cervical lesions is done using pap smear test or visual inspection using acetic acid (staining). Digital colposcopy, an inexpensive methodology, provides painless and efficient screening results. Therefore, automating cervical cancer screening using colposcopy images will be highly useful in saving many lives. Nowadays, many automation techniques using computer vision and machine learning in cervical screening gained attention, paving the way for diagnosing cervical cancer. However, most of the methods rely entirely on the annotation of cervical spotting and segmentation. This paper aims to introduce the Faster Small-Object Detection Neural Networks (FSOD-GAN) to address the cervical screening and diagnosis of cervical cancer and the type of cancer using digital colposcopy images. The proposed approach automatically detects the cervical spot using Faster Region-Based Convolutional Neural Network (FR-CNN) and performs the hierarchical multiclass classification of three types of cervical cancer lesions. Experimentation was done with colposcopy data collected from available open sources consisting of 1,993 patients with three cervical categories, and the proposed approach shows 99% accuracy in diagnosing the stages of cervical cancer.\n",
            "----------------------------------------\n",
            "Title: Cognitive spectrum sensing algorithm based on an RBF neural network and machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Analysis of Final Ratings in Tourism Using Various Machine Learning Techniques\n",
            "Abstract: Abstract: User-generated ratings are a tremendous asset to product descriptions and significantly impact decision-making in Context-Aware Recommender Systems. Researchers exploit this information to predict user preferences, model the item's attributes, and offer intelligible recommendations. However, not all contextual ratings are significant because they may be posted by various users for various reasons and based on different routines. Further, as users care about different attributes of multiple contexts, not all user ratings equally reflect the users' opinion of the overall rating, a primary concern in recommender systems. This article predicts the overall rating using user-user and item collaborative filtering with significant contexts and the outcome tested on various machine and deep learning models using the contextual segments.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Techniques for Network-based Intrusion Detection System: A Survey Paper\n",
            "Abstract: The rapid growth of Internet technologies and further dependence on online services, increase the demand for keeping these networks and data secure. The protection of online information is becoming even more vital to the national security and economic stability. Recently, network security has become one of the most concerning subjects in the current research and industry fields. Intrusion Detection Systems (IDSs) are considered as the backbone for network and data protection. Throughout time, different IDS approaches have been implemented to attain maximum detection accuracy. Machine learning IDS is one of the promising IDS techniques that have been created to detect known as well as unknown attacks. This paper investigates various machine learning techniques used to deploy Network-based Intrusion Detection System (NIDS). This survey could provide a more robust understanding of the existing techniques and assists intrigued researchers to identify research opportunities and investigate more in this direction.\n",
            "----------------------------------------\n",
            "Title: A Novel Framework for High-category Coverage Clothing Recommendation System Based on Sentiment Analysis\n",
            "Abstract: Users are always accustomed to checking others' reviews to determine if the product meets their expectations before purchasing clothing online. Sentiment analysis (SA) technology can effectively identify emotional feedback from numerous reviews and help users and manufacturers accurately identify product defects. However, traditional SA techniques, such as sentiment lexicons and machine learning, have limitations when dealing with large-scale datasets, it is challenging to identify clothing defects or provide extensive category recommendations accurately on high-category coverage clothing. To address this issue, this study proposes a new framework for a fine-grained feature-level SA-based high-category coverage clothing recommendation system (HCCRS). We constructed a dataset containing 82,832 clothing reviews and extracted nine clothing features that users are concerned about from questionnaires and the BERT model. We designed a hybrid SA method combining BERT and SentiStrength and built a relationship model based on feature weights and sentiment scores. The experiment results show that our method outperforms traditional lexicon-based methods by 10-25% and improves by 3% compared to BERT alone. HCCRS introduces a personalized and more authentic approach, offering a fresh perspective for clothing recommendation researchers and practitioners.\n",
            "----------------------------------------\n",
            "Title: A Comprehensive Study of Blockchain for Federated Learning Toward Safe Distributed Machine Learning Systems\n",
            "Abstract: Individuals have the ability to reveal the necessary data by using federated learning (FL), which is a possible decentralized method to deep learning. FL is in the process of rewriting the industrial paradigms that are now used for mathematical modelling and analysis in order to make it possible for an expanding range of industries to construct distributed machine learning models that are secure and safeguard users' privacy. However, when put into reality, FL’s core traits have led to problems such as insufficient protection of users' privacy, high communication costs, varied system architectures, and unreliable model uploads. In contrast to the widespread notion, adding Blockchain technology offers the FL the opportunity to significantly improve both its performance and its level of security, in addition to expanding the applications for which it may be used. is what we refer to as this hybrid form that combines elements of the block chain and FL. This article provides a comprehensive look into BCFL and discusses the implications that may be drawn from this innovative research paradigm. To begin, we will provide a brief overview of the FL technology and then discuss the challenges that it now confronts. After that, a brief summary of the Blockchain ecosystem is provided. After that, the platform as well as the structural design of BCFL are emphasized. We also examine the efforts being made to enhance the performance of FL by using Blockchain technology, as well as numerous implementations of FL incentive systems that have been integrated. In this section, we will summarize the BCFL industrial application scenarios.\n",
            "----------------------------------------\n",
            "Title: MANAGEMENT OF COMPLEX OBJECTS IN CONDITIONS OF UNCERTAINTY OF INFORMATION IN THE REGIONAL AND SECTORAL ASPECT\n",
            "Abstract: Making managerial decisions in conditions of uncertain reliability, quality and analytical significance of information is almost an everyday task for any analyst tasked with determining the future decision- making corridor. In most classifications, uncertainty is divided into informational and situational. Effective decision-making in an environment with an unobvious further outcome, which in practice happens extremely rarely, cannot be carried out without the use of special methods of expert assessments, modern technologies for systematization and data processing, as well as the latest methods of machine learning, due to the extreme complexity and complexity of modern operating environments of economic entities.\n",
            "----------------------------------------\n",
            "Title: Data Normalisation using Differential Evolution and Aggregated Logistic Functions\n",
            "Abstract: Can evolutionary algorithms discover transformation functions capable of normalising arbitrary data? Many statistical and machine learning techniques that input data is normally distributed. However, in most realistic situations the data is distinctly non-normal. Therefore predictive performance may be compromised if steps are not taken to address this issue. We propose in this paper a new algorithm in which differential evolution is used to optimise the multiple parameters of a complex data transformation function. In order to optimise the transformation function, differential evolution is guided by a statistic used to measure the normality of the resulting output data. A set of soft constraints for controlling the scale and position of the output distribution are also included. On a set of fifteen datasets which includes a mixture of artificial data drawn from various different non-normal distributions; blood glucose level data from patients with diabetes; and gene expression data; our method is shown to effectively normalise the data in most cases.\n",
            "----------------------------------------\n",
            "Title: Innovations in News Media: Crisis Classification System\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Image Generation Estimation & Analysis under Gaussian And Poisson Noise Environment Using Machine Learning\n",
            "Abstract: : In this paper we are generating the image of numbers from one to five and predicting these numbers using machine learning tool. After predicting the or estimating the number we have choose second number and add the Gaussian noise in that number with two different amounts i.e. 5%, and 50 %.We have seen the effect of noise on the number image. The same experiment was repeated with the Poisson noise environment. Finally we compare between the images affected by Gaussian and Poisson noise.\n",
            "----------------------------------------\n",
            "Title: Harnessing the power of artificial intelligence: A new door for quick surgery in Pakistan.\n",
            "Abstract: Artificial intelligence (AI) has the potential to transform surgery in Pakistan, improving results, reducing complications, and increasing patient safety. Deep learning, a branch of machine learning, can assist surgeons in making wise judgments. Pubmed and Research Gate discuss the promise of AI in surgery. Incorporating AI in healthcare systems can expedite diagnosis and management while avoiding injudicious resource allocation.\n",
            "AI-based techniques in cardiology, nephrology, and neurology enable high-accuracy detection of cardiovascular disease risks, kidney disease treatment, and epileptic episode identification. Neurological devices like bispectral index monitor (BIS) and Near-infrared spectroscopy (NIRS) utilize advanced technology for reliable monitoring and objective diagnosis of neurological issues (Ahmed, 2022). AI uses electronic data and neural network methods to evaluate operating room logistics, time management, and anesthesiologist activities using electronic data and neural network methods (Khan F. H., 2019). AI algorithms are effectively detect minute differences for accurate diagnosis, with studies showing high specificity, sensitivity, and inter-operator repeatability. AI can be used to train and assess neurosurgical residents and early mid-career surgeons, improving diagnosis and 3D simulation labs (Shlobin, 2022). Surgeons play a crucial role in adopting AI-based technologies for surgical care by partnering with data scientists to capture novel clinical data and generate meaningful interpretations. They should demand transparency and interpretability in algorithms to hold AI accountable for its predictions and recommendations.AI advancements in plastic surgery practice, research, and education offer opportunities for improvement. Combining AI-enabled decision-making tools with predictive analytics and human intuition, surgeons can make real-time decisions based on 3D planning, anatomical localization, and navigation (Rasteau, 2022). While current AI tools cannot perform complex surgical procedures, advancements may enable them to perform more complex tasks in the future.\n",
            "Pakistan is a significant market for AI-based solutions, utilizing technology in various industries to address challenges and boost demand. The country has enhanced its self-security systems, including AI-powered missiles, cyber security, and effective cameras (Khan, 2022). AI allows tasks to be completed more precisely and efficiently, with machine learning and deep learning being advanced subtypes. In developing countries like Pakistan, AI tools are needed for patient-centred diagnosis and treatment assistance, especially in emergency surgery such as cardiac illnesses or life threatening bleeding caused road traffic accident. Hence insuring patient receive care timely. An appropriate budget should be allocated for AI technologies in the health sector.\n",
            "----------------------------------------\n",
            "Title: Classifying different movement of human body based on EEG data using Machine Learning Algorithms.\n",
            "Abstract: v\n",
            "----------------------------------------\n",
            "Title: Books Received Since January 1, 1994\n",
            "Abstract: Computational Learning Theory and Natural Learning Systems: Vol. 1. Constraints and Prospects, ed. by S.J. Hanson, G.A. Drastal, and R.L. Rivest. Cambridge, MA: MIT Press, 1994.565 pp. + xii. Paper, $49.95. Vol. 2. Intersections Between Theory and Experiment, ed. by S.J. Hanson, T. Petsche, M. Keams, and R.L. Rivest. Cambridge, MA: MIT Press, 1994. 449 pp. + xxiii. Paper, $49.95. The state of the learning field: computational learning theory, neural networks, and symbolic machine learning.\n",
            "----------------------------------------\n",
            "Title: Machine learning and pharmacophore‐based prediction of allosteric modulators of Nicotinic acetylcholine receptors\n",
            "Abstract: Nicotinic acetylcholine receptors are important members of the ligand‐gated ion channel family.\n",
            "----------------------------------------\n",
            "Title: Enhancing Privacy in Federated Learning: A Practical Assessment of Combined PETs in a Cross-Silo Setting\n",
            "Abstract: Federated Learning (FL) has emerged as a revolutionary machine learning setting to enable collaborative training in a privacy-preserving way. However, recent research has showcased significant privacy attacks that pose a serious threat to the proliferation of FL as a technology designed to safeguard privacy during training with sensitive data from multiple entities. The rapid evolution of Privacy Enhancing Technologies offers promising methods for securing data inputs and outputs in FL scenarios. This paper evaluates and benchmarks the practical application of two PET methods, which has been integrated within a custom-built FL platform. The work conducts a comparative analysis of several privacy techniques applied to Federated Learning scenarios, with a primary focus on computational and communication performance.\n",
            "----------------------------------------\n",
            "Title: Malware Propagation on Social Time Varying Networks: A Comparative Study of Machine Learning Frameworks\n",
            "Abstract: Significant research into the logarithmic analysis of complex networks yields solution to help minimize virus spread and propagation over networks. This task of virus propagation is been a recurring subject, and design of complex models will yield modeling solutions used in a number of events not limited to and include propagation, dataflow, network immunization, resource management, service distribution, adoption of viral marketing etc. Stochastic models are successfully used to predict the virus propagation processes and its effects on networks. The study employs SI-models for independent cascade and the dynamic models with Enron dataset (of e-mail addresses) and presents comparative result using varied machine models. Study samples 25,000 emails of Enron dataset with Entropy and Information Gain computed to address issues of blocking targeting and extent of virus spread on graphs. Study addressed the problem of the expected spread immunization and the expected epidemic spread minimization; but not the epidemic threshold (for space constraint).\n",
            "----------------------------------------\n",
            "Title: Prediction of Body Weight by Using PCA-Supported Gradient Boosting and Random Forest Algorithms in Water Buffaloes (Bubalus bubalis) Reared in South-Eastern Mexico\n",
            "Abstract: Simple Summary Accurately estimating body weight is crucial for managing water buffalo health and optimizing feeding strategies. This study explored the effectiveness of machine learning models in predicting body weight based on body measurements. Principal component analysis was employed to reduce the dimensionality of the data and identify the most relevant features. Subsequently, Gradient Boosting and Random Forest algorithms were utilized to predict body weight using the reduced data set. The Gradient Boosting algorithm demonstrated superior performance compared to the Random Forest algorithm. These findings suggest that the combination of principal component analysis and Gradient Boosting offers a reliable and effective method for estimating body weight in water buffaloes. This approach holds promise for improving animal production and health management practices. Future research could focus on enhancing the applicability and generalizability of these models to diverse water buffalo populations across various geographical regions. Abstract This study aims to use advanced machine learning techniques supported by Principal Component Analysis (PCA) to estimate body weight (BW) in buffalos raised in southeastern Mexico and compare their performance. The first stage of the current study consists of body measurements and the process of determining the most informative variables using PCA, a dimension reduction method. This process reduces the data size by eliminating the complex structure of the model and provides a faster and more effective learning process. As a second stage, two separate prediction models were developed with Gradient Boosting and Random Forest algorithms, using the principal components obtained from the data set reduced by PCA. The performances of both models were compared using R2, RMSE and MAE metrics, and showed that the Gradient Boosting model achieved a better prediction performance with a higher R2 value and lower error rates than the Random Forest model. In conclusion, PCA-supported modeling applications can provide more reliable results, and the Gradient Boosting algorithm is superior to Random Forest in this context. The current study demonstrates the potential use of machine learning approaches in estimating body weight in water buffalos, and will support sustainable animal husbandry by contributing to decision making processes in the field of animal science.\n",
            "----------------------------------------\n",
            "Title: Integrated Calibration of Simulation Models for Autonomous Space Habitat Operations\n",
            "Abstract: Space habitats for exploration beyond low earth orbit need to provide the crew with enhanced capabilities for earth-independent operations. Mission control has traditionally been the main decision maker in anomaly response procedures, but this role will be limited in deep space due to increased communication delays. Digital simulation models are used by ground control for troubleshooting tasks and are likely to be essential assets for the crew to test \"what-if\" scenarios when important faults are detected onboard. Migrating models from mission control to a space habitat is however challenging as these models are typically heterogeneous and rely on the knowledge of sub-system specialists to be operated. Efforts have been made to automate the integration of multiple simulation models, but their calibration, i.e., the assignment of model parameters that best represent the system behavior, typically remains expert-driven and focused on individual models. To alleviate this reliance on experts and facilitate integration without human intervention, we propose leveraging the interpretable representation ability of probabilistic graphical models to encode dependencies between simulation models at the time of calibration. In this mathematical abstraction, nodes represent random variables, and edges embed causal relationships as conditional probability distributions. We build a graphical model hierarchically with a first layer of nodes representing subsystem states, and a second layer for the simulation model parameters, e.g., a set of possible slopes and intercepts of a regression model. The two layers are mapped probabilistically using domain knowledge from sub-system specialists thereby enabling the migration of reasoning capabilities from mission control to a space habitat. The created network is used to infer the most likely set of simulation parameters given the believed system state which is derived from a diagnosis module. We study the proposed mechanism by implementing it in a docking scenario. In this scenario, the crew of an incoming vehicle is performing a system readiness check before docking to a space station. An algorithm detects a CO2 removal fault, and we perform calibration accordingly using a graphical model. Three types of simulation models are being integrated via calibration, namely: (i) machine learning models trained on empirical data from a testbed of the ISS Carbon Dioxide Removal Assembly, (ii) physics-based models that were designed for this same testbed and (iii) knowledge-based models derived from NASA’s flight rules on admissible CO2 concentrations in a space habitat. We explore a method to implement such a graphical model that consists of (i) selecting a subset of system states as degrees of faulty behaviors, (ii) identifying their dependencies, i.e., defining the likelihood of cascading fault symptoms across subsystems, and (iii) selecting the simulation models that are expected to provide the most insight onboard and which can be parameterized given the network of system states established in the previous two steps. Our study reveals challenges that are to be solved for implementing this graphical model-based calibration. Specifically, it identifies a need to formalize the creation of the network for the subsystem states and to assess how to leverage existing standards for simulation model interfaces.\n",
            "----------------------------------------\n",
            "Title: Predicting pain among female survivors of recent interpersonal violence: A proof-of-concept machine-learning approach\n",
            "Abstract: Interpersonal violence (IPV) is highly prevalent in the United States and is a major public health problem. The emergence and/or worsening of chronic pain are known sequelae of IPV; however, not all those who experience IPV develop chronic pain. To mitigate its development, it is critical to identify the factors that are associated with increased risk of pain after IPV. This proof-of-concept study used machine-learning strategies to predict pain severity and interference in 47 young women, ages 18 to 30, who experienced an incident of IPV (i.e., physical and/or sexual assault) within three months of their baseline assessment. Young women are more likely than men to experience IPV and to subsequently develop posttraumatic stress disorder (PTSD) and chronic pain. Women completed a comprehensive assessment of theory-driven cognitive and neurobiological predictors of pain severity and pain-related interference (e.g., pain, coping, disability, psychiatric diagnosis/symptoms, PTSD/trauma, executive function, neuroendocrine, and physiological stress response). Gradient boosting machine models were used to predict symptoms of pain severity and pain-related interference across time (Baseline, 1-,3-,6- follow-up assessments). Models showed excellent predictive performance for pain severity and adequate predictive performance for pain-related interference. This proof-of-concept study suggests that machine-learning approaches are a useful tool for identifying predictors of pain development in survivors of recent IPV. Baseline measures of pain, family life impairment, neuropsychological function, and trauma history were of greatest importance in predicting pain and pain-related interference across a 6-month follow-up period. Present findings support the use of machine-learning techniques in larger studies of post-IPV pain development and highlight theory-driven predictors that could inform the development of targeted early intervention programs. However, these results should be replicated in a larger dataset with lower levels of missing data.\n",
            "----------------------------------------\n",
            "Title: Reference evapotranspiration estimation using machine learning approaches for arid and semi-arid regions of India\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A New Approach for Classifier Model Selection and Tuning Using Logistic Regression and Genetic Algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: GNNExplainer: Generating Explanations for Graph Neural Networks\n",
            "Abstract: Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GnnExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GnnExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GnnExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GnnExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0% in explanation accuracy. GnnExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.\n",
            "----------------------------------------\n",
            "Title: Exposure to Spoken Communication During the COVID-19 Pandemic Among Children With Cochlear Implants\n",
            "Abstract: Key Points Question Did decreases in exposure to spoken communication, found in the early stages of the COVID-19 pandemic among children using cochlear implants, resolve as lockdowns became more intermittent in later pandemic stages? Findings In this cohort study, sound environments cataloged using machine learning for cochlear implants were measured by 2746 datalogs for 262 children using cochlear implants before and during 2 years of COVID-19 lockdowns in Ontario, Canada. Due to school closures during lockdowns, school-aged children experienced significantly decreased exposure to spoken language, which has not recovered to the prepandemic baseline. Meaning This study suggests that school closures due to COVID-19 lockdowns are associated with reduced exposure to spoken communications among children using cochlear implants during sensitive periods of development.\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Prediction Model for Immediate Graft Function After Deceased Donor Kidney Transplantation\n",
            "Abstract: Background. After kidney transplantation (KTx), the graft can evolve from excellent immediate graft function (IGF) to total absence of function requiring dialysis. Recipients with IGF do not seem to benefit from using machine perfusion, an expensive procedure, in the long term when compared with cold storage. This study proposes to develop a prediction model for IGF in KTx deceased donor patients using machine learning algorithms. Methods. Unsensitized recipients who received their first KTx deceased donor between January 1, 2010, and December 31, 2019, were classified according to the conduct of renal function after transplantation. Variables related to the donor, recipient, kidney preservation, and immunology were used. The patients were randomly divided into 2 groups: 70% were assigned to the training and 30% to the test group. Popular machine learning algorithms were used: eXtreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine, Gradient Boosting classifier, Logistic Regression, CatBoost classifier, AdaBoost classifier, and Random Forest classifier. Comparative performance analysis on the test dataset was performed using the results of the AUC values, sensitivity, specificity, positive predictive value, negative predictive value, and F1 score. Results. Of the 859 patients, 21.7% (n = 186) had IGF. The best predictive performance resulted from the eXtreme Gradient Boosting model (AUC, 0.78; 95% CI, 0.71–0.84; sensitivity, 0.64; specificity, 0.78). Five variables with the highest predictive value were identified. Conclusions. Our results indicated the possibility of creating a model for the prediction of IGF, enhancing the selection of patients who would benefit from an expensive treatment, as in the case of machine perfusion preservation.\n",
            "----------------------------------------\n",
            "Title: Modeling human behavior at a large scale\n",
            "Abstract: Until recently, complex phenomena—such as human behavior and disease epidemics—have been modeled primarily at an aggregate level. Detailed studies have been limited to small domains encompassing only a few subjects, as scaling the methods involved poses considerable challenges in terms of cost, human effort required, computational bottlenecks, and data sources available. With the surge of online social media and sensor networks, the abundance of interesting and publicly accessible data is beginning to increase. However, we also need the ability to reason about it efficiently. The underlying theme of this thesis is the unification and data mining of diverse, noisy, and incomplete sensory data over large numbers of individuals. We show that the mined patterns can be leveraged in predictive models of human behavior and other phenomena at a large scale. We find that raw sensory data linked with the content of users' online communication, the explicit as well as the implicit online social interactions, and interpersonal relationships are rich information sources upon which strong machine learning models can be built. Example domains where such models apply include understanding human activities, predicting people's location and social ties from their online behavior, and predicting the emergence of global epidemics from day-to-day interpersonal interactions.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Techniques Associated With Infrared Thermography to Optimize the Diagnosis of Bovine Subclinical Mastitis\n",
            "Abstract: Bovine subclinical mastitis (SCM) is the costliest disease for the dairy industry. Technologies aimed at the early diagnosis of this condition, such as infrared thermography (IRT), can be used to generate large amounts of data that provide valuable information when analyzed using learning techniques. The objective of this study was to evaluate and optimize the use of machine learning by applying the Extreme Gradient Boosting (XGBoost) algorithm in the diagnosis of bovine SCM, based on udder thermogram analysis. Over 14 months, a total of 1035 milk samples were collected from 97 dairy cows subjected to an automatic milking system. Somatic cell counts were performed by flow cytometry, and the health status of the mammary gland was determined based on a cutoff of 200,000 cells/mL of milk. The attributes analyzed collectively included air temperature, relative humidity, temperature‐humidity index, breed, body temperature, teat dirtiness score, parity, days in milk, mammary gland position, milk yield, electrical conductivity, milk fat, coldest and hottest points in the mammary gland region of interest, average mammary gland temperature, thermal amplitude, and the difference between the average temperature of the region of interest and the animal’s body temperature, as well as the microbiological evaluation of the milk. Using the XGBoost algorithm, the most relevant variables for solving the classification problem were identified and selected to construct the final model with the best fit and performance. The best area under the receiver operating characteristic curve (AUC: 0.843) and specificity (Sp: 93.3%) were obtained when using all thermographic variables. The coldest point in the region of interest was considered the most important for decision making in mastitis diagnosis. The use of XGBoost can enhance the diagnostic capability for SCM when IRT is employed. The developed optimized model can be used as a confirmatory mechanism for SCM.\n",
            "----------------------------------------\n",
            "Title: Self-Organizing Maps Fusion: An Approach to Different Size Maps\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Examining the radius valley: a machine-learning approach\n",
            "Abstract: \n",
            " The ‘radius valley’ is a relative dearth of planets between two potential populations of exoplanets, super-Earths and mini-Neptunes. This feature appears in examining the distribution of planetary radii, but has only ever been characterized on small samples. The valley could be a result of photoevaporation, which has been predicted in numerous theoretical models, or a result of other processes. Here, we investigate the relationship between planetary radius and orbital period through two-dimensional kernel density estimator and various clustering methods, using all known super-Earths (R < 4.0RE). With our larger sample, we confirm the radius valley and characterize it as a power law. Using a variety of methods, we find a range of slopes that are consistent with each other and distinctly negative. We average over these results and find the slope to be $m=-0.319^{+0.088}_{-0.116}$. We repeat our analysis on samples from previous studies. For all methods we use, the resulting line has a negative slope, which is consistent with models of photoevaporation and core-powered mass-loss but inconsistent with planets forming in a gas-poor disc\n",
            "----------------------------------------\n",
            "Title: Distributed Programming Frameworks in Cloud Platforms\n",
            "Abstract: : Cloud computing technology has enabled storage and analysis of large volumes of data or big data. With cloud computing, a new discipline in computer science known as Data Science came into existence. Data Science is an interdisciplinary field which includes statistics, machine learning, predictive analytics and deep learning. It is meant for extracting hidden patterns from big data. Since big data consumes more storage space that cannot be accommodated with traditional storage devices, cloud computing resources of Infrastructure as a Service (IaaS) is used. Therefore, big data and big data analytics cannot exist without cloud computing. Another important fact is that big data can be subjected to analytics for obtaining Business Intelligence (BI). This process needs distributed programming frameworks like Hadoop, Apache Spark, Apache Flink, Apache Storm and Apache Samza. Without thorough understanding about these frameworks that run in cloud platforms, it is difficult to use them appropriately. Therefore, this paper throws light into a comparative study of these frameworks and evaluation of Apache Flink and Apache Spark with an empirical study. TeraSort benchmark is used for experiments.\n",
            "----------------------------------------\n",
            "Title: Transductive Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Predictive Factors for High Post-void Residual Volume in Older Females After OnabotulinumA Treatment for Severe Overactive Bladder Using a Machine Learning Model\n",
            "Abstract: Introduction Intravesical onabotulinumA injection is actively used for the treatment of overactive bladder (OAB). However, it occasionally results in significant post-void residual urine (PVR) volume, which can lead to complications and can further impair the activities of daily living in older people. Therefore, this study aimed to identify the predictors of a high post-onabotulinumA injection PVR volume in older women with severe OAB. Methods An observational study was conducted on older women who had previously received intravesical onabotulinumA injections to treat OAB between 2020 and 2022. Urodynamic studies and symptom assessments were conducted, and machine learning models, including random forest and support vector machine (SVM) models, were developed using the R code generated by Chat Generative Pre-trained Transformer 4 (ChatGPT, OpenAI, San Francisco, USA). Results Among 128 patients with OAB, 23 (18.0%) had a PVR volume of > 200 mL after receiving onabotulinumA injections. The factors associated with a PVR volume of > 200 mL were investigated using univariate and multivariate analyses. Age, frailty, OAB-wet, daytime frequency, and nocturia were significant predictors. Random forest analysis highlighted daytime frequency, frailty, and voiding efficiency as important factors. An SVM model incorporating daytime frequency, frailty, and voiding efficiency improved PVR volume prediction. Logit(p) estimation yielded an area under the receiver operating characteristic curve of 0.926294. Conclusion The study found daytime frequency, frailty, and voiding inefficiency to be significant factors associated with a PVR volume of > 200 mL, in older women with severe OAB. Utilizing advanced machine learning techniques and following the guidance of ChatGPT, this research emphasizes the relevance of considering multiple intersecting factors for predicting PVR volume. The findings contribute to our understanding of onabotulinumA injection treatment for OAB and support evidence-based decision-making using readily available information.\n",
            "----------------------------------------\n",
            "Title: Synaptic Learning of Long-Term Cognitive Networks with Inputs\n",
            "Abstract: In contrast with the extense variety of machine learning algorithms, to fully automate the reasoning process, only a few can take advantage of the expert knowledge. Fuzzy Cognitive Maps (FCMs) are neural networks that can naturally integrate this kind of knowledge in the inference process. Nevertheless, FCMs have serious drawbacks difficult to overcome from the absence of an intrinsically learning algorithm or limited prediction horizon of the activation space of the neurons. Recently, some variants of the FCMs like Short-Term Cognitive Networks (STCN) and Long Term Cognitive Networks (LTCN) have been proposed to solve these problems. In this paper, we propose a new neural network model as a variant of LTCNs called Long-Term Cognitive Networks with Inputs (LTCNIs). A new kind of input neuron which is not present in the traditional FCMs approach or the derived algorithms STCNs and LTCNs is introduced, in order to model inputs like energy or mass in physical systems. The performance of the method is discussed through the modeling of a passive circuit problem. As a second contribution, a new flexible reasoning strategy, which preserves the expert knowledge through synaptic learning is presented. A synaptic learning based on a gradient descent method is implemented limited by a set of restrictions that preserves the model semantics.\n",
            "----------------------------------------\n",
            "Title: A Hybrid Model for Medical Data Using Machine Learning Approaches\n",
            "Abstract: — Clustering is the process of grouping data into clusters, where objects within each cluster have high similarity, but are dissimilar to the objects in other clusters. The K-means algorithm is used for clustering large sets of data. The accuracy of the K-Means depends upon the selection of Centroids. The execution of the standard K-Means algorithm need to reassign the data points a number of times, during every iteration of the loop. The hybrid approach that includes both K-Means algorithm and genetic algorithm yields good result in the process of clustering. In this study, we proposed an implementation of genetic algorithm which we investigate the quality of clustering technique compared with standard K-Means clustering algorithm using the Medical data set.\n",
            "----------------------------------------\n",
            "Title: Deep Learning in Medical Research\n",
            "Abstract: Deep Learning proposed by Hinton[1] is a new learning algorithm of multi-layer neural network and is a type of machine learning . Deep Learning helps researchers analyze medical data to treat disease. It also helps in diagnosis of disease in early stages like cancer, Alzheimer’s disease and so on. This paper analyzes research directions and future prospects of Deep Learning in medical field which help patients to enhance quality of life. Also ease doctors to make strong predictions on basis of datasets previewed.\n",
            "----------------------------------------\n",
            "Title: Performance Evaluation of Predictive Machine Learning Models for Diabetic Disease Using Python\n",
            "Abstract: The discovery of knowledge from medical database is always beneficial as well as challenging task for diagnosis. For example, patients having high blood glucose are required to diagnose as they fall within a group of Diabetes mellitus. Prediction of diabetes mellitus is an essential research in the domain of medical industry. With the advent of artificial intelligence and machine learning this type of prediction removes the hurdles faced in data mining used for similar task. In case of data mining, extraction of knowledge from information stored in database takes place and an understandable description of patterns is achieved. A large number of researches have been already taken place to predict diabetes using traditional machine learning algorithm such as artificial neural network, Naïve Bayes theorem, decision tree, etc. However, determination of diabetes with a certain degree of confidence is required from the accuracy or any other performance measures point of view. In this context, this research work presents machine learning models such as decision tree, support vector machine, random forest, k-nearest neighbours and Naïve-Bayes as classifier to classify whether a patient is diabetic or prone to diabetic. Performance measures of these algorithms have been carried out in terms of accuracy score. Dataset for training and testing the algorithms mentioned is retrieved from Pima Indian Database. On the basis of their comparative evaluation, most important feature with respect to identification of diabetic is extracted. A complete python code has been developed for this research work.\n",
            "----------------------------------------\n",
            "Title: IDRMutPred: predicting disease-associated germline nonsynonymous single nucleotide variants (nsSNVs) in intrinsically disordered regions\n",
            "Abstract: Abstract Motivation Despite of the lack of folded structure, intrinsically disordered regions (IDRs) of proteins play versatile roles in various biological processes, and many nonsynonymous single nucleotide variants (nsSNVs) in IDRs are associated with human diseases. The continuous accumulation of nsSNVs resulted from the wide application of NGS has driven the development of disease-association prediction methods for decades. However, their performance on nsSNVs in IDRs remains inferior, possibly due to the domination of nsSNVs from structured regions in training data. Therefore, it is highly demanding to build a disease-association predictor specifically for nsSNVs in IDRs with better performance. Results We present IDRMutPred, a machine learning-based tool specifically for predicting disease-associated germline nsSNVs in IDRs. Based on 17 selected optimal features that are extracted from sequence alignments, protein annotations, hydrophobicity indices and disorder scores, IDRMutPred was trained using three ensemble learning algorithms on the training dataset containing only IDR nsSNVs. The evaluation on the two testing datasets shows that all the three prediction models outperform 17 other popular general predictors significantly, achieving the ACC between 0.856 and 0.868 and MCC between 0.713 and 0.737. IDRMutPred will prioritize disease-associated IDR germline nsSNVs more reliably than general predictors. Availability and implementation The software is freely available at http://www.wdspdb.com/IDRMutPred. Supplementary information Supplementary data are available at Bioinformatics online.\n",
            "----------------------------------------\n",
            "Title: A Survey of Privacy Attacks in Machine Learning\n",
            "Abstract: As machine learning becomes more widely used, the need to study its implications in security and privacy becomes more urgent. Although the body of work in privacy has been steadily growing over the past few years, research on the privacy aspects of machine learning has received less focus than the security aspects. Our contribution in this research is an analysis of more than 45 papers related to privacy attacks against machine learning that have been published during the past seven years. We propose an attack taxonomy, together with a threat model that allows the categorization of different attacks based on the adversarial knowledge, and the assets under attack. An initial exploration of the causes of privacy leaks is presented, as well as a detailed analysis of the different attacks. Finally, we present an overview of the most commonly proposed defenses and a discussion of the open problems and future directions identified during our analysis.\n",
            "----------------------------------------\n",
            "Title: Machine learning-based image analysis for PM2.5 measurement\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Optimum Maintenance Strategy of a Repairable System Under Long-Term Free Preventive Maintenance Warranty with Predicted Maintenance\n",
            "Abstract: In this paper, the optimum user’s maintenance strategy of a repairable system for free preventive maintenance (PM) warranty policy is proposed. This study considers predicted maintenance due to the system failure is likely occurring and requires repair during periodic maintenance time. Periodic maintenance can be classified as one of three types — imperfect PM, perfect PM and predicted maintenance. The probability that periodic maintenance is perfect PM or predicted maintenance depends on the number of imperfect maintenance operations conducted since the previous renewal cycle. The sellers offer free perfect and imperfect PM warranty. An optimal periodic maintenance time is determined by minimizing the total cost. Some special cases, implemented with machine learning and human learning, are given to demonstrate the feasibility of the proposed strategy. A numerical example is given.\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning to Demystify Startups Funding, Post-Money Valuation, and Success\n",
            "Abstract: This chapter develops a novel approach to predict post-money valuation of startups across various regions and sectors, as well as their probabilities of success. Using startup funding data and descriptions from Crunchbase over a ten-year period, we develop two models linking information such as description, region, and venture capital funding to successful outcomes such as the achievement of an acquisition or IPO. The first model utilizes latent Dirichlet allocation, a generative statistical model in natural language processing, to organize the startups in the dataset into clusters representing various sectors in the typical economy. An optimized distributed gradient boosting regressor (XGBoost) is subsequently deployed to make use of the resultant feature set to predict post-money valuation, with Bayesian optimization used to find the optimal hyperparameters. Our model consistently achieves an accuracy of over 95% on hold-out test sets, even with some continuous features removed. The second model is a feed-forward neural network constructed using TensorFlow, with the final layer providing probabilities of success.We find that post-money valuations across regions are typically log-normally distributed, and startups in regions such as San Francisco Bay Area typically witness higher valuations across most sectors. We also find that startups operating in specific geographical regions and sectors of economy (e.g., regions and sectors with higher number of investors) typically have higher predicted probabilities of success. Our approach offers an empirical perspective to startups, policymakers, and venture funds to benchmark and predict valuation and success, clearing some opacity in the modern startup economy.\n",
            "----------------------------------------\n",
            "Title: Achieving Technological Equity and Equal Access to the Learning Tools of the 21st Century\n",
            "Abstract: Is there a problem of technology equity in our schools? Just ask the kids and teachers who use it. Even better, ask those who can't access it enough or at all. Technology's new tools are seen as empowering, productive and motivational. They make learning fun; more importantly, they let the user both access and create new realms of knowing and doing. But there simply aren't enough of these learning tools to go around, and many learners are being denied access. School decision-makers are aware of the critical need for broader technology access. Parents, too, recognize the importance and, those who can, provide it at home. Employers tell us that nearly all workers entering the job market in this next century need to have an expanded set of technical skills in communication, problem-solving and production. Productivity and profit will both be linked to workers' effective uses of new technologies. Many high school graduates can't compete for entry-level technical jobs. Once hired, they're unable to progress to more responsible, remunerative levels of their chosen professions. Inequities of class, gender, ethnicity and economic disparity correlate highly with denied or restricted access to the tools of technology. The have-nots have increasingly less. When it comes to gaining greater access, many groups and classes are simply unable. The resources are just not there. Futurists tell us that tomorrow's workers who want to stay employed, or be re-employed, will need the skill of learning new skills. Technology will be the common link among most of tomorrow's jobs. Our growth as a national power has depended largely on the expertise of our workers. If our schools fail to pass on these new skills, there may not be another opportunity. Inequity of access to today's new tools becomes tomorrow's enduring societal loss. The State of Technology Students don't have to share pencils. Most teachers even have their own overhead projectors, and certainly their own chalkboards. But when it comes to technology, there clearly isn't enough to go around. Yes, it does cost a lot more than paper and pencils: camcorders and computers are hundreds to thousands of dollars apiece. Most schools don't have the funds to address the issue of adequate access, let alone equity. In Minnesota's Saint Paul Public Schools, there are 13 students to each computer. That's not quite as attractive as our state average of about 10:1 and the national ratio of 11:1. Ratios vary considerably among the 16,000 school districts and, taken alone, don't tell us much about equity of usage, anyway. Many of our district's computers are older, less-powerful machines without high-resolution color, CD-ROMs or Internet access. We need to remind ourselves, too, that there's more to technology tools than computers. Video tools are smaller and more powerful. New camcorders are hand-held and with editing features formerly found only on more expensive equipment. We find technology permeating new areas, enriching music, art and industrial/vocational education. But, it's not just the number of tools we make available, the number of new features makes a difference, too. Newer technologies are functionally different than a decade ago. We see far more powerful tools, which let us move from thinking to doing, to modifying, to creating. Knowledge and information are made more accessible to both learners and teachers. Special needs students are also major beneficiaries of these new tools. For the first time, technology makes learning accessible to many challenged students. While a convenience for some learners, technology can be an absolute necessity for others. Instead of adapting our needs to technology, these new tools are better able to adapt to us and our unique learning needs. Equity Issues A recent search disclosed few current articles on the topic of equity and technology. However, Neuman's 1991 article[1] was helpful in clarifying who are the technology \"have-nots. …\n",
            "----------------------------------------\n",
            "Title: Positioning for conceptual development using latent semantic analysis Conference or Workshop Item\n",
            "Abstract: With increasing opportunities to learn online, the problem of positioning learners in an educational network of content offers new possibilities for the utilisation of geometry-based natural language processing techniques. In this article, the adoption of latent semantic analysis (LSA) for guiding learners in their conceptual development is investigated. We propose five new algorithmic derivations of LSA and test their validity for positioning in an experiment in order to draw back conclusions on the suitability of machine learning from previously accredited evidence. Special attention is thereby directed towards the role of distractors and the calculation of thresholds when using similarities as a proxy for assessing conceptual closeness. Results indicate that learning improves positioning. Distractors are of low value and seem to be replaceable by generic noise to improve threshold calculation. Furthermore, new ways to flexibly calculate thresholds could be identified.\n",
            "----------------------------------------\n",
            "Title: Use of machine learning to identify relevant research publications in clinical oncology.\n",
            "Abstract: 6558 Background: Finding high-quality science to support decisions for individual patients is challenging. Common approaches to assess clinical literature quality and relevance rely on bibliometrics or expert knowledge. We describe a method to automatically identify clinically relevant, high-quality scientific citations using abstract content. Methods: We used machine learning trained on text from PubMed papers cited in 3 expert resources: NCCN, NCI-PDQ, and Hemonc.org. Balanced training data included text cited in at least two sources to form an “on topic” set (i.e., relevant and high quality), and an “off-topic” set, not cited in any of the above 3 sources. The off-topic set was published in lower ranked journals, using a citation-based score. Articles were part of an Oncology Clinical Trial corpus generated using a standard PubMed query. We used a gradient boosted-tree approach with a binary logistic supervised learning classification. Briefly, 988 texts were processed to produce a term frequency-inverse document frequency (tf-idf) n-gram representation of both the training and the test set (70/30 split). Ideal parameters were determined using 1000-fold cross validation. Results: Our model classified papers in the test set with 0.93 accuracy (95% CI (0.09:0.96) p ≤ 0.0001), with sensitivity 0.95 and specificity 0.91. Some false positives contained language considered clinically relevant that may have been missed or not yet included in expert resources. False negatives revealed a potential bias towards chemotherapy-focused research over radiation therapy or surgical approaches. Conclusions: Machine learning can be used to automatically identify relevant clinical publications from biographic databases, without relying on expert curation or bibliometric methods. The use of machine learning to identify relevant publications may reduce the time clinicians spend finding pertinent evidence for a patient. This approach is generalizable to cases where a corpus of high-quality publications that can serve as a training set exists or cases where document metadata is unreliable, as is the case of “grey” literature within oncology and beyond to other diseases. Future work will extend this approach and may integrate it into oncology clinical decision-support tools.\n",
            "----------------------------------------\n",
            "Title: Learning Expressive Models of Gene Regulation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Review of Metaheuristic Optimization for Network Traffic Management in Telecommunications\n",
            "Abstract: This review aims to identify metaheuristic optimization and machine learning in the context of network management in the current era and some graphs of real network applications, such as traffic prediction, resource assignment, and network protection. Bio-inspired meta-functions, which model heuristic approaches to problem-solving in nature, have been shown to provide the best solutions to the OP problem and possess properties that make them ideal for optimizing dynamic networks. In the same vein, neural networks and reinforcement learning models have also performed significantly better in optimizing network performance by providing precise forecasts and decision-making adaptabilities. Incorporating these methodologies into folded working models has facilitated the development of solutions for the more complicated new networks such as SDNs, MANETs and IoTs. This review consolidates the most recent work in this field while identifying new advances as revolutionary technologies for refining the next-generation networks; it discusses possible paths for future research to overcome the existing drawbacks.\n",
            "----------------------------------------\n",
            "Title: Efficient Model Quality Evaluation in Federated Learning via Functional Encryption\n",
            "Abstract: Federated Learning(FL) is a distributed machine learning paradigm that exchanges data among multiple parties without directly sharing the original data. However, FL faces the inherent issue of statistical heterogeneity. Recently, some privacy preserving federated learning scheme have considered this issue. But they use homomorphic encryption, which imposes significant computational and communication overhead on the clients. To address this issue, we propose an efficient model quality evaluation scheme in FL via functional encryption. Specifically, we first use inner product functional encryption(IPFE) to efficiently and securely calculate the cosine similarity between global update and each local update on the server, then use clustering algorithm to assign weights to each client based on cosine similarity, and finally update the global model through weighted aggregation. Experimental results show that compared with other model quality evaluation scheme, our approach increases the computational efficiency by up to 25% and reduces communication cost by up to 70%.\n",
            "----------------------------------------\n",
            "Title: FedACA: An Adaptive Communication-Efficient Asynchronous Framework for Federated Learning\n",
            "Abstract: Federated Learning (FL) is a type of distributed machine learning, which avoids sharing privacy and sensitive data with a central server. Despite the advances in FL, current approaches cannot provide satisfactory performance when dealing with heterogeneity in data and unpredictability of system devices. First, straggler devices can adversely impact convergence speed of the global model training. Second, for model aggregation in traditional FL, edge devices communicate frequently with a central server using their local updates. However, this process may encounter communication bottleneck caused by substantial bandwidth usage. To address these challenges, this paper presents an adaptive, communication-efficient and asynchronous FL technique called FedACA comprising feedback loops at two levels. Our approach contains a self-adjusting local training step with active participant selection to accelerate the convergence of the global model. To reduce the communication overhead, FedACA supports an adaptive uploading policy at the edge devices, which leverages the model similarity and L2-norm differences between the current and previous local gradient. It also utilizes contrastive learning to tackle data heterogeneity by regularizing the local training if the local model has deviated from the global model and helps with the model similarity measurement in the uploading policy. Extensive experiments on a benchmark comprising three image datasets with non-independent and identically distributed (non-i.i.d) data show that FedACA adapts well to the straggler effect in asynchronous environments and also provides significant reductions in communication costs compared to other state-of-the-art FL algorithms.\n",
            "----------------------------------------\n",
            "Title: Enhancing Named Entity Recognition in Twitter Messages Using Entity Linking\n",
            "Abstract: In this paper, we describe our approach for Named Entity Recognition in Twitter, a shared task for ACL 2015 Workshop on Noisy User-generated Text (Baldwin et al., 2015). Because of the noisy, short, and colloquial nature of Twitter, the performance of Named Entity Recognition (NER) degrades significantly. To address this problem, we propose a novel method to enhance the performance of the Twitter NER task by using Entity Linking which is a method for detecting entity mentions in text and resolving them to corresponding entries in knowledge bases such as Wikipedia. Our method is based on supervised machine-learning and uses the highquality knowledge obtained from several open knowledge bases. In comparison with the other systems proposed for this shared task, our method achieved the best performance.\n",
            "----------------------------------------\n",
            "Title: Combining machine and deep transfer learning for mediastinal lymph node evaluation in patients with lung cancer\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine Learning from Noisy Information\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Proceedings of the 20th ACM international conference on Multimedia\n",
            "Abstract: We are delighted to welcome you to 20th ACM International Conference on Multimedia, ACM Multimedia 2012, which is held from October 29th to November 2nd, 2012 in Nara, Japan. Welcome to Japan's ancient capital, the cradle of Japanese culture and final destination of the Silk Road. \n",
            " \n",
            "Like the Silk Road of ancient times, multimedia today provides a medium allowing the diverse exchange of ideas across many fields including signal processing, information retrieval, machine learning, content analysis, networking, applications, human-centered systems, art and education and many more. Because of this confluence, multimedia has become one of the fastest growing and most interesting areas in Computer Science. It is again in 2012 that Nara, Japan is a final destination, this time for sharing ideas in multimedia. ACM Multimedia is the premier conference and worldwide event bringing together multimedia experts and practitioners across academia and industry. The central feature of the conference, which continues this year as in every year since its inception, is the outstanding Technical Program. This year's conference features both oral and poster presentations covering all aspects of the multimedia field chosen through a highly selective review process. Notably, this year's conference includes special Technical Program activities recognizing the 20th anniversary of ACM Multimedia. \n",
            " \n",
            "In addition to the Technical Program, this year's conference features a diverse range of activities including Panels, Demonstrations and Tutorials. Additionally, a wide array of Workshops brings focus on new topics for investigation. The conference features also special sessions on Brave New Ideas, a Grand Challenge contest and Open Source Software Competition and includes a Doctoral Symposium for mentoring graduate students. Finally, the conference provides a rich Multimedia Art Exhibition to stimulate artists and researchers alike to meet and discover the frontiers of multimedia artistic communication! \n",
            " \n",
            "The 20th Anniversary Keynote Talk and 20th Anniversary Panel This year celebrates the 20th Anniversary of ACM Multimedia, which was first initiated by the ACM SIGMM in 1993. To mark this auspicious occasion, the conference features a 20th Anniversary Keynote Talk and a 20th Anniversary Panel. These two events reflect on major milestones and achievements in multimedia as well as discuss promising ideas and directions for the future. \n",
            " \n",
            "Innovations for this Year's Conference: In attempt to continuously improve ACM Multimedia and ensure its vibrant role for the multimedia community, we have made a number of enhancements for this year's conference: \n",
            "The Technical Program Committee defined eleven Technical Areas for major focus for this year's conference, including introducing new Technical Areas for Multimedia Activity and Event Understanding and Social Media to reflect their growing interest and promise. \n",
            "Technical Short Papers are presented as plenary posters to make them more visible at this year's conference, which reflects the growing quality of short papers. \n",
            "Plenary sessions bring singular focus to conference activities in the morning sessions each day, and afternoon sessions are held in parallel to allow pursuit of more specialized interests at the conference. \n",
            "Workshops and Tutorials are held on separate days from the main conference in order to reduce conflict with the regular Technical Program. \n",
            "Since Workshops are important seeds for the next generation of multimedia, two complementary workshop registrations are provided for invited talks of each workshop to encourage participation of notable speakers. \n",
            "The Multimedia Art Exhibition features both invited and selected artists and is open for two weeks in the satellite venue close to the main conference with good public access, which allows stimulation broadly to visitors to Nara. \n",
            "nFollowing the last year's precedent, Tutorials are made free for all participants. \n",
            "Recognizing that students are the lifeblood of our next generation of multimedia thinkers, this year's Student Travel Grant is greatly expanded.\n",
            "----------------------------------------\n",
            "Title: Automatic assessment of students' software models using a simple heuristic and machine learning\n",
            "Abstract: Software models are increasingly popular. To educate the next generation of software engineers, it is important that they learn how to model software systems well, so that they can design them effectively in industry. It is also important that instructors have the tools that can help them assess students' models more effectively. In this paper, we investigate how a tool that combines a simple heuristic with machine learning techniques can be used to help assess student submissions in model-driven engineering courses. We apply our proposed technique to first identify submissions of high quality and second to predict approximate letter grades. The results are comparable to human grading and a complex rule-based technique for the former and surprisingly accurate for the latter.\n",
            "----------------------------------------\n",
            "Title: Ego-motion and Surrounding Vehicle State Estimation Using a Monocular Camera\n",
            "Abstract: Understanding ego-motion and surrounding vehicle state is essential to enable automated driving and advanced driving assistance technologies. Typical approaches to solve this problem use fusion of multiple sensors such as LiDAR, camera, and radar to recognize surrounding vehicle state, including position, velocity, and orientation. Such sensing modalities are overly complex and costly for production of personal use vehicles. In this paper, we propose a novel machine learning method to estimate ego-motion and surrounding vehicle state using a single monocular camera. Our approach is based on a combination of three deep neural networks to estimate the 3D vehicle bounding box, depth, and optical flow from a sequence of images. The main contribution of this paper is a new framework and algorithm that integrates these three networks in order to estimate the ego-motion and surrounding vehicle state. To realize more accurate 3D position estimation, we address ground plane correction in real-time. The efficacy of the proposed method is demonstrated through experimental evaluations that compare our results to ground truth data available from other sensors including Can-Bus and LiDAR.\n",
            "----------------------------------------\n",
            "Title: Causally Colored Reflections on Leo Breiman's \"Statistical Modeling: The Two Cultures\" (2001)\n",
            "Abstract: Abstract:This note provides a re-assessment of Breiman's contributions to the art of statistical modeling, in light of recent advances in machine learning and causal inference. It highlights the crisp separation between the data-fitting and data-interpretation components of statistical modeling.\n",
            "----------------------------------------\n",
            "Title: Bilinear Scoring Function Search for Knowledge Graph Learning\n",
            "Abstract: Learning embeddings for entities and relations in knowledge graph (KG) have benefited many downstream tasks. In recent years, scoring functions, the crux of KG learning, have been human designed to measure the plausibility of triples and capture different kinds of relations in KGs. However, as relations exhibit intricate patterns that are hard to infer before training, none of them consistently perform the best on benchmark tasks. In this paper, inspired by the recent success of automated machine learning (AutoML), we search bilinear scoring functions for different KG tasks through the AutoML techniques. However, it is non-trivial to explore domain-specific information here. We first set up a search space for AutoBLM by analyzing existing scoring functions. Then, we propose a progressive algorithm (AutoBLM) and an evolutionary algorithm (AutoBLM+), which are further accelerated by filter and predictor to deal with the domain-specific properties for KG learning. Finally, we perform extensive experiments on benchmarks in KG completion, multi-hop query, and entity classification tasks. Empirical results show that the searched scoring functions are KG dependent, new to the literature, and outperform the existing scoring functions. AutoBLM+ is better than AutoBLM as the evolutionary algorithm can flexibly explore better structures in the same budget.\n",
            "----------------------------------------\n",
            "Title: Host microbiomes in tumor precision medicine: how far are we?\n",
            "Abstract: The human gut microbiome has received a crescendo of attention in recent years, due to the countless influences on human pathophysiology, including cancer. Research on cancer and anticancer therapy is constantly looking for new hints to improve the response to therapy while reducing the risk of relapse. In this scenario, the gut microbiome and the plethora of microbial-derived metabolites are considered a new opening in the development of innovative anticancer treatments for a better prognosis. This narrative review summarizes the current knowledge on the role of the gut microbiome in the onset and progression of cancer, as well as in response to chemo-immunotherapy. Recent findings regarding the tumor microbiome and its implications for clinical practice are also commented on. Current microbiome-based intervention strategies (i.e., prebiotics, probiotics, live biotherapeutics and fecal microbiota transplantation) are then discussed, along with key shortcomings, including a lack of long-term safety information in patients who are already severely compromised by standard treatments. The implementation of bioinformatic tools applied to microbiomics and other omics data, such as machine learning, has an enormous potential to push research in the field, enabling the prediction of health risk and therapeutic outcomes, for a truly personalized precision medicine.\n",
            "----------------------------------------\n",
            "Title: Research Aligned Analysis on Web Access Behavioral Pattern Mining for User Identificationa\n",
            "Abstract: Human activity understanding includes activity recognition and activity pattern discovery. Monitoring human activity and finding abnormality in their activities used by many field like medical applications, security systems etc. Basically it helps and support in decision making systems. Mining user activity from web logs can helps in finding hidden information about the user access pattern which reveals the web access behaviour of the users. Clustering and Classification techniques are used for web user identification. Clustering is the task of grouping similar patterns for web user identification. Classification is the process of classifying web patterns for user identification. In this paper we have implemented the existing works and discussed the results here to find the limitations. In existing methods, many data mining techniques were introduced for web user behaviour identification. But, the user identification accuracy was not improved and time consumption was not reduced. Our objective is to study the existing work and explore the possibility to improve the identification accuracy and reduce the time consumption using machine learning and deep learning techniques\n",
            "----------------------------------------\n",
            "Title: SAAFEC-SEQ: A Sequence-Based Method for Predicting the Effect of Single Point Mutations on Protein Thermodynamic Stability\n",
            "Abstract: Modeling the effect of mutations on protein thermodynamics stability is useful for protein engineering and understanding molecular mechanisms of disease-causing variants. Here, we report a new development of the SAAFEC method, the SAAFEC-SEQ, which is a gradient boosting decision tree machine learning method to predict the change of the folding free energy caused by amino acid substitutions. The method does not require the 3D structure of the corresponding protein, but only its sequence and, thus, can be applied on genome-scale investigations where structural information is very sparse. SAAFEC-SEQ uses physicochemical properties, sequence features, and evolutionary information features to make the predictions. It is shown to consistently outperform all existing state-of-the-art sequence-based methods in both the Pearson correlation coefficient and root-mean-squared-error parameters as benchmarked on several independent datasets. The SAAFEC-SEQ has been implemented into a web server and is available as stand-alone code that can be downloaded and embedded into other researchers’ code.\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Based Multi-Room Indoor Localization Using Fingerprint Technique\n",
            "Abstract: Nowadays, developing Wi-Fi-based indoor localization systems has become an attractive research topic due to the growing need for pervasive location determination. The fingerprint technique offers higher positioning accuracy in indoor localization than the distance-based technique. Fingerprint-based techniques via machine learning have been proposed for many years to provide high-accuracy indoor localization services. These works attempt to establish the optimal correlation between the user fingerprint and a pre-defined set of grid points on a radio map. In this paper, a comparative analysis of selected machine learning algorithms is conducted within the context of online phase fingerprint techniques for localization, focusing on implementation in a multi-room case. The experiment involves measurements using a Wi-Fi module in a laboratory, an aisle, a lobby, and a typical classroom, resulting in a small-sized fingerprint database covering a total area of 573.71 m2. The results reveal that Naïve Bayes (NB) obtains the highest localization accuracy in the laboratory and classroom. Meanwhile, Support Vector Machine (SVM) outperforms other algorithms in the aisle, while K-Nearest Neighbor (KNN) delivers the best accuracy in the lobby. In summary, NB, KNN, and SVM are suitable pattern-matching algorithms for multi-room indoor localization and relatively small fingerprint databases.\n",
            "----------------------------------------\n",
            "Title: Abstract 060: Association Of Antecedent Statin Use With Outcomes Of People With Covid-19 Admitted At Northwestern Medicine Health System\n",
            "Abstract: \n",
            " Background:\n",
            " Several observational studies have found that antecedent statin use (i.e., use prior to getting admitted) was associated with lower mortality risk in hospitalized COVID-19 patients, but this is not a consistent finding. Differences maybe due to covariate imbalance, model misspecification, or selection bias.\n",
            " \n",
            " \n",
            " Objective:\n",
            " Estimate the association of antecedent statin use with adverse outcomes (in-hospital death, intubation, ICU admission) in patients admitted for COVID-19 in an academic health system in Chicago.\n",
            " \n",
            " \n",
            " Methods:\n",
            " We analyzed electronic health records from an academic health system in Chicago (Mar ‘20-Mar ‘21) comparing rates of adverse events (composite and per outcome) between antecedent users and non-users. Eligible individuals were ≥40 years old in Illinois, admitted for ≥24 hours, and tested positive for COVID-19 in the 30 days before to 7 days after admission. Antecedent use is defined as existence of statins prescription ≥30 days before admission. We used augmented inverse probability weighting (AIPW) with targeted maximum likelihood estimation to improve covariate balance and estimate the risk difference. Compared to standard methods, this approach allowed use of machine learning models and is doubly robust to misspecification.\n",
            " \n",
            " \n",
            " Results:\n",
            " Of 6267 admitted, 1337 (20%) were antecedent users. Users tend to be older, male, White, smoke, and have a comorbidity. Unadjusted analysis showed significantly higher rates of negative outcomes in non-users except in-hospital death. Analysis using AIPW improved covariate balance and showed that users had significantly lower rates of the composite outcome (RD: -3.9%, 95%CI: -6.0, -1.9) and ICU admissions (RD: -4.0, 95%CI: -7.0, -1.0). No differences in intubation and mortality rates were detected.\n",
            " \n",
            " \n",
            " Conclusion:\n",
            " Antecedent statin use is associated with lower risk of ICU admissions but not with intubation or in-hospital mortality. We were not able to confirm the mortality benefit detected by prior studies nor any differences in rates of intubations.\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "----------------------------------------\n",
            "Title: An evaluation of machine learning and latent semantic analysis in text sentiment classification\n",
            "Abstract: Abstract In this paper, we compare the following machine learning methods as classifiers for sentiment analysis: k – nearest neighbours (kNN), artificial neural network (ANN), support vector machine (SVM), random forest. We used a dataset containing 5,000 movie reviews in which 2,500 were marked as positive and 2,500 as negative. We chose 5,189 words which have an influence on sentence sentiment. The dataset was prepared using a term document matrix (TDM) and classical multidimensional scaling (MDS). This is the first time that TDM and MDS have been used to choose the characteristics of text in sentiment analysis. In this case, we decided to examine different indicators of the specific classifier, such as kernel type for SVM and neighbour count in kNN. All calculations were performed in the R language, in the program R Studio v 3.5.2. Our work can be reproduced because all of our data sets and source code are public.\n",
            "----------------------------------------\n",
            "Title: Catastrophic risk management: Stochastic hybrid model to calculate the loss index trigger for catastrophe bonds (cat bonds). Adjustment using evolutionary strategies\n",
            "Abstract: Purpose: This paper develops a stochastic model to calculate the loss index trigger for catastrophe bonds as alternative instruments for the management of major insured risks, such as natural catastrophe. Methodology: The underlying loss index of catastrophe bonds is the aggregate catastrophe losses reported before the end of certain period. The catastrophe severity is defined as the sum of two random variable: the reported loss amount and incurred-but-not-yet-reported loss amount, and the central hypothesis is that the latter decreases proportionally to a linearly increasing function up to a certain time and constant thereafter, called the hybrid claim reporting rate. Randomness in the reporting process is represented by a geometric Brownian motion in the claim reporting rate. The validity of the proposed model is evaluated by estimating its parameters using machine learning techniques (specifically, evolutionary strategies, ES). Findings: The results shows that the model accurately captures the uneven behavior of the claim reporting process over time and therefore correctly describes the catastrophic claims reporting process. Originality: The model proposed allows for an easy calculation of catastrophic loss indexes, thus facilitating the pricing of loss index-triggered Cat bonds. This translates into better catastrophe risk management for both insurance and reinsurance companies, as well as for those companies that diversify their portfolios with this type of financial instruments. The simplicity of the presented model facilitates parameter estimation and simulation.\n",
            "----------------------------------------\n",
            "Title: Combinatorial and Machine Learning Approaches for Improved Somatic Variant Calling From Formalin-Fixed Paraffin-Embedded Genome Sequence Data\n",
            "Abstract: Formalin fixation of paraffin-embedded tissue samples is a well-established method for preserving tissue and is routinely used in clinical settings. Although formalin-fixed, paraffin-embedded (FFPE) tissues are deemed crucial for research and clinical applications, the fixation process results in molecular damage to nucleic acids, thus confounding their use in genome sequence analysis. Methods to improve genomic data quality from FFPE tissues have emerged, but there remains significant room for improvement. Here, we use whole-genome sequencing (WGS) data from matched Fresh Frozen (FF) and FFPE tissue samples to optimize a sensitive and precise FFPE single nucleotide variant (SNV) calling approach. We present methods to reduce the prevalence of false-positive SNVs by applying combinatorial techniques to five publicly available variant callers. We also introduce FFPolish, a novel variant classification method that efficiently classifies FFPE-specific false-positive variants. Our combinatorial and statistical techniques improve precision and F1 scores compared to the results of publicly available tools when tested individually.\n",
            "----------------------------------------\n",
            "Title: Predicting Molecular Phenotypes with Single Cell RNA Sequencing Data: an Assessment of Unsupervised Machine Learning Models\n",
            "Abstract: According to the National Cancer Institute, there were 9.5 million cancer-related deaths in 2018. A challenge in improving treatment is resistance in genetically unstable cells. The purpose of this study is to evaluate unsupervised machine learning on classifying treatment-resistant phenotypes in heterogeneous tumors through analysis of single cell RNA sequencing(scRNAseq) data with a pipeline and evaluation metrics. scRNAseq quantifies mRNA in cells and characterizes cell phenotypes. One scRNAseq dataset was analyzed (tumor/non-tumor cells of different molecular subtypes and patient identifications). The pipeline consisted of data filtering, dimensionality reduction with Principal Component Analysis, projection with Uniform Manifold Approximation and Projection, clustering with nine approaches (Ward, BIRCH, Gaussian Mixture Model, DBSCAN, Spectral, Affinity Propagation, Agglomerative Clustering, Mean Shift, and K-Means), and evaluation. Seven models divided tumor versus non-tumor cells and molecular subtype while six models classified different patient identification (13 of which were presented in the dataset); K-Means, Ward, and BIRCH often ranked highest with ~80% accuracy on the tumor versus non-tumor task and ~60% for molecular subtype and patient ID. An optimized classification pipeline using K-Means, Ward, and BIRCH models was evaluated to be most effective for further analysis. In clinical research where there is currently no standard protocol for scRNAseq analysis, clusters generated from this pipeline can be used to understand cancer cell behavior and malignant growth, directly affecting the success of treatment.\n",
            "----------------------------------------\n",
            "Title: A summary-statistics-based approach to examine the role of serotonin transporter promoter tandem repeat polymorphism in psychiatric phenotypes\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: TeD-Q: a tensor network enhanced distributed hybrid quantum machine learning framework\n",
            "Abstract: TeD-Q is an open-source software framework for quantum machine learning, variational quantum algorithm (VQA), and simulation of quantum computing. It seamlessly integrates classical machine learning libraries with quantum simulators, giving users the ability to leverage the power of classical machine learning while training quantum machine learning models. TeD-Q supports auto-differentiation that provides backpropagation, parameters shift, and finite difference methods to obtain gradients. With tensor contraction, simulation of quantum circuits with large number of qubits is possible. TeD-Q also provides a graphical mode in which the quantum circuit and the training progress can be visualized in real-time.\n",
            "----------------------------------------\n",
            "Title: Transformer-Based Embeddings for Greek Language Categorization\n",
            "Abstract: The Greek School Network (GSN) provides support to students, teachers, and school units in secondary education across Greece. Handling numerous user queries manually can be challenging, necessitating the development of an automated system for accurate categorization of these queries. This paper presents a comparative study of various transformer-based models for multi-class text categorization of Greek language queries submitted to the GSN helpdesk. We introduce a new experimental balanced dataset and extract vector representations from eleven transformer-based models. These representations are evaluated using ten classic machine learning classifiers. Our findings highlight the superior performance of the Multilingual E5 Text Embeddings model, particularly when paired with the extreme gradient-boosting classifier. This combination demonstrates a clear advantage in accurately categorizing user queries, paving the way for more efficient automated helpdesk systems.\n",
            "----------------------------------------\n",
            "Title: A Network Attack Model based on Colored Petri Net\n",
            "Abstract: The researches have shown that not all the Petri Net machines can be used to describe attack behavior. When Petri Net machines adapted for attack behavior modeling are detecting the network, for some event of current status, if there is matching event in the model, it has only one corresponding transition; otherwise that may cause errors. Since sharing synthesis and synchronization synthesis of traditional machines cannot ensure synthetic model reserves original detection capability, we propose the novel concept for synthesis operation and colored synthetic operation. By the analysis on the relation among these operations, the ability to reserve original detection is verified. Then an improved colored judgement Petri Net machine is adopted for modeling and renewing the knowledge repository. The inductive learning method is used to extend the attack modes. It creates a four-layered concept space, which actually provides a depth-first search path for matching. To solve the problems in multi-pattern matching and incremental learning, various modes are generalized by colored operation. We also adopt the decomposition and synthesis operation to handle the pattern matching of distributed attack behavior and attack information fusion. Finally the actual cases verify that our algorithm is feasible\n",
            "----------------------------------------\n",
            "Title: Analysis-ready optical underwater images of Manganese-nodule covered seafloor of the Clarion-Clipperton Zone\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Deep Learning for Time Series Forecasting: The Electric Load Case\n",
            "Abstract: Management and efficient operations in critical infrastructure such as Smart Grids take huge advantage of accurate power load forecasting which, due to its nonlinear nature, remains a challenging task. Recently, deep learning has emerged in the machine learning field achieving impressive performance in a vast range of tasks, from image classification to machine translation. Applications of deep learning models to the electric load forecasting problem are gaining interest among researchers as well as the industry, but a comprehensive and sound comparison among different architectures is not yet available in the literature. This work aims at filling the gap by reviewing and experimentally evaluating on two real-world datasets the most recent trends in electric load forecasting, by contrasting deep learning architectures on short term forecast (one day ahead prediction). Specifically, we focus on feedforward and recurrent neural networks, sequence to sequence models and temporal convolutional neural networks along with architectural variants, which are known in the signal processing community but are novel to the load forecasting one.\n",
            "----------------------------------------\n",
            "Title: Soft electronic material based sensor with optical network in sports application for player movement analysis using machine learning model\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: An Ensemble Machine Learning Model Using Gradient Boosting Identifies Patients with Disease Progression in Newly Diagnosed Multiple Myeloma\n",
            "Abstract: \n",
            " Introduction:\n",
            " In many cases, treatment decisions for multiple myeloma patients must be made in the absence of high quality randomized controlled clinical trials. As a result, many clinicians lean on prognostic models to drive treatment selection. The most widely used of these models incorporate a limited number of patient related factors that reflect tumor burden, cytogenetic features, or gene expression profiling. These prediction scores are derived from regression models that incorporate these variables at the time of diagnosis. They do not account for variables that change dynamically over time, do not explore the relationship between treatment selection and progression, and imperfectly predict survival outcomes. We designed a prognostic model based on an ensemble machine learning platform to predict progression in NDMM using Extreme Gradient Boosting Machine (XGBoost) combined with accelerated failure time modeling for survival analysis.\n",
            " Methods:\n",
            " We utilized a large retrospective data set containing treatment and response information for 1127 patients with newly diagnosed multiple myeloma (NDMM) treated at the Cleveland Clinic Foundation between 2000 and 2023. Following data preprocessing based on data completeness, 953 patient records were included in our training, testing, and cross validation datasets. For the purposes of our analysis, the initial dataset was randomly split into training (70%), testing (15%) and validation (15%) subsets at the patient level. We also defined the lower and upper bounds for each subset, which is critical due to the right-censored nature of survival data. Hyperparameters for XGBoost were optimized using Bayesian search, minimizing the negative log-likelihood. A random forest method was applied for the imputation of missing data (MissForest). We then trained the XGBoost model using GPU acceleration for enhanced computational efficiency. Finally, a log-rank test on predicted survival times was used to test the model's performance on patients with and without known progression.\n",
            " Results:\n",
            " Our preprocessed data set had 953 patients with a mean age at disease onset of 65 years and a slight male predominance (55%). Approximately 27% of patients harbored high cytogenetic risk disease and 3.5% of the cohort presented with extramedullary disease a diagnosis. At a median follow up of 35 months, 47% of patients had experienced disease progression or death. Induction therapy included an immunomodulatory drug in 40% of patients and proteasome inhibitors in 22%. Frontline autologous stem cell transplantation followed induction in 28% of patients. Median progression free survival in the overall data set was 44 months. These features were consistent across the randomly assigned training, testing, and validation cohorts.\n",
            " Following data preprocessing, 34 independent clinical and genomic variables including selection of first line treatment were assessed as model inputs each available record. Under optimized parameters, the model was trained with a maximum tree depth = 7 and a learning rate ~ 0.22 for the desired output of progression free survival (PFS). We then queried PFS for both the training and validation sets and divided patients into those known to have progressed and those without a progression event. Survival analysis was undertaken using predicted PFS values for patients known to have progressed and those who remained progression free. For the validation data set, our model successfully discerned between progressed and non-progressed cases (log-rank test statistic = 22.07, p < 0.005) (Figure 1).\n",
            " Discussion:\n",
            " We present a machine learning approach based on regularized gradient boosting that accurately discerns between patients who experience progression and those who remain progression free at a median ~35 months of follow-up in a large retrospective data set in patients presenting with NDMM. Further elaboration of our model will allow for the incorporation of large amounts data to predict survival outcomes on the basis of dynamic variables such as depth of response and treatment selection. With the ability to parse outcomes among multiple myeloma patients at high resolution, future clinicians and clinical trialists may be able to overcome limitations in trial design and patient-level therapy selection for both newly diagnosed and relapsed patients.\n",
            "----------------------------------------\n",
            "Title: Modelo basado en Machine Learning para el Neurorendimiento Académico de estudiantes en la Universidad José Carlos Mariátegui filial Tacna 2018 – I\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Smart contract based automated cervical cancer prediction using ensemble machine learning\n",
            "Abstract: Cervical cancer is a serious health concern that entails high risks for individuals due to delayed detection and treatment worldwide. Formal screening for the condition is challenging in both developed and developing countries due to a number of factors, including medical costs, access to healthcare facilities, social norms, and delayed symptom manifestation. Bypassing conventional, time-consuming medical procedures, machine learning presents a promising path for the efficient and economical early diagnosis of a variety of diseases, including cervical cancer. However, the fact that existing machine classification techniques for identifying diseases rely heavily on the predictive accuracy of a single classifier poses a significant drawback. Single classification methods alone might not provide the best predictions because of bias, over-fitting, improper handling of noisy data, and outliers, among other issues. Moreover, machine learning algorithms deals with sensitive patient data therefore Security measures are necessary to prevent unauthorized access and safeguard individual and organisations’ privacy, guard against model tampering. This paper proposes a novel framework for cervical cancer automated prediction using ensemble model training and blockchain smart contracts. The research records a noteworthy improvement in prediction test accuracy of 99.7% and train accuracy of 93%, surpassing the accuracy of predictions made by individual categorization techniques.\n",
            "----------------------------------------\n",
            "Title: Modeling Rapport for Conversations About Health with Autonomous Avatars from Video Corpus of Clinician-Client Therapy Sessions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Data science in Asia (for PAKDD 2016)\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Verified perceptron convergence theorem\n",
            "Abstract: Frank Rosenblatt invented the perceptron algorithm in 1957 as part of an early attempt to build ``brain models'', artificial neural networks. In this paper, we apply tools from symbolic logic such as dependent type theory as implemented in Coq to build, and prove convergence of, one-layer perceptrons (specifically, we show that our Coq implementation converges to a binary classifier when trained on linearly separable datasets). Our perceptron and proof are extensible, which we demonstrate by adapting our convergence proof to the averaged perceptron, a common variant of the basic perceptron algorithm. We perform experiments to evaluate the performance of our Coq perceptron vs. an arbitrary-precision C++ implementation and against a hybrid implementation in which separators learned in C++ are certified in Coq. We find that by carefully optimizing the extraction of our Coq perceptron, we can meet -- and occasionally exceed -- the performance of the arbitrary-precision C++ implementation. Our hybrid Coq certifier demonstrates an architecture for building high-assurance machine-learning systems that reuse existing codebases.\n",
            "----------------------------------------\n",
            "Title: Machine Learning and the Re‐Enchantment of the Administrative State\n",
            "Abstract: Machine learning algorithms present substantial promise for more effective decision‐making by administrative agencies. However, some of these algorithms are inscrutable, namely, they produce predictions that humans cannot understand or explain. This trait is in tension with the emphasis on reason‐giving in administrative law. The article explores this tension, advancing two interrelated arguments. First, providing adequate reasons is a significant facet of respecting individuals’ agency. Incorporating inscrutable algorithmic predictions into administrative decision‐making compromises this normative ideal. Second, as a long‐term concern, the use of inscrutable algorithms by administrative agencies may generate systemic effects by gradually reducing the realm of the humanly explainable in public life, a phenomenon Max Weber termed ‘re‐enchantment’. As a result, the use of inscrutable machine learning algorithms might trigger a special kind of re‐enchantment, making us comprehend less rather than more of shared human experience, and consequently altering the way we understand the administrative state and experience public life.\n",
            "----------------------------------------\n",
            "Title: The Method of Machine Learning Considering Tamper of Training Data\n",
            "Abstract: Big data is increasingly used as training data for machine learning. However, large-scale data such as big data is not always appropriate as training data at all times. Particularly when collecting data from Web services such as SNS, unspeciﬁed number of people using the service can indirectly tamper with data. In this research, we propose a learning method and verify its eﬀectiveness so as to obtain a learning result close to the case without tampering even in an environment in which part of the training data has been tampered with. In this method, learning is divided into two stages\n",
            "----------------------------------------\n",
            "Title: IDDF2023-ABS-0074 Pretreatment prediction of T cell-inflamed gene expression profile in hepatocellular carcinoma: a contrast-enhanced ultrasound radiomics-based machine learning model\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Jucazinho Dam Streamflow Prediction: A Comparative Analysis of Machine Learning Techniques\n",
            "Abstract: The centuries-old history of dam construction, from the Saad el-Kafara Dam to global expansion in the 1950s, highlights the importance of these structures in water resource management. The Jucazinho Dam, built in 1998, emerged as a response to the scarcity of water in the Agreste region of Pernambuco, Brazil. After having less than 1% of its water storage capacity in 2016, the dam recovered in 2020 after interventions by the local water utility. In this context, the reliability of influent flow prediction models for dams becomes crucial for managers. This study proposed hydrological models based on artificial intelligence that aim to generate flow series, and we evaluated the adaptability of these models for the operation of the Jucazinho Dam. Data normalization between 0 and 1 was applied to avoid the predominance of variables with high values. The model was based on machine learning and employed support vector regression (SVM), random forest (RF) and artificial neural networks (ANNs), as provided by the Python Sklearn library. The selection of the monitoring stations took place via the Brazilian National Water and Sanitation Agency’s (ANA) HIDROWEB portal, and we used Spearman’s correlation to identify the relationship between precipitation and flow. The evaluation of the performance of the model involved graphical analyses and statistical criteria such as the Nash–Sutcliffe model efficiency coefficient (NSE), the percentage of bias (PBIAS), the coefficient of determination (R2) and the root mean standard deviation ratio (RSR). The results of the statistical coefficients for the test data indicated unsatisfactory performance for long-term predictions (8, 16 and 32 days ahead), revealing a downward trend in the quality of the fit with an increase in the forecast horizon. The SVM model stood out by obtaining the best indices of NSE, PBIAS, R2 and RSR. The graphical results of the SVM models showed underestimation of the flow values with an increase in the forecast horizon due to the sensitivity of the SVM to complex patterns in the time series. On the other hand, the RF and ANN models showed hyperestimation of the flow values as the number of forecast days increased, which was mainly attributed to overfitting. In summary, this study highlights the relevance of artificial intelligence in flow prediction for the efficient management of dams, especially in water scarcity and data-scarce scenarios. A proper choice of models and the ensuring of reliable input data are crucial for obtaining accurate forecasts and can contribute to water security and the effective operation of dams such as Jucazinho.\n",
            "----------------------------------------\n",
            "Title: RESUME ANALYZER\n",
            "Abstract: Resume analysis is the process in which a machine analyses a resume based on given requirements of the job description. With the flood of resumes received by companies, it is not effective and also not possible for a person to go through a number of resumes to select a candidate. They have become very popular among the companies in the process of determining candidate selection. The main objective of the project is to be able to match the requirements and skills from a job description to the resume applied. This gives an instantaneous result on whether the resume is accepted or rejected. The end process allows the company itself to be able to select candidates without the requirement of a third party and thus is also cost effective. A big number of resumes could be used in this project to sort the necessary application using various classifiers. Following classifications, the top n candidates will be sorted in accordance with the job description using content-based recommendation and cosine similarity. The project employs k-NN to determine which CVs are most similar to the supplied job description. Through machine learning, the system evaluates a resume for a particular position using NLP.\n",
            "----------------------------------------\n",
            "Title: Developing Affordable, Portable and Simplistic Diagnostic Sensors to Improve Access to Care\n",
            "Abstract: Ophthalmology is a highly technical specialty, especially in the area of diagnostic equipment. While the field is innovative, the access to cutting-edge technology is limited with reference to the global population. A significant way to improve overall healthcare is to understand the needs and possibilities of all possible consumers when developing sophisticated and accurate medical devices. The Smartphone-based Keratograph (SBK), is an example of a new project that uses real world feedback, addresses an unmet medical need, and implements commercially available components to create a device that is affordable, portable and simplistic to operate. The long-term goal of the SBK is to collect data from users for supervised machine-learning. This machine-learning aspect will ultimately aid in the development of an artificial intelligence device to enable even earlier detection of keratoconus, especially in children and adolescents. Again, the ultimate goal of any medical device should be to improve patient care, and to make a significant improvement on vision healthcare for the global population, providing access to this technology is essential.\n",
            "----------------------------------------\n",
            "Title: Further (Potential) Application Fields\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Offshore field experimentation for novel hybrid condition monitoring approaches\n",
            "Abstract: This study details the development of a fully automated pipeline for the condition monitoring of wind turbine drive trains. Vibration data is collected using hardware designed and manufactured in-house and used directly to monitor the condition of the drive trains. The complex nature of wind turbine vibration signals, due to the large number of components and highly variable operating conditions, makes drive train condition monitoring a challenging task. This paper details the full data measurement and analysis flow from sensor to insights and proposes a hybrid automated pipeline with signal processing and data-driven techniques to address the complexity of dealing with wind turbine vibration data. The vibration signals are directly employed to estimate the wind turbine’s instantaneous angular speed to compensate for any rotation speed fluctuations. Pre-processing is performed on the speed-independent signals to evaluate condition indicators in both the time and spectral domain for the vibration signals and their envelopes. Machine learning is then employed to distinguish the healthy state of the machine from a faulty one using the computed condition indicators. Besides the scalar indicators, also two-dimensional vibration decompositions such as the cyclic spectral correlation maps are used as inputs to the machine learning pipeline. This comprehensive and automated approach ensures both an early and reliable fault detection. Experimental results demonstrate that the fully automated hybrid pipeline can effectively be used for fleet-based health tracking of offshore wind turbine drivetrains.\n",
            "----------------------------------------\n",
            "Title: A Comparative Analysis of Machine Learning Models in Prediction of Mortar Compressive Strength\n",
            "Abstract: Predicting the mechanical properties of cement-based mortars is essential in understanding the life and functioning of structures. Machine learning (ML) algorithms in this regard can be especially useful in prediction scenarios. In this paper, a comprehensive comparison of nine ML algorithms, i.e., linear regression (LR), random forest regression (RFR), support vector regression (SVR), AdaBoost regression (ABR), multi-layer perceptron (MLP), gradient boosting regression (GBR), decision tree regression (DT), hist gradient boosting regression (hGBR) and XGBoost regression (XGB), is carried out. A multi-attribute decision making method called TOPSIS (technique for order of preference by similarity to ideal solution) is used to select the best ML metamodel. A large dataset on cement-based mortars consisting of 424 sample points is used. The compressive strength of cement-based mortars is predicted based on six input parameters, i.e., the age of specimen (AS), the cement grade (CG), the metakaolin-to-total-binder ratio (MK/B), the water-to-binder ratio (W/B), the superplasticizer-to-binder ratio (SP) and the binder-to-sand ratio (B/S). XGBoost regression is found to be the best ML metamodel while simple metamodels like linear regression (LR) are found to be insufficient in handling the non-linearity in the process. This mapping of the compressive strength of mortars using ML techniques will be helpful for practitioners and researchers in identifying suitable mortar mixes.\n",
            "----------------------------------------\n",
            "Title: Identification of Unclassified Ships Implementing AIS Information and SAR Image-Based Ship Detection Results\n",
            "Abstract: Monitoring and detecting ships via machine learning based algorithm were regarded efficient in martial and economic manners. As an algorithm regarding automated training data retrieval from SAR image was proposed, the identification of unclassified ships without AIS information could be raised as another challenging issue of ship surveillance. This study presented the effective identification algorithm of discerning unclassified ships from AIS information and the results of conventional ship detection based on machine learning. The accurately detected ships were selected from the conventional ship detection results, followed by the preprocessing of AIS information corresponding to the SAR images containing the detection results. Superposition of AIS information on accurate detection results was conducted and concluded the ships without AIS information as unclassified ships. From 3 Sentinel-1 SAR images, it obtained the average rate of identification as 85.67%. Additional research implementing the identification algorithm accompanied by rapidly acquired satellite or airborne SAR images could be effective in rendering a ship surveillance system with rapid response.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Based Unpleasant Sound Detection by Electroencephalography\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Machine-Learning-Based Risk Factor Analysis for Hypertension: Korea National Health and Nutrition Examination Survey 2016–2019\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: lociPARSE: a locality-aware invariant point attention model for scoring RNA 3D structures\n",
            "Abstract: A scoring function that can reliably assess the accuracy of a 3D RNA structural model in the absence of experimental structure is not only important for model evaluation and selection but also useful for scoring-guided conformational sampling. However, high-fidelity RNA scoring has proven to be difficult using conventional knowledge-based statistical potentials and currently-available machine learning-based approaches. Here we present lociPARSE, a locality-aware invariant point attention architecture for scoring RNA 3D structures. Unlike existing machine learning methods that estimate superposition-based root mean square deviation (RMSD), lociPARSE estimates Local Distance Difference Test (lDDT) scores capturing the accuracy of each nucleotide and its surrounding local atomic environment in a superposition-free manner, before aggregating information to predict global structural accuracy. Tested on multiple datasets including CASP15, lociPARSE significantly outperforms existing statistical potentials (rsRNASP, cgRNASP, DFIRE-RNA, and RASP) and machine learning methods (ARES and RNA3DCNN) across complementary assessment metrics. lociPARSE is freely available at https://github.com/Bhattacharya-Lab/lociPARSE.\n",
            "----------------------------------------\n",
            "Title: LabelMars: Creating an extremely large Martian image dataset through machine learning\n",
            "Abstract: Introduction: Four landers (Viking 1,2, Phoenix and Insight) and 4 rovers (Sojourner, Spirit, Opportunity, and Curiosity) have successfully operated on the Martian surface since 1976, with the combined operation time of landers exceeding 3680 sols and that of rovers exceeding 9660 sols at the time of writing of this abstract (December 2018)[1]. This has returned a large dataset of images from the cameras on board, with examples of recent image-based research on Curiosity images alone including, but not limited to, studies of aeolian, active bedforms [2,3], conglomerates and river beds [4], sedimentary structures [5,6,7], and erosional features [8], together for a reconstruction of the geology of the site [9,10,11]. This list is clearly not exhaustive but it demonstrates how images are key to understanding of the geologic environment at the site, and thus are basis for operational decisions and an invaluable science data resource. With two missions currently active (Curiosity, InSight) and two more scheduled to launch in 2020 (ESA ExoMars, NASA Mars2020) this data set is a ‘big data’ problem, and growing. In order to facilitate easier access, especially for researchers who do not have the luxury of following the mission on a daily basis, this research has developed an automated terrain labelling and classification system based on state of the art machine/deep learning which enables keyword based search. The project: LabelMars achieved 5000 annotated images from the Spirit, Opportunity and Rover navigation camera data bases. The project was a part of a larger European Space Agency (ESA) project called Novelty or Anomaly Hunter (NOAH) which has a number of other tasks, including the labelling as a citizen science project [12], an AI algorithmic evaluation, and a prototype flight detector developed which ported some of the algorithms to flight C versions in order to enable future on-board operations of the technology. We started with the entire set of available navigation camera images from the MER and MSL rovers sourced from the Analyst’s Notebook [13] and down-selected those by selecting continuous rows of sols from different terrains and subsequently deleting all unsuitable ones from this set of images (e.g., if they were too dark or an exact repeat of another one). This resulted in 5917 images {Spirit (2724), Opportunity (1173) and Curiosity (2020)}, which were further reduced to exactly 5000 by eliminating similar scenes and very dark images. The resulting images were manually labelled. Table 1. Example of the category structure for the labelling.\n",
            "----------------------------------------\n",
            "Title: Global and Local Features Based Classification for Bleed-Through Removal\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Traffic Prediction for Intelligent Transportation System using Machine Learning\n",
            "Abstract: Abstract: Machine learning is a set of algorithms and statistical models that computers use to perform a desired task. Machine learning can be used in many applications such as face detection, speech recognition, medical diagnostics, statistical arbitrage, traffic prediction, etc. The traffic environment includes everything that can affect traffic on the road, whether it is traffic lights, accidents, rallies, or even road repairs that can cause congestion. If we have preconceived information very close to all of the above and the many everyday situations that can affect traffic, the driver or passenger can make an informed decision. It also helps with the future of automotive vehicles. In the present decades, traffic data has been massively generated, and we have moved towards big data concepts for transportation. The to be had site visitors glide forecasting strategies use a few site visitors’ prediction fashions and are nonetheless unsatisfactory to address real-global applications. It is lumbering to figure out the traffic flow precisely since the information accessible for the transportation framework is madly colossal. In this work, we arranged to utilize machine learning, genetic, soft computing, and deep learning algorithms to analyse the big-data for the transportation system with much-reduced complexity. Moreover, Image Processing algorithms are included in traffic sign recognition, which inevitably helps for the right training of autonomous vehicles. In economic years, Mobility GPS has become very popular in big cities in determining traffic percentage with the help of centralized traffic - server management. The data collected can be used to build an idea that displays the current traffic in the city and can be used in the future in predicting traffic and congestion analysis can be done\n",
            "----------------------------------------\n",
            "Title: Bibliometric Analysis of the Journal of Big Data: Trends, Impact, and Future Directions\n",
            "Abstract: The Journal of Big Data, a peer-reviewed publication since 2014, has played a pivotal role in the field of big data research by disseminating a total of 788 papers over its ten years of activity. Of these, 649 papers have garnered citations, with 46 receiving over 100 citations. The journal maintains an average of 37.13 citations per paper, with a higher average of 45.09 citations per cited paper, reflecting its significant impact. An h-index of 70 and a g-index of 158 further underscore its academic influence. The journal’s active year growth rate of 39.88% signifies its consistent expansion, while the average document age of 2.83 years indicates a focus on current developments. Collaborative research is a hallmark of the journal, evident in its 3.47 average authors per paper and 19.67% of papers with international co-authorships. The analysis of year-wise performance and citation trends offers insights into scholarly output and engagement. Visualizing collaborative relationships among authors highlights prominent nodes of interaction, revealing key contributors. Noteworthy institutions such as Florida Atlantic University, USA, and Bina Nusantara University, Indonesia, emerge in the landscape of research productivity. An exploration of keywords and their co-occurrence uncovers thematic clusters, ranging from big data technologies and deep learning to natural language processing and machine learning. In conclusion, the Journal of Big Data stands as a vital platform for disseminating impactful research in the dynamic realm of big data. Its comprehensive analysis emphasizes its academic influence through citation metrics, collaborative research, and thematic explorations. Through its decade-long journey, the journal has solidified its role in advancing the field and fostering global collaboration among researchers.\n",
            "----------------------------------------\n",
            "Title: Detecting foodborne pathogens with darkfield hyperspectral microscopy\n",
            "Abstract: The presence of pathogenic microorganisms such as salmonella, listeria and E. coli in foods is a major threat to consumer safety. The failure to detect these pathogens can result in severe outbreaks of foodborne illness. There are several technologies utilized in food pathogen detection today including plating, nucleic acid-based polymerase chain reaction techniques and immunoassays. While these technologies have their merits, each approach requires significant sample incubation and total time to answer of 18 – 72hrs. HinaLea is working in collaboration with the USDA to develop a system which will significantly accelerate the identification of foodborne pathogens. The system combines darkfield microscopy, hyperspectral imaging, machine learning and automation in a standalone unit. Our vision is to move towards real-time identification of pathogens in the food production environment.\n",
            "----------------------------------------\n",
            "Title: Method and Apparatus for Stock Performance Prediction Using Momentum Strategy along with Social Feedback\n",
            "Abstract: Stock prediction and historical stock data analysis have been of great interest over the decades. The research is wide from classical deterministic algorithms to machine learning models and techniques along with the supply huge amounts of historical data. Volatility and Market Sentiment are key parameters to account for during the construction of any stock prediction model. Commonly used techniques like the n-moving days average is not responsive to swings in the stocks and the information sent and posted online has made a huge effect on investors' opinions on the market, making these the two optimal parameters of prediction. Hence, we present an automatic pipeline that has 2 modules - N-Observation period momentum strategy to identify potential stocks and then a stock holding module that identifies market sentiment using NLP techniques.\n",
            "----------------------------------------\n",
            "Title: ETL-FEXIC Model for Secured Heart Rate Abnormality Healthcare Framework\n",
            "Abstract: In traditional methods, it is critical for an effective continuous pulse monitor for humans prone to heart rate abnormalities. This paper proposes a secured heartrate abnormality detector which continuously monitors human pulse rate and SpO2 level. The current studies proposes that machine learning (ML) models performs well in classification; also, TinyML model shows better performance for data from resource constrained IoT devices. Hence, the research first analyses abnormal heart rate detection and spam data identification using standard ML algorithms such as SVM, Random Forest, Decision Tree, and TinyML. Though ML models are superior in classification, deep learning approaches outperforms them in feature learning. Hence, our proposed framework combines the merits of both ML and DL models. In our approach, the generated healthcare dataset is fed to DL models such as ANN, and autoencoder and also to SHAP XAI (eXplainable Artificial Intelligence) for feature extraction and learning. These learnt features are fed to ML models for classification. In this experiment, the proposed ETL-FEXIC (Enhanced Tiny Machine Learning with Automated Feature Extraction) outperforms the other ML models where the extracted features from XAI is fed to optimized TinyML classification model.\n",
            "----------------------------------------\n",
            "Title: Navigating Industry 4.0 Frontiers: A Scalable and Resilient Next-Generation IoT Framework to Implement Future Advancements in Smart and Adaptive Industrial Systems\n",
            "Abstract: The emergence of Industry 4.0 signifies a paradigm shift in industrial systems, characterized by the amalgamation of digital technologies with tangible operations. The goal of this study is to present a state-of-the-art, scalable, and robust Internet of Things (IoT) framework that will enable future innovations in intelligent and adaptable industrial systems to be seamlessly integrated. Our framework gives scalability first priority in response to Industry 4.0's dynamic nature, which is marked by fast technical evolution and rising connection in order to handle the expanding ecosystem of networked devices. The suggested structure places a strong emphasis on resilience and is designed to resist setbacks and guarantee the continuation of vital industrial processes. Our framework improves industrial systems' intelligence by utilizing edge computing, machine learning techniques, and improved communication protocols. This allows the systems to self-adapt to changing situations. Moreover, it adopts a modular architecture that facilitates interoperability and makes it simple to integrate various devices and technologies. Our IoT framework creates a solid, flexible, and future-proof industrial environment with this all-encompassing strategy, enabling businesses to confidently and effectively traverse Industry 4.0's frontiers.\n",
            "----------------------------------------\n",
            "Title: Complex system health condition estimation using tree-structured simple recurrent unit networks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Measuring Caloric Intake at the Population Level (NOTION): Protocol for an Experimental Study\n",
            "Abstract: Background The monitoring of caloric intake is an important challenge for the maintenance of individual and public health. The instruments used so far for dietary monitoring (eg, food frequency questionnaires, food diaries, and telephone interviews) are inexpensive and easy to implement but show important inaccuracies. Alternative methods based on wearable devices and wrist accelerometers have been proposed, yet they have limited accuracy in predicting caloric intake because analytics are usually not well suited to manage the massive sets of data generated from these types of devices. Objective This study aims to develop an algorithm using recent advances in machine learning methodology, which provides a precise and stable estimate of caloric intake. Methods The study will capture four individual eating activities outside the home over 2 months. Twenty healthy Italian adults will be recruited from the University of Padova in Padova, Italy, with email, flyers, and website announcements. The eligibility requirements include age 18 to 66 years and no eating disorder history. Each participant will be randomized to one of two menus to be eaten on weekdays in a predefined cafeteria in Padova (northeastern Italy). Flows of raw data will be accessed and downloaded from the wearable devices given to study participants and associated with anthropometric and demographic characteristics of the user (with their written permission). These massive data flows will provide a detailed picture of real-life conditions and will be analyzed through an up-to-date machine learning approach with the aim to accurately predict the caloric contribution of individual eating activities. Gold standard evaluation of the energy content of eaten foods will be obtained using calorimetric assessments made at the Laboratory of Dietetics and Nutraceutical Research of the University of Padova. Results The study will last 14 months from July 2017 with a final report by November 2018. Data collection will occur from October to December 2017. From this study, we expect to obtain a series of relevant data that, opportunely filtered, could allow the construction of a prototype algorithm able to estimate caloric intake through the recognition of food type and the number of bites. The algorithm should work in real time, be embedded in a wearable device, and able to match bite-related movements and the corresponding caloric intake with high accuracy. Conclusions Building an automatic calculation method for caloric intake, independent on the black-box processing of the wearable devices marketed so far, has great potential both for clinical nutrition (eg, for assessing cardiovascular compliance or for the prevention of coronary heart disease through proper dietary control) and public health nutrition as a low-cost monitoring tool for eating habits of different segments of the population. International Registered Report Identifier (IRRID) DERR1-10.2196/12116\n",
            "----------------------------------------\n",
            "Title: StockNet: A Multivariate Deep Neural Architecture for stock prices prediction\n",
            "Abstract: Stock price forecasting is an inherently difficult problem. According to the efficient market hypothesis financial prices are unpredictable. However, a great number of machine learning methods have obtained consistent results on anticipating market movements. Most recent time-series prediction methods attempt to predict prices polarity, that is, whether prices have increased or fallen compared to the last time-step. Such approaches are inefficient in real scenarios, as forecasting price polarity alone makes financial planning a hard task, due to the fees and operation costs. Most of these methods use only Recurrent Neural Networks, but recent advances in temporal convolutional networks also may prove to be promising in prediction of general time-series, making better predictions with easier to train models. Recent hybrid architectures have also obtained important results using additional unstructured information from financial news. We propose a novel deep neural architecture to predict stock prices based on Temporal Convolutional Networks and built upon on a state of the art acoustic model for voice synthesis. Experimental results show that our model can consistently improve individual stocks prediction when compared to traditional methods.\n",
            "----------------------------------------\n",
            "Title: Proceedings 44th IEEE Symposium on Foundations of Computer Science - FOCS 2003\n",
            "Abstract: The following topics are discussed: computer science; network performance analysis; algorithms and data structures, computational complexity, cryptography, computational geometry, algorithmic graph theory and combinatorics, parallel and distributed computing, machine learning, applications of logic, algorithmic algebra and coding theory, theoretical aspects of databases, information retrieval, networks, computational biology, robotics, and quantum computing; constraint satisfaction problems; and traveling salesman problem.\n",
            "----------------------------------------\n",
            "Title: Analyzing analytics\n",
            "Abstract: Many organizations today are faced with the challenge of processing and distilling information from huge and growing collections of data. Such organizations are increasingly deploying sophisticated mathematical algorithms to model the behavior of their business processes to discover correlations in the data, to predict trends and ultimately drive decisions to optimize their operations. These techniques, are known collectively as analytics, and draw upon multiple disciplines, including statistics, quantitative analysis, data mining, and machine learning. In this survey paper, we identify some of the key techniques employed in analytics both to serve as an introduction for the non-specialist and to explore the opportunity for greater optimizations for parallelization and acceleration using commodity and specialized multi-core processors. We are interested in isolating and documenting repeated patterns in analytical algorithms, data structures and data types, and in understanding howthese could be most effectively mapped onto parallel infrastructure. To this end, we focus on analytical models that can be executed using different algorithms. For most major model types, we study implementations of key algorithms to determine common computational and runtime patterns. We then use this information to characterize and recommend suitable parallelization strategies for these algorithms, specifically when used in data management workloads.\n",
            "----------------------------------------\n",
            "Title: Abstract 16427: Despite Machine Learning Models, QRS Duration Remains the Superior ECG Criterion for Predicting Left Ventricular Dilation in Patients With Left Bundle Branch Block\n",
            "Abstract: \n",
            " Introduction:\n",
            " The utility of ECG to diagnose left ventricular (LV) dilation in patients with left bundle branch block (LBBB) is not known. We sought to compare the diagnostic yield of ECG using (i) QRS duration, (ii) published LVH criteria, and (iii) machine learning (ML) models to detect increased left ventricular end diastolic volume indexed (LVEDVi) in the setting of LBBB.\n",
            " \n",
            " \n",
            " Hypothesis:\n",
            " ML is superior to QRS duration and LVH criteria to detect increased LVEDVi among LBBB.\n",
            " \n",
            " \n",
            " Methods:\n",
            " 12-lead ECGs were processed to reconstruct orthogonal X, Y, Z leads using Kors’s matrix and obtain root-mean-squared (3D) ECG. R wave, S wave and overall amplitudes, voltage-time-integrals (VTIs), and other ECG features were extracted from all ECG leads. ML algorithms [logistic regression (LR), support vector classifier (SVC), decision trees (DT), random forest (RF), gradient boosted machine (GBM) and boosted trees (BT)] were trained to predict increased LVEDVi (women >61 mL/m\n",
            " 2\n",
            " , men >74 mL/m\n",
            " 2\n",
            " ) from ECG features on a training set of 2668 ECGs with typical LBBB and echocardiogram within 45 days before or after ECG. LVEDV was measured using ASE biplane method of discs. We obtained ROC AUCs for prediction of increased LVEDVi by (i) QRS duration, (ii) published LVH criteria, and (iii) ML models in a separate validation set of adults with typical LBBB.\n",
            " \n",
            " \n",
            " Results:\n",
            " Among the validation set of 413 adults (53% women, age 73±12 yr) with LBBB, QRS duration alone had a higher AUC (women 0.668, men 0.699) for diagnosing increased LVMi compared to standard LVH criteria (Table). The best ML model (RF with overall AUC 0.694) did not substantially outperform QRS duration alone.\n",
            " \n",
            " \n",
            " Conclusions:\n",
            " In patients with LBBB, QRS duration ≥150 in women and ≥160 in men is a superior predictor of LV dilation than traditional ECG-based LVH criteria, with no additional value added by ML methods.\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "----------------------------------------\n",
            "Title: Evaluation of Tree Diameter and Height Measurements in UAV Data by Integrating Remote Sensing and Machine Learning Methods\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: L2 SUPPORT VECTOR MACHINES REVISITED - NOVEL DIRECT LEARNING ALGORITHM AND SOME GEOMETRIC INSIGHTS\n",
            "Abstract: : The paper presents a novel learning algorithm for the class of L2 Support Vector Machines classifiers dubbed Direct L2 SVM. The proposed algorithm avoids solving the quadratic programming problem and yet, it produces both the same exact results as the classic quadratic programming based solution in a significantly shorter CPU time. The connections between various L2 SVM algorithms will be highlighted and some geometric properties of the Direct L2 SVM will be pointed at. All the other known L2 based SVMs can be looked at as the special cases of a Direct L2 SVM. The developed Direct L2 SVM algorithm is posed as the Non-Negative Least Squares problem which solves the comprehensive L2 SVM exactly and, in a striking difference to both the Least Squares SVM and proximal SVM, is able to produce the sparse solutions.\n",
            "----------------------------------------\n",
            "Title: Unsupervised Insider Detection Through Neural Feature Learning and Model Optimisation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Toolbox for Automating Development of Personalized Epileptic Seizure Detection Algorithms\n",
            "Abstract: Objective: A toolbox for automating the development of real-time personalized epileptic seizure detection algorithms is presented. The toolbox contains modules that cover feature extraction, feature selection, classiﬁer training and performance evaluation using cross-validation. Methods: A large pool of features is extracted from the training dataset of a given patient using di ↵ erent signal processing methods. Then, the feature selection modules picks an e � cient subset of features. Next, a high-level machine learning classiﬁer is created to automatically classify EEG data as seizure or non-seizure. Results: The toolbox performance was evaluated using 3-fold cross-validation on multiple patients from three publicly available datasets. The overall sensitivities were between 74 . 2% and 92 . 7% with median false positive rates below 2 per day. Conclusion: The toolbox was able to create individualized detection algorithms with suitable sensitivities and low false positive rates for most of the patients. Signiﬁcance: The performance of the toolbox conﬁrms its potential to be used in clinical settings, raising alarms when patients su ↵ er from seizures. Moreover, it can pre-process EEG recordings by ﬁnding seizure occurrences. The modularity of the toolbox enables its components to be used in the design of new algorithms tailored for di ↵ erent tasks.\n",
            "----------------------------------------\n",
            "Title: Traduction automatique de termes biomédicaux pour la recherche d'information interlingue\n",
            "Abstract: In this article, we present a new method to automatically translate biomedical terms. This method relies on an original machine-learning technique that infers rewriting rules and on the use of language models. Evaluations presented here prove that this method yields good results and allows one to translate between any two languages provided that their differences are regular enough to be learnt. This translation method is applied and evaluated on a interlingual IR task in the biomedical domain with queries in several languages (French, Spanish, Portuguese, Russian, Italian); the good results we obtain prove the interest of such an automatic approach for the information retrieval domain. MOTS-CLES : RI interlingue, traduction artificielle, apprentissage artificiel, termes biomedicaux\n",
            "----------------------------------------\n",
            "Title: Forecasting the Energy Utilization in WSN by Support Vector Regression Model\n",
            "Abstract: Energy management issues in Wireless Sensor Networks (WSNs) are an important research topic because they are widely used to monitor a variety of physical conditions. Though several analytical methods are available, it is still challenging to make a precise model to forecast energy utilization due to the prompting parameters' difficulty. It is critical for an energy manager to accurately predict energy consumption in order to make sound decisions and achieve energy utilization. The dimensionality reduction and efficient feature selection process in WSN is challenging. In many real-time situations, machine learning methods such as Support Vector Regression (SVR) provide greater accuracy. This paper proposes a Support Vector Regression (SVR) model for forecasting the processing energy utilization in WSN. The SVR system maps the input variables to high dimensional feature space and discovers the nonlinear connection between the input and output by reducing the data load. Furthermore, the Boruta algorithm is used to select the feature and improve the forecasting accuracy. The experimental outcomes demonstrate the FSVR method enhances the accuracy and minimizes the processing energy utilization in the WSN.\n",
            "----------------------------------------\n",
            "Title: ANOMALY DETECTION WITH SELF-SUPERVISED AUDIO EMBEDDINGS Technical\n",
            "Abstract: The majority of approaches to machine condition monitoring via anomalous sound detection are based on supervised learning. The metadata of the datasets is used as data labels for training supervised models. However, data labeling is expensive and often impossible for industries with significant amount of equipment. In this case self-supervised methods could solve the problem since they do not require labeled data. In this work we applied the recent self-supervised approach to compute embeddings of audio signals named BYOL-A and classical machine learning method Local Out-lier Factor (LOF) to compute outlier scores for anomalous sounds. The main focus of this work is to not use any labels from the meta-data of the datasets and explore a self-supervised learning approach.\n",
            "----------------------------------------\n",
            "Title: Machine Learning: Frontmatter\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Federated Learning without Full Labels: A Survey\n",
            "Abstract: Data privacy has become an increasingly important concern in real-world big data applications such as machine learning. To address the problem, federated learning (FL) has been a promising solution to building effective machine learning models from decentralized and private data. Existing federated learning algorithms mainly tackle the supervised learning problem, where data are assumed to be fully labeled. However, in practice, fully labeled data is often hard to obtain, as the participants may not have sufficient domain expertise, or they lack the motivation and tools to label data. Therefore, the problem of federated learning without full labels is important in real-world FL applications. In this paper, we discuss how the problem can be solved with machine learning techniques that leverage unlabeled data. We present a survey of methods that combine FL with semi-supervised learning, self-supervised learning, and transfer learning methods. We also summarize the datasets used to evaluate FL methods without full labels. Finally, we highlight future directions in the context of FL without full labels.\n",
            "----------------------------------------\n",
            "Title: Diagnosing Skin Cancer using Machine Learning Techniques\n",
            "Abstract: Melanoma skin cancer is one of the deadly types of skin cancer and Biopsy is the method that is used to detect this cancer and success rate depends on performance of a trained doctor. The biopsy Process is very painful and requires considerable time. So, there is a need for a technique that can detect melanoma cancer that could avoid biopsy and that would be based on looking deep into skin cancer images. This paper has conducted a study on image classification of melanoma skin cancer using machine learning and various neural network techniques. The stages of the cancer image classification process melanoma skin in this study include the preprocessing process, segmentation, feature extraction with ABCD namely Asymmetry, Border Irregularity, Color Variation and Diameter. Subsequently, it's quantified that both the machine learning and neural network can be used for skin cancer diagnostics.\n",
            "----------------------------------------\n",
            "Title: Clean-label Backdoor Attack on Machine Learning-based Malware Detection Models and Countermeasures\n",
            "Abstract: In recent years, machine learning technology has been extensively utilized, leading to increased attention to the security of AI systems. In the field of image recognition, an attack technique called clean-label backdoor attack has been widely studied, and it is more difficult to detect than general backdoor attacks because data labels do not change when tampering with poisoning data during model training. However, there remains a lack of research on malware detection systems. Some of the current work is under the white-box assumption that requires knowledge of machine learning-based models which can be advantageous for attackers. In this study, we focus on clean-label backdoor attacks in malware detection systems and propose a new clean-label backdoor attack under the black-box assumption that does not require knowledge of machine learning-based models, which is riskier. The experimental evaluation of the proposed attack method shows that the attack success rate is up to 80.50% when the poisoning rate is 14.00%, demonstrating the effectiveness of the proposed attack method. In addition, we experimentally evaluated the effectiveness of the dimensionality reduction techniques in preventing clean-label backdoor attacks, and showed that it can reduce the attack success rate by 76.00%.\n",
            "----------------------------------------\n",
            "Title: Response Time Determinism in Healthcare Data Analytics Using Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Rapidly adapting machine learning methods for brain-computer interfaces\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: SENTRI: Jurnal Riset Ilmiah\n",
            "Abstract: : Deteksi warna merupakan salah satu metode yang dapat digunakan untuk tracking objek maupun klasifikasi benda dalam robotic dan aplikasi lainnya. Dalam paper ini dibahas mengenai deteksi warna primer dengan memanfaatkan webcam yang terdapat pada laptop. Inisialisasi awal variable HSV amatlah penting untuk menentukan warna yang diinginkan. Berdasarkan variable warna dapat didefinisikan dan dilakukan deteksi lebih lanjut. Dari hasil percobaan, terdapat non objek yang tedeteksi akibat system yang bersifat real-time sehingga diperlukan tambahan machine learning sebagai penstabil data yang ditangkap kamera\n",
            "----------------------------------------\n",
            "Title: Precision therapy for ulcerative colitis: insights from mitochondrial dysfunction interacting with the immune microenvironment\n",
            "Abstract: Background Accumulating evidence reveals mitochondrial dysfunction exacerbates intestinal barrier dysfunction and inflammation. Despite the growing knowledge of mitochondrial dysfunction and ulcerative colitis (UC), the mechanism of mitochondrial dysfunction in UC remains to be fully explored. Methods We integrated 1137 UC colon mucosal samples from 12 multicenter cohorts worldwide to create a normalized compendium. Differentially expressed mitochondria-related genes (DE-MiRGs) in individuals with UC were identified using the “Limma” R package. Unsupervised consensus clustering was utilized to determine the intrinsic subtypes of UC driven by DE-MiRGs. Weighted gene co-expression network analysis was employed to investigate module genes related to UC. Four machine learning algorithms were utilized for screening DE-MiRGs in UC and construct MiRGs diagnostic models. The models were developed utilizing the over-sampled training cohort, followed by validation in both the internal test cohort and the external validation cohort. Immune cell infiltration was assessed using the Xcell and CIBERSORT algorithms, while potential biological mechanisms were explored through GSVA and GSEA algorithms. Hub genes were selected using the PPI network. Results The study identified 108 DE-MiRGs in the colonic mucosa of patients with UC compared to healthy controls, showing significant enrichment in pathways associated with mitochondrial metabolism and inflammation. The MiRGs diagnostic models for UC were constructed based on 17 signature genes identified through various machine learning algorithms, demonstrated excellent predictive capabilities. Utilizing the identified DE-MiRGs from the normalized compendium, 941 patients with UC were stratified into three subtypes characterized by distinct cellular and molecular profiles. Specifically, the metabolic subtype demonstrated enrichment in epithelial cells, the immune-inflamed subtype displayed high enrichment in antigen-presenting cells and pathways related to pro-inflammatory activation, and the transitional subtype exhibited moderate activation across all signaling pathways. Importantly, the immune-inflamed subtype exhibited a stronger correlation with superior response to four biologics: infliximab, ustekinumab, vedolizumab, and golimumab compared to the metabolic subtype. Conclusion This analysis unveils the interplay between mitochondrial dysfunction and the immune microenvironment in UC, thereby offering novel perspectives on the potential pathogenesis of UC and precision treatment of UC patients, and identifying new therapeutic targets.\n",
            "----------------------------------------\n",
            "Title: Identification of Multimorbidity Patterns in Rheumatoid Arthritis Through Machine Learning\n",
            "Abstract: Recognizing that the interrelationships between chronic conditions that complicate rheumatoid arthritis (RA) are poorly understood, we aimed to identify patterns of multimorbidity and to define their prevalence in RA through machine learning.\n",
            "----------------------------------------\n",
            "Title: Contextual Sentence Decomposition\n",
            "Abstract: In this thesis, we introduce and study contextual sentence decomposition, which, intuitively, decomposes a given sentence into parts that semantically “belong together”. For example, a valid decomposition of the sentence “Usable parts of rhubarb include the edible stalks and the medicinally used roots, however its leaves are toxic” are the sub-sentences “Usable parts of rhubarb include the edible stalks”, “Usable parts of rhubarb include the edible stalks” and “however its leaves are toxic”. Our motivation for this problem comes from semantic full-text search. For a query plant edible leaves, semantic full-text search returns passages where instances of a plant, such as “rhubarb” (and not the word “plant”), are mentioned along with the words “edible” and “leaves”. One of the results this query might erroneously return is the original sentence above. With contextual sentence decomposition we avoid this false-positive, while at the same time maintaining the true factual contents of the original sentence. We propose two approaches for our problem, one based on a set of rules and one using machine learning. On a manually assembled ground truth, we achieve an F-measure of about 65 percent for the former and of 40 percent for the latter. For the semantic full-text search based on these approaches, evaluated on the English Wikipedia (27 GB of raw text), we achieve improvements nearly doubling the F-measure for some queries.\n",
            "----------------------------------------\n",
            "Title: Machine learning for improved dengue diagnosis, Puerto Rico\n",
            "Abstract: Background:Diagnosing dengue accurately, especially in resource-limited settings, remains challenging due to overlapping symptoms with other febrile illnesses and limitations of current diagnostic methods. This study aimed to develop machine learning (ML) models that leverage readily available clinical data to improve diagnostic accuracy for dengue, potentially offering a more accessible and rapid diagnostic tool for healthcare providers. Methods:We used data from the Sentinel Enhanced Dengue Surveillance System (SEDSS) in Puerto Rico (May 2012-June 2024). SEDSS primarily targets acute febrile illness but also includes cases with other symptoms during outbreaks (e.g., Zika and COVID-19). ML models (logistic regression, random forest, support vector machine, artificial neural network, adaptive boosting, light gradient boosting machine [LightGBM], and extreme gradient boosting [XGBoost]) were evaluated across different feature sets, including demographic, clinical, laboratory, and epidemiological variables. Model performance was assessed using the area under the receiver operating characteristic curve (AUC), where higher AUC values indicate better performance in distinguishing dengue cases from non-dengue cases. Results:Among 49,679 patients in SEDSS, 1,640 laboratory-confirmed dengue cases were identified.TheXGBoost and LightGBM models achieved the highest diagnostic accuracy, with AUCs exceeding 90%, particularly with comprehensive feature sets. Incorporating predictors such as monthly dengue incidence, leukopenia, thrombocytopenia, rash, age, and absence of nasal discharge significantly enhanced model sensitivity and specificity for diagnosing dengue. Adding more relevant clinical and epidemiological features consistently improved the models' ability to correctly identify dengue cases. Conclusions:ML models, especially XGBoost and LightGBM, show promise for improving diagnostic accuracy for dengue using widely accessible clinical data, even in resource-limited settings. Future research should focus on developing user-friendly tools, such as mobile apps, web-based platforms, or clinical decision systems integrated into electronic health records, to implement these models in clinical practice and exploring their application for predicting dengue.\n",
            "----------------------------------------\n",
            "Title: Machine learning based algorithms for uncertainty quantification in numerical weather prediction models\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Based Price Forecasting for Polypropylene Granules in Thailand\n",
            "Abstract: The plastic industry plays a vital role in Thailand, with a significant dependence on plastic materials for a majority of industrial products. Among the various types of plastics, polypropylene (PP) emerges as the most extensively used, making it indispensable for the country's plastic industry. This research focuses on presenting and comparing forecasting models for the price of PP granules in Thailand. The primary objective is to identify the most accurate forecasting model, with the mean absolute percentage error (MAPE) serving as the criterion for assessing the forecast model's performance. Three machine learning forecasting models, namely Support Vector Regression (SVR), eXtreme Gradient Boosting (XGBoost), and Artificial Neural Network (ANN), are employed in the study. The findings reveal that the ANN model demonstrates the highest accuracy, achieving a MAPE of 5.89% on the test dataset.\n",
            "----------------------------------------\n",
            "Title: Regression Training using Model Parallelism in a Distributed Cloud\n",
            "Abstract: Machine learning requires a relevant amount of computational resources and it is usually executed in high-capacity centralized cloud infrastructures (e.g., data centers). In such infrastructures, resources are shared in a scalable manner through instantiation and orchestration of multiple virtualized services. Emerging trends in machine learning are distribution and parallelization of model training, which allows the execution of model training tasks in multiple distributed computational domains, with the aim of reducing the overall training time. A possible drawback in decentralization of machine learning is that performance latency issues may arise when the computation of training is geographically distributed to nodes with long distance from each other. One way to reduce latency is to utilize edge computing infrastructure, i.e., to distribute computation near the origin of the request. As edge resources can be scarce, it is important to orchestrate the model training in a parallelized manner. To this extent, in order to effectively ease the use of parallelization both in centralized and in distributed scenarios, we propose and implement a concept that we refer to Intelligent Agent (IA). An IA is responsible for instantiating and scheduling of the machine learning tasks (e.g., model training), and deriving inferences. In our solution, model training is distributed to multiple IAs in parallel. Each IA is packaged into a Linux container in order to take advantage of container portability across heterogenous deployments and to reuse existing container orchestration tools. We validate our proposal by deploying and instantiating multiple IAs across a distributed cloud environment, where each IA is accounting for a fixed amount of computational resources. Keywords - Intelligent agent, Model parallelism, Regression training, Intelligent cloud\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Approach for Steel Surface Textural Defect Classification Based on Wavelet Scattering Features and PCA\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Anomaly detection of electricity load data based on MixMatch\n",
            "Abstract: With the development of power industry, electricity has become one of the most important energy sources in our country, related to the lifeline of the country's economy. The electricity system is becoming more and more mature, but abnormal electricity consumption behaviors are also emerging endlessly, causing potential safety hazards in the electricity industry and even the electricity supply system. Considering the lack of abnormal annotations in the electricity load data, this paper proposes a semi-supervised electricity load data anomaly detection method based on MixMatch. Firstly, data cleaning of electricity load data is used to remove incorrect data. Secondly, Convolutional Autoencoder (CAE) is used to extract its time-domain and frequency-domain features separately, and the features are combined through feature fusion. Thirdly, the Borderline Synthetic Minority Oversampling Technique (Borderline-SMOTE) is used to solve the problem of data imbalance. The MixMatch semi-supervised algorithm is used to label the abnormal data to realize the anomaly detection of the electricity load data. Finally, this paper uses the k-means clustering and T-Stochastic neighbour Embedding (T -SNE) to classify the abnormal data and visualize the data. The experimental results show that, compared with traditional machine learning methods, the proposed method has a significant improvement on AUC.\n",
            "----------------------------------------\n",
            "Title: GAN Augmentation: Augmenting Training Data using Generative Adversarial Networks\n",
            "Abstract: One of the biggest issues facing the use of machine learning in medical imaging is the lack of availability of large, labelled datasets. The annotation of medical images is not only expensive and time consuming but also highly dependent on the availability of expert observers. The limited amount of training data can inhibit the performance of supervised machine learning algorithms which often need very large quantities of data on which to train to avoid overfitting. So far, much effort has been directed at extracting as much information as possible from what data is available. Generative Adversarial Networks (GANs) offer a novel way to unlock additional information from a dataset by generating synthetic samples with the appearance of real images. This paper demonstrates the feasibility of introducing GAN derived synthetic data to the training datasets in two brain segmentation tasks, leading to improvements in Dice Similarity Coefficient (DSC) of between 1 and 5 percentage points under different conditions, with the strongest effects seen fewer than ten training image stacks are available.\n",
            "----------------------------------------\n",
            "Title: A Personal Intelligent Information Assistant Based on Web Mining\n",
            "Abstract: Web mining technology and web information service with personalization and initiative are research focus all long. The studies on both problems also have lots of difficulties because the web data with complicated structure is a great deal and changeful. In this paper, we integrate Web mining with agent and machine learning, and design a personal intelligent information assistant based on web mining (PIIA) at the center of user, and design in detail its primary function. lastly the characteristic of the system is expounded.\n",
            "----------------------------------------\n",
            "Title: Novel Hypoxia-related Biomarkers and Targeted Drugs for Acute Myocardial Infarction Revealed by Bioinformatics\n",
            "Abstract: \n",
            "\n",
            "Acute myocardial infarction (MI) is a serious emergency disease with high\n",
            "mortality. Hypoxia is associated with unfavorable outcomes in cancer patients. Nevertheless, there\n",
            "remains a shortage of effective hypoxia-related biomarkers to forecast the prognosis of acute MI\n",
            "patients and to identify targeted therapies.\n",
            "\n",
            "\n",
            "\n",
            "First, data on acute MI patient samples and hypoxia-related genes were obtained based on\n",
            "public databases. Hypoxia-related gene scores were calculated by single sample Gene Set Enrichment\n",
            "Analysis (ssGSEA). Hypoxia-related hub genes in acute MI were screened via weighted correlation\n",
            "network analysis (WGCNA). Acute MI samples were analyzed for differentially expressed\n",
            "genes (DEGs) using the limma package and intersected with hub gene for hypoxia-related DEGs.\n",
            "Then, machine learning methods were used to identify hypoxia-related biomarkers in acute MI. Gene\n",
            "set enrichment analysis (GSEA) and immune infiltration analysis were performed on biomarkers.\n",
            "Targeted drug prediction and molecular docking were conducted based on biomarkers.\n",
            "\n",
            "\n",
            "\n",
            "1) To determine whether there is difference in hypoxia-related gene score between acute MI and control samples. 2) To identify the hypoxia-related hubgene in acute MI. 3) To screen the hypoxia-related biomarkers for acute MI. 4) To assess the correlation between biomarkers and immune cells infiltration. 5) To predict drugs for acute MI based on biomarkers.\n",
            "\n",
            "\n",
            "\n",
            "The hypoxia-related gene score of the acute MI group was higher than the control group,\n",
            "and 319 hypoxia-related hub genes in acute MI were acquired. A total of 7 hypoxia-related DEGs\n",
            "were obtained by WGCNA and DEGs analysis. Then, 2 hypoxia-related biomarkers in acute MI,\n",
            "HAUS3 and SLC2A3, were identified based on machine learning algorithms. Both HAUS3 and\n",
            "SLC2A3 were enriched in the ribosome and spliceosome pathways. The expression levels of SLC2A3\n",
            "and HAUS3 were correlated with immune cell infiltration. Furthermore, 8-hydroxyquinoline, perhexiline,\n",
            "and sotalol were selected as the targeted drugs, which could bind to HAUS3 and SLC2A3.\n",
            "\n",
            "\n",
            "\n",
            "In short, we screened two important hypoxia-related biomarkers and three potential\n",
            "target drugs based on bioinformatics techniques. This provides new ideas and potential drug targets\n",
            "for early diagnosis and targeted therapy of acute MI.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Optimizing the development of contaminated land in China: Exploring machine-learning to identify risk markers.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Cybersecurity enhancement to detect credit card frauds in health care using new machine learning strategies\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Parkinson's disease detection using olfactory loss and REM sleep disorder features\n",
            "Abstract: In Parkinson's disease, there exists a prodromal or a premotor phase characterized by symptoms like olfactory loss and sleep disorders, which may last for years or even decades before the onset of motor clinical symptoms. Diagnostic tools based on machine learning using these features can be very useful as they have the potential in early diagnosis of the disease. In the paper, we use olfactory loss feature from 40-item University of Pennsylvania Smell Identification Test (UPSIT) and Sleep behavior disorder feature from Rapid eye movement sleep Behavior Disorder Screening Questionnaire (RBDSQ), obtained from the Parkinson's Progression Marker's Initiative (PPMI) database, to develop automated diagnostic models using Support Vector Machine (SVM) and classification tree methods. The advantage of using UPSIT and RBDSQ is that they are quick, cheap, and can be self-administered. Results show that the models performed with high accuracy and sensitivity, and that they have the potential to aid in early diagnosis of Parkinson's disease.\n",
            "----------------------------------------\n",
            "Title: K-Local hyperplane distance nearest neighbor algorithm and protein fold recognition\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Leveraging Flask API and Machine Learning to Forecast Multiple Diseases\n",
            "Abstract: The study described in this abstract used machine learning to predict several diseases, and it integrated the model into a Flask API. A user-friendly platform for disease prediction based on patient symptoms and medical history was the goal of the paper. A number of strategies were used to optimize the predictive performance once the machine learning model had been trained on a sizable dataset of patient records. The model was made accessible as a web service through the usage of the Flask API, enabling simple deployment and integration into current healthcare systems. The study's findings demonstrated that the model could accurately forecast diseases with a high degree of precision, and the Flask API gave healthcare professionals an easy way to use the model in real-world settings. The study underscores the significance of developing open and user-friendly platforms for healthcare applications and shows the potential of machine learning and online APIs in improving disease detection. Additionally, the study discovered that the model could correctly identify disorders even in the absence of conclusive diagnostic tests.\n",
            "----------------------------------------\n",
            "Title: Pre-trained deep learning models for brain MRI image classification\n",
            "Abstract: Brain tumors are serious conditions caused by uncontrolled and abnormal cell division. Tumors can have devastating implications if not accurately and promptly detected. Magnetic resonance imaging (MRI) is one of the methods frequently used to detect brain tumors owing to its excellent resolution. In the past few decades, substantial research has been conducted in the field of classifying brain images, ranging from traditional methods to deep-learning techniques such as convolutional neural networks (CNN). To accomplish classification, machine-learning methods require manually created features. In contrast, CNN achieves classification by extracting visual features from unprocessed images. The size of the training dataset had a significant impact on the features that CNN extracts. The CNN tends to overfit when its size is small. Deep CNNs (DCNN) with transfer learning have therefore been developed. The aim of this work was to investigate the brain MR image categorization potential of pre-trained DCNN VGG-19, VGG-16, ResNet50, and Inception V3 models using data augmentation and transfer learning techniques. Validation of the test set utilizing accuracy, recall, Precision, and F1 score showed that the pre-trained VGG-19 model with transfer learning exhibited the best performance. In addition, these methods offer an end-to-end classification of raw images without the need for manual attribute extraction.\n",
            "----------------------------------------\n",
            "Title: Machine learning forecasts of Scandinavian numerical weather prediction wind model residuals with control theory for wind energy\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Information retrieval using machine learning from breast cancer diagnosis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Heat Transport Properties of Au-Nanoparticles Supported by TiO2: Insights from E(3)-Equivariant Machine Learning Potentials.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Novel Statistical Regularized Extreme Learning Algorithm to Address the Multicollinearity in Machine Learning\n",
            "Abstract: The multicollinearity problem is a common phenomenon in data-driven studies, significantly affecting the performance of machine learning algorithms during the process of extracting information from data. Despite its widespread use across various fields, the extreme learning machine (ELM) also suffers from multicollinearity issues. To address this challenge, the ridge and Liu estimators, drawn from statistics literature, have been integrated into ELM theory, resulting in a notable advancement. This study aims to further enhance the capabilities of ridge and Liu estimators within the ELM framework by introducing two innovative two-parameter algorithms (TP1-ELM and TP2-ELM) that simultaneously incorporate both estimators. The proposed algorithms undergo comprehensive benchmarking against ELM, ELM-based algorithms, and other commonly used machine learning techniques across seven diverse datasets. Benchmark results demonstrate that the proposed algorithms consistently outperform both ELM-focused approaches and traditional machine learning algorithms on most datasets, yielding more generalizable and stable results. These findings suggest that the proposed algorithms offer a promising alternative to traditional machine learning techniques for regression and classification tasks, particularly in scenarios where multicollinearity is a concern.\n",
            "----------------------------------------\n",
            "Title: Artificial Intelligence in General\n",
            "Abstract: There are many kinds of uses for artificial intelligence (AI) in almost every field. AI is quite often used for control, computer aided design (CAD) and computer aided manufacturing (CAM), machine control, computer integrated manufacturing (CIM), production spot control, factory control, intelligent control, intelligent systems, deep learning, the cloud, knowledge bases, database, management, production systems, statistics, to assist sales forces, environment examination, agriculture, art, livings, daily life, etc. The present AI uses will be reexamined whether there is any matter to be considered further or not in AI research directions and their purposes behind the current status by looking at the history of AI development.\n",
            "----------------------------------------\n",
            "Title: Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks\n",
            "Abstract: The integration of Machine Learning and Artifi-cial Intelligence (ML/AI) into fifth-generation (5G) networks has made evident the limitations of network intelligence with ever-increasing, strenuous requirements for current and next-generation devices. This transition to ubiquitous intelligence demands high connectivity, synchronicity, and end-to-end communication between users and network operators, and will pave the way towards full network automation without human intervention. Intent-based networking is a key factor in the reduction of human actions, roles, and responsibilities while shifting towards novel extraction and interpretation of automated network management. This paper presents the development of a custom Large Language Model (LLM) for 5G and next-generation intent-based networking and provides insights into future LLM developments and integrations to realize end-to-end intent-based networking for fully automated network intelligence.\n",
            "----------------------------------------\n",
            "Title: Zeroth-Order Online Alternating Direction Method of Multipliers: Convergence Analysis and Applications\n",
            "Abstract: In this paper, we design and analyze a new zeroth-order online algorithm, namely, the zeroth-order online alternating direction method of multipliers (ZOO-ADMM), which enjoys dual advantages of being gradient-free operation and employing the ADMM to accommodate complex structured regularizers. Compared to the first-order gradient-based online algorithm, we show that ZOO-ADMM requires $\\sqrt{m}$ times more iterations, leading to a convergence rate of $O(\\sqrt{m}/\\sqrt{T})$, where $m$ is the number of optimization variables, and $T$ is the number of iterations. To accelerate ZOO-ADMM, we propose two minibatch strategies: gradient sample averaging and observation averaging, resulting in an improved convergence rate of $O(\\sqrt{1+q^{-1}m}/\\sqrt{T})$, where $q$ is the minibatch size. In addition to convergence analysis, we also demonstrate ZOO-ADMM to applications in signal processing, statistics, and machine learning.\n",
            "----------------------------------------\n",
            "Title: Unsupervised Assessment of Balance and Falls Risk Using a Smartphone and Machine Learning\n",
            "Abstract: Assessment of health and physical function using smartphones (mHealth) has enormous potential due to the ubiquity of smartphones and their potential to provide low cost, scalable access to care as well as frequent, objective measurements, outside of clinical environments. Validation of the algorithms and outcome measures used by mHealth apps is of paramount importance, as poorly validated apps have been found to be harmful to patients. Falls are a complex, common and costly problem in the older adult population. Deficits in balance and postural control are strongly associated with falls risk. Assessment of balance and falls risk using a validated smartphone app may lessen the need for clinical assessments which can be expensive, requiring non-portable equipment and specialist expertise. This study reports results for the real-world deployment of a smartphone app for self-directed, unsupervised assessment of balance and falls risk. The app relies on a previously validated algorithm for assessment of balance and falls risk; the outcome measures employed were trained prior to deployment on an independent data set. Results for a sample of 594 smartphone assessments from 147 unique phones show a strong association between self-reported falls history and the falls risk and balance impairment scores produced by the app, suggesting they may be clinically useful outcome measures. In addition, analysis of the quantitative balance features produced seems to suggest that unsupervised, self-directed assessment of balance in the home is feasible.\n",
            "----------------------------------------\n",
            "Title: Review\n",
            "Abstract: Deep Learning is-one of the machine learning areas, applied in recent areas. Various techniques have been proposed depends on varieties of learning, including unsupervised, semi-supervised, and supervised-learning. Some of the experimental results proved that the deep learning systems are performed well compared to conventional machine learning systems in image processing, computer vision and pattern recognition. This paper provides a brief survey, beginning with Deep Neural Network (DNN) in Deep Learning area. The survey moves on-the Convolutional Neural Network (CNN) and its architectures, such as LeNet, AlexNet, GoogleNet, VGG16, VGG19, Resnet50 etc. We have included transfer learning by using the CNN’s pre-trained architectures. These architectures are tested with large ImageNet data sets. The deep learning techniques are analyzed with the help of most popular data sets, which are freely available in web. Based on this survey, conclude the performance of the system depends on the GPU system.\n",
            "----------------------------------------\n",
            "Title: Pre-Processing Data with a Horizontal Tuning Framework Using Microservices and its Impact on Machine Learning Algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Detecting Risk Gene and Pathogenic Brain Region in EMCI Using a Novel GERF Algorithm Based on Brain Imaging and Genetic Data\n",
            "Abstract: Fusion analysis of disease-related multi-modal data is becoming increasingly important to illuminate the pathogenesis of complex brain diseases. However, owing to the small amount and high dimension of multi-modal data, current machine learning methods do not fully achieve the high veracity and reliability of fusion feature selection. In this paper, we propose a genetic-evolutionary random forest (GERF) algorithm to discover the risk genes and disease-related brain regions of early mild cognitive impairment (EMCI) based on the genetic data and resting-state functional magnetic resonance imaging (rs-fMRI) data. Classical correlation analysis method is used to explore the association between brain regions and genes, and fusion features are constructed. The genetic-evolutionary idea is introduced to enhance the classification performance, and to extract the optimal features effectively. The proposed GERF algorithm is evaluated by the public Alzheimer's Disease Neuroimaging Initiative (ADNI) database, and the results show that the algorithm achieves satisfactory classification accuracy in small sample learning. Moreover, we compare the GERF algorithm with other methods to prove its superiority. Furthermore, we propose the overall framework of detecting pathogenic factors, which can be accurately and efficiently applied to the multi-modal data analysis of EMCI and be able to extend to other diseases. This work provides a novel insight for early diagnosis and clinicopathologic analysis of EMCI, which facilitates clinical medicine to control further deterioration of diseases and is good for the accurate electric shock using transcranial magnetic stimulation.\n",
            "----------------------------------------\n",
            "Title: Comprehending Lexical and Affective Ontologies in the Demographically Diverse Spatial Social Media Discourse\n",
            "Abstract: This study aims to comprehend linguistic and sociodemographic features, encompassing English language styles, conveyed sentiments, and lexical diversity within spatial online social media review data. To this end, we undertake a case study that scrutinizes reviews composed by two distinct and demographically diverse groups. Our analysis entails the extraction and examination of various statistical, grammatical, and sentimental features from these two groups. Subsequently, we leverage these features with machine learning (ML) classifiers to discern their potential in effectively differentiating between the groups. Our investigation unveils substantial disparities in certain linguistic attributes between the two groups. When integrated into ML classifiers, these attributes exhibit a marked efficacy in distinguishing the groups, yielding a macro F1 score of approximately 0.85. Furthermore, we conduct a comparative evaluation of these linguistic features with word n-gram-based lexical features in discerning demographically diverse review data. As expected, the n-gram lexical features, coupled with finetuned transformer-based models, show superior performance, attaining accuracies surpassing 95% and macro F1 scores exceeding 0.96. Our meticulous analysis and comprehensive evaluations substantiate the efficacy of linguistic and sentimental features in effectively discerning demographically diverse review data. The findings of this study provide valuable guidelines for future research endeavors concerning the analysis of demographic patterns in textual content across various social media platforms.\n",
            "----------------------------------------\n",
            "Title: A Novel Feature Encoding Scheme for Machine Learning Based Malware Detection Systems\n",
            "Abstract: Malware detection is an ever-evolving area given that the strides in the detection capabilities being matched by radical attempts to bypass the detection. As the sophistication of malware continues to increase, the demand for innovative approaches to improve detection capabilities become paramount. Machine learning/Deep learning models are being increasingly used for Malware Detection, however one of the most important and frequently overlooked aspects of building such models is feature encoding. This research paper explores the importance of feature encoding to improve the efficiency of threat detection and proposes a novel entropy-based encoding scheme for the categorical features present in the data extracted from malicious inputs. The KDDCUP99, UNSW-NB15 and CIC-Evasive-PDFMal2022 datasets have been used to evaluate the effectiveness of the proposed encoding scheme. The results of the proposed encoding scheme are validated against seven other encoding schemes to ascertain the credibility and usability of the proposed scheme. The efficiency of the proposed system evaluated by applying different encoded versions of the datasets to train various machine learning models and determining the classification performance of the models on each dataset. The machine learning models trained with the proposed encoding scheme produced stable classification results and outperformed other encoding schemes when dimensionality reduction was applied on the data. The ensemble classifier trained using the proposed scheme was able to classify the data with an F1 score of 99.99% when the dimension-reduced entropy-encoded KDD Cup99 dataset was used to build the model. On the CIC-Evasive-PDFMal2022 dataset, the entropy encoding has exhibited a slightly improved classification parameters with the ensemble methods yielding a peak F1 score of 99.27%. We have also determined the feature importance values of the features present in the datasets to study the change in the contribution levels of the features when multiple categorical encoding schemes are applied upon the data.\n",
            "----------------------------------------\n",
            "Title: Sistema de sugestão de produtos para e-commerce utilizando Inteligência Artificial\n",
            "Abstract: Resumo. O trabalho trata da implementação de um sistema de recomendação baseado em filtragem colaborativa, utilizando técnicas de Machine Learning e Deep Learning. Esse sistema, diferentemente de outros do tipo, não depende de avaliações de clientes e infere a popularidade dos produtos com base em seu volume e recorrência de venda. Nesse estudo, as recomendações geradas são analisadas a fim de obter insights sobre as lojas virtuais das quais se originaram.\n",
            "----------------------------------------\n",
            "Title: Application of Machine Learning Methods in Inferring Surface Water Groundwater Exchanges using High Temporal Resolution Temperature Measurements\n",
            "Abstract: We examine the ability of machine learning (ML) and deep learning (DL) algorithms to infer surface/ground exchange flux based on subsurface temperature observations. The observations and fluxes are produced from a high-resolution numerical model representing conditions in the Columbia River near the Department of Energy Hanford site located in southeastern Washington State. Random measurement error, of varying magnitude, is added to the synthetic temperature observations. The results indicate that both ML and DL methods can be used to infer the surface/ground exchange flux. DL methods, especially convolutional neural networks, outperform the ML methods when used to interpret noisy temperature data with a smoothing filter applied. However, the ML methods also performed well and they are can better identify a reduced number of important observations, which could be useful for measurement network optimization. Surprisingly, the ML and DL methods better inferred upward flux than downward flux. This is in direct contrast to previous findings using numerical models to infer flux from temperature observations and it may suggest that combined use of ML or DL inference with numerical inference could improve flux estimation beneath river systems.\n",
            "----------------------------------------\n",
            "Title: Telephone-based Dementia Screening I: Automated Semantic Verbal Fluency Assessment\n",
            "Abstract: Dementia has a large economic impact on our society as cost-effective population-wide screening for early signs of dementia is still an unsolved medical supply resource problem. A solution should be fast, require a minimum of external material, and automatically indicate potential persons at risk of cognitive decline. Despite encouraging results, leveraging pervasive sensing technologies for automatic dementia screening, there are still two main issues: significant hardware costs or installation efforts and the challenge of effective pattern recognition. Conversely, automatic speech recognition (ASR) and speech analysis have reached sufficient maturity and allow for low-tech remote telephone-based screening scenarios. Therefore, we examine the technologic feasibility of automatically assessing a neuropsychological test---Semantic Verbal Fluency (SVF)--via a telephone-based solution. We investigate its suitability for inclusion into an automated dementia frontline screening and global risk assessment, based on concise telephone-sampled speech, ASR and machine learning classification. Results are encouraging showing an area under the curve (AUC) of 0.85. We observe a relatively low word error rate of 33% despite phone-quality speech samples and a mean age of 77 years of the participants. The automated classification pipeline performs equally well compared to the classifier trained on manual transcriptions of the same speech data. Our results indicate SVF as a prime candidate for inclusion into an automated telephone-screening system.\n",
            "----------------------------------------\n",
            "Title: Analysis Model of Terrorist Attacks Based on Big Data\n",
            "Abstract: With the continuous deepening of international anti-terrorism movement the anti-terrorism has entered a new stage5 and it is facing new challenges. One of the new challenges is to extract useful and valuable information from massive data efficiently. The anti-terrorism system model based on local shallow information is imperfect, which is not conducive to obtaining accurate prediction results. The shortcomings of existing research are the lack of comprehensive analysis and deeper mining of data. In order to improve the efficiency and accuracy of the present anti-terrorism system5 we propose an effective method for risk assessment and prediction based on machine learning by using Global Terrorism Database (GTD). There are four basic steps: first, we reduce the data dimension through correlation calculation and Singular Value Decomposition(SVD) then the function is established to rank the harmfulness of terrorist attacks; second, the cascaded network with attention mechanism is used to predict suspects; third, k-means is used to cluster the regions of terrorist attacks5 and then we establish a generalized linear regression model to predict the situation of terrorist attacks. We verify the feasibility of the model by comparing with the real data. The experimental results show that the proposed method can analyze and predict the information related to terrorist attacks comprehensively and accurately.\n",
            "----------------------------------------\n",
            "Title: Machine learning-based grassland aboveground biomass estimation and its response to climate variation in Southwest China\n",
            "Abstract: The demand for accurate estimation of aboveground biomass (AGB) at high spatial resolution is increasing in grassland-related research and management, especially for those regions with complex topography and fragmented landscapes, where grass and shrub are interspersed. In this study, based on 519 field AGB observations, integrating Synthetic Aperture Radar (SAR; Sentinel-1) and high-resolution (Sentinel-2) remote sensing images, environmental and topographical data, we estimated the AGB of mountain grassland in Southwest China (Yunnan Province and Guizhou Province) by using remote sensing algorithms ranging from traditional regression to cutting edge machine learning (ML) and deep learning (DL) models. Four models (i.e., multiple stepwise regression (MSR), random forest (RF), support vector machine (SVM) and convolutional neural network (CNN)) were developed and compared for AGB simulation purposes. The results indicated that the RF model performed the best among the four models (testing dataset: decision co-efficient (R2) was 0.80 for shrubland and 0.75 for grassland, respectively). Among all input variables in the RF model, the vegetation indices played the most important role in grassland AGB estimation, with 6 vegetation indices (EVI, EVI2, NDVI, NIRv, MSR and DVI) in the top 10 of input variables. For shrubland, however, topographical factors (elevation, 12.7% IncMSE (increase in mean squared error)) and SAR data (VH band, 11.3% IncMSE) were the variables which contributed the most in the AGB estimation model. By comparing the input variables to the RF model, we found that integrating SAR data has the potential to improve grassland AGB estimation, especially for shrubland (26.7% improvement in the estimation of shrubland AGB). Regional grassland AGB estimation showed a lower mean AGB in Yunnan Province (443.6 g/m2) than that in Guizhou Province (687.6 g/m2) in 2021. Moreover, the correlation between five consecutive years (2018–2022) of AGB data and climatic factors calculated by partial correlation analysis showed that regional AGB was positively related with mean annual precipitation in more than 70% of the grassland and 60% of the shrubland area, respectively. Also, we found a positive relationship with mean annual temperature in 62.8% of the grassland and 55.6% of the shrubland area, respectively. This study demonstrated that integrating SAR into grassland AGB estimation led to a remote sensing estimation model that greatly improved the accuracy of modeled mountain grassland AGB in southwest China, where the grassland consists of a complex mix of grass and shrubs.\n",
            "----------------------------------------\n",
            "Title: Limbic/paralimbic connection weakening in preschool autism-spectrum disorder based on diffusion basis spectrum imaging.\n",
            "Abstract: This study aims to investigate the value of basal ganglia and limbic/paralimbic networks alteration in identifying preschool children with ASD and normal controls using diffusion basis spectrum imaging (DBSI). DBSI data from 31 patients with ASD and 30 NC were collected in Hunan Children's Hospital. All data were imported into the post-processing server. The most discriminative features were extracted from the connection, global and nodal metrics separately using the two-sample t-test. To effectively integrate the multimodal information, we employed the multi-kernel learning support vector machine (MKL-SVM). In ASD group, the value of global efficiency, local efficiency, clustering coefficient and synchronization were lower than NC group, while modularity score, hierarchy, normalized clustering coefficient, normalized characteristic path length, small-world, characteristic path length and assortativity were higher. Significant weaker connections are mainly distributed in the limbic/paralimbic networks. The model combining consensus connection, global and nodal graph metrics features can achieve the best performance in identifying ASD patients, with an accuracy of 96.72%.The most specific brain regions connection weakening associated with preschool ASD are predominantly located in limbic/paralimbic networks, suggesting their involvement in abnormal brain development processes. The effective combination of connection, global and nodal metrics information by MKL-SVM can effectively distinguish patients with ASD.\n",
            "----------------------------------------\n",
            "Title: “Decision tree analysis for assessing the risk of post-traumatic haemorrhage after mild traumatic brain injury in patients on oral anticoagulant therapy”\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Open-Ended Questions\n",
            "Abstract: Natural language processing (NLP) is the field of decoding human written language. This chapter responds to the growing interest in using machine learning–based NLP approaches for analyzing open-ended employee survey responses. These techniques address scalability and the ability to provide real-time insights to make qualitative data collection equally or more desirable in organizations. The chapter walks through the evolution of text analytics in industrial–organizational psychology and discusses relevant supervised and unsupervised machine learning NLP methods for survey text data, such as latent Dirichlet allocation, latent semantic analysis, sentiment analysis, word relatedness methods, and so on. The chapter also lays out preprocessing techniques and the trade-offs of growing NLP capabilities internally versus externally, points the readers to available resources, and ends with discussing implications and future directions of these approaches.\n",
            "----------------------------------------\n",
            "Title: Reinforcement Learning based Scheduling for Spark Jobs in Cloud Environment\n",
            "Abstract: Recently, big data computing paradigm has been gaining proliferation due to wide applications for processing enormous volumes of data to produce meaningful information. The big data computing frameworks perform data processing in cloud computing or physical on-premises. Cloud service providers provide flexible, affordable, and reliable resources that are easier to manage than on-premise physical data centers. So many organization are now moving their big data computing framework over to the cloud computing environment. However, due to several limitations, including the need to reduce costs for using virtual machines, optimize system performance by lowering the Average job completion time, and adhere to service level agreements for the jobs, scheduling Spark jobs efficiently in a cloud environment is a challenging problem. Numerous heuristic-based solutions are available in the literature; however, they do not work well in heterogeneous cloud environments where many constraints are present while scheduling the jobs. So, in this paper, we have optimized the use of computing resources in a cloud environment by analyzing spark job scheduling based on reinforcement learning algorithms. The case study's proposed analysis demonstrates how a reinforcement learning algorithm enables an agent to learn the inherent properties of the computing environment for job scheduling.\n",
            "----------------------------------------\n",
            "Title: Traditional and Machine Learning Methods for Credit Scoring: an introduction\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Research on State of Health Estimation of Lithium Batteries Based on EIS and CNN-VIT Models\n",
            "Abstract: \n",
            " With the development of electric vehicles, the demand for lithium-ion batteries has been increasing annually. Accurately estimating the State of Health (SOH) of lithium-ion batteries is crucial for their efficient and reliable use. Most of the existing research on SOH estimation is based on parameters such as current, voltage, and temperature, which are prone to fluctuations. Estimating the SOH of lithium-ion batteries based on Electrochemical Impedance Spectroscopy (EIS) and data-driven approaches has been proven effective. In this paper, we explore a novel SOH estimation model for lithium batteries based on EIS and Convolutional Neural Network (CNN)-Vision Transformer (VIT). The EIS data is treated as a grayscale image, eliminating the need for manual feature extraction and simultaneously capturing both local and global features in the data. To validate the effectiveness of the proposed model, a series of simulation experiments are conducted, comparing it with various traditional machine learning models in terms of Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Coefficient of Determination (R2). The simulation results demonstrate that the proposed model performs best overall in the testing dataset at three different temperatures. This confirms that the model can accurately and stably estimate the SOH of lithium-ion batteries without requiring manual feature extraction and knowledge of battery aging temperature.\n",
            "----------------------------------------\n",
            "Title: From Big Data to Deep Data to Support People Analytics for Employee Attrition Prediction\n",
            "Abstract: In the era of data science and big data analytics, people analytics help organizations and their human resources (HR) managers to reduce attrition by changing the way of attracting and retaining talent. In this context, employee attrition presents a critical problem and a big risk for organizations as it affects not only their productivity but also their planning continuity. In this context, the salient contributions of this research are as follows. Firstly, we propose a people analytics approach to predict employee attrition that shifts from a big data to a deep data context by focusing on data quality instead of its quantity. In fact, this deep data-driven approach is based on a mixed method to construct a relevant employee attrition model in order to identify key employee features influencing his/her attrition. In this method, we started thinking ‘big’ by collecting most of the common features from the literature (an exploratory research) then we tried thinking ‘deep’ by filtering and selecting the most important features using survey and feature selection algorithms (a quantitative method). Secondly, this attrition prediction approach is based on machine, deep and ensemble learning models and is experimented on a large-sized and a medium-sized simulated human resources datasets and then a real small-sized dataset from a total of 450 responses. Our approach achieves higher accuracy (0.96, 0.98 and 0.99 respectively) for the three datasets when compared previous solutions. Finally, while rewards and payments are generally considered as the most important keys to retention, our findings indicate that ‘business travel’, which is less common in the literature, is the leading motivator for employees and must be considered within HR policies to retention.\n",
            "----------------------------------------\n",
            "Title: Evolutionary machine learning builds smart education big data platform: Data-driven higher education\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Chatbot: A Deep Neural Network Based Human to Machine Conversation Model\n",
            "Abstract: A conversational agent (chatbot) is computer software capable of communicating with humans using natural language processing. The crucial part of building any chatbot is the development of conversation. Despite many developments in Natural Language Processing (NLP) and Artificial Intelligence (AI), creating a good chatbot model remains a significant challenge in this field even today. A conversational bot can be used for countless errands. In general, they need to understand the user's intent and deliver appropriate replies. This is a software program of a conversational interface that allows a user to converse in the same manner one would address a human. Hence, these are used in almost every customer communication platform, like social networks. At present, there are two basic models used in developing a chatbot. Generative based models and Retrieval based models. The recent advancements in deep learning and artificial intelligence, such as the end-to-end trainable neural networks have rapidly replaced earlier methods based on hand-written instructions and patterns or statistical methods. This paper proposes a new method of creating a chatbot using a deep neural learning method. In this method, a neural network with multiple layers is built to learn and process the data.\n",
            "----------------------------------------\n",
            "Title: BlindFL: Vertical Federated Machine Learning without Peeking into Your Data\n",
            "Abstract: Due to the rising concerns on privacy protection, how to build machine learning (ML) models over different data sources with security guarantees is gaining more popularity. Vertical federated learning (VFL) describes such a case where ML models are built upon the private data of different participated parties that own disjoint features for the same set of instances, which fits many real-world collaborative tasks. Nevertheless, we find that existing solutions for VFL either support limited kinds of input features or suffer from potential data leakage during the federated execution. To this end, this paper aims to investigate both the functionality and security of ML modes in the VFL scenario. To be specific, we introduce BlindFL, a novel framework for VFL training and inference. First, to address the functionality of VFL models, we propose the federated source layers to unite the data from different parties. Various kinds of features can be supported efficiently by the federated source layers, including dense, sparse, numerical, and categorical features. Second, we carefully analyze the security during the federated execution and formalize the privacy requirements. Based on the analysis, we devise secure and accurate algorithm protocols, and further prove the security guarantees under the ideal-real simulation paradigm. Extensive experiments show that BlindFL supports diverse datasets and models efficiently whilst achieves robust privacy guarantees.\n",
            "----------------------------------------\n",
            "Title: A Comprehensive Survey on Conflict Detection and Resolution in Unmanned Aircraft System Traffic Management\n",
            "Abstract: The anticipated proliferation of Unmanned Aerial Vehicles (UAVs) in the airspace in the coming years has raised concerns about how to manage their flights to avoid collisions and crashes at various stages of flight. To this end, many Unmanned Aircraft Traffic Management systems (UTM) have been designed. These systems use various methods for managing UAV conflicts. Several surveys have reviewed conflict resolution methods for UAVs. However, to the best of our knowledge, there is no survey specifically addressing conflict detection and resolution methods in UTM, particularly those using AI-based methods. Therefore, this article serves as a comprehensive survey of all UAVs conflicts detection and resolution methods proposed in the literature and their use in the UTM systems. This survey classifies the methods into two categories: classical (non-learning) methods and learning-based methods. Classical methods typically rely on pre-defined algorithms or rules for UAVs to avoid collisions, whereas Artificial Intelligence-based methods, including Machine Learning (ML) and especially Reinforcement Learning (RL), enable UAVs to adapt to their environment, autonomously resolve conflicts, and exhibit intelligent behavior based on their experiences. It also presents their application in the conflict resolution service for UTMs. Additionally, the challenges and issues associated with each type of methods are discussed. This article can serve as a foundational resource for researchers in guiding their selection of methods for conflict resolution, particularly those relevant to UTM systems.\n",
            "----------------------------------------\n",
            "Title: S1417 Comparison of Logistic Regression Model With Machine Learning Models to Predict Acute Liver Injury in Patients Hospitalized With COVID-19\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Fast learning network: a novel artificial neural network with a fast learning speed\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: QGeo: Q-Learning-Based Geographic Ad Hoc Routing Protocol for Unmanned Robotic Networks\n",
            "Abstract: This letter proposes a novel protocol that uses Q-learning-based geographic routing (QGeo) to improve the network performance of unmanned robotic networks. A rapid and reliable network is essential for the remote control and monitoring of mobile robotic devices. However, controlling the network overhead required for route selection and repair is still a notable challenge, owing to high mobility of the devices. To alleviate this problem, we propose a machine-learning-based geographic routing scheme to reduce network overhead in high-mobility scenarios. We evaluate the performance of QGeo in comparison with other methods using the NS-3 simulator. We find that QGeo has a higher packet delivery ratio and a lower network overhead than existing methods.\n",
            "----------------------------------------\n",
            "Title: Development and Validation of a Machine Learning Model for Detection and Classification of Vertigo.\n",
            "Abstract: PURPOSE\n",
            "This study aims to investigate whether artificial intelligence can improve the diagnostic accuracy of vertigo related diseases.\n",
            "\n",
            "\n",
            "EXPERIMENTAL DESIGN\n",
            "Based on the clinical guidelines, clinical symptoms and laboratory test results were extracted from electronic medical records as variables. These variables were then input into a machine learning diagnostic model for classification and diagnosis. This study encompasses two primary objectives: Task 1 to distinguish between patients with Benign Paroxysmal Positional Vertigo (BPPV) and non-BPPV. In Task 2, further classifying non-BPPV patients into Ménière's Disease (MD), Vestibular Migraine (VM), and Sudden Sensorineural Hearing Loss accompanied by Vertigo (SSNHLV). The sensitivity, precision, and area under the curve (AUC) metric is primarily used to assess the performance of the machine learning model development phase in a prospective validation cohort.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "In our study, 1789 patients were recruited as the training cohort and 1148 patients as the prospective validation cohort. The comprehensive diagnostic performance of the XGBoost model surpasses that of traditional models. The sensitivity, accuracy, and AUC in task 1 were 98.32%, 87.03%, and 0.947, respectively. In task 2, the sensitivity values for MD, SSNHLV, and VM were 89.00%, 100.0%, and 79.40%, respectively. The precision values were 88.80%, 100.0%, and 80.00%, respectively. The AUC values were 0.933, 1.000, and 0.931, respectively. The model can significantly improve the accuracy of diagnosing vertigo diseases.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "This system may enhance the accuracy of classification and diagnosis of vertigo diseases. It offers initial therapy or referrals to clinical doctors, particularly in resource-limited settings.\n",
            "\n",
            "\n",
            "LEVEL OF EVIDENCE\n",
            "N/A Laryngoscope, 2024.\n",
            "----------------------------------------\n",
            "Title: Optimization of Power Efficient Spatial Division Multiplexed Submarine Cables Using Adaptive Transponders and Machine Learning\n",
            "Abstract: Historically, undersea systems capacity increases were primarily based on maximizing the total throughput per fiber. Whilst previously designed to operate at optimum launch power of the fiber, subsea systems are now designed for higher optical power efficiency. Next generation of spatial division multiplexed (SDM) cables require operation at lower signal power enabling repeater pump farming and providing higher reliability and efficiency. To adapt to these power constraints, the benefits of adaptive transponders and the application of machine learning to submarine line design are investigated.\n",
            "----------------------------------------\n",
            "Title: Sexual Trauma and Post-Traumatic Stress Disorder Among Warfighters in Army STARRS\n",
            "Abstract: Abstract : The current report presents an update of results from the previous annual report. A great deal of progress has been made over the past year. The most exciting results are those that focus on the association between self-reported risk and protective factors in the Army STARRS New Soldier Survey (NSS), which was administered during reception week, and subsequent administrative records showing that the new soldiers in the NSS either were perpetrators or victims of Military Sexual Trauma (MST) over their first two years of Army service. We used machine learning methods to develop optimal prediction equations from the NSS data. Even though final models have not yet been completed, preliminary results are very positive: showing that the 10% of new male soldiers classified as having highest risk of MST perpetration were responsible for 58.3% of all actual MST perpetration that occurred over the next two years, while the 5% of new female soldiers classified as having highest risk of MST victimization were involved in 32% of all actual MST victimization that occurred over the next two years. These percentages can only increase with model refinements that will be made over the next few months. Concentrations of risk as high as these are actionable, as they can be used to target high-risk new soldiers for enhanced preventive intervention efforts aimed at reducing incidence of MST.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Methods in Statistical Model Checking and System Design - Tutorial\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Deep Illumination: Approximating Dynamic Global Illumination with Generative Adversarial Network\n",
            "Abstract: We present Deep Illumination, a novel machine learning technique for approximating global illumination (GI) in real-time applications using a Conditional Generative Adversarial Network. Our primary focus is on generating indirect illumination and soft shadows with offline rendering quality at interactive rates. Inspired from recent advancement in image-to-image translation problems using deep generative convolutional networks, we introduce a variant of this network that learns a mapping from Gbuffers (depth map, normal map, and diffuse map) and direct illumination to any global illumination solution. Our primary contribution is showing that a generative model can be used to learn a density estimation from screen space buffers to an advanced illumination model for a 3D environment. Once trained, our network can approximate global illumination for scene configurations it has never encountered before within the environment it was trained on. We evaluate Deep Illumination through a comparison with both a state of the art real-time GI technique (VXGI) and an offline rendering GI technique (path tracing). We show that our method produces effective GI approximations and is also computationally cheaper than existing GI techniques. Our technique has the potential to replace existing precomputed and screen-space techniques for producing global illumination effects in dynamic scenes with physically-based rendering quality.\n",
            "----------------------------------------\n",
            "Title: Design and Implementation of Network Security Management System Based on K-Means Algorithm\n",
            "Abstract: With the rapid development of computer technology and Internet worldwide, people are using computers more and more to deal with various affairs. However, due to the late start of information construction and weak foundation, there are still many problems that need to be solved in China: such as unreasonable network structure, unsound network management system and lack of effective network security protection system, which have seriously restricted the rapid and healthy development of China’s economy and society. Therefore, how to strengthen the scientific and rational use of information network resources has become one of the important issues that need to be studied urgently. As an emerging information processing method, cluster analysis is to measure the similarity in a collection of objects and divide them into several categories according to certain criteria, so that the objects in the same category have a greater degree of similarity or similarity. It can discover a large amount of potentially useful knowledge, and thus is widely used in pattern recognition, machine learning, image segmentation and text classification. However, traditional clustering algorithms often need to specify the number of clusters or the initial centroid positions in advance, which leads to the final result may not be the optimal solution; In addition, when the size of the dataset increases, the computational effort also increases dramatically, which is difficult to meet the actual demand. To address the above problems, this paper proposes a new K-Means algorithm-based model for network security management systems, which can automatically determine the number of clusters and their optimal initial values, while using a parallel approach to execute tasks to reduce running time and improve efficiency.\n",
            "----------------------------------------\n",
            "Title: Structured Representations for Coreference Resolution\n",
            "Abstract: Coreference resolution is the task of determining which expressions in a text are used to refer to the same entity. This task is one of the most fundamental problems of natural language understanding. Inherently, coreference resolution is a structured task, as the output consists of sets of coreferring expressions. This complex structure poses several challenges since it is not clear how to account for the structure in terms of error analysis and representation. \n",
            " \n",
            "In this thesis, we present a treatment of computational coreference resolution that accounts for the structure. Our treatment encompasses error analysis and the representation of approaches to coreference resolution. In particular, we propose two frameworks in this thesis. \n",
            " \n",
            "The first framework deals with error analysis. We gather requirements for an appropriate error analysis method and devise a framework that considers a structured graph-based representation of the reference annotation and the system output. Error extraction is performed by constructing linguistically motivated or data-driven spanning trees for the graph-based coreference representations. \n",
            " \n",
            "The second framework concerns the representation of approaches to coreference resolution. We show that approaches to coreference resolution can be understood as predictors of latent structures that are not annotated in the data. From these latent structures, the final output is derived during a post-processing step. We devise a machine learning framework for coreference resolution based on this insight. In this framework, we have a unified representation of approaches to coreference resolution. Individual approaches can be expressed as instantiations of a generic approach. We express many approaches from the literature as well as novel variants in our framework, ranging from simple pairwise classification approaches to complex entity-centric models. Using the uniform representation, we are able to analyze differences and similarities between the models transparently and in detail. \n",
            " \n",
            "Finally, we employ the error analysis framework to perform a qualitative analysis of differences in error profiles of the models on a benchmark dataset. We trace back differences in the error profiles to differences in the representation. Our analysis shows that a mention ranking model and a tree-based mention-entity model with left-to-right inference have the highest performance. We discuss reasons for the improved performance and analyze why more advanced approaches modeled in our framework cannot improve on these models. An implementation of the frameworks discussed in this thesis is publicly available.\n",
            "----------------------------------------\n",
            "Title: Optimization of Crime Scene Reconstruction Based on Bloodstain Patterns and Machine Learning Techniques\n",
            "Abstract: Crime scene reconstruction based on circumstantial evidence and bloodstain patterns at the scene is often affected by unwanted expert bias. Using features such as bloodstain pattern, wound analysis, size of bloodstains on objects etc., predictions could be made about the relative position of the victim/s, bystander/s and perpetrator/s. Supervised learning techniques can be used to make predictions related to the murder weapon used. Gender of an individual could also be estimated from the bloody broken plastic footprint of an individual using a suitable dataset and supervised classifier. These intermediate prediction modules are important for development of event segments. The event segments add up towards the development of the events that transpired at the crime scene. An optimal sequence of events that might have transpired at the crime scene could thereby be developed using event timestamp and logical sequencing of similar incidents that had occurred in the past using probability theory.\n",
            "----------------------------------------\n",
            "Title: Weighted Fuzzy System for Identifying DNA N4-Methylcytosine Sites With Kernel Entropy Component Analysis\n",
            "Abstract: N4-methylcytosine (4mC) is a common DNA methylation that has been implicated in epigenetic regulation and host defense. Accurate prediction of 4mC sites in DNA sequences will help to better explore the biological processes and mechanisms. For this problem, computational methods based on machine learning and deep learning are faster, less complex, and less expensive than experimental detection methods. However, the existing computational methods are still unsatisfactory in terms of prediction accuracy, so we propose a new method with better performance. In this work, we propose a weighted fuzzy system for identifying DNA 4mC sites by kernel entropy component analysis (KECA). We named it as W-TSK-FS-KECA. This model is improved based on the Takagi–Sugeuo–Kang fuzzy system (TSK-FS). We use position-specific trinucleotide propensity to construct feature vectors on representative benchmark datasets. Then we use KECA to get the reconstruct error. Finally, we put the calculated reconstruction error add to the regular term of TSK-FS as the weights to enhance the model performance. Comparative experiments with other methods show that it has good classification perfor- mance.\n",
            "----------------------------------------\n",
            "Title: Gender Aspects in Driving Style and Its Impact on Battery Ageing\n",
            "Abstract: The long and tiring discussion of who are the best drivers, men or women, is not answered in this article. This article, though, sheds some light on the actual differences that can be seen in how men and women drive. In this study, GPS-recorded driving dynamics data from 123 drivers, 48 women and 75 men, are analysed and drivers are categorised as aggressive, normal or gentle. A total of 10% of the drivers was categorised as aggressive, with an even distribution between the genders. For the gentle drivers, 11% of the drivers, the men dominated. The driving style investigation was extended to utilise machine learning, confirming the results from statistical tools. As driving style highly impacts a vehicle’s fuel consumption, while switching over to battery electric vehicles it is important to investigate how the different driving styles impact battery utilisation. Two Li-ion battery cell types were tested utilising the same load cycle with three levels of current amplitude, to represent accelerations for the three drive categories. While one cell type was insensitive to the current amplitude, the highly energy-optimised cell proved to be sensitive to higher current amplitudes, corresponding to a more aggressive driving style. Thus, the amplitude of the dynamic current can for some cells be a factor that needs to be considered for lifetime predictions, while it can be neglected for other cells.\n",
            "----------------------------------------\n",
            "Title: Spin-Current Thermoelectric Conversion — Informatics-Based Materials Development and Scope of Applications\n",
            "Abstract: There are many cases in which the discovery of a material or device possessing new functionality changes not only the structures of individual enterprises but also exerts a very great impact on leading to the reform of the entire society. Some such examples include the neodymium magnet, the high-temperature superconductor and the blue LED. All of which have achieved significant success due to the extensive committed research, as well as the impact of chance events. However, the environments that surround material and device development are changing continually. The need for results has now reached a very high level of urgency in the fields that are experiencing severe competition. Consequently, attention is drawn to approaches that can develop materials and devices more efficiently by the maximum use of advanced technologies. Particularly, the materials informatics (MI) gathers special attention as a new technique for accelerating development by utilizing the knowledge obtained via informatics. In the present paper, section 2 describes the trends of MI technology development, section 3 reports on an Since the energy conversion technology that makes use of a new physical property called the spin current was reported in 2008, conversion efficiencies have been improved significantly, being helped by the discovery of new materials. This improvement has been backed not only by the accumulation of discoveries of new materials and mechanisms but more importantly, by efforts aimed at improving the efficiencies of materials development processes by taking a completely new approach. This paper introduces the creation of a new materials development process that combines an attempt at large-scale data acquisition in the field of materials development and an informatics approach for analyzing the acquired data by using machine learning. The potential benefits of its utilization are also discussed. In addition, the paper discusses the application domains of the spin-current thermoelectric conversion technology that are currently being put into practical use.\n",
            "----------------------------------------\n",
            "Title: Root identification in minirhizotron imagery with multiple instance learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Accurate Multi-Scale Feature Fusion CNN for Time Series Classification in Smart Factory\n",
            "Abstract: Time series classification (TSC) has attracted various attention in the community of machine learning and data mining and has many successful applications such as fault detection and product identification in the process of building a smart factory. However, it is still challenging for the efficiency and accuracy of classification due to complexity, multi-dimension of time series. This paper presents a new approach for time series classification based on convolutional neural networks (CNN). The proposed method contains three parts: short-time gap feature extraction, multi-scale local feature learning, and global feature learning. In the process of short-time gap feature extraction, large kernel filters are employed to extract the features within the short-time gap from the raw time series. Then, a multi-scale feature extraction technique is applied in the process of multi-scale local feature learning to obtain detailed representations. The global convolution operation with giant stride is to obtain a robust and global feature representation. The comprehension features used for classifying are a fusion of short time gap feature representations, local multi-scale feature representations, and global feature representations. To test the efficiency of the proposed method named multi-scale feature fusion convolutional neural networks (MSFFCNN), we designed, trained MSFFCNN on some public sensors, device, and simulated control time series data sets. The comparative studies indicate our proposed MSFFCNN outperforms other alternatives, and we also provided a detailed analysis of the proposed MSFFCNN.\n",
            "----------------------------------------\n",
            "Title: Applications of Machine Learning in Wireless Communication: 5G and Beyond\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: The relationship between students’ interest in bilingual science learning and students’ English competence\n",
            "Abstract: The correlation of students’ interest in bilingual science learning and their English competence was investigated. Forty-six students of elementary-school teacher candidate program participated in this study. The students received five topics of science (Heat, Changes in Matters, Plant Life and Environment, Simple Machine, Animal Life and Environment) with English usage embedded. The students’ interest in science learning involving English was examined. Meanwhile, the students’ mastery of general English was measured. The result shows that the students’ interest in bilingual science learning and their English mastery is not significantly correlated. The finding suggests that the students might still enjoy and get benefit from bilingual science learning despite their English abilities. This leads to the opportunity to have more bilingual science classes to enhance not only students’ science mastery but also their English competence.\n",
            "----------------------------------------\n",
            "Title: Weather Condition Clustering for Improvement of Photovoltaic Power Plant Generation Forecasting Accuracy\n",
            "Abstract: Together with the growing interest towards renewable energy sources within the framework of different strategies of various countries, the number of solar power plants keeps growing. However, managing optimal power generation for solar power plants has its own challenges. First comes the problem of work interruption and reduction in power generation. As the system must be tolerant to the faults, the relevance and significance of short-term forecasting of solar power generation becomes crucial. Within the framework of this research, the applicability of different forecasting methods for short-time forecasting is explained. The main goal of the research is to show an approach regarding how to make the forecast more accurate and overcome the above-mentioned challenges using opensource data as features. The data clustering algorithm based on KMeans is proposed to train unique models for specific groups of data samples to improve the generation forecast accuracy. Based on practical calculations, machine learning models based on Random Forest algorithm are selected which have been proven to have higher efficiency in predicting the generation of solar power plants. The proposed algorithm was successfully tested in practice, with an achieved accuracy near to 90%.\n",
            "----------------------------------------\n",
            "Title: Insights into Ionic Liquids for Flame Retardant: A Study Based on Bibliometric Mapping\n",
            "Abstract: Fire is a typical disaster in the processing industry. Ionic liquids, as a type of green flame retardant, play an important role in process safety. In order to grasp the current research status, hotspots, and frontiers in the field of ionic liquids in flame retardancy, the bibliometric mapping method is applied to study the relevant literature in Web of Science datasets from 2000–2022 in this paper. The results show that the research on ionic liquids in flame retardancy is multidisciplinary and involves some disciplines such as energy science, material science, and environmental protection. Journal of Power Sources, Polymer Degradation and Stability, ACS Applied Materials and Interfaces, and Chemical Engineering Journal are the core journals in the field. The results of keyword co-occurrence indicate that the hotspots of research can be divided into five components: the improvement and application of pure ionic liquids electrolytes, the research of gel polymer electrolytes, applying ionic liquids to enhance the polymer materials’ flame retardancy properties, utilizing ionic liquids and inorganic materials to synergize flame retardant polymers, and using ionic liquids flame retardant to improve material’s multiple properties. The burst terms and time zone diagram’s results point out the combination of computational quantum chemistry to study the flame retardancy mechanism of ionic liquids, the study of fluorinated electrolytes, ionic liquids for smoke suppression, phosphorus-containing ionic liquids for flame retardant, and machine learning-assisted design of ILs flame retardants are the research frontiers and future research trends.\n",
            "----------------------------------------\n",
            "Title: A 3-Tier Architecture for Network Latency Reduction in Healthcare Internet-of-Things Using Fog Computing and Machine Learning\n",
            "Abstract: Healthcare Internet-of-things comprises a huge number of wearable sensors and interconnected computers. The high volume of IoT data is transacted over servers leading to servers overloading with high traffic causing network congestion. These cloud servers are typically for analyzing, retrieving and storing the large data generated from IoT devices. There exist challenges regarding sending real-time healthcare data from cloud servers to end-users. These challenges include the high computational latency, high communication latency, and high network latency. Due to these challenges, IoTs may not be able to send data in real-time to end-users. Fog nodes can be used to play a major role in reducing the high delay and high traffic. It can be a solution to increase system performance. In this paper, we proposed a 3-tier architecture, an analytical model for healthcare IoT using a hybrid approach consisting of fuzzy logic and reinforcement learning in a fog computing environment. The aim is to minimize network latency. The proposed model and 3-tier architecture are simulated using iFogSim simulator.\n",
            "----------------------------------------\n",
            "Title: Artificial Intelligence for Urban Safety: A Case Study for reducing road accident in Genoa\n",
            "Abstract: Abstract. This study explores the application of Machine Learning (ML) and citizen engagement in improving road safety for vulnerable populations (pedestrians, cyclists) in Genoa, Italy. Aligned with the UN's 2030 Agenda for Sustainable Development, the project aims for a 50% reduction in traffic accidents by 2030.The AI4PublicPolicy initiative introduces the Virtual Policy Management Environment (VPME) platform. VPME utilizes ML, Deep Learning (DL), Natural Language Processing (NLP), and chatbots to empower the policy development lifecycle. Citizen feedback is integrated through workshops and surveys, fostering a citizen-centric approach. The Genoa pilot program demonstrates VPME's capabilities. ML models analyse historical accident and Geographic Information Systems (GIS) data to predict future high-risk areas. These predictions inform resource allocation and targeted interventions for pedestrian crossings and school walking routes (\"Pedibus\"). Dashboards visualize the model outputs, allowing users to assess risk levels and predict accident occurrences. Future improvements include incorporating additional data sources (demographics, real-time traffic) for enhanced model accuracy. Citizen engagement played a vital role. Co-creation workshops facilitated stakeholder participation in defining Use Cases, User Stories, and project objectives. Discussions focused on integrating data from environmental, traffic, and citizen reporting systems with VPME solutions. Participants evaluated the project approach and provided valuable feedback. The project highlights the potential of AI and citizen collaboration for data-driven policymaking. This approach empowers municipalities to make informed decisions that prioritize public safety and well-being.\n",
            "\n",
            "----------------------------------------\n",
            "Title: A Fast Interactive Search System for Healthcare Services\n",
            "Abstract: In this paper we describe the design, development, and evaluation of a general human-machine interaction search system, and its potential and use in the context of a collaboration project with SAP and Saffron. The objective of a specialized version of the system is to provide medical and healthcare information services to users via interactive search for personalized patient needs. Patients usually have questions regarding healthcare, including those which concern illness symptoms, duration and types of treatment, possible drug effects, and more. Authorized personnel would often be ideal in responding to such needs; however they could potentially be very expensive, and not easy to support and maintain. If patients could have access to information at their home, by means of i-phone or online access, this could save time, doctor office visit expenses, as well as valuable and restricted medical time. What is more, information concerning other anonymized and similar patient cases provides knowledge and perspective on a wide range of patient issues. From the doctors' perspective, they typically need to spend time on differential analysis about new patient cases: study symptoms, research possible causes, rank results by emergency priority and treat them accordingly. A search system that would direct a doctor (or patient/user) to similar patient cases would save significant amount of manual search time. The powerful new feature of this system is the storage and mining of past patient cases knowledge, to create metadata to be used in the subsequent retrieval of relevant documents. Finally, the interactive search system would speed up identification of rare cases; for instance, symptoms that do not appear commonly in past cases may require special treatment or expert referral. We build a model which dynamically learns medical needs of interacting MDs and patients. The model works on free or unstructured text, allowing disambiguation of vague words and flexibility in describing medical needs. In addition, both experts with an advanced knowledge of medical terminology, and beginning users using basic medical terms, can achieve high search relevance. Furthermore, our approach obviates the need for the assignment of tags or labels, such as treatment, symptoms, causes, to documents, to respond effectively to user queries. In particular, we build a temporal difference algorithm to predict user's information needs by incorporating both current and predicted knowledge into learning the user profile. Our source of information about the user consists of submitted queries and feedback on the returned results. We tested our system on publicly available medical data (OhsuMed TREC dataset 2002) and we achieved a significant improvement in retrieval accuracy, compared to the literature. We provide quantitative results as well as demonstration screenshots which illustrate a) the value of interaction (user time spent with system versus results accuracy), b) the value of using medical terminology understanding, when compared with simple general words, and c) the value of allowing the maximum number of feedback submissions to vary.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Based Technology for Reducing Engine Starting Vibration of Hybrid Vehicles\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Music Classification Model Development Based on Audio Recognition using Transformer Model\n",
            "Abstract: There are several music genres, such as blues, classical, disco, and more. Music genres can be predicted by supervised machine learning using extracted features. This research explores the Transformer deep learning model for audio classification using music genres as labels. The dataset used in this paper is the GTZAN dataset, which contains music in a waveform audio file (WAV) format. The features of this dataset are extracted using Mel-frequency Cepstral Coefficients (MFCC). This study finds that the Transformer model's performance gives higher accuracy than other neural network architectures. Furthermore, the Transformer model's performance is compared with related research results that utilize various traditional machine learning methods with the same dataset. The best result achieved was the accuracy of 75.1% for the Transformer model with the best fine-tune parameters.\n",
            "----------------------------------------\n",
            "Title: Autonomous vehicle control via deep reinforcement learning\n",
            "Abstract: The automotive industry as well as academia are currently conducting a lot of research related to autonomous driving. Autonomous driving is an interesting topic that holds the potential to benefit society in many ways, such as reduce the number of fatalities and reducing the environmental footprint of modern day traffic. In this thesis, we investigate Machine Learning algorithms that can automatically learn to control a vehicle based on its own experience of driving. More specifically we employ two Reinforcement Learning (RL) algorithms called Deterministic Policy Gradient (DDPG), and Actor-Critic with Experience Replay (ACER). The algorithms were trained and evaluated in a synthetic environment. The input to both models are images captured by a front-facing camera and internal states of the ego-vehicle, i.e., velocity, acceleration, and jerk. The results presented in this thesis show that current RL-methods are capable of controlling the vehicle steering, using only images to provide information regarding the position of the ego-vehicle. The results also indicate that a driving policy obtained via RL is more robust towards tricky driving scenarios than policies obtained via supervised learning techniques. However, evaluation of data captured from the real world domain is still needed, to verify the usability of models trained on synthetic data.\n",
            "----------------------------------------\n",
            "Title: A Machine Learning based Preventing the Occurrence of Cyber Bullying Messages on OSN\n",
            "Abstract: The process of threaten or harassment of any user with the help of posting wrong/abused or vulgar messages using the social media in the internet is known as Cyber bullying .These messages may sometime contain a text posted by a teen, or preteen or a child who want to threaten or harassed or embarrassed other child by posting the messages. So in this project, we mainly try to propose another depiction learning strategy to handle this issue known as SEMdae. Here the semantic augmentation comprises of predefined words that contain noise or abused meaning which is posted into the database by the admin and these words are classified based on the five categories that are available in the literature like “HATE, VULGAR, OFFENSIVE, SEX, and VOILENCE”.\n",
            "----------------------------------------\n",
            "Title: Evaluation of a Natural Language Processing Approach to Identify Diagnostic Errors and Analysis of Safety Learning System Case Review Data: Retrospective Cohort Study.\n",
            "Abstract: BACKGROUND\n",
            "Diagnostic errors are an underappreciated cause of preventable mortality in hospitals and pose a risk for severe patient harm and increase hospital length of stay.\n",
            "\n",
            "\n",
            "OBJECTIVE\n",
            "This study aims to explore the potential of machine learning and natural language processing techniques in improving diagnostic safety surveillance. We conducted a rigorous evaluation of the feasibility and potential to use electronic health records clinical notes and existing case review data.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Safety Learning System case review data from 1 large health system composed of 10 hospitals in the mid-Atlantic region of the United States from February 2016 to September 2021 were analyzed. The case review outcome included opportunities for improvement including diagnostic opportunities for improvement. To supplement case review data, electronic health record clinical notes were extracted and analyzed. A simple logistic regression model along with 3 forms of logistic regression models (ie, Least Absolute Shrinkage and Selection Operator, Ridge, and Elastic Net) with regularization functions was trained on this data to compare classification performances in classifying patients who experienced diagnostic errors during hospitalization. Further, statistical tests were conducted to find significant differences between female and male patients who experienced diagnostic errors.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "In total, 126 (7.4%) patients (of 1704) had been identified by case reviewers as having experienced at least 1 diagnostic error. Patients who had experienced diagnostic error were grouped by sex: 59 (7.1%) of the 830 women and 67 (7.7%) of the 874 men. Among the patients who experienced a diagnostic error, female patients were older (median 72, IQR 66-80 vs median 67, IQR 57-76; P=.02), had higher rates of being admitted through general or internal medicine (69.5% vs 47.8%; P=.01), lower rates of cardiovascular-related admitted diagnosis (11.9% vs 28.4%; P=.02), and lower rates of being admitted through neurology department (2.3% vs 13.4%; P=.04). The Ridge model achieved the highest area under the receiver operating characteristic curve (0.885), specificity (0.797), positive predictive value (PPV; 0.24), and F1-score (0.369) in classifying patients who were at higher risk of diagnostic errors among hospitalized patients.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Our findings demonstrate that natural language processing can be a potential solution to more effectively identifying and selecting potential diagnostic error cases for review and therefore reducing the case review burden.\n",
            "----------------------------------------\n",
            "Title: A Probability-Based Close Domain Metric in Lifelong Learning for Multi-label Classification\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Annotated Dataset Creation through General Purpose Language Models for non-English Medical NLP\n",
            "Abstract: Obtaining text datasets with semantic annotations is an effortful process, yet crucial for supervised training in natural language processsing (NLP). In general, developing and applying new NLP pipelines in domain-specific contexts for tasks often requires custom designed datasets to address NLP tasks in supervised machine learning fashion. When operating in non-English languages for medical data processing, this exposes several minor and major, interconnected problems such as lack of task-matching datasets as well as task-specific pre-trained models. In our work we suggest to leverage pretrained language models for training data acquisition in order to retrieve sufficiently large datasets for training smaller and more efficient models for use-case specific tasks. To demonstrate the effectiveness of your approach, we create a custom dataset which we use to train a medical NER model for German texts, GPTNERMED, yet our method remains language-independent in principle. Our obtained dataset as well as our pre-trained models are publicly available at: https://github.com/frankkramer-lab/GPTNERMED\n",
            "----------------------------------------\n",
            "Title: Enabling robust offline active learning for machine learning potentials using simple physics-based priors\n",
            "Abstract: Machine learning surrogate models for quantum mechanical simulations have enabled the field to efficiently and accurately study material and molecular systems. Developed models typically rely on a substantial amount of data to make reliable predictions of the potential energy landscape or careful active learning (AL) and uncertainty estimates. When starting with small datasets, convergence of AL approaches is a major outstanding challenge which has limited most demonstrations to online AL. In this work we demonstrate a Δ-machine learning (ML) approach that enables stable convergence in offline AL strategies by avoiding unphysical configurations with initial datasets as little as a single data point. We demonstrate our framework’s capabilities on a structural relaxation, transition state calculation, and molecular dynamics simulation, with the number of first principle calculations being cut down anywhere from 70%–90%. The approach is incorporated and developed alongside AMPtorch, an open-source ML potential package, along with interactive Google Colab notebook examples.\n",
            "----------------------------------------\n",
            "Title: Modeling of sliding wear characteristics of Polytetrafluoroethylene (PTFE) composite reinforced with carbon fiber against SS304\n",
            "Abstract: Introduction. Over the last decade, composite materials based on polytetrafluoroethylene (PTFE) have been increasingly used as alternative materials for automotive applications. PTFE is characterized by a low coefficient of friction, hardness and corrosion resistance. However, this material has a high wear rate. A group of researchers attempted to improve the wear resistance of PTFE material by reinforcing it with different fillers. The purpose of the work: This study experimentally investigates the dry sliding wear characteristics of a PTFE composite reinforced with carbon fiber (35 wt.%) compared to SS304 stainless steel. In addition, experimental mathematical and ANN models are developed to predict the specific wear rate, taking into account the influence of pressure, sliding speed, and interface temperature. The methods of investigation. Dry sliding experiments were performed on a pin-on-disk wear testing machine with varying the normal load on the pin, disk rotation, and interface temperature. Experiments were planned systematically to investigate the effect of input parameters on specific wear rates with a wide range of design space. In total, fifteen experiments were carried out at a 5-kilometer distance without repeating the central run experiment. Sliding velocities were obtained by selecting the track diameter on the disk and corresponding rotation of the disk. A feedforward back-propagation machine learning algorithm was used to the ANN model. Results and Discussion. This study finds better prediction accuracy with the ANN architecture having two hidden layers with 150 neurons on each layer. This study finds an increase in specific wear rates with normal load, sliding velocity, and interface temperature. However, the increase is more prominent at higher process parameters. The normal load followed by sliding velocity most significantly affects the specific wear rate. The results predicted by the developed models for specific wear rates are in good agreement with the experimental values with an average error close to 10%. This shows that the model could be reliably used to obtain the wear rate of PTFE composite reinforced with carbon fiber (35 wt.%) compared to SS304 stainless steel. This study finds scope for further studies considering the effect of varying ANN architectures, different amount of neurons, and hidden layers on the prediction accuracy of the wear rate.\n",
            "----------------------------------------\n",
            "Title: Remote Health Monitoring IoT Framework using Machine Learning Prediction and Advanced Artificial Intelligence (AI) Model\n",
            "Abstract: Real intervention and treatment standards drew attention to remote health monitoring frameworks. Remote monitoring frameworks for disease detection at an early stage are opposed by most conventional works. Even so, it ran into issues like increased operational complexity, higher resource costs, inaccurate predictions, longer data collection times, and a lower convergence rate. A remote health monitoring framework that uses artificial intelligence (AI) to predict heart disease and diabetes from medical datasets is the goal of this project. Patients' health data is collected via smart devices, and the resulting data is then combined using a variety of nodes, including a detection node, a visualisation node, and a prognostic node. People with long-term illnesses (such as the elderly and disabled) are in such greater demand than ever before that a new approach to healthcare delivery is essential. In the evolved paradigm, conventional physical medical services foundations like clinics, nursing homes, and long haul care offices will be old. Due to recent advancements in modern technology, such as artificial intelligence (AI) and machine learning (ML), the smart healthcare system has become increasingly necessary (ML). This paper will discuss wearable and smartphone technologies, AI for medical diagnostics, and assistive structures, including social robots, that have been created for the surrounding upheld living climate. The review presents programming reconciliation structures that are urgent for consolidating information examination and other man-made consciousness instruments to develop brilliant medical care frameworks (AI).\n",
            "----------------------------------------\n",
            "Title: Computed tomography-based radiomic model predicts radiological response following stereotactic body radiation therapy in early-stage non-small-cell lung cancer and pulmonary oligo-metastases\n",
            "Abstract: Purpose Radiomic models elaborate geometric and texture features of tumors extracted from imaging to develop predictors for clinical outcomes. Stereotactic body radiation therapy (SBRT) has been increasingly applied in the ablative treatment of thoracic tumors. This study aims to identify predictors of treatment responses in patients affected by early stage non-small cell lung cancer (NSCLC) or pulmonary oligo-metastases treated with SBRT and to develop an accurate machine learning model to predict radiological response to SBRT. Materials and Methods Computed tomography (CT) images of 85 tumors (stage I–II NSCLC and pulmonary oligo-metastases) from 69 patients treated with SBRT were analyzed. Gross tumor volumes (GTV) were contoured on CT images. Patients that achieved complete response (CR) or partial response (PR) were defined as responders. One hundred ten radiomic features were extracted using PyRadiomics module based on the GTV. The association of features with response to SBRT was evaluated. A model using support vector machine (SVM) was then trained to predict response based solely on the extracted radiomics features. Receiver operating characteristic curves were constructed to evaluate model performance of the identified radiomic predictors. Results Sixty-nine patients receiving thoracic SBRT from 2008 to 2018 were retrospectively enrolled. Skewness and root mean squared were identified as radiomic predictors of response to SBRT. The SVM machine learning model developed had an accuracy of 74.8%. The area under curves for CR, PR, and non-responder prediction were 0.86 (95% confidence interval [CI], 0.794–0.921), 0.946 (95% CI, 0.873–0.978), and 0.857 (95% CI, 0.789–0.915), respectively. Conclusion Radiomic analysis of pre-treatment CT scan is a promising tool that can predict tumor response to SBRT.\n",
            "----------------------------------------\n",
            "Title: Adaptive Fuzzy Filtering in a Deterministic Setting\n",
            "Abstract: Many real-world applications involve the filtering and estimation of process variables. This study considers the use of interpretable Sugeno-type fuzzy models for adaptive filtering. Our aim in this study is to provide different adaptive fuzzy filtering algorithms in a deterministic setting. The algorithms are derived and studied in a unified way without making any assumptions on the nature of signals (i.e., process variables). The study extends, in a common framework, the adaptive filtering algorithms (usually studied in signal processing literature) and p -norm algorithms (usually studied in machine learning literature) to semilinear fuzzy models. A mathematical framework is provided that allows the development and an analysis of the adaptive fuzzy filtering algorithms. We study a class of nonlinear LMS-like algorithms for the online estimation of fuzzy model parameters. A generalization of the algorithms to the p-norm is provided using Bregman divergences (a standard tool for online machine learning algorithms).\n",
            "----------------------------------------\n",
            "Title: Building Indoor Point Cloud Datasets with Object Annotation for Public Safety\n",
            "Abstract: An accurate model of building interiors with detailed annotations is critical to protecting the first responders’ safety and building occupants during emergency operations. In collaboration with the City of Memphis, we collected extensive LiDAR and image data for the city’s buildings. We apply machine learning techniques to detect and classify objects of interest for first responders and create a comprehensive 3D indoor space database with annotated safety-related objects. This paper documents the challenges we encountered in data collection and processing, and it presents a complete 3D mapping and labeling system for the environments inside and adjacent to buildings. Moreover, we use a case study to illustrate our process and show preliminary evaluation\n",
            "----------------------------------------\n",
            "Title: Forecast and prediction of COVID-19 using machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: STAMP: Lightweight TEE-Assisted MPC for Efficient Privacy-Preserving Machine Learning\n",
            "Abstract: In this paper, we propose S TAMP , an end-to-end 3-party MPC protocol for efﬁcient privacy-preserving machine learning inference assisted by a lightweight TEE (LTEE), which will be far easier to secure and deploy than today’s large TEEs. S TAMP provides three main advantages over the state-of-the-art; (i) S TAMP achieves signiﬁcant performance improvements compared to state-of-the-art MPC protocols, with only a small LTEE that is comparable to a discrete security chip such as the Trusted Platform Module (TPM) or on-chip security subsystems in SoCs similar to the Apple enclave processor. In a semi-honest setting with WAN/GPU, S TAMP is 4 × -63 × faster than Falcon (PoPETs’21) and Ar-iaNN (PoPETs’22) and 3.8 × -12 × more communication ef-ﬁcient. We achieve even higher performance improvements in a malicious setting. (ii) S TAMP guarantees security with abort against malicious adversaries under honest majority assumption. (iii) S TAMP is not limited by the size of secure memory in a TEE and can support high-capacity modern neural networks like ResNet18 and Transformer.\n",
            "----------------------------------------\n",
            "Title: Inhibitors of Calcium Oxalate Crystallization for the Treatment of Oxalate Nephropathies\n",
            "Abstract: Calcium oxalate (CaOx) crystal‐induced nephropathies comprise a range of kidney disorders, for which there are no efficient pharmacological treatments. Although CaOx crystallization inhibitors have been suggested as a therapeutic modality already decades ago, limited progress has been made in the discovery of potent molecules with efficacy in animal disease models. Herein, an image‐based machine learning approach to systematically screen chemically modified myo‐inositol hexakisphosphate (IP6) analogues is utilized, which enables the identification of a highly active divalent inositol phosphate molecule. To date, this is the first molecule shown to completely inhibit the crystallization process in the nanomolar range, reduce crystal–cell interactions, thereby preventing CaOx‐induced transcriptomic changes, and decrease renal CaOx deposition and kidney injury in a mouse model of hyperoxaluria. In conclusion, IP6 analogues based on such a scaffold may represent a new treatment option for CaOx nephropathies.\n",
            "----------------------------------------\n",
            "Title: Statement : Mathematical Foundations of Data Science\n",
            "Abstract: Today’s data deluge is driving a transformation of the world-economy and even the modern way of life. Cutting edge data science challenges are pushing the boundaries of what can be learned from data, giving rise to an array of applications in artificial intelligence, medicine, and social sciences. My past work has provided several major contributions at the front of mathematical statistics and information theory, addressing some of the fundamental theoretical aspects of data science. Among these contributions, my Ph.D. work addressed the effects of data compression on real-world analog data. It provided the first complete characterization of the optimal trade-offs between sampling rate, compression bitrate, and distortion in processing real-world signals digitally. My postdoc work focuses on challenging high-dimensional signal estimation and classification settings. The high-dimensionality here is typically the result of a vast number of features available for inference. These features can represent raw measurements, the result of compression or dimensionality reduction procedures, or the output of data-driven techniques like a neural network’s activations. Arguably, the most pressing issues of modern data-driven inference techniques are their general inability to explain models’ decisions and to generalize to unexpected new situations. Feature-based inference techniques are perfectly suited for resolving this ‘interpretability’ and ‘generalizability’ crises. Interpretability is attained by crafting many meaningful features, while generalizability is attained by using optimal feature selection and inference rules for these features. For this reason, we are witnessing a shift in machine learning and artificial intelligence communities from end-to-end to feature-based approaches. The theoretical tools to handle feature-based inference include multiple hypothesis testing and variable selection in statistics and geometric understanding of high-dimensional distributions from information theory. My research integrates these two disciplines with ambitious computations, validating theoretical results and assessing inference’s performance on real-world datasets. In what follows, I will review in more detail my past achievements and describe my shortand long-term future research plans.\n",
            "----------------------------------------\n",
            "Title: Assessing the Robustness of Cluster Solutions in Emotionally-Annotated Pictures Using Monte-Carlo Simulation Stabilized K-Means Algorithm\n",
            "Abstract: Clustering is a very popular machine-learning technique that is often used in data exploration of continuous variables. In general, there are two problems commonly encountered in clustering: (1) the selection of the optimal number of clusters, and (2) the undecidability of the affiliation of border data points to neighboring clusters. We address both problems and describe how to solve them in application to affective multimedia databases. In the experiment, we used the unsupervised learning algorithm k-means and the Nencki Affective Picture System (NAPS) dataset, which contains 1356 semantically and emotionally annotated pictures. The optimal number of centroids was estimated, using the empirical elbow and silhouette rules, and validated using the Monte-Carlo simulation approach. Clustering with k = 1–50 centroids is reported, along with dominant picture keywords and descriptive statistical parameters. Affective multimedia databases, such as the NAPS, have been specifically designed for emotion and attention experiments. By estimating the optimal cluster solutions, it was possible to gain deeper insight into affective features of visual stimuli. Finally, a custom software application was developed for study in the Python programming language. The tool uses the scikit-learn library for the implementation of machine-learning algorithms, data exploration and visualization. The tool is freely available for scientific and non-commercial purposes.\n",
            "----------------------------------------\n",
            "Title: Intelligent Robotic Perception Systems\n",
            "Abstract: Robotic perception is related to many applications in robotics where sensory data and artificial intelligence/machine learning (AI/ML) techniques are involved. Examples of such applications are object detection, environment representation, scene understand - ing, human/pedestrian detection, activity recognition, semantic place classification, object modeling, among others. Robotic perception, in the scope of this chapter, encom - passes the ML algorithms and techniques that empower robots to learn from sensory data and, based on learned models, to react and take decisions accordingly. The recent developments in machine learning, namely deep-learning approaches, are evident and, consequently, robotic perception systems are evolving in a way that new applications and tasks are becoming a reality. Recent advances in human-robot interaction, complex robotic tasks, intelligent reasoning, and decision-making are, at some extent, the results of the notorious evolution and success of ML algorithms. This chapter will cover recent and emerging topics and use-cases related to intelligent perception systems in robotics.\n",
            "----------------------------------------\n",
            "Title: Physics Guided Machine Learning Significantly Improves Outcomes for Data-Based Production Optimization\n",
            "Abstract: \n",
            " Hydrocarbon production systems generate huge datasets, often with time series going back many years. However, much of the data may be obsolete due to changing reservoir conditions and modification of the asset, and there may be scant data close to optimal operating conditions due to the inadequacy of existing optimization tools. It is widely recognized that data science, artificial intelligence (AI) and machine learning can contribute significantly to the optimization of production operations, and there is a trend towards hybrid AI, which combines data science with traditional physics-based simulators to deliver added value. In our work we show how to make use of physical principles in feature engineering to improve machine learning outcomes. This squeezes additional value from a pure data-based approach while avoiding expensive, time-consuming and often inaccurate simulations. Our toolbox includes energy, mass and force balances; PVT data for production fluids; order-of-magnitude analysis; and dimensional analysis.\n",
            " We illustrate the value of physics guided machine learning with three examples from production optimisation: First example shows a significant improvement in separator operation to achieve environmental limits for safe disposal of produced water using a root-cause analysis to identify bad actors in the production system and recommending operator actions to mitigate oil-in water issues. By physics modeling of key physical processes, such as choke-dispersion and separator efficiency, the predictions were greatly improved. Second example is a data-based VFM using physics-based feature engineering, outperforming a VFM based purely on measured data. Last use-case is a dynamic maximum separator flow capacity calculation that safely allows flow rates above static design limits.\n",
            " We conclude that physics-guided machine learning can add tremendous value to digitalisation rollout across a wide range of production optimisation use cases, and speed up the decision process toward mitigation of production losses in complex industrial phenomena.\n",
            "----------------------------------------\n",
            "Title: Machine learning and multimedia content generation for energy demand reduction\n",
            "Abstract: Domestic energy demand accounts for about 30% of overall energy use. The IDEAL project uses a variety of IT methods to investigate whether, and in which social groups, feedback of personalised, household-specific and behaviour-specific information results in greater reduction in energy use than overall consumption information reported by Smart Meters. It is a sociotechnical study, concentrated on existing housing, with a strong social science component and an experimental design that looks at income levels and household composition as primary factors. Temperature and humidity data related to behaviour is gathered using a small number of wireless sensors in the home, together with data on weather, building factors and household composition. This data is streamed over the internet to servers where it is analysed using Bayesian machine-learning methods to extract household-specific behaviours in near-realtime. Information on the cost, carbon content and amount of energy used for specific behaviours is reported back to the householders via a dedicated wireless tablet. This interactive content is automatically generated using multimedia methods based on natural language generation techniques. The project is in its design phase, with the main project planned (and funded) to run 2013-2016. It is anticipated to demonstrate whether such low-cost sensing, analysis and feedback is significantly more effective than standard Smart Meters in reducing demand, and a business opportunity for green service organisations.\n",
            "----------------------------------------\n",
            "Title: A Novel Generative AI-Based Framework for Anomaly Detection in Multicast Messages in Smart Grid Communications\n",
            "Abstract: Cybersecurity breaches in digital substations can pose significant challenges to the stability and reliability of power system operations. To address these challenges, defense and mitigation techniques are required. Identifying and detecting anomalies in information and communication technology (ICT) is crucial to ensure secure device interactions within digital substations. This paper proposes a task-oriented dialogue (ToD) system for anomaly detection (AD) in datasets of multicast messages e.g., generic object oriented substation event (GOOSE) and sampled value (SV) in digital substations using large language models (LLMs). This model has a lower potential error and better scalability and adaptability than a process that considers the cybersecurity guidelines recommended by humans, known as the human-in-the-loop (HITL) process. Also, this methodology significantly reduces the effort required when addressing new cyber threats or anomalies compared with machine learning (ML) techniques, since it leaves the models complexity and precision unaffected and offers a faster implementation. These findings present a comparative assessment, conducted utilizing standard and advanced performance evaluation metrics for the proposed AD framework and the HITL process. To generate and extract datasets of IEC 61850 communications, a hardware-in-the-loop (HIL) testbed was employed.\n",
            "----------------------------------------\n",
            "Title: Forecasting trends in the cryptocurrency exchange rate through the machine learning theory\n",
            "Abstract: Subject. The study discusses methodological approaches to forecasting trends in the development of the cryptocurrency market (bitcoin).\n",
            "Objectives. The study aims to discover and explain tools and mechanisms for predicting how the cyptocurrency market may evolve in a short run through time series modeling methods and machine learning methods, which are based on artificial neural networks LSTM.\n",
            "Methods. Using Python-based programming methods, we constructed and substantiated a neural network model for the analyzable series describing how the stock exchange rate of bitcoin develops.\n",
            "Results. Matching loss functions, optimizer and parameters for constructing a neural network that predicts the BTC/USD exchange rate for a coming day, we proved its applicability and feasibility, which is confirmed with the lowest number of errors in the test and validation set.\n",
            "Conclusions and Relevance. The findings mainly prove that the above mechanism is feasible for predicting the cryptocurrency market. The mechanism is based on algorithms for constructing LSTM networks. The approach should be used to analyze and evaluate the current and future parameters of the cryptocurrency market development. The tools can be of interest for investors which operate in new markets of e-money.\n",
            "----------------------------------------\n",
            "Title: Integration of Petrophysical Log Data with Computational Intelligence for the Development of a Lithology Predictor\n",
            "Abstract: \n",
            " Wrong manual interpretation from the log data about the formation type and other important information can be catastrophic for the company-operator. With Machine-Learning (ML) (a branch of Artificial Intelligence) algorithms, the interpretation of formation type from the log data has been addressed. As a result, we have successfully developed a program able to accurately predict the type of formation.\n",
            " Using the conventional Machine Learning technique of splitting the data into training, validation and test sets, we tried six different ML algorithms to fit with the training part of the data and then verify their prediction accuracy with cross-validation scores and cross-validation predictions which tests the performance of the classifiers (ML algorithms) on the validation set. The three best performing classifiers were selected and further improved by a search of classifier's best hyperparameters. These improved classifiers are further tested on unseen data to produce a comparative analysis.\n",
            " Our prediction accuracy with Receiver Operating Characteristic (ROC) scores and ROC-Area Under-the-Curve (ROC-AUC) for each type of formation from the log data lies in the range of 95-99%, except for formations such as shaly sandstone and shale (50% and 84% respectively). The reason for this seemed to be under-fitting i.e., during the training, the classifiers did not see enough instances of these types of formation to know exactly what characteristics of the data make the type of formation to be shaly sandstone or shale. The issue of under-fitting was verified by skimming through the data. To resolve this problem, we suggest training classifiers with a larger data with more targets (types of formation). Furthermore, during the data cleaning (prior to classifier training) and data analysis phases we have discovered important relationships between well logs and defined relative importance of each well log for different formations. This observation can be investigated further to help eliminate the use of multiple well logs while dealing with some formations (based on prior geological knowledge) and reduce the cost of the well logging operations. Using our program with a larger well log data consisting of more formation type instances, we can train the classifiers to accurately predict the formation type irrespectively of differences in formation type.\n",
            " Our program is dynamic in the sense that with different targets, i.e., type of formation fluid instead of type of formation or both together, it can successfully predict either or both targets. Increasing the numbers of data instances resulted in a better training and thus, more accurate predictions. Utilization of the program will make the formation-evaluation process easier, faster, automated and more-precise.\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning to Predict Student Success in Undergraduate Engineering Programs\n",
            "Abstract: Undergraduate engineering programs are typically considered some of the most challenging as their curricula require students to have an aptitude for math, science, and engineering. The resources (time, effort, funds) required to finish an engineering degree is substantial. Therefore, it is imperative that the engineering students are supported with well-informed academic guidance as early in their education as possible so that these resources can be used most effectively. Analytical and data-driven methods such as machine learning techniques can be used to inform this guidance process by predicting student success based on features such as individual traits and academic performance. In that direction, we investigated the effectiveness of using machine learning in predicting engineering student success based on academic performance in core math, physics, and engineering courses in three undergraduate engineering programs. The data categories selected for training and testing of the machine learning models in this study are common to most engineering programs nationwide and can be customized in a straightforward manner for other engineering disciplines. The methodology and results outlined in this preliminary study shows promise for predicting degree and cumulative GPA in our three engineering programs.\n",
            "----------------------------------------\n",
            "Title: Images with TensorFlow\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Identification of the Association between Hepatitis B Virus and Liver Cancer using Machine Learning Approaches based on Amino Acid\n",
            "Abstract: Primary liver cancer has been a common reason for death from cancer globally. The most common type of primary liver cancer is the hepatocellular carcinoma (HCC). The major cause of HCC is chronic infections with hepatitis B virus (HBV). In this research, we used next generation sequencing (NGS), which has been very widely used to produce deep, efficient, and high-quality sequence data. NGS was used to sequence the pre-S region of the HBV genome of total 139 patients, which contain 94 HCC patients and 45 chronic HBV (CHB) patients. We generated two types of datasets. Firstly, for the data of amino acid occurrence frequency, we used basic local alignment search tool (BLAST) to map each NGS short read and translated each alignment into amino acid by DNA codon table. The input features are the occurrence frequencies of 20 basic amino acids using Shannon entropy. We picked 40 patients with 27 HCC and 13 CHB as the independent testing set. Then we used machine learning methods including logistic regression, random forest and support vector machine (SVM) to construct the classification models and make the prediction. The AUC values on the independent testing set for those machine learning methods (logistic regression, random forest and SVM) are 0.946, 0.923 and 0.960 respectively. Secondly, for the data of word pattern frequency of amino acids, we calculated word pattern frequencies of amino acids of all individuals and compared them using Euclidean distance. The input features are the frequencies of amino acid word of length 2, which is normalized by dividing the total occurrence number of all words. What's more, word pattern frequencies of amino acids were used to construct the classification models for HCC status using machine learning methods. Principal coordinate analysis (PCoA) was also used to visualize the associations between patient clusters, the HCC disease status of patients, and the fraction of HBV genotypes. We found that word patterns are powerful for the analysis of the HBV sequences from the aspect of amino acids because the AUC values of the classification models for machine learning methods are all above 0.9. Hence, our study showed that word pattern frequencies of amino acids is powerful for revealing the underlying principles of the occurrence of HCC triggered by HBV. Our essential findings consist of three parts. Firstly, all machine learning methods can generate classification models with high AUC values. Then, we can find some certain positions of amino acids or word patterns of amino acids that the mutation occurred on those positions will induce the HCC. Last, PCoA is associated with the disease status (HCC or CHB) and the fraction of genotype B (or C).\n",
            "----------------------------------------\n",
            "Title: Towards Competence in Autonomous Agents\n",
            "Abstract: My thesis aims to contribute towards building autonomous agents that are able to develop what White (1959) called competency over their environment—agents that are able to achieve mastery over their domain and are able to solve new problems as they arise using the knowledge and skills they acquired in the past. While the field of machine learning has made much progress in solving individual, isolated problems, progress has been slow in developing agents that are able to interact effectively with their environment and flexibly deal with new tasks. There is still a large gap between the abilities of humans in this respect and the current capabilities of autonomous agents. My thesis will propose a number of methods for building competence in autonomous agents using the reinforcement learning (RL) framework, a computational approach to learning from interaction that has proved effective in certain types of problems (Sutton & Barto 1998). I expect that the methods I propose will extend the capabilities of RL agents in ways that are more than incremental, essentially allowing an autonomous agent to operate at a qualitatively different level.\n",
            "----------------------------------------\n",
            "Title: Automated Pediatric TMJ articular disk identification and displacement classification in MRI with machine learning.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Optimization of ultrasonic-excited double-pipe heat exchanger with machine learning and PSO\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Finding Optimally Robust Data Mixtures via Concave Maximization\n",
            "Abstract: Machine learning models are often required to perform well across several pre-defined settings, such as a set of user groups. Worst-case performance is a common metric to capture this requirement, and is the objective of group distributionally robust optimization (group DRO). Unfortunately, these methods struggle when the loss is non-convex in the parameters, or the model class is non-parametric. Here, we make a classical move to address this: we reparameterize group DRO from parameter space to function space, which results in a number of advantages. First, we show that group DRO over the space of bounded functions admits a minimax theorem. Second, for cross-entropy and mean squared error, we show that the minimax optimal mixture distribution is the solution of a simple convex optimization problem. Thus, provided one is working with a model class of universal function approximators, group DRO can be solved by a convex optimization problem followed by a classical risk minimization problem. We call our method MixMax. In our experiments, we found that MixMax matched or outperformed the standard group DRO baselines, and in particular, MixMax improved the performance of XGBoost over the only baseline, data balancing, for variations of the ACSIncome and CelebA annotations datasets.\n",
            "----------------------------------------\n",
            "Title: Towards efficient powder quality control in additive manufacturing via an in situ capable device and methodology leveraging multispectral machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Editorial: Applying Machine Learning for Combating Fake News and Internet/Media Content Manipulation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Analysing Economic Convergence Across the America: A Survival Analysis Approach to GDP Per Capita Trajectories\n",
            "Abstract: Machine learning algorithms, and economic interpretation, integrated with survival analysis, are used to examine the temporal dynamics associated with achieving a 5% increase in purchasing power parity-adjusted GDP per capita over a period of 120 months (2013-2022). The comparative investigation reveals that DeepSurv effectively captures non-linear interactions, though standard models exhibit comparable performance under certain conditions. The weight matrix evaluates the economic implications of vulnerabilities, risks, and capacities. To meet the GDP per capita objective, the findings emphasize the necessity of a balanced approach to risk-taking, strategic vulnerability reduction, and investment in governmental capacities and social cohesiveness. The policy guidelines advocate for individualized approaches that account for the complex dynamics at play in decision-making processes.\n",
            "----------------------------------------\n",
            "Title: Using AI/ML to gain situational understanding from passive network observations\n",
            "Abstract: The data available in the network traffic fromany Government building contains a significant amount ofinformation. An analysis of the traffic can yield insightsand situational understanding about what is happening inthe building. However, the use of traditional network packet inspection, either deep or shallow, is useful for only a limited understanding of the environment, with applicability limited to some aspects of network and security management. If weuse AI/ML based techniques to understand the network traffic, we can gain significant insights which increase our situational awareness of what is happening in the environment.At IBM, we have created a system which uses a combination of network domain knowledge and machine learning techniques to convert network traffic into actionable insights about the on premise environment. These insights include characterization of the communicating devices, discovering unauthorized devices that may violate policy requirements, identifying hidden components and vulnerability points, detecting leakage of sensitive information, and identifying the presence of people and devices.In this paper, we will describe the overall design of this system, the major use-cases that have been identified for it, and the lessons learnt when deploying this system for some of those use-cases\n",
            "----------------------------------------\n",
            "Title: Differentiating peritoneal tuberculosis and peritoneal carcinomatosis based on a machine learning model with CT: a multicentre study\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Development of an automated manufacturing course with lab for undergraduates\n",
            "Abstract: Many engineering programs at universities across the country have dropped machine shop and manufacturing courses from their curriculum due to budget constraints, accreditation requirements, and concerns about student safety. At the University of Portland, we have resurrected and enhanced a hands-on advanced CAD and automated manufacturing course that introduces students to advanced solid modeling techniques in CAD, such as sweeps, lofts, and surfacing methods. In addition, students learn manual machining and vacuum forming in our machine shop, along with learning how to create tool paths for CNC machining their designed CAD parts out of wax on various three axis end mills, a 3D printer, and a 3D laser scanner. The end mills were all refurbished and/or repaired over a period of four years to get this course up and running. A commercial software package, MasterCAM, was used in conjunction with SolidWorks as the platform from which to learn about automated manufacturing. In addition, a MakerBot 3D printer was built from a kit to give students experience with future manufacturing techniques. The 3D laser scanner was student designed and built and creates CAD surface models of parts, useful for learning about reverse engineering. The machinable wax used for machining is recycled, melted down, and formed into blocks again for reuse. This saves considerable money. Our goal has been to enhance design quality in our curriculum through experiential learning. Prior to taking this course, all mechanical engineering students are required to take a solid modeling CAD course to learn the basics. However, our experience has been that students do not conceptually understand the importance of designing for manufacture. Although emphasized in all courses, without the hands-on experience, it is difficult for students to remember to apply fillet radii to the bottom of pockets, for example. When faced with having to fit a block with sharp corners into a machined pocket with its default small corner radii, however, learning is instantaneous. The early outcomes of this course show students have learned a great deal about design for manufacturing and manufacturing techniques from taking this course.\n",
            "----------------------------------------\n",
            "Title: An Extension of the Gamma Test Statistics to Binary Variables and Some Applications\n",
            "Abstract: In this paper, we discuss the problem of estimating the minimum error reachable by a regression model given a dataset, prior to learning. More specifically, we extend the Gamma Test estimates of the variance of the noise from the continuous case to the binary case. We give some heuristics for further possible extensions of the theory in the continuous case with the [Formula: see text]-norm and conclude with some applications and simulations. From the point of view of machine learning, the result is relevant because it gives conditions under which there is no need to learn the model in order to predict the best possible performance.\n",
            "----------------------------------------\n",
            "Title: Machine learning techniques in bankruptcy prediction: A systematic literature review\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Harnessing the power of promising technologies to transform science education: prospects and challenges to promote adaptive epistemic beliefs in science learning\n",
            "Abstract: ABSTRACT Forming learners’ science concepts and conceptual change entails adaptive epistemic beliefs to support a high degree of interactivity within a coherent knowledge structure. Adaptive epistemic beliefs are characterized by beliefs that knowledge is uncertain and should be justified through experimentation or multiple sources dependent upon the task contexts. Thus, assessing and evaluating learners’ adaptive epistemic beliefs is a complex process that requires laborious analysis of learner artifacts based on reliable and valid coding schemes. This article aims to describe new ways of assessing and applying technologies that can measure and foster adaptive epistemic beliefs. We propose new strategies for a theoretically-based human-and-machine symbiotic Learning Analytics (LA) framework. The application of this LA framework may facilitate the development of real-time detecting and representation of the individual and collective epistemic belief networks as well as diagnosing and providing appropriate scaffolds to promote adaptive epistemic beliefs via the design of personalised pedagogical feedback with experts’ input. The heuristic application of technology infrastructure may propel a movement for more tangible and personalised learning in science education. The current gaps of using AI-based emerging technologies in science learning and implications for science education are discussed to advance science education in new directions.\n",
            "----------------------------------------\n",
            "Title: Long-term evolution of winter habitats in Poyang Lake derived from satellite imagery using machine learning methods\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Gender Identification from Speech Recognition Using Machine Learning Techniques and Convolutional Neural Networks\n",
            "Abstract: Gender identification represents a fundamental component of speech recognition and automatic interacting sound responding systems. Identifying the voice gender minimizes the computational loads of these systems for additional processing. Standard approaches for gender estimation from the speech have broadly relied on the extraction of speech features and classification tasks. This paper proposes a technique for gender identification of speech samples using the speech recognition process. The proposed technique extracts essential voice features like Mean, Zero-Crossing, Standard Deviation, and Amplitude, as well as 12 most significant features from every voice sample, and combines them to create voice feature vectors. The proposed technique uses several machine and deep learning methods such as Random Forest, KNN, Logistic Regression, Decision Tree, and CNNs, in order to classify the voice vectors into Male and Female classes. After comparing the evaluation metrics results of all classifiers, the proposed technique finds out that the CNN model is the best classifier used to classify the voice vectors with a higher precision value of 1.0.\n",
            "----------------------------------------\n",
            "Title: Unification of Machine Learning Features\n",
            "Abstract: In the Information Age, Machine learning (ML) provides a competitive advantage to any business. Machine learning applications are not limited to driverless cars or online recommendations but are widely used in healthcare, social services, government systems, telecommunications, and so on. As many enterprises are trying to step up machine learning applications, it is critical to have a long-term strategy. Most of the enterprises are not able to truly realize the fruits of ML capabilities due to its complexity. It is easier to access a variety of data today due to data democratization, distributed storage, technological advancements, and big data applications. Despite easier data access and recent advancements in ML, developers still spend most of the time in data cleansing, data preparation, and data modeling for ML applications. These steps are often repeated and result in identical features. As identical features can have inconsistent processing while testing and training, more issues pop up at later stages in ML application development. The unification of ML features is an effective way to address these issues. This paper presents details about numerous methods to achieve ML features unification.\n",
            "----------------------------------------\n",
            "Title: Experimental verification and identifying biomarkers related to insomnia\n",
            "Abstract: Introduction Insomnia is the most common form of sleep deprivation (SD) observed in clinics. Although there are differences between insomnia and SD, they have similar symptoms and the same animal model. Currently, there is a lack of microarray data on insomnia. Therefore, for now, we are going to apply the SD data to insomnia. Although many studies have explained the possible mechanisms associated with insomnia, no previous studies have considered the key genes associated with insomnia or the relationship between insomnia and immune cells. In this study, we analyzed the relationship between key genes and immune cells by identifying biomarkers for the diagnosis of insomnia. Next, we verified the efficacy of these biomarkers experimentally. Methods First, we downloaded four microarrays (GSE11755, GSE12624, GSE28750, and GSE48080) from the Gene Expression Omnibus (GEO) database, which included data from 239 normal human blood samples and 365 blood specimens from patients with SD. Then, we analyzed two groups of differentially expressed genes (DEGs) and used Support Vector Machine Recursive Feature Elimination (SVM-RFE) analysis and the Least Absolute Shrinkage and Selection Operator (LASSO) regression model to investigate these key genes. Next, we used CIBERSORT to investigate the composition of 22 immune cell components of key genes in SD patients. Finally, the expression levels of key biomarkers in sleep-deprived patients were examined by quantitative real-time polymerase chain reaction (qRT-PCR). Results A total of 50 DEGs were identified: six genes were significantly upregulated, and 44 genes were significantly downregulated. Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analysis showed that Salmonella infection, NOD-like receptor (NLR) signaling pathway, Kaposi sarcoma-associated herpesvirus infection, and Th17 cell differentiation were significant. Based on machine learning, we identified C2CD2L, SPINT2, APOL3, PKNOX1, and A2M as key genes for SD; these were confirmed by receiver operating characteristic (ROC) analysis. Immune cell infiltration analysis showed that C2CD2L, SPINT2, APOL3, PKNOX1, and A2M were related in different degrees to regulatory T cells (Tregs), follicular T helper cells, CD8 cells, and other immune cells. The qRT-PCR experiments confirmed that the expression levels of C2CD2L concurred with the results derived from machine learning, but PKNOX1 and APOL3 did not. Discussion In summary, we identified a key gene (C2CD2L) that may facilitate the development of biomarkers for insomnia.\n",
            "----------------------------------------\n",
            "Title: Dynamic Patterns: The Self-Organization of Brain and Behavior\n",
            "Abstract: Part 1 How nature handles complexity: what is a pattern? kinds of patterns principles of dynamic pattern formation the messages of self-organized patterns new laws to be expected in the organism matters of mind and matter the mind revealed? or, what this book's about. Part 2 Self-organization of behaviour - the basic picture: some historical remarks about the science of psychology are actions self-organized? if so, how? from synergies to synergetics requirements of a theory of self-organized behaviour. Part 3 Self-organization of behaviour - first steps of generalization: Hubris tempered? on Harvard horses and Russian cats coordination between components of an organism coordination between organisms on coupling. Part 4 Extending the basic picture - breaking away: relative coordination relative coordination explained absolute and relative coordination unified related models - fireflies, lampreys, and lasers instability and the nature of life - the intermittency mechanism exposed postscript. Part 5 Intentional dynamics: goal-directness in biology the second cornerstone of biological self-organization - informational specificity intentional behaviourial change related views - termites, predator-prey cycles, and quantum mechanics summing up. Part 6 Learning dynamics: issues in learning the main concepts the 'seagull effect' - competition and cooperation questions of learning transfer and generalization - symmetry again behaviourial development evolution and morphogenesis summary and conclusions. Part 7 perceptual dynamics: the barrier of meaning - perceptual dynamics I the barrier of meaning - perceptual dynamics II metastability of mind principles of perceiving - calculating, settling, resonating, and twinkling. Part 8 Self-organizing dynamics of the nervous system: microscale events mesoscale events macroscale events extending the basic picture...again postscript on etymology. Part 9 Self-organization of the human brain: prolegomenon obstacles to understanding the brain is not a static machine the 'brain dynamics' approach - fractural dimension spatiotemporal patterns of the brain models of brain behaviour - coupled modes and Sil'nikov chaos summary and conclusions - brain behaviour.\n",
            "----------------------------------------\n",
            "Title: Assessment of Readiness of Croatian Companies to Introduce I4.0 Technologies\n",
            "Abstract: The main topic of this paper is to estimate the possibility and inclination of Croatian companies towards technology and innovation as well as to analyze advantages, limitations and risks involved with this significant technological leap. We analyzed 7147 Croatian business entities operating in different industries in this paper. The starting point in this research is to identify subjects, which could be users of I4.0 or its elements, based on the similarity of indicators with indicators of a sample of 58 identified I4.0 companies. We developed a machine-learning model by using the eXtreme Gradient Boosting algorithm (XGBoost) for this purpose, an approach that has not been used in any similar research. This research shows that the main difference between I4.0 and traditional industry is mostly observable in significantly better business performance of investment indicators, cost efficiency, technical equipment and market competitiveness. We identified 141 companies (1.97% of total analyzed sample) as potential users of I4.0, which makes up around 27% of total assets of the analyzed sample and around 26% of revenues.\n",
            "----------------------------------------\n",
            "Title: Adaptive multi-agent smart academic advising framework\n",
            "Abstract: Abdelaziz A. Abdelhamid, College of Computing & Information Technology, Shaqra University, Saudi Arabia. Email: Abdelaziz@cis.asu.edu.eg Abstract Academic advising is a crucial process in higher education and usually requires better understanding of student capabilities and curriculum structure to achieve its intended goals. Here, the authors propose a framework of integrated environment based on multi‐ agents to automate the full process of academic advising. The proposed framework consists of six agents namely, student agent, instructor agent, administrator agent, performance agent, schedule agent, and smart advisor agent. These agents are interacting together with the help of smart advisor agent, which manages the communication between them and provides smart advice based on machine learning techniques. In addition, the analysis of the proposed framework along with the deployment map is discussed by the authors. Moreover, a case study is presented in terms of a sample part of adaptive multi‐agent smart academic advising framework to demonstrate the workflow of the proposed approach.\n",
            "----------------------------------------\n",
            "Title: Predicting Survival Time of Ball Bearings in the Presence of Censoring\n",
            "Abstract: Ball bearings find widespread use in various manufacturing and mechanical domains, and methods based on machine learning have been widely adopted in the field to monitor wear and spot defects before they lead to failures. Few studies, however, have addressed the problem of censored data, in which failure is not observed. In this paper, we propose a novel approach to predict the time to failure in ball bearings using survival analysis. First, we analyze bearing data in the frequency domain and annotate when a bearing fails by comparing the Kullback-Leibler divergence and the standard deviation between its break-in frequency bins and its break-out frequency bins. Second, we train several survival models to estimate the time to failure based on the annotated data and covariates extracted from the time domain, such as skewness, kurtosis and entropy. The models give a probabilistic prediction of risk over time and allow us to compare the survival function between groups of bearings. We demonstrate our approach on the XJTU and PRONOSTIA datasets. On XJTU, the best result is a 0.70 concordance-index and 0.21 integrated Brier score. On PRONOSTIA, the best is a 0.76 concordance-index and 0.19 integrated Brier score. Our work motivates further work on incorporating censored data in models for predictive maintenance.\n",
            "----------------------------------------\n",
            "Title: PAS: Probably Approximate Safety Verification of Reinforcement Learning Policy Using Scenario Optimization\n",
            "Abstract: With the advancement of machine learning based automation in the current digital world, the problem of safety verification of such systems is becoming crucial, especially in safety-critical domains like self-driving cars, robotics, etc. Reinforcement learning (RL) is an emerging machine learning technique with many applications, including in safety-critical domains. The classical safety verification approach of making a binary decision on determining whether a system is safe or unsafe is particularly challenging for an RL system. Such an approach generally requires prior knowledge about the system, e.g., the transition model of the system, the set of unsafe states in the environment, etc., which are typically unavailable in a standard RL setting. Instead, this paper addresses the safety verification problem from a quantitative safety perspective, i.e., we quantify the safe behavior of the policy in terms of probability. We formulate the safety verification problem as a chance-constrained optimization using the technique of barrier certificate. We then use a sampling based approach called scenario optimization to solve the chance-constrained problem, which gives the desired probabilistic guarantee on the safe behavior of the policy. Our extensive empirical evaluation shows the validity and robustness of our approach in three RL domains.\n",
            "----------------------------------------\n",
            "Title: Constructing and predicting school advice for academic achievement: a comparison of item response theory and machine learning techniques\n",
            "Abstract: Educational tests can be used to estimate pupils' abilities and thereby give an indication of whether their school type is suitable for them. However, tests in education are usually conducted for each content area separately which makes it difficult to combine these results into one single school advice. To help with school advice, we provide a comparison between both domain-specific and domain-agnostic methods for predicting school types. Both use data from a pupil monitoring system in the Netherlands, a system that keeps track of pupils' educational progress over several years by a series of tests measuring multiple skills. A domain-specific item response theory (IRT) model is calibrated from which an ability score is extracted and is subsequently plugged into a multinomial log-linear regression model. Second, we train domain-agnostic machine learning (ML) models. These are a random forest (RF) and a shallow neural network (NN). Furthermore, we apply case weighting to give extra attention to pupils who switched between school types. When considering the performance of all pupils, RFs provided the most accurate predictions followed by NNs and IRT respectively. When only looking at the performance of pupils who switched school type, IRT performed best followed by NNs and RFs. Case weighting proved to provide a major improvement for this group. Lastly, IRT was found to be much easier to explain in comparison to the other models. Thus, while ML provided more accurate results, this comes at the cost of a lower explainability in comparison to IRT.\n",
            "----------------------------------------\n",
            "Title: IPC Multi-label Classification Applying the Characteristics of Patent Documents\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Predicting Citation Counts Using Text and Graph Mining\n",
            "Abstract: As the volume of scientific literature grows faster it becomes more difficult for researchers to identify promising papers that are likely to become influential in their field. We study the problem of predicting future citation counts of papers given information available at the time of publication (five years forward in our pilot study). We apply machine learning techniques on a dataset of millions of academic papers from several research domains to identify predictive features including venue reputation, authors and institutions, citation networks and content measures. We identify how these features are differentially predictive in various domains and identify possible reasons where citation behaviors might lead to these differences.\n",
            "----------------------------------------\n",
            "Title: Predicting Cyber Risks through National Vulnerability Database\n",
            "Abstract: ABSTRACT Software vulnerabilities are the major cause of cyber security problems. The National Vulnerability Database (NVD) is a public data source that maintains standardized information about reported software vulnerabilities. Since its inception in 1997, NVD has published information about more than 43,000 software vulnerabilities affecting more than 17,000 software applications. This information is potentially valuable in understanding trends and patterns in software vulnerabilities so that one can better manage the security of computer systems that are pestered by the ubiquitous software security flaws. In particular, one would like to be able to predict the likelihood that a piece of software contains a yet-to-be-discovered vulnerability, which must be taken into account in security management due to the increasing trend in zero-day attacks. We conducted an empirical study on applying data-mining techniques on NVD data with the objective of predicting the time to next vulnerability for a given software application. We experimented with various features constructed using the information available in NVD and applied various machine learning algorithms to examine the predictive power of the data. Our results show that the data in NVD generally have poor prediction capability, with the exception of a few vendors and software applications. We suggest possible reasons for why the NVD data have not produced a reasonable prediction model for time to next vulnerability with our current approach, and suggest alternative ways in which the data in NVD can be used for the purpose of risk estimation.\n",
            "----------------------------------------\n",
            "Title: Potential of Artificial Intelligence in Improving Speed and Efficiency of Clinical Trials\n",
            "Abstract: \n",
            " In recent years, artificial intelligence (AI) has demonstrated its ability to improve many facets of health care. Clinical trials are no exception. There s enormous potential in the use of AI in all stages of clinical trials – planning, conduct, and analysis. However, clinical trials are highly regulated, and the guidance on the use of AI in trials has not yet been developed. Once these challenges are overcome or in the appropriate setting, AI can offer significant speed and cost advantage across all stages of clinical trials. In the planning stage, AI can simulate patient journey to enable patient-centric study design and identify the patient pool and investigational sites based on eligibility criteria. The tools can run multiple scenarios on timeline, cost, and complexity to determine feasibility. Generative AI can be used to create study documents. During study conduct, AI can be deployed to identify risks for data quality and integrity enabling reduction in monitoring visits and potentially reducing carbon footprint. AI can predict event accrual and data cleaning using machine learning. During study closeout, AI can accelerate data query resolution by bots and reduce site burden. The generative AI applied during the creation of study documents can be efficiently used to write study reports and generate tables and figures. In summary, AI has the potential to improve the efficiency of clinical trials, and if development is successful, AI can even potentially reduce the cost of drug to the patient.\n",
            "----------------------------------------\n",
            "Title: Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification\n",
            "Abstract: Chronic kidney disease (CKD) is a significant public health challenge, often progressing to end-stage renal disease (ESRD) if not detected and managed early. Early intervention, warranted by silent disease progression, can significantly reduce associated morbidity, mortality, and financial burden. In this study, we propose a novel approach to modeling CKD progression using a combination of machine learning techniques and classical statistical models. Building on the work of Liu et al. (2023), we evaluate linear models, tree-based methods, and deep learning models to extract novel predictors for CKD progression, with feature importance assessed using Shapley values. These newly identified predictors, integrated with established clinical features from the Kidney Failure Risk Equation, are then applied within the framework of Cox proportional hazards models to predict CKD progression.\n",
            "----------------------------------------\n",
            "Title: Predicting stock movement direction with machine learning: An extensive study on S&P 500 stocks\n",
            "Abstract: Stocks movement direction forecasting has received a lot of attention. Indeed, being able to make accurate forecasts has strong implications on trading strategies. Surprisingly enough little has been published, relatively to the importance of the topic. In this paper, we reviewed how well four classic classification algorithms: random forest, gradient boosted trees, artificial neural network and logistic regression perform in predicting 463 stocks of the S&P 500. Several experiments were conduced to thoroughly study the predictability of these stocks. To validate each prediction algorithm, three schemes we compared: standard cross validation, sequential validation and single validation. As expected, we were not able to predict stocks future prices from their past. However, unexpectedly, we were able to show that taking into account recent information — such as recently closed European and Asian indexes — to predict S&P 500 can lead to a vast increase in predictability. Moreover, we also found out that, among various sectors, financial sector stocks are comparatively more easy to predict than others.\n",
            "----------------------------------------\n",
            "Title: A survey of ontology learning techniques and applications\n",
            "Abstract: Abstract Ontologies have gained a lot of popularity and recognition in the semantic web because of their extensive use in Internet-based applications. Ontologies are often considered a fine source of semantics and interoperability in all artificially smart systems. Exponential increase in unstructured data on the web has made automated acquisition of ontology from unstructured text a most prominent research area. Several methodologies exploiting numerous techniques of various fields (machine learning, text mining, knowledge representation and reasoning, information retrieval and natural language processing) are being proposed to bring some level of automation in the process of ontology acquisition from unstructured text. This paper describes the process of ontology learning and further classification of ontology learning techniques into three classes (linguistics, statistical and logical) and discusses many algorithms under each category. This paper also explores ontology evaluation techniques by highlighting their pros and cons. Moreover, it describes the scope and use of ontology learning in several industries. Finally, the paper discusses challenges of ontology learning along with their corresponding future directions.\n",
            "----------------------------------------\n",
            "Title: Design of Badminton Technical Movement Recognition System Based on Improved Agnes Algorithm\n",
            "Abstract: The Badminton Technical Movement Recognition System is a technology-driven solution aimed at identifying and analyzing various technical movements performed by badminton players during gameplay. Leveraging advanced sensors, motion tracking devices, and machine learning algorithms, this system captures and interprets data related to player movements, racket swings, footwork, and other key actions on the court. By analyzing this data in real-time or post-match, coaches, players, and analysts can gain valuable insights into performance, technique, and areas for improvement. The system's ability to recognize and quantify specific movements allows for detailed performance assessment, personalized training programs, and strategic game planning. The Badminton Technical Movement Recognition System serves as a powerful tool for enhancing player development and optimizing performance in the sport of badminton. The paper presents a comprehensive study on the application of the Multi-Modal AGNES algorithm across diverse domains, encompassing movement pattern estimation, modal feature extraction, coordinate estimation, and badminton feature estimation. Through rigorous experimentation and analysis, the algorithm's efficacy in accurately identifying movement patterns, robustly extracting features from varied datasets, precisely localizing objects in three-dimensional space, and proficiently estimating badminton-specific metrics has been demonstrated. Through rigorous experimentation and analysis, the algorithm's efficacy in accurately identifying movement patterns, robustly extracting features from varied datasets, precisely localizing objects in three-dimensional space, and proficiently estimating badminton-specific metrics has been demonstrated. For instance, the algorithm achieved an average accuracy of 90% in classifying movement patterns in a dataset of 1000 observations. Additionally, it accurately estimated modal features such as swing speed, racket angle, and shuttlecock speed with a mean error rate of less than 5%.    \n",
            "----------------------------------------\n",
            "Title: 基于认知算法的中文本体自动构建工具研究与实现 Research and implementation of automatic Chinese ontology-building tools based on cognitive algorithms 云南民族大学学报：自然科学版，2018，27（3）：234-242\n",
            "Abstract: 本体广泛应用于语义网、自然语言处理、数字图书馆等领域，而自动构建本体是这些领域的难点之一.全自动的本体构建以及如何令机器自己不断学习并更新已有的本体知识的研究仍然缺乏.提出了一种基于认知算法的中文本体自动构建方法，建立了自动构建本体的概念和物理模型，并根据此模型实现了一个初步的自动构建本体的工具，在此基础上基于某些公理化算子来实现对已有本体的扩充、缩减、修正等操作，实验证明该模型和系统很大程度上降低了在构建本体过程中的人力投入. Ontology is widely used in the fields of semantic network, natural language processing, digital library and so on, while the automatic construction of ontology is one of the difficult points in these fields. There is a lack of research on fully automatic ontology construction and the approaches to maintaining the machine learning or updating the existing knowledge ontology. Research and implementation of automatic Chinese ontology-building tools based on cognitive algorithms creates a model of automatic Chinese ontology-building tool; meanwhile, a system is programmed to simulate this kind of ontology-learning. This system can do basic ontology-operations like ontology-expansion, ontology-reduction, ontology-correction and so on. And the results of all the above-mentioned experiments show that this model and system can reduce manpower on ontology engineering effectively.\n",
            "----------------------------------------\n",
            "Title: Combining phylogeny and coevolution improves the inference of interaction partners among paralogous proteins\n",
            "Abstract: Predicting protein-protein interactions from sequences is an important goal of computational biology. Various sources of information can be used to this end. Starting from the sequences of two interacting protein families, one can use phylogeny or residue coevolution to infer which paralogs are specific interaction partners within each species. We show that these two signals can be combined to improve the performance of the inference of interaction partners among paralogs. For this, we first align the sequence-similarity graphs of the two families through simulated annealing, yielding a robust partial pairing. We next use this partial pairing to seed a coevolution-based iterative pairing algorithm. This combined method improves performance over either separate method. The improvement obtained is striking in the difficult cases where the average number of paralogs per species is large or where the total number of sequences is modest. Author summary When two protein families interact, their sequences feature statistical dependencies. First, interacting proteins tend to share a common evolutionary history. Second, maintaining structure and interactions through the course of evolution yields coevolution, detectable via correlations in the amino-acid usage at contacting sites. Both signals can be used to computationally predict which proteins are specific interaction partners among the paralogs of two interacting protein families, starting just from their sequences. We show that combining them improves the performance of interaction partner inference, especially when the average number of potential partners is large and when the total data set size is modest. The resulting paired multiple-sequence alignments might be used as input to machine-learning algorithms to improve protein-complex structure prediction, as well as to understand interaction specificity in signaling pathways.\n",
            "----------------------------------------\n",
            "Title: Machine learning and brain imaging in psychosis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Recent trends in marine microplastic modeling and machine learning tools: Potential for long-term microplastic monitoring\n",
            "Abstract: The increase in the global demand for plastics, and more recently during the pandemic, is a major concern for the future of plastic waste pollution and microplastics. Efficient microplastic monitoring is imperative to understanding the long-term effects and progression of microplastic effects in the environment. Numerical models are valuable in studying microplastic transport as they can be used to examine the effects of different parameters systematically to help elucidate the fate and transport processes of microplastics, thus providing a holistic view of microplastics in the ocean environment. By incorporating physical parameters (such as size, shape, density, and identity of microplastics), numerical models have gained better understanding of the physics of microplastic transport, predicted sinking velocities more accurately, and estimated microplastic pathways in marine environments. However, availability of large amounts of information about microplastic physical and chemical parameters is sparse. Machine learning and computer-vision tools can aid in acquiring environmental information and provide input to develop more accurate models and verify their predictions. More accurate models can further the understanding of microplastic transport, facilitate monitoring efforts, and thus optimize where more data collection can take place to ultimately improve machine learning tools. This review offers a perspective on how image-based machine learning can be exploited to help uncover the physics of microplastic transport behaviors. Additionally, the authors hope the review inspires studies that can bridge the gap between numerical modeling and machine learning for microplastic analysis to exploit their joined potential.\n",
            "----------------------------------------\n",
            "Title: Global output on artificial intelligence in the field of nursing: A bibliometric analysis and science mapping.\n",
            "Abstract: PURPOSE\n",
            "To analyze the AI research in the field of nursing, to explore the current situation, hot topics, and prospects of AI research in the field of nursing, and to provide a reference for researchers to carry out related studies.\n",
            "\n",
            "\n",
            "METHODS\n",
            "We used the VOSviewer 1.6.17, SciMAT, and CiteSpace 5.8.R3 to generate visual cooperation network maps for the country, organizations, authors, citations, and keywords and perform burst detection, theme evolution, and so forth.\n",
            "\n",
            "\n",
            "FINDINGS\n",
            "A total of 9318 articles were obtained from the Web of Science Core Collection database. Four hundred and thirty-one AI research related to the field of nursing was published by 855 institutions from 54 countries. CIN-Computers Informatics Nursing was the top productive journal. The United States was the dominant country. The transnational cooperation between authors from developed countries was closer than that between authors from developing countries. The main hot topics included nurse rostering, nursing diagnosis, nursing decision support, disease risk factor prediction, nursing big data management, expert system, support vector machine, decision tree, deep learning, natural language processing, and nursing education. Machine learning represented one of the cutting-edge and most applicable branches of artificial intelligence in the field of nursing, and deep learning was the hottest technology among many machine learning methods in recent years. One of the most cited papers was published by Burke in 2004 and cited 500 times, which critically evaluated AI methods to deal with nurse scheduling problems.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Although AI has been paid more and more attention to the field of nursing, there is still a lack of high-yielding authors who have been engaged in this field for a long time. Most of the high contribution authors and institutions came from developed countries; therefore, more transnational and multi-disciplinary cooperation is needed to promote the development of AI in the nursing field. This bibliometric analysis not only provided a comprehensive overview to help researchers to understand the important articles, journals, potential collaborators, and institutions in this field but also analyzed the history, hot spots, and future trends of the research topic to provide inspiration for researchers to choose research directions.\n",
            "----------------------------------------\n",
            "Title: Intelligence-led policing in the 21st Century: How increased mobility requires new paradigms of information sharing\n",
            "Abstract: The challenge posed by mobile criminality to law enforcement has increased in the 21st Century, as technology and digital communication have accelerated. This study examines the threat by analysing foreign national suspects data (arrested in a UK police force, n = 293) and UK-based practitioner interviews (n = 36). The evidence reveals the threat from offenders who travel between countries is growing, in quantity and sophistication. To keep pace with this evolution, law enforcement must develop new paradigms of information sharing, using technological advances and machine learning to their benefit and relying less on resource-intensive human practice. It suggests such a change will create cultural challenges.\n",
            "----------------------------------------\n",
            "Title: AirDraw: Leveraging smart watch motion sensors for mobile human computer interactions\n",
            "Abstract: Wearable computing is one of the fastest growing technology markets today, with smart watches poised to take over at least of half the wearable device market. Approaches to text entry on smart watches and other wrist worn systems, independent of the small screen, is of importance to the further growth of wearable systems. The consistent user interaction and hands-free, heads-up operation of smart watches paves the way for gesture recognition methods for text entry. This paper proposes a new text input method for smart watches, which utilizes motion sensor data and machine learning approaches to detect letters written in the air by a user. This method is less computationally intensive, less expensive, and unaffected by lighting factors, when compared to computer vision approaches. The AirDraw system prototype developed to test this approach is presented, along with experimental results with close to 71% accuracy in letter recognition.\n",
            "----------------------------------------\n",
            "Title: Research and Application of Feature Extraction and Multi-objective Machine Learning\n",
            "Abstract: A feature extraction and multi-objective machine learning algorithm is proposed based on multi-objective coevolutionary algorithm.Training samples core attributes are found by feature extraction and attribute groups are composed of core attributes and non-core attributes,so the classified accuracy is improved.All attribute groups are supervised clustering by attribute similarity and class tags.The number and center of class families can automatically determined by using the fitness function in machine learning as the goal;in this way,they can avoid the effect of subjective factors and the two key elements owning optimization nature are guaranteed.The class tag using the nearest neighbor method determines a genus of the unclassified samples.At last,the algorithm is demonstrated by the UCI data sets of Liver Disorders,Hepatitis data sets and summery abnormal megathermal forecast in the north area of Zhejiang province.The experiment results indicate that feature extraction and multi-objective machine learning algorithm is better than the well-known NBC,C4.5 and SVM.\n",
            "----------------------------------------\n",
            "Title: Design and Development of a Personality Traits Classifier based on Machine Learning Techniques\n",
            "Abstract: Recently, during the last few years the use of digital devices, with Internet access, such as smartphones or tablets, has been increasing considerably in people's day after day. Because of this, Internet usage and therefore social networks usage has also increased. In social networks, users share personal data to broadcast content between users and this also implicitly convey useful information for companies studies. This makes interesting the task of characterizing users (in this case using personality) through their activity in social networks. \n",
            "In previous studies, there has been seen that personality can affect users in different aspects: preferences for interaction styles in the digital world or musical genres, for example. \n",
            "Consequently, the design of customized user interfaces and music recommender systems can help us to provide better experiences to users. \n",
            "This thesis is the result of a project whose main aim has been to obtain a personality traits classifier, whose task was set in a workshop in 2014, working on a YouTube dataset, using Python as programming language and deploying the system as a Senpy plug-in. \n",
            "During the development phase, there have been used supervised machine learning tools, natural language processing techniques (NLP) and queries to the sentiments and emotions analysis platform, Senpy. \n",
            "Regarding the workshop, there have been obtained similar results, what means that predicting personality can be seen as a real possibility.\n",
            "----------------------------------------\n",
            "Title: Mapping the daily nitrous acid (HONO) concentrations across China during 2006-2017 through ensemble machine-learning algorithm.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Method for reducing dimensions of hyper-spectral data on basis of pairwise constraint discriminate analysis and non-negative sparse divergence\n",
            "Abstract: The invention discloses a method for reducing dimensions of hyper-spectral data on the basis of pairwise constraint discriminate analysis and non-negative sparse divergence, and belongs to methods for processing hyper-spectral remote sensing images. The method aims to solve the problem of deterioration of the classification performance of most advanced algorithms for classifying hyper-spectral data on the basis of machine learning when source hyper-spectral data and target hyper-spectral data are distributed differently. The method includes firstly, performing pairwise constraint discriminate analysis according to pairwise constraint samples; secondly, designing a non-negative sparse divergence criterion to create a bridge among source-field hyper-spectral data and target-field hyper-spectral data which are distributed differently; thirdly, combining the pairwise constraint discriminate analysis with the bridge to transfer knowledge from the source hyper-spectral data to the target hyper-spectral data. The pairwise constraint samples containing discriminate information can be automatically acquired. The method has the advantages that the knowledge can be transferred among the hyper-spectral data acquired at different moments, in different areas or by different sensors; the information of the source-field hyper-spectral data can be effectively utilized to analyze the target-field hyper-spectral data, and high integral classification precision and a high Kappa coefficient can be acquired.\n",
            "----------------------------------------\n",
            "Title: Explainable Supervised Method for Genetics Ancestry Estimation\n",
            "Abstract: Ancestry estimation is one crucial stage in genomic research. It generates scores that represent the admixed genetics profile as the result of human evolution. In the previous research, we implemented multiple unsupervised methods to estimate these scores from large genomics data obtained from the 1000 Genome Project. These methods were limited to only cluster the samples to the five global populations in the dataset. The main challenge arose when implementing these methods to cluster the samples into more specific subpopulations. In this paper, we proposed a supervised approach to answer this challenge. Two state-of-the-art supervised machine learning methods, XGBoost and Deep Neural Network (DNN), were applied to the same dataset. These methods were aimed to classify samples, both into five main populations and also into 26 sub-populations. In the first classification task, both methods achieved similar results to our previous unsupervised approach. Interestingly, for the second classification task, which posses a relatively higher difficulty, DNN yielded better performance in the train, validation, and test dataset, despite its overfitting problem. Furthermore, the feature importance scores from each model were calculated using Shapley Additive Explanations (SHAP) method. Finally, 11 overlapped SNPs from all models were evaluated based on the reported Minor Allele Frequency (MAF) from the 1000 Genome Project. Overall, only using these 11 SNPs, we could differentiate each population in regards to its average MAF.\n",
            "----------------------------------------\n",
            "Title: Optimisation of System Configuration Using Machine Learning as a Surrogate Model\n",
            "Abstract: Complex mechanical systems provide a degree of reliability through redundancy. That is, they have duplicate systems, either similar or dissimilar, performing the same function. These duplicate systems will vary in their dynamic properties and may have different vibration transmission\n",
            " paths due to their connections within the overall system. Therefore, the use of redundancy gives rise to different vibrational behaviour of the overall system depending on the machines selected to deliver the intended system output. In some circumstances, it is necessary to minimise vibration\n",
            " levels by selecting a particular system configuration. In large complex systems consisting of multiple sources, this is not a trivial task, and virtually impossible to investigate all possible machinery combinations leading to the lowest vibration levels, whilst delivering the desired output.\n",
            " To address this, a machine learning model has been trained to provide predictions of machinery vibration levels. Data are obtained using an experimental vibration rig, emulating a complex, multi-source mechanical system. The machine learning model is subsequently utilised within a genetic\n",
            " algorithm optimisation routine in order to obtain the system configuration producing the lowest vibration levels at a number of observer locations for a specified system output.\n",
            "----------------------------------------\n",
            "Title: Learning Algorithm of Boltzmann Machine Based on Spatial Monte Carlo Integration Method\n",
            "Abstract: The machine learning techniques for Markov random fields are fundamental in various fields involving pattern recognition, image processing, sparse modeling, and earth science, and a Boltzmann machine is one of the most important models in Markov random fields. However, the inference and learning problems in the Boltzmann machine are NP-hard. The investigation of an effective learning algorithm for the Boltzmann machine is one of the most important challenges in the field of statistical machine learning. In this paper, we study Boltzmann machine learning based on the (first-order) spatial Monte Carlo integration method, referred to as the 1-SMCI learning method, which was proposed in the author’s previous paper. In the first part of this paper, we compare the method with the maximum pseudo-likelihood estimation (MPLE) method using a theoretical and a numerical approaches, and show the 1-SMCI learning method is more effective than the MPLE. In the latter part, we compare the 1-SMCI learning method with other effective methods, ratio matching and minimum probability flow, using a numerical experiment, and show the 1-SMCI learning method outperforms them.\n",
            "----------------------------------------\n",
            "Title: Performance Analysis of Multilayer Perceptron Neural Network Models in Week-Ahead Rainfall Forecasting\n",
            "Abstract: Multilayer perceptron neural network (MLPNN) is considered as one of the most efficient forecasting techniques which can be implemented for the prediction of weather occurrence. As with any machine learning implementation, the challenge on the utilization of MLPNN in rainfall forecasting lies in the development and evaluation of MLPNN models which delivers optimal forecasting performance. This research conducted performance analysis of MLPNN models through data preparation, model designing, and model evaluation in order to determine which parameters are the best-fit configurations for MLPNN model implementation in rainfall forecasting. During rainfall data preparation, imputation process and spatial correlation evaluation of weather variables from various weather stations showed that the geographical location of the chosen weather stations did not have a direct correlation between stations with respect to rainfall behavior leading to the decision of utilizing the weather station having the most complete weather data to be fed in the MLPNN. By conducting performance analysis of MLPNN models with different combinations of training algorithms, activation functions, learning rate, and momentum, it was found out that MLPNN model having 100 hidden neurons with Scaled Conjugate Gradient training algorithm and Sigmoid activation function delivered the lowest RMSE of 0.031537 while another MLPNN model having the same number of hidden neurons, the same activation function but Resilient Propagation as training algorithm had the lowest MAE of 0.0209. The results of this research showed that performance analysis of MLPNN models is a crucial process in model implementation of MLPNN for week-ahead rainfall forecasting.\n",
            "----------------------------------------\n",
            "Title: Transcriptomic analysis of immune cells in a multi-ethnic cohort of systemic lupus erythematosus patients identifies ethnicity- and disease-specific expression signatures\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Multiple Machine Learning Algorithms for Cancer Prognosis in Lung Adenocarcinoma\n",
            "Abstract: Lung cancer is the most prevailing source of death due to cancer, accounting for over 25% of death in the United States. Being able to predict the survival time for patients will provide valuable information for the choice of their treatment plans and benefit patient management. With the advancement of next-generation sequencing, many high-throughput sequencing data for DNA and RNA becomes available for cancer patients. Here we present the results for using multiple machine learning algorithms in predicting the survivorship of patients with Lung cancer adenocarcinoma. Using the publicly available datasets in TCGA with the overall survival length, and transcriptomic information, we evaluated our ability to predict prognosis. We found that using the expression level of a few candidate genes alone generates significant statistical power from a very limited number of patients, suggesting more future studies to be conducted on collecting such data to facilitate personalized medicine.\n",
            "----------------------------------------\n",
            "Title: Spatiotemporal estimation of the PM2.5 concentration and human health risks combining the three-dimensional landscape pattern index and machine learning methods to optimize land use regression modeling in Shaanxi, China.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: 6G-SECUREIDS: Blockchain-Enhanced Secure Knowledge Transfer for Distributed Intrusion Detection Systems in Advanced Networks\n",
            "Abstract: As the development of wireless networks advances towards the deployment of 6G technology, ensuring robust security measures becomes crucial. In this paper, we propose 6G-SECUREIDS, a novel intrusion detection system designed specifically for 6G wireless networks. The system leverages machine learning techniques and blockchain technology to detect and mitigate security threats, safeguard data privacy, and ensure efficient and optimized training. Our experimental results demonstrate the effectiveness and reliability of the system, with the clients achieving high accuracy scores across different model architectures. The promising results highlight the potential of 6G-SECUREIDS as a valuable security solution for future 6G networks, contributing to the overall protection and integrity of the wireless communication ecosystem.\n",
            "----------------------------------------\n",
            "Title: Machine learning algorithm for ventilator mode selection, pressure and volume control\n",
            "Abstract: Mechanical ventilation techniques are vital for preserving individuals with a serious condition lives in the prolonged hospitalization unit. Nevertheless, an imbalance amid the hospitalized people demands and the respiratory structure could cause to inconsistencies in the patient’s inhalation. To tackle this problem, this study presents an Iterative Learning PID Controller (ILC-PID), a unique current cycle feedback type controller that helps in gaining the correct pressure and volume. The paper also offers a clear and complete examination of the primarily efficient neural approach for generating optimal inhalation strategies. Moreover, machine learning-based classifiers are used to evaluate the precision and performance of the ILC-PID controller. These classifiers able to forecast and choose the perfect type for various inhalation modes, eliminating the likelihood that patients will require mechanical ventilation. In pressure control, the suggested accurate neural categorization exhibited an average accuracy rate of 88.2% in continuous positive airway pressure (CPAP) mode and 91.7% in proportional assist ventilation (PAV) mode while comparing with the other classifiers like ensemble classifier has reduced accuracy rate of 69.5% in CPAP mode and also 71.7% in PAV mode. An average accuracy of 78.9% rate in other classifiers compared to neutral network in CPAP. The neural model had an typical range of 81.6% in CPAP mode and 84.59% in PAV mode for 20 cm H2O of volume created by the neural network classifier in the volume investigation. Compared to the other classifiers, an average of 72.17% was in CPAP mode, and 77.83% was in PAV mode in volume control. Different approaches, such as decision trees, optimizable Bayes trees, naive Bayes trees, nearest neighbour trees, and an ensemble of trees, were also evaluated regarding the accuracy by confusion matrix concept, training duration, specificity, sensitivity, and F1 score.\n",
            "----------------------------------------\n",
            "Title: Geometric Data Analysis Across Scales via Laplacian Eigenvector Cascading.\n",
            "Abstract: We develop here an algorithmic framework for constructing consistent multiscale Laplacian eigenfunctions (vectors) on data. Consequently, we address the unsupervised machine learning task of finding scalar functions capturing consistent structure across scales in data, in a way that encodes intrinsic geometric and topological features. This is accomplished by two algorithms for eigenvector cascading. We show via examples that cascading accelerates the computation of graph Laplacian eigenvectors, and more importantly, that one obtains consistent bases of the associated eigenspaces across scales. Finally, we present an application to TDA mapper, showing that our multiscale Laplacian eigenvectors identify stable flair-like structures in mapper graphs of varying granularity.\n",
            "----------------------------------------\n",
            "Title: Assessing responses to climate stressors in two contrasting pine species\n",
            "Abstract: \n",
            " <p>Climate conditions in which tree species are able to grow are determined by their ecophysiological traits. The genus Pinus spp. is widespread across Eurasia, so that the different Pinus species have evolved to live within diverse climate envelops, from the boreal Scots pine (Pinus sylvestris L.) to the Mediterranean Aleppo pine (Pinus halepensis Mill.). Therefore, the different pine species are expected to present contrasting responses to environmental stressors, depending on the ones that populations had faced in the past.</p><p>Here we analyze the impact of climate on stand carbon fluxes in two contrasting stands -i.e. a boreal Finnish Scots pine stand and a Mediterranean Israeli Aleppo pine stand. We use a machine learning approach -i.e. Random Forest algorithm- to evaluate seasonal changes in the most limiting environmental driver (MLED) for forest productivity. Then, we use data from controlled experiments with Aleppo and Scots pine saplings, in which we evaluated their response to drought and heat stresses, in order to assess if differences in their ecophysiological traits may explain their ability to grow in such contrasting climate conditions.</p><p>Our results suggest that the MLED of forest productivity during all year in the boreal stand are low temperatures. Conversely but not surprisingly, the MLED in the Mediterranean stand is soil water availability, especially during summer. Therefore, we expect P. halepensis to be better adapted to heat and drought stresses, whereas we expect P. sylvestris to present higher photosynthetic rates at lower temperatures. Controlled experiments confirm these expectations, with a remarkable isohydric behavior of P. halepensis during drought, and different species responses of photosynthesis thermal optimum to heat and drought stress. Our results highlight the need to understand how traits determine tree species&#8217; responses to different environmental stressors, in order to anticipate their performance in a warmer world.</p>\n",
            "\n",
            "----------------------------------------\n",
            "Title: SOUNDLAB AI Tool – Machine Learning zur Bestimmung des bewerteten Schalldämmmaßes\n",
            "Abstract: Die moderne Architektur strebt nach transparenten Gebäudehüllen und insbesondere nach nachhaltigen und bauphysikalisch adäquaten Glasfassaden. Typischerweise werden Glasfassaden entworfen, um eine Vielzahl von Zielen zu erfüllen, eines davon sind die Anforderungen an den Schallschutz. Eine zuverlässige Abschätzung der Schalldämmeigenschaften beliebiger Glasaufbauten ist aufgrund der Komplexität experimenteller Tests oder numerischer Simulationen zeitaufwendig und kostenintensiv. Daher wird in dieser Arbeit ein maschineller Lern‐Ansatz zur Prädiktion der akustischen Eigenschaften beliebiger Glasaufbauten vorgestellt.\n",
            "----------------------------------------\n",
            "Title: Consensus models to predict oral rat acute toxicity and validation on a dataset coming from the industrial context\n",
            "Abstract: ABSTRACT We report predictive models of acute oral systemic toxicity representing a follow-up of our previous work in the framework of the NICEATM project. It includes the update of original models through the addition of new data and an external validation of the models using a dataset relevant for the chemical industry context. A regression model for LD50 and multi-class classification model for toxicity classes according to the Global Harmonized System categories were prepared. ISIDA descriptors were used to encode molecular structures. Machine learning algorithms included support vector machine (SVM), random forest (RF) and naïve Bayesian. Selected individual models were combined in consensus. The different datasets were compared using the generative topographic mapping approach. It appeared that the NICEATM datasets were lacking some relevant chemotypes for chemical industry. The new models trained on enlarged data sets have applicability domains (AD) sufficiently large to accommodate industrial compounds. The fraction of compounds inside the models’ AD increased from 58% (NICEATM model) to 94% (new model). The increase of training sets improved models’ prediction performance: RMSE values decreased from 0.56 to 0.47 and balanced accuracies increased from 0.69 to 0.71 for NICEATM and new models, respectively.\n",
            "----------------------------------------\n",
            "Title: Using machine learning to develop a clinical prediction model for SSRI-associated bleeding: a feasibility study\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Social Credibility Incorporating Semantic Analysis and Machine Learning: A Survey of the State-of-the-Art and Future Research Directions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Armor Guard: Revolutionizing Motorcycle Safety with Smart Helmet\n",
            "Abstract: Motorcycle accidents continue to be a significant concern worldwide, with riders facing various risks on the road. In response to these challenges, The design and development of a smart helmet system, intended to improve rider safety and encourage responsible riding, is presented in this study. The smart helmet integrates cutting-edge technologies and innovative features to provide a comprehensive safety solution for motorcycle riders. Key functionalities of the smart helmet include advanced navigation assistance, seamless call management, proactive accident detection, real-time alcohol detection, fog removal, and backlight indicators. These features are designed to improve visibility, prevent accidents, and ensure compliance with safety protocols. The smart helmet has a safety feature that prevents the vehicle from turning on unless the person wearing the helmet follows specific safety requirements. Additionally, an LED stripe integrated into the helmet's visor assists in fog removal, while a backlight indicator at the back of the helmet enhances visibility to fellow riders. Testing and evaluation of the smart helmet system demonstrate its functionality, reliability, and effectiveness in real-world scenarios. Response time testing confirms the system's prompt detection and response to various events, such as helmet activation and accident detection. The research also identifies areas for future work, including the integration of advanced sensor technologies, enhanced communication and connectivity, AI and machine learning applications, and improvements in energy efficiency and user experience.\n",
            "----------------------------------------\n",
            "Title: Extracting normative relationships from business contracts\n",
            "Abstract: The normative concepts offer a principled basis for engineering flexible multiagent systems for business and other cross-organizational settings. However, producing suitable specifications is nontrivial: the difficulty is an obstacle to the adoption of multiagent systems in industry. This paper considers normative relationships of six main types, namely, commitments (both practical and dialectical), authorizations, powers, prohibitions, and sanctions. It applies natural language processing and machine learning to extract these relationships from business contracts, establishing that they are realistic and their encoding can assist modelers, thereby lowering a barrier to adoption. A ten-fold cross-validation over more than 800 sentences randomly drawn from a corpus of real-life contracts (and manually labeled) yields promising results for the viability of this approach.\n",
            "----------------------------------------\n",
            "Title: Design of a recommendation system based on collaborative filtering and machine learning considering personal needs of the user\n",
            "Abstract: The paper reports a study into recommendation algorithms and determination of their advantages and disadvantages. The method for developing recommendations based on collaborative filtering such as Content-Based Filtering (CBF), Collaborative Filtering (CF), and hybrid methods of Machine Learning (ML) has been improved. The paper describes the design principles and functional requirements to a recommendation system in the form of a Web application for choosing the content required by user using movies as an example. The research has focused on solving issues related to cold start and scalability within the method of collaborative filtering. To effectively address these tasks, we have used hybrid training methods. A hybrid recommendation system (HRS) has been practically implemented for providing relevant content recommendations using movies as an example, taking into consideration the user's personal preferences based on the constructed hybrid method. We have improved an algorithm for developing content recommendations based on the collaborative filtering and Machine Learning for the combined filtration of similarity indicators among users or goods. The hybrid algorithm receives initial information in a different form, normalizes it, and generates relevant recommendations based on a combination of CF and CBF methods. Machine Learning is capable of defining those factors that influence the selection of relevant films, which improves development of recommendations specific to the user. To solve these tasks, a new improved method has been proposed, underlying which, in contrast to existing systems of recommendations, are the hybrid methods and Machine Learning. Machine Learning data for the designed HRS were borrowed from MovieLens. We have analyzed methods for developing recommendations to the user; existing recommendation systems have been reviewed. Our experimental results demonstrate that the operational indicators for the proposed HRS, based on the technology of CF+CBF+ML, outperform those for two individual models, CF and CBF, and such their combinations as CF CBF, CF+ML, and CBF+ML. We recommend using HRS to collect data on people's preferences in selecting goods and to providing relevant recommendations.\n",
            "----------------------------------------\n",
            "Title: Establishment and interpretation of the gamma pass rate prediction model based on radiomics for different intensity-modulated radiotherapy techniques in the pelvis\n",
            "Abstract: Backgroundand objectives: Implementation of patient-specific quality assurance (PSQA) is a crucial aspect of precise radiotherapy. Various machine learning-based models have showed potential as virtual quality assurance tools, being capable of accurately predicting the dose verification results of fixed-beam intensity-modulated radiation therapy (IMRT) or volumetric modulated arc therapy (VMAT) plans, thereby ensuring safe and efficient treatment for patients. However, there has been no research yet that simultaneously integrates different IMRT techniques to predict the gamma pass rate (GPR) and explain the model.Methods: Retrospective analysis of the 3D dosimetric verification results based on measurements with gamma pass rate criteria of 3%/2 mm and 10% dose threshold of 409 pelvic IMRT and VMAT plans was carried out. Radiomics features were extracted from the dose files, from which the XGBoost algorithm based on SHapley Additive exPlanations (SHAP) values was used to select the optimal feature subset as the input for the prediction model. The study employed four different machine learning algorithms, namely, random forest (RF), adaptive boosting (AdaBoost), extreme gradient boosting (XGBoost), and light gradient boosting machine (LightGBM), to construct predictive models. Sensitivity, specificity, F1 score, and AUC value were calculated to evaluate the classification performance of these models. The SHAP values were utilized to perform a related interpretive analysis on the best performing model.Results: The sensitivities and specificities of the RF, AdaBoost, XGBoost, and LightGBM models were 0.96, 0.82, 0.93, and 0.89, and 0.38, 0.54, 0.62, and 0.62, respectively. The F1 scores and area under the curve (AUC) values were 0.86, 0.81, 0.88, and 0.86, and 0.81, 0.77, 0.85, and 0.83, respectively. The explanation of the model output based on SHAP values can provide a reference basis for medical physicists when adjusting the plan, thereby improving the efficiency and quality of treatment plans.Conclusion: It is feasible to use a machine learning method based on radiomics to establish a gamma pass rate classification prediction model for IMRT and VMAT plans in the pelvis. The XGBoost model performs better in classification than the other three tree-based ensemble models, and global explanations and single-sample explanations of the model output through SHAP values may offer reference for medical physicists to provide high-quality plans, promoting the clinical application and implementation of GPR prediction models, and providing safe and efficient personalized QA management for patients.\n",
            "----------------------------------------\n",
            "Title: M3ICRO: Machine Learning-Enabled Compact Photonic Tensor Core based on PRogrammable Multi-Operand Multimode Interference\n",
            "Abstract: Photonic computing shows promise for transformative advancements in machine learning (ML) acceleration, offering ultrafast speed, massive parallelism, and high energy efficiency. However, current photonic tensor core (PTC) designs based on standard optical components hinder scalability and compute density due to their large spatial footprint. To address this, we propose an ultracompact PTC using customized programmable multi-operand multimode interference (MOMMI) devices, named M3ICRO. The programmable MOMMI leverages the intrinsic light propagation principle, providing a single-device programmable matrix unit beyond the conventional computing paradigm of one multiply-accumulate operation per device. To overcome the optimization difficulty of customized devices that often requires time-consuming simulation, we apply ML for optics to predict the device behavior and enable differentiable optimization flow. We thoroughly investigate the reconfigurability and matrix expressivity of our customized PTC and introduce a novel block unfolding method to fully exploit the computing capabilities of a complex-valued PTC for near-universal real-valued linear transformations. Extensive evaluations demonstrate that M3ICRO achieves a 3.5–8.9× smaller footprint, 1.6–4.4× higher speed, 9.9–38.5× higher compute density, 3.7–12× higher system throughput, and superior noise robustness compared to state-of-the-art coherent PTC designs. It also outperforms electronic digital A100 graphics processing unit by 34.8–403× higher throughput while maintaining close-to-digital task accuracy across various ML benchmarks.\n",
            "----------------------------------------\n",
            "Title: A Right to a Human Decision\n",
            "Abstract: Recent advances in computational technologies have spurred anxiety about a shift of power from human to machine decision-makers. From prison sentences to loan approvals to college applications, corporate and state actors increasingly lean on machine learning tools (a subset of artificial intelligence) to allocate goods and to assign coercion. Machine-learning tools are perceived to be eclipsing, even extinguishing, human agency in ways that sacrifice important individual interests. An emerging legal response to such worries is a right to a human decision. European law has already embraced the idea in the General Data Protection Regulation. American law, especially in the criminal justice domain, is already moving in the same direction. But no jurisdiction has defined with precision what that right entails, or furnished a clear justification for its creation. This Article investigates the legal possibilities of a right to a human decision. I first define the conditions of technological plausibility for that right as applied against state action. To understand its technological predicates, I specify the margins along which machine decisions are distinct from human ones. Such technological contextualization enables a nuanced exploration of why, or indeed whether, the gaps that do separate human and machine decisions might have normative import. Based on this technological accounting, I then analyze the normative stakes of a right to a human decision. I consider three potential normative justifications: (a) an appeal to individual interests to participation and reason-giving; (b) worries about the insufficiently reasoned or individuated quality of state action; and (c) arguments based on negative externalities. A careful analysis of these three grounds suggests that there is no general justification for adopting a right to a human decision by the state. Normative concerns about insufficiently reasoned or accurate decisions, which have a particularly powerful hold on the legal imagination, are best addressed in other ways. Similarly, concerns about the ways that algorithmic tools create asymmetries of social power are not parried by a right to a human decision. Indeed, rather than firmly supporting a right to a human decision, available evidence tentatively points toward a countervailing ‘right to a well-calibrated machine decision’ as ultimately more normatively wellgrounded. * Frank and Bernice J. Greenberg Professor of Law, University of Chicago Law School. Thanks to Faith Laken for terrific research aid. Thanks to Tony Casey, David Driesen, Lauryn Gouldin, Daniel Hemel, Darryl Li, Anup Malani, Richard McAdams, Eric Posner, Julie Roin, and Lior Strahilevitz for thoughtful conversation. Workshop participants at the University of Chicago, the University of Houston, and Syracuse University School of Law also provided thoughtful feedback. All errors are mine. Electronic copy available at: https://ssrn.com/abstract=3382521\n",
            "----------------------------------------\n",
            "Title: Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing\n",
            "Abstract: The ACL 2005 Workshop on Feature Engineering for Machine Learning in Natural Language Processing is an opportunity to explore the various dimensions of feature engineering for problems that are of interest to the ACL community. Feature Engineering encompasses feature design, feature selection, feature induction, studies of feature impact (including feature ablation studies), and related topics. In 2003, there was a NIPS workshop on feature engineering (\"Feature Extraction and Feature Selection\"), but the focus was not on NLP problems specifically. Also, although the various aspects of feature engineering have been dealt with at times in various ACL forums, until now, to our knowledge, the spotlight has never been shone directly on this topic specifically for NLP and language technology problems. We feel that now is the time to look more closely. \n",
            " \n",
            "As experience with machine learning for solving natural language processing tasks accumulates in the field, practitioners are finding that feature engineering is as critical as the choice of machine learning algorithm, if not more so. Feature engineering significantly affects the performance of systems and deserves greater attention. Also, in the wake of the shift in our field away from knowledge engineering and of the successes of data-driven and statistical methods, researchers are likely to make further progress by incorporating additional, sometimes familiar, sources of knowledge as features. Feature design may benefit from expert insight even where the relative merits of features must be assessed through empirical techniques from data. Although some experience in the area of feature engineering is to be found in the theoretical machine learning community, the particular demands of natural language processing leave much to be discovered. \n",
            " \n",
            "In the call for papers, we expressed our intent of bringing together practitioners of NLP, machine learning, information extraction, speech processing, and related fields with the goal of sharing experimental evidence for successful approaches to feature engineering. Judging by the quality and diversity of the submissions received, we believe we have succeeded, and the resulting program should be of great interest to many researchers in the ACL community. We hope that the workshop will contribute to the distillation of best practices and to the discovery of new sources of knowledge and features previously untapped.\n",
            "----------------------------------------\n",
            "Title: Mixed state entanglement classification using artificial neural networks\n",
            "Abstract: Reliable methods for the classification and quantification of quantum entanglement are fundamental to understanding its exploitation in quantum technologies. One such method, known as separable neural network quantum states (SNNS), employs a neural network inspired parameterization of quantum states whose entanglement properties are explicitly programmable. Combined with generative machine learning methods, this ansatz allows for the study of very specific forms of entanglement which can be used to infer/measure entanglement properties of target quantum states. In this work, we extend the use of SNNS to mixed, multipartite states, providing a versatile and efficient tool for the investigation of intricately entangled quantum systems. We illustrate the effectiveness of our method through a number of examples, such as the computation of novel tripartite entanglement measures, and the approximation of ultimate upper bounds for qudit channel capacities.\n",
            "----------------------------------------\n",
            "Title: English -Malayalam Vision aid with Multi Modal Machine Learning Technologies\n",
            "Abstract: Most of the blind assistive devices accessible in the market operate in the English language. This narrow downs the product’s scope in multilingual countries. To deal with this, some assistive devices make use of translation APIs and modules to make an interpretation of English into the regional language, but these translations are not up to the mark when comparing with the original text. Most of the translation APIs make use of traditional machine translation models that intakes single context as input and produce translations out of it. Linguistic ambiguity is very common among such models. This is mainly because of the morphological and syntactical divergence between the languages. This makes English-Indic language translation a challenging task. This research work proposes an efficient translation algorithm exclusively for blind assistive devices. This approach employs an image-guided multi-modal machine translation methodology, in which an image is used as an additional input to generate more accurate translations/scene distributions on Malayalam.\n",
            "----------------------------------------\n",
            "Title: Recent advances in feature selection and its applications\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Automata Learning from Preference and Equivalence Queries\n",
            "Abstract: Active automata learning from membership and equivalence queries is a foundational problem with numerous applications. We propose a novel variant of the active automata learning problem: actively learn finite automata using preference queries -- i.e., queries about the relative position of two sequences in a total order -- instead of membership queries. Our solution is REMAP, a novel algorithm which leverages a symbolic observation table along with unification and constraint solving to navigate a space of symbolic hypotheses (each representing a set of automata), and uses satisfiability-solving to construct a concrete automaton from a symbolic hypothesis. REMAP is guaranteed to correctly infer the minimal automaton with polynomial query complexity under exact equivalence queries, and achieves PAC-identification ($\\varepsilon$-approximate, with high probability) of the minimal automaton using sampling-based equivalence queries. Our empirical evaluations of REMAP on the task of learning reward machines for two reinforcement learning domains indicate REMAP scales to large automata and is effective at learning correct automata from consistent teachers, under both exact and sampling-based equivalence queries.\n",
            "----------------------------------------\n",
            "Title: Identification of blood-based transcriptomics biomarkers for Alzheimer's disease using statistical and machine learning classifier\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Active sonar target classification using a physics-cognizant feature representation\n",
            "Abstract: Active sonar target classification is challenging due to the non-linear overlap of changing oceanic and target parameters, creating entangled acoustic color spectra that should be disentangled prior to classification. A physics-cognizant feature extraction algorithm, used before interfacing with three machine learning techniques for active sonar target classification of experimental field data, is presented. The feature extraction algorithm convolves a two-dimensional Gabor wavelet across acoustic color spectra prior to threshold-based binarization, feature culling, and dimensional reduction. The optimal two-dimensional Gabor wavelet parameters are chosen through sensitivity analysis by a support vector machine (SVM) on a disjoint subset of data. Classification is performed on the second subset of data with an SVM, random forest tree, and neural network on the Gabor filtered spectra and unfiltered spectra to show the increased classification accuracy of the application of the geometric wavelet. Classification results are presented as confusion matrices for four targets of two public domain experiments. Ongoing and future work will include extending this feature extraction technique using various geometric feature representations to capture and describe far-field large scattering mechanisms from targets such as oil rigs, tankers, and shipwrecks. [This research is funded by the Office of Naval Research under Grant No. N00014-19-1-2436.]\n",
            "----------------------------------------\n",
            "Title: Enhancing Comparative Effectiveness Research With Automated Pediatric Pneumonia Detection in a Multi-Institutional Clinical Repository: A PHIS+ Pilot Study\n",
            "Abstract: Background Community-acquired pneumonia is a leading cause of pediatric morbidity. Administrative data are often used to conduct comparative effectiveness research (CER) with sufficient sample sizes to enhance detection of important outcomes. However, such studies are prone to misclassification errors because of the variable accuracy of discharge diagnosis codes. Objective The aim of this study was to develop an automated, scalable, and accurate method to determine the presence or absence of pneumonia in children using chest imaging reports. Methods The multi-institutional PHIS+ clinical repository was developed to support pediatric CER by expanding an administrative database of children’s hospitals with detailed clinical data. To develop a scalable approach to find patients with bacterial pneumonia more accurately, we developed a Natural Language Processing (NLP) application to extract relevant information from chest diagnostic imaging reports. Domain experts established a reference standard by manually annotating 282 reports to train and then test the NLP application. Findings of pleural effusion, pulmonary infiltrate, and pneumonia were automatically extracted from the reports and then used to automatically classify whether a report was consistent with bacterial pneumonia. Results Compared with the annotated diagnostic imaging reports reference standard, the most accurate implementation of machine learning algorithms in our NLP application allowed extracting relevant findings with a sensitivity of .939 and a positive predictive value of .925. It allowed classifying reports with a sensitivity of .71, a positive predictive value of .86, and a specificity of .962. When compared with each of the domain experts manually annotating these reports, the NLP application allowed for significantly higher sensitivity (.71 vs .527) and similar positive predictive value and specificity . Conclusions NLP-based pneumonia information extraction of pediatric diagnostic imaging reports performed better than domain experts in this pilot study. NLP is an efficient method to extract information from a large collection of imaging reports to facilitate CER.\n",
            "----------------------------------------\n",
            "Title: ADAPTIVE SCHEDULING THROUGH MACHINE LEARNING-BASED PROCESS PARAMETER PREDICTION\n",
            "Abstract: Detailed manufacturing process data and sensor signals are typically disregarded in production scheduling. However, they have strong relations since a longer processing time triggers a change in schedule. Although promising approaches already exist for mapping the influence of manufacturing processes on production scheduling, the variability of the production environment, including changing process conditions, technological parameters and the status of current orders, is usually ignored. For this reason, this paper presents a novel, data-driven approach that adaptively refines the production schedule by applying Machine Learning (ML)-models during the manufacturing process in order to predict the process-dependent parameters that influence the schedule. With the proper prediction of these parameters based on the process conditions, the production schedule is proactively adjusted to changing conditions not only to ensure the sufficient product quality but also to reduce the negative effects and losses that delayed rescheduling would cause. The proposed approach aims on minimizing the overall lateness by utilizing an active data exchange between the scheduling system and the predictive ML-models on the process level. The efficiency of the solution is demonstrated by a realistic case study using discrete event simulation.\n",
            "----------------------------------------\n",
            "Title: Factorial models and refiltering for speech separation and denoising\n",
            "Abstract: This paper proposes the combination of several ideas, some old and some new, from machine learning and speech processing. We review the max approximation to log spectrograms of mixtures, show why this motivates a “refiltering” approach to separation and denoising, and then describe how the process of inference in factorial probabilistic models performs a computation useful for deriving the masking signals needed in refiltering. A particularly simple model, factorial-max vector quantization (MAXVQ), is introduced along with a branch-and-bound technique for efficient exact inference and applied to both denoising and monaural separation. Our approach represents a return to the ideas of Ephraim, Varga and Moore but applied to auditory scene analysis rather than to speech recognition. 1. Sparsity & Redundancy in Spectrograms 1.1. The Log-MaxApproximation When two clean speech signals are mixed additively in the time domain, what is the relationship between the individual log spectrograms of the sources and the log spectrogram of the mixture? Unless the sources are highly dependent (synchronized), the spectrogram of the mixture is almost exactly the maximum of the individual spectrograms, with the maximum operating over small time-frequency regions (fig. 2). This amazing fact, first noted by Roger Moore in 1983, comes from the fact that unless e1 and e2 are both large and almost equal, log(e1 + e2) ≈ max(log e1, log e2) (fig. 1a). The sparse nature of the speech code across time and frequency is the key to the practical usefulness of this approximation: most narrow frequency bands carry substantial energy only a small fraction of the time and thus it is rare that two independent sources inject large amounts of energy into the same subband at the same time. (Figure 1b shows a plot of the relative energy of two simultaneous speakers in a narrow subband; most of the time at least one of the two sources shows negligible power.) 1.2. Masking and Refiltering Fortunately, the speech code is also redundant across timefrequency. Different frequency bands carry, to a certain extent, independent information and so if information in some bands is suppressed or masked, even for significant durations, other bands can fill in. (A similar effect occurs over time: if brief sections of the signal are obscured, even across all bands, the speech is still intelligible; while also useful, we do not exploit this here.) This is partly why humans perform so well on many monaural speech separation and denoising tasks. When we solve the cocktail party problem or recognize degraded speech, we are doing structural analysis, or a kind of “perceptual grouping” on the incoming sound. There is substantial evidence that the appropriate subparts of an audio signal for use in grouping may be narrow frequency bands over short times. To generate these parts computationally, we can perform multiband analysis – break the original speech signal y(t) into many subband signals bi(t) each lo g e2 ma\n",
            "----------------------------------------\n",
            "Title: Aircraft Fleet Health Monitoring with Anomaly Detection Techniques\n",
            "Abstract: Predictive maintenance has received considerable attention in the aviation industry where costs, system availability and reliability are major concerns. In spite of recent advances, effective health monitoring and prognostics for the scheduling of condition-based maintenance operations is still very challenging. The increasing availability of maintenance and operational data along with recent progress made in machine learning has boosted the development of data-driven prognostics and health management (PHM) models. In this paper, we describe the data workflow in place at an airline for the maintenance of an aircraft system and highlight the difficulties related to a proper labelling of the health status of such systems, resulting in a poor suitability of supervised learning techniques. We focus on investigating the feasibility and the potential of semi-supervised anomaly detection methods for the health monitoring of a real aircraft system. roposed methods are evaluated on large volumes of real sensor data from a cooling unit system on a modern wide body aircraft from a major European airline. For the sake of confidentiality, data has been anonymized and only few technical and operational details about the system had been made available. We trained several deep neural network autoencoder architectures on nominal data and used the anomaly scores to calculate a health indicator. Results suggest that high anomaly scores are correlated with identified failures in the maintenance logs. Also, some situations see an increase in the anomaly score for several flights prior to the system’s failure, which paves a natural way for early fault identification.\n",
            "----------------------------------------\n",
            "Title: Active machine learning-driven experimentation to determine compound effects on protein patterns\n",
            "Abstract: High throughput screening determines the effects of many conditions on a given biological target. Currently, to estimate the effects of those conditions on other targets requires either strong modeling assumptions (e.g. similarities among targets) or separate screens. Ideally, data-driven experimentation could be used to learn accurate models for many conditions and targets without doing all possible experiments. We have previously described an active machine learning algorithm that can iteratively choose small sets of experiments to learn models of multiple effects. We now show that, with no prior knowledge and with liquid handling robotics and automated microscopy under its control, this learner accurately learned the effects of 48 chemical compounds on the subcellular localization of 48 proteins while performing only 29% of all possible experiments. The results represent the first practical demonstration of the utility of active learning-driven biological experimentation in which the set of possible phenotypes is unknown in advance. DOI: http://dx.doi.org/10.7554/eLife.10047.001\n",
            "----------------------------------------\n",
            "Title: Fault Diagnosis of Rolling Bearing Based on Improved LeNet-5 CNN\n",
            "Abstract: To solve the problem of fault diagnosis of rolling bearing caused by large amount of data and difficulties of processing those data on to bearing set, based on Convolution Neural Network, a new method of data processing is proposed in this paper. With this method, one-dimensional time domain signal can be transformed into two-dimensional images, which is more suitable for Convolutional Neural Network processing. Meanwhile, the traditional machine learning method has the disadvantage of low robustness and low recognition rate with noise interference. Therefore, based on the feature extraction of Convolution Neural Network, in this paper we proposed an improved LeNet-5 Convolution Neural Network model, that is, adding a convolution layer and a pooling layer to the classic LeNet-5 model. The hidden layer features are extracted by using the trainable convolution kernel, while the extracted implicit features are reduced by the pooling layer, the Softmax classifier is used for classification and recognition of rolling bearing faults. In this paper we verified the effectiveness of the improved LeNet-5 model for fault diagnosis of rolling bearing by using the rolling bearing data to train the classic LeNet-5 model and the improved model.\n",
            "----------------------------------------\n",
            "Title: Can machine learning make naturalism about health truly naturalistic? A reflection on a data-driven concept of health\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Population subset selection for the use of a validation dataset for overfitting control in genetic programming\n",
            "Abstract: ABSTRACT Genetic Programming (GP) is a technique which is able to solve different problems through the evolution of mathematical expressions. However, in order to be applied, its tendency to overfit the data is one of its main issues. The use of a validation dataset is a common alternative to prevent overfitting in many Machine Learning (ML) techniques, including GP. But, there is one key point which differentiates GP and other ML techniques: instead of training a single model, GP evolves a population of models. Therefore, the use of the validation dataset has several possibilities because any of those evolved models could be evaluated. This work explores the possibility of using the validation dataset not only on the training-best individual but also in a subset with the training-best individuals of the population. The study has been conducted with 5 well-known databases performing regression or classification tasks. In most of the cases, the results of the study point out to an improvement when the validation dataset is used on a subset of the population instead of only on the training-best individual, which also induces a reduction on the number of nodes and, consequently, a lower complexity on the expressions.\n",
            "----------------------------------------\n",
            "Title: Interactive tools for the transcription of handwritten documents\n",
            "Abstract: Public and private archives contain hundreds of precious ancient documents for historic and genealogical research: Civil records, church records, military records, population censuses. These archives are regularly scanned for preservation and sharing. However accessing information is tedious when the corpus is not indexed nor transcribed. Several project aim at indexing and transcribing such documents automatically, such as Transkribus [6] or Himanis [5]. Despite their efforts, transcribing documents automatically remain complicated and unsatisfactory for historians [4]. Automatic methods are not able to interpret complex writings (irregular, with overlaps, bad scan quality) [3]. Moreover these algorithms require hand-made learning database and machine learning experts to adapt the tool to a specific document corpus.\n",
            "----------------------------------------\n",
            "Title: A Bag of Strings Representation for Image Categorization\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Computational challenges for multimodal astrophysics\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Malware Detection Using Machine Learning Models\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Copyright lessons on Machine Learning: what impact on algorithmic art?\n",
            "Abstract: JIPITEC 10 (2020) 3 - Nowadays, Artificial Intelligence (AI) is described as “the new electricity”. Current algorithmic innovation allowed the development of software which enables machines to learn and to achieve autonomous decision making, with limited or no human involvement, in a vast number of applications, such as speech recognition, machine translation and algorithmic creation of works (computer generated art), on the basis of a process widely known as Machine Learning (ML). Within the ML context, machines are repeatedly trained by means of specifically designed learning algorithms that use a corpus of examples in the form of data sets as training material. Very often and, especially in the context of algorithmic creativity, the training material is mainly composed by copyrighted works, such as texts, images, paintings, musical compositions, and others. Machine Learning workflow typically involves the realization of (multiple) reproductions of any protected work used as training material. The present paper aims to assess the extent to which the use of copyrighted works for Machine Learning purposes in the field of algorithmic creativity is controlled by the monopolistic power of the copyright rightholder on that work. The answer to this question will be researched in the context of EU copyright law, by examining the content of reproduction right and exceptions possibly applicable in a typical ML workflow in the field of algorithmic art, before making an overall assessment of the current EU regulatory framework for artistic ML projects, as it is shaped after the DSM Directive 2019/790.\n",
            "----------------------------------------\n",
            "Title: Wind turbine drivetrains condition monitoring through SCADA data on farm level\n",
            "Abstract: The offshore wind industry has grown rapidly over the last decade and drivetrains are increasing in size to reduce the cost of energy. These turbines are operating in a harsh environment. Adopting a preventive maintenance strategy is important to achieve an as high as possible availability of the farm and reduce the cost of maintenance. A well performing condition monitoring system that utilizes SCADA data from the wind farm can enable this strategy without the need in additional cost in hardware. This master thesis focusses on the development of a framework that can be utilized for this task. This framework can process raw operational SCADA data collected at the Egmond aan Zee offshore wind farm to create a clean dataset to train supervised machine learning models on. This work provides an insight in the correlation between different SCADA signals using a mathematical approach and from a understanding of the system integration of drivetrain components. Bearing temperatures are modelled using a data driven approach to describe the temperatures under healthy conditions. Several models are evaluated for this task and it was concluded that a decision tree supervised machine learning regression model resulted in the lowest error between predicted and measured values. Anomalies are detected and tracked with a normal behaviour model and a Sherward and CUSUM control chart that are applied on the residual error between modelled and measured temperature signals. 4 anomalies could be identified in the gearbox bearings using the developed framework. Abnormal behaviour of the drivetrain could be identified as early as 1 month before the turbine was taken out of productions. This highlights that temperature based condition monitoring that utilizes SCADA data can be used for early detection of faults by combining the accuracy of supervised machine learning methods with different fault detection methods like the CUSUM control chart. This work also investigates the relation between experienced wake of a wind turbine and the influence on the drivetrain component temperatures. The wake conditions at Egmond aan Zee, modelled with an Ishahara wake model, and the component temperature measurements from the SCADA data are used for this analysis. The bearing temperature distributions under different operational and wake conditions can be compared by clustering over the wind speed and the velocity deficit or turbulence intensity at turbine level. It is concluded from this work that wake effects do not result in a change in drivetrain component temperatures. The effects of asymmetric wake conditions opposed to wake experienced over the entire rotor is analysed by comparing the temperature distributions under these conditions in a cluster where the turbine is partially waked. A small shift towards higher component temperatures can observed on a limited amount of data for turbines under asymmetric loading conditions.\n",
            "----------------------------------------\n",
            "Title: Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles\n",
            "Abstract: Ensemble deep learning has been shown to achieve high predictive accuracy and uncertainty estimation in a wide variety of medical imaging contexts. However, perturbations in the input images at test time (e.g. noise, domain shifts) can still lead to significant performance degradation, posing challenges for trustworthy clinical deployment. In order to address this, we propose LaDiNE, a novel and robust probabilistic method that is capable of inferring informative and invariant latent variables from the input images. These latent variables are then used to recover the robust predictive distribution without relying on a predefined functional-form. This results in improved (i) generalization capabilities and (ii) calibration of prediction confidence. Extensive experiments were performed on the task of disease classification based on the Tuberculosis chest X-ray and the ISIC Melanoma skin cancer datasets. Here the performance of LaDiNE was analysed under a range of challenging covariate shift conditions, where training was based on\"clean\"images, and unseen noisy inputs and adversarial perturbations were presented at test time. Results show that LaDiNE outperforms existing state-of-the-art baseline methods in terms of accuracy and confidence calibration. This increases the feasibility of deploying reliable medical machine learning models in real clinical settings, where accurate and trustworthy predictions are crucial for patient care and clinical decision support.\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning to Determine Morphologies of z < 1 AGN Host Galaxies in the Hyper Suprime-Cam Wide Survey\n",
            "Abstract: We present a machine-learning framework to accurately characterize the morphologies of active galactic nucleus (AGN) host galaxies within z < 1. We first use PSFGAN to decouple host galaxy light from the central point source, then we invoke the Galaxy Morphology Network (GaMorNet) to estimate whether the host galaxy is disk-dominated, bulge-dominated, or indeterminate. Using optical images from five bands of the HSC Wide Survey, we build models independently in three redshift bins: low (0 < z < 0.25), mid (0.25 < z < 0.5), and high (0.5 < z < 1.0). By first training on a large number of simulated galaxies, then fine-tuning using far fewer classified real galaxies, our framework predicts the actual morphology for ∼60%–70% of the host galaxies from test sets, with a classification precision of ∼80%–95%, depending on the redshift bin. Specifically, our models achieve a disk precision of 96%/82%/79% and bulge precision of 90%/90%/80% (for the three redshift bins) at thresholds corresponding to indeterminate fractions of 30%/43%/42%. The classification precision of our models has a noticeable dependency on host galaxy radius and magnitude. No strong dependency is observed on contrast ratio. Comparing classifications of real AGNs, our models agree well with traditional 2D fitting with GALFIT. The PSFGAN+GaMorNet framework does not depend on the choice of fitting functions or galaxy-related input parameters, runs orders of magnitude faster than GALFIT, and is easily generalizable via transfer learning, making it an ideal tool for studying AGN host galaxy morphology in forthcoming large imaging surveys.\n",
            "----------------------------------------\n",
            "Title: Projecting the Thermal Response in a HTGR-Type System during Conduction Cooldown Using Graph-Laplacian Based Machine Learning\n",
            "Abstract: Accurate prediction of an off-normal event in a nuclear reactor is dependent upon the availability of sensory data, reactor core physical condition, and understanding of the underlying phenomenon. This work presents a method to project the data from some discrete sensory locations to the overall reactor domain during conduction cooldown scenarios similar to High Temperature Gas-cooled Reactors (HTGRs). The existing models for conductive cooldown in a heterogeneous multi-body system, such as an assembly of prismatic blocks or pebble beds relies on knowledge of the thermal contact conductance, requiring significant knowledge of local thermal contacts and heat transport possibilities across those contacts. With a priori knowledge of bulk geometry features and some discrete sensors, a machine learning approach was devised. The presented work uses an experimental facility to mimic conduction cooldown with an assembly of 68 cylindrical rods initially heated to 1200 K. High-fidelity temperature data were collected using an infrared (IR) camera to provide training data to the model and validate the predicted temperature data. The machine learning approach used here first converts the macroscopic bulk geometry information into Graph-Laplacian, and then uses the eigenvectors of the Graph-Laplacian to develop Kernel functions. Support vector regression (SVR) was implemented on the obtained Kernels and used to predict the thermal response in a packed rod assembly during a conduction cooldown experiment. The usage of SVR modeling differs from most models today because of its representation of thermal coupling between rods in the core. When trained with thermographic data, the average normalized error is less than 2% over 400 s, during which temperatures of the assembly have dropped by more than 500 K. The rod temperature prediction performance was significantly better for rods in the interior of the assembly compared to those near the exterior, likely due to the model simplification of the surroundings.\n",
            "----------------------------------------\n",
            "Title: Sensitivity study using machine learning algorithms on simulated r-mode gravitational wave signals from newborn neutron stars\n",
            "Abstract: This is a follow-up sensitivity study on $r$-mode gravitational wave signals from newborn neutron stars illustrating the applicability of machine learning algorithms for the detection of long-lived gravitational wave transients. In this sensitivity study, we examine three machine learning algorithms (MLAs): artificial neural networks, support vector machines, and constrained subspace classifiers. The objective of this study is to compare the detection efficiencies that MLAs can achieve to the efficiency of the conventional (seedless clustering) detection algorithm discussed in an earlier paper. Comparisons are made using two distinct $r$-mode waveforms. For the training of the MLAs, we assumed that some information about the distance to the source is given so that the training was performed over distance ranges not wider than half an order of magnitude. The results of this study suggest that we can use the machine learning algorithms as part of an investigative stage in the pipeline that would be able to provide very fast and solid triggers for further, and more intense, investigation.\n",
            "----------------------------------------\n",
            "Title: Prediction of Blood Glucose Concentration Based on CEEMD and Improved Particle Swarm Optimization LSSVM.\n",
            "Abstract: Aiming at the difficulty of accurate prediction due to the randomness and nonstationary nature of blood glucose concentration series, a blood glucose concentration prediction model based on complementary ensemble empirical mode decomposition (CEEMD) and least squares support vector machine (LSSVM) is proposed. Firstly, CEEMD is used to convert the blood glucose concentration sequence into a series of intrinsic mode functions (IMFs) to reduce the impact of randomness and nonstationary signals on prediction performance. Then, a LSSVM prediction model is established for each mode IMF. The comprehensive learning particle swarm optimization (CLPSO) algorithm is used to optimize the kernel parameters of LSSVM. Finally, the prediction results of all IMFs are superimposed to yield the final blood glucose concentration prediction value. The experimental results show that the proposed prediction model has higher prediction accuracy in short-term blood glucose concentration values.\n",
            "----------------------------------------\n",
            "Title: Modality Influence in Multimodal Machine Learning\n",
            "Abstract: Multimodal Machine Learning has emerged as a prominent research direction across various applications such as Sentiment Analysis, Emotion Recognition, Machine Translation, Hate Speech Recognition, and Movie Genre Classification. This approach has shown promising results by utilizing modern deep learning architectures. Despite the achievements made, challenges remain in data representation, alignment techniques, reasoning, generation, and quantification within multimodal learning. Additionally, assumptions about the dominant role of textual modality in decision-making have been made. However, limited investigations have been conducted on the influence of different modalities in Multimodal Machine Learning systems. This paper aims to address this gap by studying the impact of each modality on multimodal learning tasks. The research focuses on verifying presumptions and gaining insights into the usage of different modalities. The main contribution of this work is the proposal of a methodology to determine the effect of each modality on several Multimodal Machine Learning models and datasets from various tasks. Specifically, the study examines Multimodal Sentiment Analysis, Multimodal Emotion Recognition, Multimodal Hate Speech Recognition, and Multimodal Disease Detection. The study objectives include training SOTA MultiModal Machine Learning models with masked modalities to evaluate their impact on performance. Furthermore, the research aims to identify the most influential modality or set of modalities for each task and draw conclusions for diverse multimodal classification tasks. By undertaking these investigations, this research contributes to a better understanding of the role of individual modalities in multi-modal learning and provides valuable insights for future advancements in this field.\n",
            "----------------------------------------\n",
            "Title: SAFFIRRE: Selective Aggregate Filtering Through Filter Rule Refinement\n",
            "Abstract: Volumetric Distributed Denial of Service attacks send unsolicited high-volume traffic to overwhelm network infrastructures and disrupt service availability. To counteract such attacks, we introduce Selective Aggregate Filtering through Filter Rule Refinement. This novel approach monitors traffic aggregates over the IP address hierarchy with hierarchical heavy hitter algorithms. Based on this, it builds effective droplists for upstream filtering to protect network infrastructures. By estimating attack traffic volumes in traffic aggregates with machine learning, filter rule refinement compensates several drawbacks of hierarchical heavy hitters to achieve low false positive and false negative rates. Furthermore, it enables adaptation to dynamic traffic by tracking filter rule precision over time. We evaluate mitigation effectiveness in dynamic situations with challenging mixed legitimate and attack traffic distributions.\n",
            "----------------------------------------\n",
            "Title: Benchmarking Invasive Alien Species Image Recognition Models for a Citizen Science Based Spatial Distribution Monitoring\n",
            "Abstract: Abstract. Recent developments in image recognition technology including artificial intelligence and machine learning led to an intensified research in computer vision models. This progress also allows advances for the collection of spatio-temporal data on Invasive Alien Species (IAS), in order to understand their geographical distribution and impact on the biodiversity loss. Citizen Science (CS) approaches already show successful solutions how the public can be involved in collecting spatio-temporal data on IAS, e.g. by using mobile applications for monitoring. Our work analyzes recently developed image-based species recognition models suitable for the monitoring of IAS in CS applications. We demonstrate how computer vision models can be benchmarked for such a use case and how their accuracy can be evaluated by testing them with IAS of European Union concern. We found out that available models have different strengths. Depending on which criteria (e.g. high species coverage, costs, maintenance, high accuracies) are considered as most important, it needs to be decided individually which model fits best. Using only one model alone may not necessarily be the best solution, thus combining multiple models or developing a new custom model can be desirable. Generally, cooperation with the model providers can be advantageous.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Real‐time recognition of power quality disturbance‐based deep belief network using embedded parallel computing platform\n",
            "Abstract: This paper proposes a novel integrated solution for real‐time power quality (PQ) disturbance analysis. Traditionally, the recognitions are based on the feature extraction and are implemented offline or on the advanced reduced instruction set computer machine/digital signal processor platforms. In this paper, the optimized deep belief network (DBN) analyzes the PQ signals by learning knowledge from raw data of signals directly, which maximizes the features of original signals, and runs on an embedded parallel computing platform (EPCP). In simulation studies, eight types of common PQ disturbances are divided into 17 classes of data frame models according to the PQ disturbances that may occur during a fixed period of time. These samples of data frame models are utilized to train and optimize the DBNs on a central server. Compared with the existing classifiers, the simulation results demonstrate that the proposed approach has higher accuracy and stronger robustness. Then, the optimized DBN is sent to EPCP, and the previous DBN model is updated. The EPCPs are used to recognize the signals of PQ disturbances from a real time digital system (RTDS). The proposed integrated solution has excellent performance regarding accuracy but is time consuming. © 2020 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc.\n",
            "----------------------------------------\n",
            "Title: MindMiner: A Mixed-Initiative Interface for Interactive Distance Metric Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Kernel Perceptrons to Learn Action Effects for Planning\n",
            "Abstract: We investigate the problem of learning action effects in STRIPS and ADL planning domains. Our approach is based on a kernel perceptron learning model, where action and state information is encoded in a compact vector representation as input to the learning mechanism, and resulting state changes are produced as output. Empirical results of our approach indicate efficient training and prediction times, with low average error rates (< 3%) when tested on STRIPS and ADL versions of an object manipulation scenario. This work is part of a project to integrate machine learning techniques with a planning system, as part of a larger cognitive architecture linking a high- level reasoning component with a low-level robot/vision system.\n",
            "----------------------------------------\n",
            "Title: ASSIMILATION OF PASSIVE MICROWAVE BRIGHTNESS TEMPERATURES FOR SNOW WATER EQUIVALENT ESTIMATION USING THE NASA CATCHMENT LAND SURFACE MODEL AND MACHINE LEARNING ALGORITHMS IN NORTH AMERICA\n",
            "Abstract: Title of dissertation: ASSIMILATION OF PASSIVE MICROWAVE BRIGHTNESS TEMPERATURES FOR SNOW WATER EQUIVALENT ESTIMATION USING THE NASA CATCHMENT LAND SURFACE MODEL AND MACHINE LEARNING ALGORITHMS IN NORTH AMERICA Yuan Xue, Doctor of Philosophy, 2017 Dissertation directed by: Assistant Professor Barton A. Forman Department of Civil and Environmental Engineering Snow is a critical component in the global energy and hydrologic cycle. It is important to know the mass of snow because it serves as the dominant source of drinking water for more than one billion people worldwide. To accurately estimate the depth of snow and mass of water within a snow pack across regional or continental scales is a challenge, especially in the presence of dense vegetations since direct quantification of SWE is complicated by spatial and temporal variability. To overcome some of the limitations encountered by traditional SWE retrieval algorithms or radiative transfer-based snow emission models, this study explores the use of a welltrained support vector machine to merge an advanced land surface model within a variant of radiance emission (i.e., brightness temperature) assimilation experiments. In general, modest improvements in snow depth, and SWE predictability were witnessed as a result of the assimilation procedure over snow-covered terrain in North America when compared against available snow products as well as ground-based observations. These preliminary findings are encouraging and suggest the potential for global-scale snow estimation via the proposed assimilation procedure.\n",
            "----------------------------------------\n",
            "Title: The Discovery and Interpretation of Evidence Accumulation Stages\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A deep learning based solution for imperfect CSI problem in correlated FSO communication channel.\n",
            "Abstract: Imperfect channel state information (CSI) at the receiver, which is due to channel estimation error, is one of the main problems toward achieving optimum detection. This paper presents a deep learning based structure for combating this issue. In order to show the effect of using deep learning, the symbol error rate of a simple free space optical (FSO) communication system is simulated over correlated and un-correlated log-normal channel with write/ wrong CSI. Novelties and contributions of this paper, which are done for the first in machine learning for FSO communication include considering deep learning, considering Log-normal channel, considering correlated channel, considering imperfect CSI. The proposed deep learning based structure is compared with maximum likelihood detector, it is shown that in perfect CSI, both perform the same (because maximum likelihood is optimum), but in imperfect CSI, proposed deep learning based structure outperforms maximum likelihood in channels with un-correlation or desired correlation lengths.\n",
            "----------------------------------------\n",
            "Title: Accurate Solubility Prediction with Error Bars for Electrolytes: A Machine Learning Approach\n",
            "Abstract: Accurate in silico models for predicting aqueous solubility are needed in drug design and discovery and many other areas of chemical research. We present a statistical modeling of aqueous solubility based on measured data, using a Gaussian Process nonlinear regression model (GPsol). We compare our results with those of 14 scientific studies and 6 commercial tools. This shows that the developed model achieves much higher accuracy than available commercial tools for the prediction of solubility of electrolytes. On top of the high accuracy, the proposed machine learning model also provides error bars for each individual prediction.\n",
            "----------------------------------------\n",
            "Title: Prediction-Driven Knowledge Discovery from Data and Prior Knowledge\n",
            "Abstract: This paper presents a novel approach to knowledge discovery. As opposed to the vast majority of existing approaches that use statistical machine learning to discover knowledge from data, we synergistically integrate ideas from artificial intelligence, machine learning, science of evidence, logic and probabilities to use both existing incomplete domain knowledge and imperfect data to discover new knowledge. We illustrate this approach in the precision agriculture domain considering the practices associated with cover crops, and learning how abiotic and biotic factors and cover crops management practices (planting and termination dates and methods) influence cereal cover crop biomass accumulation across corn-growing, soybean-growing, and cotton-growing regions of the U.S.\n",
            "----------------------------------------\n",
            "Title: The Role of Declarative Querying in Bioinformatics\n",
            "Abstract: THE RECENT PUBLICATION of a draft of the entire human genome (McPherson et al., 2001; Venter et al., 2001) has served to fuel an already explosive area of research in bioinformatics that is involved in deriving meaningful knowledge from proteins and DNA sequences (Alberts et al., 2002). Even with the full human genome sequence now in hand, scientists still face the challenges of determining exact gene locations and functions, observing interactions between proteins in complex molecular machines, and learning the structure and function of proteins, just to name a few. The progress of this scientific research is closely connected to the research in the database community in that analyzing large volumes of biological data sets involves being able to maintain and query large databases (Moussouni et al., 1999; Davidson, 2002). Database management systems (DBMSs) could help support life sciences applications, in a number of different ways. A partial list of tasks that such applications require is: querying large structured databases (such as sequence and graph databases), querying semi-structured (such as published manuscripts), managing data replication, querying distributed data sources, and managing parallelism in high-throughput bioinformatics. Unfortunately, current DBMSs have largely ignored supporting life sciences applications, and consequently, the life sciences researches have been forced to write tools and scripts to perform these tasks. An interesting parallel can be drawn between the state of data management tools in life sciences, and the state of data management tools for business applications, such as a banking application, about three decades ago. Prior to the advent of the relational data model, business data was managed and queried using customized programs/scripts that were developed for each application. Reusing programs, and the algorithms for querying the data, involved rewriting application program and logic, which was very time consuming and expensive. In addition, the querying programs were closely tied to the format that was used to represent the data. Any change in the format of the data representation often would break the querying programs. Furthermore, writing complex queries, such as querying over multiple data sets or posing complex analytical queries, was a daunting task. One of the critical contributions of the relational data model (Codd, 1970) was the introduction of a declarative querying paradigm for business data management, instead of the previously used procedural paradigm. In a declarative querying paradigm, the user expresses the query in a high-level language, like SQL, and the DBMS determines the best strategy for evaluating the query. In addition, the DBMS only presents to the user a logical view of the data against which queries are posed. The physical representation of the data, either on disk or in-memory, can be very different from the logical view. For example, in a relational database management system (RDBMS), indices may be created, and the user doesn’t have to query against the index. The user still queries against logical relations, and the system automatically determines if it is faster to use the indices to answer a query. The user is thus insulated from worrying about various details such as physical organization of data on disk, the exact location of the data, tuning the representation for better performance, and choosing the best plan for evaluating a query. This declarative querying paradigm has been a huge success for relational DBMSs, and today commercial RDBMSs manage terabytes of data, and allow very complex querying on these databases. Database management systems can provide similar benefits to the life sciences community, just as it did three decades ago to the business data management community. Many of the data sets that are used in life sciences are growing at an astonishing rate (such as sequence data at NCBI’s GenBank (NCBI, 2002)), and the queries\n",
            "----------------------------------------\n",
            "Title: Mechanisms and pathology of protein misfolding and aggregation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: The Intersection of Machine Learning, Zakat, and Transportation for a Healthy Society\n",
            "Abstract: . The recent Covid-19 pandemic has shown that transportation has a significant role in creating a healthy society. Human mobility can be tracked and traced to map the spread of infectious diseases using screening, tracing, and tracking methods through policies and applications. This momentum has accelerated the massive application of technology, one of which is using Machine Learning. Zakat also has an essential role during the pandemic quarantine policy. The potential of the combination of Machine Learning, Zakat, and transportation should now be increased to improve the Quality of Life to achieve a healthy society. The intersection of these three topics was researched using data scraping from the web dimension as one of the platforms that accommodates a collection of research publications. Data is limited to abstracts of research results within the last five years. Next, the data obtained was preprocessed, text-processed, and analyzed using the FP-Growth Algorithm for Association Rule. Research published so far shows that there is an intersection between Machine Learning, Zakat, and Transportation to achieve a healthy society, even with varying intersection probability values. Machine learning and transportation have the most potent intersection with health, while zakat is still lower. The results of this research can open up collaborative research topics between these domains. The results of this research can also be used as suggestions for policy-making by stakeholders to explore the existing potentials of various journals that have been published.\n",
            "----------------------------------------\n",
            "Title: ROTEX: space telerobotic flight experiment\n",
            "Abstract: In early 1993 the space robot technology experiment ROTEX flew with the space-shuttle Columbia (spacelab mission D2 on flight STS-55 from April 26 to May 6). A multisensory robot on board the space-craft successfully worked in autonomous modes, teleoperated by astronauts, as well as in different telerobotic ground control modes. These include on-line teleoperation and tele-sensor-programming, a task-level oriented programming technique involving `learning by showing' concepts in a virtual environment. The robot's key features were its multisensory gripper and the local sensory feedback schemes which are the basis for shared autonomy. The corresponding man-machine interface concepts using a 6 dof non-force- reflecting control ball and visual feedback to the human operator are explained. Stereographic simulation on ground was used to predict not only the robot's free motion but even the sensor based path refinement on board; prototype tasks performed by this space robot were the assembly of a truss structure, connecting/disconnecting an electric plug (orbit replaceable unit exchange ORU), and grasping free-floating objects.\n",
            "----------------------------------------\n",
            "Title: Surface water detection and delineation using remote sensing images: a review of methods and algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Review: Synergy between mechanistic modelling and data-driven models for modern animal production systems in the era of big data.\n",
            "Abstract: Mechanistic models (MMs) have served as causal pathway analysis and 'decision-support' tools within animal production systems for decades. Such models quantitatively define how a biological system works based on causal relationships and use that cumulative biological knowledge to generate predictions and recommendations (in practice) and generate/evaluate hypotheses (in research). Their limitations revolve around obtaining sufficiently accurate inputs, user training and accuracy/precision of predictions on-farm. The new wave in digitalization technologies may negate some of these challenges. New data-driven (DD) modelling methods such as machine learning (ML) and deep learning (DL) examine patterns in data to produce accurate predictions (forecasting, classification of animals, etc.). The deluge of sensor data and new self-learning modelling techniques may address some of the limitations of traditional MM approaches - access to input data (e.g. sensors) and on-farm calibration. However, most of these new methods lack transparency in the reasoning behind predictions, in contrast to MM that have historically been used to translate knowledge into wisdom. The objective of this paper is to propose means to hybridize these two seemingly divergent methodologies to advance the models we use in animal production systems and support movement towards truly knowledge-based precision agriculture. In order to identify potential niches for models in animal production of the future, a cross-species (dairy, swine and poultry) examination of the current state of the art in MM and new DD methodologies (ML, DL analytics) is undertaken. We hypothesize that there are several ways via which synergy may be achieved to advance both our predictive capabilities and system understanding, being: (1) building and utilizing data streams (e.g. intake, rumination behaviour, rumen sensors, activity sensors, environmental sensors, cameras and near IR) to apply MM in real-time and/or with new resolution and capabilities; (2) hybridization of MM and DD approaches where, for example, a ML framework is augmented by MM-generated parameters or predicted outcomes and (3) hybridization of the MM and DD approaches, where biological bounds are placed on parameters within a MM framework, and the DD system parameterizes the MM for individual animals, farms or other such clusters of data. As animal systems modellers, we should expand our toolbox to explore new DD approaches and big data to find opportunities to increase understanding of biological systems, find new patterns in data and move the field towards intelligent, knowledge-based precision agriculture systems.\n",
            "----------------------------------------\n",
            "Title: Preventing Watermark Forging Attacks in a MLaaS Environment\n",
            "Abstract: With the development of machine learning models for task automation, watermarking appears to be a suitable solution to protect one’s own intellectual property. Indeed, by embedding secret specific markers into the model, the model owner is able to analyze the behavior of any model on these markers, called trigger instances and hence claim its ownership if this is the case. However, in the context of a Machine Learning as a Service (MLaaS) platform where models are available for inference, an attacker could forge such proofs in order to steal the ownership of these watermarked models in order to make a profit out of it. This type of attacks, called watermark forging attacks, is a serious threat against the intellectual property of models owners. Current work provides limited solutions to this problem: They constrain model owners to disclose either their models or their trigger set to a third party. In this paper, we propose counter-measures against watermark forging attacks, in a black-box environment and compatible with privacy-preserving machine learning where both the model weights and the inputs could be kept private. We show that our solution successfully prevents two different types of watermark forging attacks with minimalist assumptions regarding either the access to the model’s weight or the content of the trigger set.\n",
            "----------------------------------------\n",
            "Title: Multimedia Technology Supporting Manufacturing Education\n",
            "Abstract: Accredited programs in manufacturing engineering technology stress hands on applications and problem solving using the computer as a tool. The computers found in technology laboratories come in many different forms directed at solving a particular problem, developing and documenting a product design, controlling a process or machine, or even helping to manage the business side of the operation. Students learn to program and operate many different computer based applications. The computer is rarely used in manufacturing classes as a teaching tool or as an aid to the instructor, other than in the basic applications of word processing and spreadsheet programs. The powerful computers in manufacturing labs are not often used to improve the teaching or learning activities of manufacturing technology classes.\n",
            "----------------------------------------\n",
            "Title: An Intelligent Approach for Prediction of Liver Disease using Machine Learning Models\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine-learning methods for inferring vocal-tract articulation from speech acoustics\n",
            "Abstract: This research explores an inverse mapping from speech acoustics to vocal-tract articulatory trajectories. Such a mapping has the potential to improve speech recognition, speaker verification, low-bit-rate speech coding, and teaching speech production to the hearing impaired. Previous attempts to construct a vocal-tract inverse mapping have been limited by the use of primarily vowel data, a lack of real articulatory data for validation, and the use of homoscedastic (unimodal with constant variance) least-mean-squared regression techniques. Instead, this project considers continuous speech, real articulatory data from five subjects, and multimodal regression models designed to capture the nonuniqueness of the instantaneous inverse that causes homoscedastic regressions to fail. We introduce Maximum-Likelihood Articulator Trajectories (MALAT) in a theoretical speech recognition framework. After discretely partitioning the speech acoustic data, the articulatory data corresponding to each acoustic centroid are modeled using some probability density function (pdf). The MALAT algorithm takes a time series of these pdfs and, using a physiologically based smoothness constraint, estimates those articulatory trajectories that maximize the likelihood of the observed acoustic data. The model is trained using one set of data, and performance is measured on an independent test set using root-mean-squared error (rmse) and the correlation between inferred and actual trajectories. MALAT with multimodal pdfs produces correlations averaged over articulators of 0.90-0.92 and rmses of 1.3-1.5 mm compared to correlations of only 0.79-0.84 and rmses of 1.7-1.9 mm using unimodal pdfs. We then use Maximum-Likelihood Continuity Mapping (MALCOM), an unsupervised method previously demonstrated by Hogden (1995) to accurately infer articulatory information for vowels, and obtain correlations only 0.05-0.21 lower than using MALAT. To find paths that maximize both the likelihood of the phoneme sequence as well as of the acoustics, we extend MALCOM to the Two-Observable case (TO-MALCOM) to incorporate phonetic labels into training. TO-MALCOM and MALCOM perform comparably at capturing articulatory information, but TO-MALCOM produces paths with greater phoneme discriminability. Because it does not require measured articulatory data--only acoustics--TO-MALCOM has the potential to be applied to speech processing tasks as an articulation-based alternative to hidden Markov models.\n",
            "----------------------------------------\n",
            "Title: Identification of high likelihood of dementia in population-based surveys using unsupervised clustering: a longitudinal analysis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Modelo de agrupamiento de precios en el autoservicio\n",
            "Abstract: . Nowadays, the retail in Mexico presents a great dynamism since most of the retailers try to o(cid:27)er the best prices to their clients in order to increase their sales volume, which leads to lost large amounts in pro(cid:28)t margin in order to achieve this target. For this reason, we decided to apply the following machine learning models that allow us to create groups of items according to their mean range price and similar patterns with the di(cid:27)erence between their price and the competitor’s price, this will let us develop unique strategies for each group of products, increasing the pro(cid:28)t of their investments by applying speci(cid:28)c price reductions to each group. The models used in this article are Hierarchical Grouping\n",
            "----------------------------------------\n",
            "Title: Predicting Industry Sectors from Financial Statements: An Illustration of Machine Learning in Accounting Research\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Handling CHD Classifier Based on Machine Learning and Fuzzy Logic Techniques\n",
            "Abstract: Developing a high performance classifier requires understanding the complex relationships hidden within statistical information. Machine learning algorithms and rule based fuzzy logic approaches can help handle classification problems due to their efficient learning capabilities. Several approaches have been defined in both categories to classify discrete class labels. Selection of appropriate techniques and algorithms can help in developing high performance classifiers. In this paper, coronary heart disease (CHD) is taken as the classification problem whose objective is to find out whether an individual is suffering from CHD or not. To handle the CHD problem, four machine learning based classifiers and two fuzzy logic based classifiers have been developed. Accuracy, precision, recall and Fl-score evaluation metrics have been used to evaluate the performance of the developed classifier. The results obtained from the developed classifiers showed that Support Vector Machine and Wang-Mendel based classifiers perform with 92.32% and 98.48% accuracy in their respective category.\n",
            "----------------------------------------\n",
            "Title: scTenifoldKnk: a machine learning workflow performing virtual knockout experiments on single-cell gene regulatory networks\n",
            "Abstract: Gene knockout (KO) experiments are a proven approach for studying gene function. A typical KO experiment usually involves the phenotypic characterization of KO organisms. The recent advent of single-cell technology has greatly boosted the resolution of cellular phenotyping, providing unprecedented insights into cell-type-specific gene function. However, the use of single-cell technology in large-scale, systematic KO experiments is prohibitive due to the vast resources required. Here we present scTenifoldKnk—a machine learning workflow that performs virtual KO experiments using single-cell RNA sequencing (scRNA-seq) data. scTenifoldKnk first uses data from wild-type (WT) samples to construct a single-cell gene regulatory network (scGRN). Then, a gene is knocked out from the constructed scGRN by setting weights of the gene’s outward edges to zeros. ScTenifoldKnk then compares this “pseudo-KO” scGRN with the original scGRN to identify differentially regulated (DR) genes. These DR genes, also called virtual-KO perturbed genes, are used to assess the impact of the gene KO and reveal the gene’s function in analyzed cells. Using existing data sets, we demonstrate that the scTenifoldKnk analysis recapitulates the main findings of three real-animal KO experiments and confirms the functions of genes underlying three Mendelian diseases. We show the power of scTenifoldKnk as a predictive method to successfully predict the outcomes of two KO experiments that involve intestinal enterocytes in Ahr-/mice and pancreatic islet cells in Malat1-/mice, respectively. Finally, we demonstrate the use of scTenifoldKnk to perform systematic KO analyses, in which a large number of genes are virtually deleted, allowing gene functions to be revealed in a cell type-specific manner.\n",
            "----------------------------------------\n",
            "Title: Radiology Decision Support System for Selecting Appropriate CT Imaging Titles Using Machine Learning Techniques Based on Electronic Medical Records\n",
            "Abstract: Radiologists use an imaging order from the ordering physician, which includes a radiology title, to select the most suitable imaging protocol. Inappropriate radiology titles can disrupt protocol selection and result in mistaken or delayed diagnosis. The objective of this work is to develop an algorithm to predict correct radiology titles from incoming exam order data. The proposed instrument is an ensemble of five decision tree-based machine learning (ML) techniques (Light Gradient Boosting Machine, eXtreme Gradient Boosting Machine, Random Forest, Adaptive Boosting, and Random UnderSampling Boosting Model) trained to recommend radiology titles of computed tomography imaging examinations based on electronic medical records. Issues of imbalanced data and generalization were addressed. The tuned models were used to predict the top three radiology titles for the radiologist revision. The models were evaluated using a 10-fold cross-validation method, yielding an approximate average accuracy of $80.5\\% \\pm 2.02\\%$ and F1-score of $80.3\\% \\pm 1.67\\%$ for all models, while the ensemble classifier (~83% F1-score) outperformed individual models. An accumulated average accuracy of ~92% was obtained for the top three predictions. ML techniques can predict radiology titles and identify highly important features. The proposed system can guide physicians toward selecting appropriate radiology titles and alert radiologists to inconsistencies between the radiology title in the exam order and the patient’s underlying conditions, thereby improving imaging utility and increasing diagnostic accuracy, which favors better patient outcomes.\n",
            "----------------------------------------\n",
            "Title: Association of Machine Learning–Based Predictions of Medial Knee Contact Force With Cartilage Loss Over 2.5 Years in Knee Osteoarthritis\n",
            "Abstract: The relationship between in vivo knee load predictions and longitudinal cartilage changes has not been investigated. We undertook this study to develop an equation to predict the medial tibiofemoral contact force (MCF) peak during walking in persons with instrumented knee implants, and to apply this equation to determine the relationship between the predicted MCF peak and cartilage loss in patients with knee osteoarthritis (OA).\n",
            "----------------------------------------\n",
            "Title: How does image quality affect computer-aided diagnosis of colorectal polyps?\n",
            "Abstract: Colorectal cancer (CRC) is one of the leading causes of cancer-related deaths with rising incidence. Since the survival rate of CRC is correlated with the cancer stage at diagnosis, timely detection and adequate treatment strategies are of utmost importance. Technical innovations such as machine learning (ML) and its application in endoscopy show promising results, but the trust of medical doctors in ML is lacking and the ‘black box’ nature complicates the understanding of such systems in clinical practice. In contrast to CT and MRI, image quality is a limiting factor in especially endoscopic imaging, as it is very operator dependent. However, the influence of image quality on convolutional (deep) neural networks (CNNs) is insufficiently studied in relation to clinical practice and the usage of medical image data for computer-aided detection and diagnosis (CADx) systems. This paper explores the influence of degraded image quality on the performance of CNNs applied to colorectal polyp (CRP) characterization. Five commonly used CNN architectures, from simple to more complex, are employed with a custom classification head for common CRP characterization. To degrade the quality of images, distortions such as noise, blur, and contrast changes are imposed on the data and their influence on the performance degradation is studied for the mentioned CNN architectures. A large prospectively collected in vivo data set, gathered from four Dutch, both academic and community, hospitals is employed. Results for CRP characterization show that promising CNN-based methods are rather susceptible to noise and blur distortions but reasonably resilient to changes in contrast. This implies that image quality needs monitoring and control prior to directly using image data in CNN models, in order to gain trustworthy use of deep learning (DL) models in a clinical setting. We propose that incorporating an image quality indicator in CADx systems will lead to better acceptance of such systems, and is necessary for the safe implementation of DL applications in clinical practice.\n",
            "----------------------------------------\n",
            "Title: Estimating Value of Customer through Store Check-in Histories and its Application for Visitor Promotion\n",
            "Abstract: : This paper proposes a method to estimate value of customers based on store check-in histories. The proposed method enables to distinguish possible loyal customers whose purchase histories are not available. Machine learning process is employed for model acquisition. The outcomes of estimation are able to improve eﬃciency of visitor promotions and new customer acquisition events. The result of actual visitor promotion trial conﬁrms eﬀectiveness of the proposed method.\n",
            "----------------------------------------\n",
            "Title: Machine-learning enabled construction of temperature-strain phase diagrams of ferroelectric thin films\n",
            "Abstract: Ferroelectric thin films have been explored for many applications such as microelectronics or system-on-a-chip prototypes. It is well established that stability of ferroelectric states of thin films are determined by both temperature and strain between the film and its underlying substrate and the chemical composition for solid solution thin films. A complexity associated with ferroelectric thin films constrained by a substrate is that often the multidomain states of multiple ferroelectric domain variants become stable. Using a combination of high-throughput calculations, classification machine-learning algorithms, and phase-field simulations, we systematically investigate the phase diagrams of (Ba_ x , Ca_1- x )TiO_3 (BCTO) solid solution thin films. We examine several machine-learning techniques to understand the differences in their accuracies and capabilities for the construction of phase diagrams of ferroelectric thin films. We demonstrate that a computational scheme consisting of high-throughput calculations, machine-learning, and phase-field simulations, can be employed to obtain accurate phase-stability diagrams of ferroelectric films. Graphical abstract\n",
            "----------------------------------------\n",
            "Title: Can Machine-learning Techniques Be Used for 5-year Survival Prediction of Patients With Chondrosarcoma?\n",
            "Abstract: Background Several studies have identified prognostic factors for patients with chondrosarcoma, but there are few studies investigating the accuracy of computationally intensive methods such as machine learning. Machine learning is a type of artificial intelligence that enables computers to learn from data. Studies using machine learning are potentially appealing, because of its possibility to explore complex patterns in data and to improve its models over time. Questions/purposes The purposes of this study were (1) to develop machine-learning algorithms for the prediction of 5-year survival in patients with chondrosarcoma; and (2) to deploy the best algorithm as an accessible web-based app for clinical use. Methods All patients with a microscopically confirmed diagnosis of conventional or dedifferentiated chondrosarcoma were extracted from the Surveillance, Epidemiology, and End Results (SEER) Registry from 2000 to 2010. SEER covers approximately 30% of the US population and consists of demographic, tumor characteristic, treatment, and outcome data. In total, 1554 patients met the inclusion criteria. Mean age at diagnosis was 52 years (SD 17), ranging from 7 to 102 years; 813 of the 1554 patients were men (55%); and mean tumor size was 8 cm (SD 6), ranging from 0.1 cm to 50 cm. Exact size was missing in 340 of 1544 patients (22%), grade in 88 of 1544 (6%), tumor extension in 41 of 1544 (3%), and race in 16 of 1544 (1%). Data for 1-, 3-, 5-, and 10-year overall survival were available for 1533 (99%), 1512 (98%), 1487 (96%), and 977 (63%) patients, respectively. One-year survival was 92%, 3-year survival was 82%, 5-year survival was 76%, and 10-year survival was 54%. Missing data were imputed using the nonparametric missForest method. Boosted decision tree, support vector machine, Bayes point machine, and neural network models were developed for 5-year survival. These models were chosen as a result of their capability of predicting two outcomes based on prior work on machine-learning models for binary classification. The models were assessed by discrimination, calibration, and overall performance. The c-statistic is a measure of discrimination. It ranges from 0.5 to 1.0 with 1.0 being perfect discrimination and 0.5 that the model is no better than chance at making a prediction. The Brier score measures the squared difference between the predicted probability and the actual outcome. A Brier score of 0 indicates perfect prediction, whereas a Brier score of 1 indicates the poorest prediction. The Brier scores of the models are compared with the null model, which is calculated by assigning each patient a probability equal to the prevalence of the outcome. Results Four models for 5-year survival were developed with c-statistics ranging from 0.846 to 0.868 and Brier scores ranging from 0.117 to 0.135 with a null model Brier score of 0.182. The Bayes point machine was incorporated into a freely available web-based application. This application can be accessed through https://sorg-apps.shinyapps.io/chondrosarcoma/. Conclusions Although caution is warranted, because the prediction model has not been validated yet, healthcare providers could use the online prediction tool in daily practice when survival prediction of patients with chondrosarcoma is desired. Future studies should seek to validate the developed prediction model. Level of Evidence Level III, prognostic study.\n",
            "----------------------------------------\n",
            "Title: BRAIN STROKE PREDICTION USING SUPERVISED MACHINE LEARNING\n",
            "Abstract: : A Stroke is a medical disorder that damages the brain by rupturing blood vessels. It can also happen when the brain's blood flow and other nutrients are interrupted. Stroke is the greatest cause of death and disability worldwide, according to the World Health Organization (WHO). The majority of research has focused on the prediction of heart stroke, while just a few studies have looked at the likelihood of a brain stroke. With this in mind, various machine learning models are being developed to forecast the likelihood of a brain stroke. This article employed machine learning techniques like K-Nearest and Nave Bayes Classification to model many physiological parameters for accurate prediction and discover the optimum approach\n",
            "----------------------------------------\n",
            "Title: Learning event representation: As sparse as possible, but not sparser\n",
            "Abstract: Selecting an optimal event representation is essential for event classification in real world contexts. In this paper, we investigate the application of qualitative spatial reasoning (QSR) frameworks for classification of human-object interaction in three dimensional space, in comparison with the use of quantitative feature extraction approaches for the same purpose. In particular, we modify QSRLib, a library that allows computation of Qualitative Spatial Relations and Calculi, and employ it for feature extraction, before inputting features into our neural network models. Using an experimental setup involving motion captures of human-object interaction as three dimensional inputs, we observe that the use of qualitative spatial features significantly improves the performance of our machine learning algorithm against our baseline, while quantitative features of similar kinds fail to deliver similar improvement. We also observe that sequential representations of QSR features yield the best classification performance. A result of our learning method is a simple approach to the qualitative representation of 3D activities as compositions of 2D actions that can be visualized and learned using 2-dimensional QSR.\n",
            "----------------------------------------\n",
            "Title: Applications in cognitive neuroscience: electroencephalography-based prediction of treatment response in schizophrenia and the effect of authenticity on emotion perception\n",
            "Abstract: Background Cognitive neuroscience is a field of science that explores the neural basis of cognition. The field is vast and includes studies from a micro-level, such as studies of individual synapses to the organisation-level studies that are interested in how specific brain regions interact with each other. For such a wide variety of applications, there is a high demand in new methods and techniques to integrate the knowledge from different parts of cognitive neuroscience. Here, we will introduce two different studies that involve different techniques and areas of cognitive neuroscience. The first study (Chapter 2) is a clinical neuroimaging study showcasing how neuroimaging techniques such as electroencephalography (EEG) could be in principle be used to predict the treatment outcomes in a group of patients with refractory schizophrenia. The second study (Chapter 3) is a behavioural investigation of authenticity of facial expressions run on an online platform. We investigated whether emotion authenticity of unseen faces can bias emotion perception of subsequent faces and whether authenticity of seen faces can affect the intensity ratings of those images.MethodsFor the clinical neuroimaging study, the data was collected by a laboratory at UCSD. Forty-five treatment-refractory patients with schizophrenia participated in the study (Hochberger et al., 2019). Two randomised groups of patients were exposed to either computer games, referred to as treatment as usual (TAU), or a novel auditory treatment, called auditory-based targeted cognitive training (TCT). In addition to the treatment, every participant completed two cognitive assessments and three EEG recordings. The goal of our study was to predict the outcome of the TCT treatment in patients with refractory schizophrenia by training a machine learning classifier on EEG data collected after the initial hour of treatment. First of all, we attempted to replicate the UCSD group’s results with a similar single-channel analysis procedure. For the single-channel analysis, we preprocessed data in two ways. The initial preprocessing was done according to standard protocols in our group. In contrast, the second preprocessing was performed in an attempt to replicate the preprocessing steps done by the group at UCSD. In addition to the single-channel analysis, we used whole spatiotemporal data (i.e. all EEG channels at all time points). For the behavioural study, the stimuli were fist validated in a separate experiment to ensure that the stimuli selection was unbiased and to confirm the emotion of each stimulus. Fifty participants (13 females) participated in the Validation task where they were asked to match authentic to posed images of the same actor. The best matching images, according to participants’ responses on the Validation task, were selected for the Subliminal Priming task. For the Subliminal Priming task, 94 people (40 females) aged 18-65 were recruited. There were two types of trial structure. The first type included a fixation cross, forward mask, prime (happy, disgust, or neutral), backward mask, and a neutral target image. The second type did not contain primes and targets were either happy or disgust images. For both types of trials, participants were asked to rate the emotion of seen target images. We examined 1) the effect of emotion and authenticity in primes on perceived emotion intensity in neutral targets and, 2) the effect of emotion and authenticity on perceived emotion intensity in the emotion targets. We also used inverted images to control for different physical features, such as an eye gaze direction.ResultsThe clinical neuroimaging study revealed that predicting cognitive outcome following initial TCT treatment in schizophrenia with EEG from these data was not viable, as the basic analysis from our group and the UCSD group using the same dataset produced strikingly different results. It is likely that these differences were due to slight changes in the eyeblink preprocessing corrections. In addition to the single-channel analysis, the spatiotemporal analysis also did not produce any significant results. Given the influence of the differences in preprocessing strategies on the results, and the limited sample size, we decided not to proceed to with the goal of using machine learning to predict treatment response. In the behavioural study, we found opposing results to previous literature about authenticity in consciously perceived faces, in that authentic emotion faces were rated as less intense than posed emotion faces. For the unconsciously perceived primes, only posed primes had an effect of neutral targets. Contrary to upward primes, inverted subliminal primes showed no effect of emotion on neutral targets. We suggest that the physical properties of primes did not bias emotion intensity ratings on neutral facial expressions. Indeed, we did find significant effects of emotion and authenticity on emotion intensity ratings for the inverted emotion targets. Suggesting that consciously perceived different physical properties in authentic versus posed and also happy versus disgust expressions influence emotion processing.ConclusionThe two studies demonstrate different areas and techniques used in cognitive neuroscience. Both studies also expose some of the important issues in the field. The lack of reproducibility of the results in the first study parallels the recent concern of the scientific community on reproducibility crisis. Our results show that when two labs perform slightly different analyses on the same data, the outcomes might be strikingly different. The second study highlights the importance of authentic emotions in research. We found that people rate the intensity of consciously perceived authentic emotions differently to posed emotions. However, as the same inverted images also had an effect of emotion, future work is needed in order to disentangle whether the effect of authenticity was due to physical features or holistic processing of authentic emotion. The effect of authenticity was not found in subliminal primes. This might suggest that authenticity is processed at the conscious level rather than at the subconscious level as was hypothesised. We also highlight the importance of developing new databases with authentic stimuli as currently, only a few such databases exist.\n",
            "----------------------------------------\n",
            "Title: Ensemble learning in the estimation of flow types and velocities of individual phases in multiphase flow using non-intrusive accelerometers' and process pressure data\n",
            "Abstract: in oil and gas industries. Accurately identifying flow types and estimating flow velocities of the individual phases are crucial for different purposes, such as observing the process status and providing inputs to control systems. This paper presents a solution for identifying flow contents and estimating flow rates in single-phase or each phase in multiphase flows by using pressure measurements and pipe vibrations caused by the flows. The necessary experiments were performed using the multiphase flow rig with three-inch diameter pipelines transporting natural gas, water, and crude oil in a closed loop with a separator tank as source and sink. A series of tree-based ensemble machine learning models have been developed and tested with the data collected from accelerometers, differential pressure transmitters, and upstream- and downstream pressure transmitters. With these inputs, the developed models can identify volume ratios of individual phases (such as water cut) and can estimate the flow velocity of each phase in the flow loop, including the open/close status of the choke valve. After describing briefly, the P&ID diagram of the multiphase flow rig, the paper focuses on exploratory data analysis of the data from three accelerometers and three pressure sensors using three submodels cascaded to perform ensemble learning.\n",
            "----------------------------------------\n",
            "Title: Invention of 3Mint for feature grouping and scoring in multi-omics\n",
            "Abstract: Advanced genomic and molecular profiling technologies accelerated the enlightenment of the regulatory mechanisms behind cancer development and progression, and the targeted therapies in patients. Along this line, intense studies with immense amounts of biological information have boosted the discovery of molecular biomarkers. Cancer is one of the leading causes of death around the world in recent years. Elucidation of genomic and epigenetic factors in Breast Cancer (BRCA) can provide a roadmap to uncover the disease mechanisms. Accordingly, unraveling the possible systematic connections between-omics data types and their contribution to BRCA tumor progression is crucial. In this study, we have developed a novel machine learning (ML) based integrative approach for multi-omics data analysis. This integrative approach combines information from gene expression (mRNA), microRNA (miRNA) and methylation data. Due to the complexity of cancer, this integrated data is expected to improve the prediction, diagnosis and treatment of disease through patterns only available from the 3-way interactions between these 3-omics datasets. In addition, the proposed method bridges the interpretation gap between the disease mechanisms that drive onset and progression. Our fundamental contribution is the 3 Multi-omics integrative tool (3Mint). This tool aims to perform grouping and scoring of groups using biological knowledge. Another major goal is improved gene selection via detection of novel groups of cross-omics biomarkers. Performance of 3Mint is assessed using different metrics. Our computational performance evaluations showed that the 3Mint classifies the BRCA molecular subtypes with lower number of genes when compared to the miRcorrNet tool which uses miRNA and mRNA gene expression profiles in terms of similar performance metrics (95% Accuracy). The incorporation of methylation data in 3Mint yields a much more focused analysis. The 3Mint tool and all other supplementary files are available at https://github.com/malikyousef/3Mint/.\n",
            "----------------------------------------\n",
            "Title: XAI Human-Machine collaboration applied to network security\n",
            "Abstract: Cyber attacking is easier than cyber defending—attackers only need to find one breach, while the defenders must successfully repel all attacks. This research demonstrates how cyber defenders can increase their capabilities by joining forces with eXplainable-AI (XAI) utilizing interactive human-machine collaboration. With a global shortfall of cyber defenders there is a need to amplify their skills using AI. Cyber asymmetries make propositional machine learning techniques impractical. Human reasoning and skill is a key ingredient in defense and must be embedded in the AI framework. For Human-Machine collaboration to work requires that the AI is an ultra-strong machine learner and can explain its models. Unlike Deep Learning, Inductive Logic Programming can communicate what it learns to a human. An empirical study was undertaken using six months of eavesdropped network traffic from an organization generating up-to 562K network events daily. Easier-to-defend devices were identified using a form of the Good-Turing Frequency estimator which is a promising form of volatility measure. A behavioral cloning grammar in explicit symbolic form was then produced from a single device's network activity using the compression algorithm SEQUITUR. A novel visualization was generated to allow defenders to identify network sequences they wish to explain. Interactive Inductive Logic Programming (the XAI) is supplied the network traffic meta data, sophisticated pre-existing cyber security background knowledge, and one recurring sequence of events from a single device to explain. A co-inductive process between the human cyber defender and the XAI where the human is able to understand, then refute and shape the XAI's developing model, to produce a model that conforms with the data as well as the original device designers programming. The acceptable model is in a form that can be deployed as an ongoing active cyber defense.\n",
            "----------------------------------------\n",
            "Title: ML-SPAs: Fortifying Healthcare Cybersecurity Leveraging Varied Machine Learning Approaches against Spear Phishing Attacks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Classifying drivers using electronic logging devices\n",
            "Abstract: In the era of personalization, being able to determine the risk of individual drivers and hence provide suitable insurance coverage to them would be a logical step. This paper proposes risk scoring for motor insurance using logged data of the drivers that are collected electronically. The proposed method uses machine learning to create a model that can be applied using the logged data. Initial studies conducted were able to achieve up to an accuracy of 79.4%. With further improvement, it can provide a suitable individual risk scoring for insurance premium computation.\n",
            "----------------------------------------\n",
            "Title: Machine learning designs new GCGR/GLP-1R dual agonists with enhanced biological potency\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Unravelling the atomistic mechanisms underpinning the morphological evolution of Al-alloyed hematite.\n",
            "Abstract: Hydrothermal synthesis based upon the use of Al3+ as the dopant and/or ethanol as the solvent is effective in promoting the growth of hematite into nanoplates rich in the (001) surface, which is highly active for a broad range of catalytic applications. However, the underpinning mechanism for the flattening of hematite crystals is still poorly comprehended. To close this knowledge gap, in this work, we have attempted intensive computational modelling to construct a binary phase diagram for Fe2O3-Al2O3 under typical hydrothermal conditions, as well as to quantify the surface energy of hematite crystal upon coverage with Al3+ and ethanol molecules. An innovative coupling of density functional theory calculation, cluster expansion and Monte Carlo simulations in analogy to machine learning and prediction was attempted. Upon successful validation by experimental observation, our simulation results suggest an optimum atomic dispersion of Al3+ within hematite in cases when its concentration is below 4 at% otherwise phase separation occurs, and discrete Al2O3 nano-clusters can be preferentially formed. Computations also revealed that the adsorption of ethanol molecules alone can reduce the specific surface energy of the hematite (001) surface from 1.33 to 0.31 J m-2. The segregation of Al3+ on the (001) surface can further reduce the specific surface energy to 0.18 J m-2. Consequently, the (001) surface growth is inhibited, and it becomes dominant after the disappearance of other surfaces upon their continual growth. This work provides atomistic insights into the synergistic effect between the aluminium textural promoter and the ethanol capping agent in determining the morphology of hematite nanoparticles. The established computation approach also applies to other oxide-based catalysts in controlling their surface growth and morphology, which are critical for their catalytic applications.\n",
            "----------------------------------------\n",
            "\n",
            "Fetching Batch 100...\n",
            "Title: Insights into Household Electric Vehicle Charging Behavior: Analysis and Predictive Modeling\n",
            "Abstract: In the era of burgeoning electric vehicle (EV) popularity, understanding the patterns of EV users’ behavior is imperative. This paper examines the trends in household charging sessions’ timing, duration, and energy consumption by analyzing real-world residential charging data. By leveraging the information collected from each session, a novel framework is introduced for the efficient, real-time prediction of important charging characteristics. Utilizing historical data and user-specific features, machine learning models are trained to predict the connection duration, charging duration, charging demand, and time until the next session. These models enhance the understanding of EV users’ behavior and provide practical tools for optimizing the EV charging infrastructure and effectively managing the charging demand. As the transportation sector becomes increasingly electrified, this work aims to empower stakeholders with insights and reliable models, enabling them to anticipate the localized demand and contribute to the sustainable integration of electric vehicles into the grid.\n",
            "----------------------------------------\n",
            "Title: Personalized Prediction of Response to Smartphone-Delivered Meditation Training: Randomized Controlled Trial\n",
            "Abstract: Background Meditation apps have surged in popularity in recent years, with an increasing number of individuals turning to these apps to cope with stress, including during the COVID-19 pandemic. Meditation apps are the most commonly used mental health apps for depression and anxiety. However, little is known about who is well suited to these apps. Objective This study aimed to develop and test a data-driven algorithm to predict which individuals are most likely to benefit from app-based meditation training. Methods Using randomized controlled trial data comparing a 4-week meditation app (Healthy Minds Program [HMP]) with an assessment-only control condition in school system employees (n=662), we developed an algorithm to predict who is most likely to benefit from HMP. Baseline clinical and demographic characteristics were submitted to a machine learning model to develop a “Personalized Advantage Index” (PAI) reflecting an individual’s expected reduction in distress (primary outcome) from HMP versus control. Results A significant group × PAI interaction emerged (t658=3.30; P=.001), indicating that PAI scores moderated group differences in outcomes. A regression model that included repetitive negative thinking as the sole baseline predictor performed comparably well. Finally, we demonstrate the translation of a predictive model into personalized recommendations of expected benefit. Conclusions Overall, the results revealed the potential of a data-driven algorithm to inform which individuals are most likely to benefit from a meditation app. Such an algorithm could be used to objectively communicate expected benefits to individuals, allowing them to make more informed decisions about whether a meditation app is appropriate for them. Trial Registration ClinicalTrials.gov NCT04426318; https://clinicaltrials.gov/ct2/show/NCT04426318\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Method to Quantify the Role of Vulnerability in Hurricane Damage\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Abstractive text summarization of low-resourced languages using deep learning\n",
            "Abstract: Background Humans must be able to cope with the huge amounts of information produced by the information technology revolution. As a result, automatic text summarization is being employed in a range of industries to assist individuals in identifying the most important information. For text summarization, two approaches are mainly considered: text summarization by the extractive and abstractive methods. The extractive summarisation approach selects chunks of sentences like source documents, while the abstractive approach can generate a summary based on mined keywords. For low-resourced languages, e.g., Urdu, extractive summarization uses various models and algorithms. However, the study of abstractive summarization in Urdu is still a challenging task. Because there are so many literary works in Urdu, producing abstractive summaries demands extensive research. Methodology This article proposed a deep learning model for the Urdu language by using the Urdu 1 Million news dataset and compared its performance with the two widely used methods based on machine learning, such as support vector machine (SVM) and logistic regression (LR). The results show that the suggested deep learning model performs better than the other two approaches. The summaries produced by extractive summaries are processed using the encoder-decoder paradigm to create an abstractive summary. Results With the help of Urdu language specialists, the system-generated summaries were validated, showing the proposed model’s improvement and accuracy.\n",
            "----------------------------------------\n",
            "Title: Detection of DDoS Attacks on Clouds Computing Environments Using Machine Learning Techniques\n",
            "Abstract: The growing number of cloud-based services has led to a rising threat of Distributed Denial of Service (DDoS) attacks. These attacks can cause significant harm to businesses and organizations by overwhelming their network resources, resulting in the unavailability of critical services. The traditional defense mechanisms, such as firewalls systems, are becoming insufficient to cope with the scale and complexity of DDoS attacks. In this research, we propose a new machine learning approach based on ensemble learning to detect DDoS attacks in cloud environments. The proposed method utilizes various features extracted from network traffic to train machine learning algorithms. The proposed solution is expected to be effective in detecting DDoS attacks in real-time with high accuracy.\n",
            "----------------------------------------\n",
            "Title: Diffusion Generative Models for Designing Efficient Singlet Fission Dimers.\n",
            "Abstract: Diffusion generative models, a class of machine learning techniques, have shown remarkable promise in materials science and chemistry by enabling the precise generation of complex molecular structures. In this article, we propose a novel application of diffusion generative models for stabilizing reactive molecular structures identified through quantum mechanical screening. Specifically, we focus on the design challenge presented by singlet fission (SF), a phenomenon crucial for advancing solar cell efficiency beyond theoretical limits. While theoretical chemistry has been successful in predicting intermolecular arrangements with enhanced SF coupling, the practical implementation of these configurations faces challenges due to discrepancies between favorable and stabilized structures. To address this gap, we introduce a three-step strategy combining quantum mechanical screening for identifying optimal molecular arrangements and diffusion generative models for predicting stabilizing linkers. Through a case study of cibalackrot dimers, a promising SF material, we demonstrate the efficacy of our approach in enhancing SF efficiency by stabilizing the desired molecular arrangements.\n",
            "----------------------------------------\n",
            "Title: Design of Network Intrusion Detection Model Based on TCA\n",
            "Abstract: The traditional machine learning model cannot effectively identify the new network traffic data set, resulting in the model failure. Therefore, in this paper, by analyzing the problems of current network intrusion detection (NID) and combining the application of transfer theory in the detection model, a NID model based on transfer component analysis (TCA) is proposed. Among them, the specific mathematical derivation of the algorithm and the detection process of transfer model are introduced in detail. Then, the classification performance of KNN and SVM based on TCA algorithm for network abnormal traffic is compared. The results show that the TCA algorithm proposed in this paper can effectively improve the accuracy of NID, which is meaningful to expand the application scope of network abnormal traffic detection scheme based on machine learning.\n",
            "----------------------------------------\n",
            "Title: Transcriptomics-Guided In Silico Drug Repurposing: Identifying New Candidates with Dual-Stage Antiplasmodial Activity\n",
            "Abstract: In tropical and subtropical areas, malaria stands as a profound public health challenge, causing an estimated 247 million cases worldwide annually. Given the absence of a viable vaccine, the timely and effective treatment of malaria remains a critical priority. However, the growing resistance of parasites to currently utilized drugs underscores the critical need for the identification of new antimalarial therapies. Here, we aimed to identify potential new drug candidates against Plasmodium falciparum, the main causative agent of malaria, by analyzing the transcriptomes of different life stages of the parasite and identifying highly expressed genes. We searched for genes that were expressed in all stages of the parasite’s life cycle, including the asexual blood stage, gametocyte stage, liver stage, and sexual stages in the insect vector, using transcriptomics data from publicly available databases. From this analysis, we found 674 overlapping genes, including 409 essential ones. By searching through drug target databases, we discovered 70 potential drug targets and 75 associated bioactive compounds. We sought to expand this analysis to similar compounds to known drugs. So, we found a list of 1557 similar compounds, which we predicted as actives and inactives using previously developed machine learning models against five life stages of Plasmodium spp. From this analysis, two compounds were selected, and the reactions were experimentally evaluated. The compounds HSP-990 and silvestrol aglycone showed potent inhibitory activity at nanomolar concentrations against the P. falciparum 3D7 strain asexual blood stage. Moreover, silvestrol aglycone exhibited low cytotoxicity in mammalian cells, transmission-blocking potential, and inhibitory activity comparable to those of established antimalarials. These findings warrant further investigation of silvestrol aglycone as a potential dual-acting antimalarial and transmission-blocking candidate for malaria control.\n",
            "----------------------------------------\n",
            "Title: Adaptive Navigation of Automated Vehicles by Image Analysis Techniques\n",
            "Abstract: Image analysis techniques are applied to adaptive automatic vehicle navigation. The proposed image-based navigation system is made adaptive to follow any selected path embedded in a curve-type path network. This is achieved with three major capabilities of the proposed system: path network learning, reference path setup, and guided path navigation. The first capability enables the system to extract relevant information out of a given network map, and the second collects along-path reference data for a selected path from the extracted network information. During guided path navigation, consecutive path images are taken by a television camera on the vehicle and then analyzed for navigation control along path curves and for angular turning at path crossings. The control structure of the automatic navigation process is modelled as a Moore-type sequential machine in automata theory. Correct path navigation is ascertained by verifying each path crossing encountered on the road against the reference data by an image matching technique. Simulation of vehicle movement with a computer-controlled pantilt is also described. Simulation results show the feasibility of the proposed approach.\n",
            "----------------------------------------\n",
            "Title: Real-Time Student Emotion and Drowsiness Detection Using YOLOv5 and CNN for Enhanced Learning\n",
            "Abstract: Recognition of student's behaviour in class based on video has a significant impact on both teacher quality and student attention. Previously, student behaviour recognition focused only on single students with low performance and efficiency. This study proposes a system for detecting student behaviour and attention in the classroom using computer vision and machine learning techniques and it uses a webcam to capture video of the students and analyse their facial expressions and eye movements to determine whether they are paying attention or not. This can also detect the emotions of students. The final output of our proposed system is, it can detect different kinds of student behaviours in classrooms, such as attention in class, drowsiness, emotion of students and finally provide the rating for staff.\n",
            "----------------------------------------\n",
            "Title: Understanding the Risk Proﬁle of Gambling Behaviour through Machine Learning Predictive Modelling and Explanation\n",
            "Abstract: The importance of providing algorithms and tools for experts to be able to analyse and explain black box learning models has been greatly acknowledged recently. This includes methods for opening the black box by providing descriptions of the entire learning model, methods for explaining individual cases, simpliﬁcation and visualization methods to achieve comprehensibility, feature ranking methods and teacher-student methods which seek to create simpler and more interpretable, surrogate models within an acceptable loss of accuracy. In this paper, we propose a simple and efﬁcient method for analysing how a chosen feature may inﬂuence the outcome of a classiﬁer. The method produces curves which can reveal the trend of a feature value all else being equal , thus complementing feature ranking methods. Speciﬁcally, we show that it can help domain experts explore the directional impact (as opposed to the scale) of predictions as a feature value changes. Trends in the average values of a chosen feature are characterised w.r.t. a target outcome and visualized alongside error bands to support assessments of signiﬁcance. The method is scalable and applicable in principle to other learning systems and domains. Differently from decision trees or rule-based approaches, it offers a visualization of feature value trends which can be used by domain experts for the iterative analysis and understanding of the learning system. We have applied this method, called feature risk curves, to the analysis of a real system used by Playtech Plc for the protection of online gamblers. The system predicts whether players may be at risk and recommends a break from the game. The curves have proved insightful in discussions with sector experts for understanding the model-level drivers of particular features towards gambling harm, providing nuance to the mainstream understanding of features like night-play or declined deposits . In particular, the use of error bands around the curves have helped us “know what we don’t know\", by drawing attention to the limits of what can be said about single features of player behaviour. Risk curves for consumer protection remain an active area of research for the team, with planned extensions listed at the end of the paper.\n",
            "----------------------------------------\n",
            "Title: When Are Two Lists Better than One?: Benefits and Harms in Joint Decision-making\n",
            "Abstract: Historically, much of machine learning research has focused on the performance of the algorithm alone, but recently more attention has been focused on optimizing joint human-algorithm performance. Here, we analyze a specific type of human-algorithm collaboration where the algorithm has access to a set of n items, and presents a subset of size k to the human, who selects a final item from among those k. This scenario could model content recommendation, route planning, or any type of labeling task. Because both the human and algorithm have imperfect, noisy information about the true ordering of items, the key question is: which value of k maximizes the probability that the best item will be ultimately selected? For k=1, performance is optimized by the algorithm acting alone, and for k=n it is optimized by the human acting alone. \n",
            "Surprisingly, we show that for multiple of noise models, it is optimal to set k in [2, n-1] - that is, there are strict benefits to collaborating, even when the human and algorithm have equal accuracy separately. We demonstrate this theoretically for the Mallows model and experimentally for the Random Utilities models of noisy permutations. However, we show this pattern is *reversed* when the human is anchored on the algorithm's presented ordering - the joint system always has strictly worse performance. We extend these results to the case where the human and algorithm differ in their accuracy levels, showing that there always exist regimes where a more accurate agent would strictly benefit from collaborating with a less accurate one, but these regimes are asymmetric between the human and the algorithm's accuracy.\n",
            "----------------------------------------\n",
            "Title: Employing Machine Learning Approaches to Determine the Heat Capacity of Cellulosic Biomass Samples with Different Origins\n",
            "Abstract: Heat capacity is among the most well-known thermal properties of cellulosic biomass samples. This study assembles a general machine learning model to estimate the heat capacity of the cellulosic biomass samples with different origins. Combining the uncertainty and ranking analyses over 819 artificial intelligence (AI) models from seven different categories confirmed that the least-squares support vector regression (LSSVR) with the Gaussian kernel function is the best estimator. This model is validated using 700 laboratory heat capacities of four cellulosic biomass samples in wide temperature ranges (AARD=0.32%, MSE=1.88×10-3, and R2=0.999991). The data validity investigation approved that only one out of 700 experimental data is an outlier. The LSSVR model considers the effect of crystallinity, temperature, and sulfur and ash content of the cellulosic samples on their heat capacity. The LSSVR improves the achieved accuracy using the empirical correlation by more than 62%.\n",
            "----------------------------------------\n",
            "Title: Consensus hashing\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Exploring Bias Analysis on Judicial Data using Machine Learning Techniques\n",
            "Abstract: The use of data driven automation is not new, but it has gain a lot of attention recently with the wide-spread understanding that it is the solution to all problems in terms of ‘fair’ and ‘non-bias’ classification. This is not different in the law area, where ‘artificial intelligence’ became a ‘magic word’. However, using historic data is a very tricky job which can quite easily propagate discrimination in a very efficient way. Thus, this work is aimed to analyse data from legal proceedings looking for evidence related to the occurrence of bias in the judges' decision-making process, considering mainly the gender or social condition of the convicts. Supervised and unsupervised machine learning techniques, preceded by data analysis and processing procedures, were used to explain and find explicit data behaviour. Our results pointed to the fragility of the techniques to identify biases but suggest the need to improve data pre-processing and the search for more robust classification techniques.\n",
            "----------------------------------------\n",
            "Title: Convolutional Neural Network Techniques on X-ray Images for Covid-19 Classification\n",
            "Abstract: At the end of 2019, the World Health Organization (WHO) referred that the Public Health Commission of Hubei Province, China, reported cases of severe and unknown pneumonia. A new coronavirus, SARS-CoV-2, was identified as responsible for the lung infection, called COVID-19 (coronavirus disease 2019). An early diagnosis of those carrying the virus becomes crucial to contain the spread, morbidity and mortality of the pandemic. The definitive diagnosis is made through specific tests, among which imaging tests play a very important role. Achieving this goal cannot be separated from radiological examination, and chest X-ray is the most easily available and least expensive alternative. The use of X-ray chest radiographs, as an element that assists the diagnosis and that allows the follow up of the disease, is the subject of many publications that adopt machine learning approaches. This work focuses on the most adopted Convolutional Neural Network Techniques applied on chest X-ray images.\n",
            "----------------------------------------\n",
            "Title: Stacked neural networks for predicting the membranes performance by treating the pharmaceutical active compounds\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Bridging machine learning and cryptography in defence against adversarial attacks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Semantic Process Retrieval with iSPARQL\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine Learning‐Based Prediction of Immunomodulatory Properties of Polymers: Toward a Faster and Easier Development of Anti‐Inflammatory Biomaterials\n",
            "Abstract: In biomaterials development, creating materials with desirable properties can be a time‐consuming and resource‐intensive process, often relying on serendipitous discoveries. A potential route to accelerate this process is to employ artificial intelligence methodologies such as machine learning (ML). Herein, the possibility to predict anti‐inflammatory properties of the polymers by using a simplified model of inflammation and a restrained dataset is explored. Cellular assays with 50 different polymers are conducted using the murine macrophage cell line RAW 264.7 as a model. These experiments generate a dataset which is used to develop a ML model based on Bayesian logistic regression. After conducting a Bayesian logistic regression analysis, two ML models, K‐nearest neighbors (KNN) and Naïve Bayes, are employed to predict anti‐inflammatory polymers properties. The study finds that the probability of a polymer having anti‐inflammatory properties is multiplied by three if it is a polycation, and that nitric oxide secretion is a good indicator in determining the anti‐inflammatory properties of a polymer, which in this work are defined by tumor necrosis factor alpha expression decrease. Overall, the study suggests that with appropriate dataset design, ML techniques can provide valuable information on functional polymer properties, enabling faster and more efficient biomaterial development.\n",
            "----------------------------------------\n",
            "Title: Property rights, market access and crop cultivation in Southern Rhodesia: evidence from historical satellite data\n",
            "Abstract: Agriculture plays a central role in the efforts to fight poverty and achieve economic growth. This is especially relevant in sub-Saharan Africa (SSA) where the majority of the population lives in rural areas. A key issue that is generally believed to unlock agriculture potential is the recognition of property rights through land titling, yet there is no overwhelming empirical evidence to support this in the case of SSA (Udry, 2011). This paper investigates access to markets as an important pre-condition for land titles to result in agricultural growth. Using the case of Southern Rhodesia, we investigate whether land titles incentivised African large-scale holders in the Native Purchase Areas (NPAs) to put more of their available land under cultivation than their counterparts in the overcrowded Tribal Trust Areas (TTAs). We create a novel dataset by applying a Support Vector Machine (SVM) learning algorithm on Landsat imagery for the period 1972 to 1984 - the period during which the debate on the nexus between land rights and agricultural production intensified. Our results indicate that land titles are only beneficial when farmers are located closer to main cities, main roads and rail stations or sidings.\n",
            "----------------------------------------\n",
            "Title: UTILIZAÇÃO DE MACHINE LEARNING PARA IDENTIFICAÇÃO DE FOCOS DE QUEIMADAS POR IMAGENS\n",
            "Abstract: Existem diversas problemáticas atualmente que influenciam no dia a dia do ser humano dentro da sociedade, as principais e mais graves se referem as mudanças climáticas e desastres naturais que fogem do controle e acabam causando danos que demoram um longo período para se normalizar. O problema de queimadas no brasil é recorrente devido à localização geográfica do país, porém, em 2024 o cenário se agravou e foram queimados mais de 22 milhões de hectares, 11 milhões de hectares a mais do que 2023, fazendo com que a sociedade voltasse suas atenções para este problema, gerando discussões em prol de melhorias. Através da tecnologia, é possível prever e reduzir um possível agravamento de situações que podem ter um potencial muito grande de devastação, e com este trabalho, além de discutir o problema, será possível visualizar o uso de inteligência artificial voltado para este cenário tão importante no país. Através do aprendizado de máquina, é possível identificar focos de queimadas em fotos, fazendo com que o monitoramento seja aprimorado e que ocorra a alarmes para uma situação que pode ser evitada. Ao final do trabalho, o leitor estará por dentro do cenário atual de queimadas do país e também entenderá as diferentes formas de se aplicar o aprendizado de máquina, especialmente no cenário de identificação de imagens utilizando YOLO.\n",
            "----------------------------------------\n",
            "Title: Web-Based Learning Under Tacit Mining of Various Data Sources\n",
            "Abstract: Nowadays, many platforms provide open educational resources to learners. So, they must browse and explore several suggested contents to better assimilate their courses. To facilitate the selecting task of these resources, the present paper proposes an intelligent tutoring system that can access teaching contents available on the web automatically and offers them to learners as additional information sources. In doing so, the authors highlight the description logic approach and its knowledge representation strength that underwrites the modulization, inference, and querying about a web ontology language, and enhanced traditional tutoring systems architecture using ontologies and description logic to enable them to access various data sources on the web. Finally, this article concludes that the combination of machine learning with the semantic web has provided a supportive study environment and enhanced the schooling conditions within open and distance learning.\n",
            "----------------------------------------\n",
            "Title: HepatitisC Classification using Data Mining Techniques\n",
            "Abstract: In this paper, we scrutinize factors that dole out significantly to augmenting the risk of hepatitis-C virus. The dataset has been taken from the machine learning warehouse of University of California. It contains nineteen features along with a class feature having binary classification. There is a total of 15 binary attributes together with a class attribute and 5 continuous attributes. The dataset contains 155 records. In order to prevail over the missing values problem, data normalization techniques are applied. First, the dimension of the problem is trimmed down. Next binary logistic regression is applied to classify the cases by using qualitative and quantitative approaches for data reduction. The three stage procedure has produced more than 89% accurate classification. Our proposed approach has a low feature complexity with a good classification rate as it is working by using only 37% of the total fields.\n",
            "----------------------------------------\n",
            "Title: P527 Telemedicine in IBD patients: results of a national survey of the Italian IBD patients’ association (AMICI Onlus)\n",
            "Abstract: Abstract Background Telemedicine is one of the major changes that clinicians have encountered over the past decade; in particular during the COVID-19 pandemic, televisits were rapidly implemented to guarantee patients’ assistance, with the intention of Health Care Providers (HCPs) to continue to use them beyond the pandemic. The aim of our national survey was to evaluate the current usage of telemedicine for IBD patients from their perspective, investigating patients’ impressions about telemedicine and factors affecting them through a Machine Learning (ML) analysis. Methods In March 2021, the Italian IBD patients’ association (AMICI Onlus) distributed to their members - through its mailing list and on social media platforms - an anonymous online questionnaire investigating the use of telemedicine. Socio-demographic and IBD characteristics were collected; the usage, patients’ satisfaction and trust of telemedicine were assessed through Likert scales. ML tools - Decision Trees (DT) and Random Forest (RF) - were applied to identify the determinants of patient’s perceptions about telemedicine; the produced RF ranking displays two indicators: %IncMSE and IncNodePurity. Results Nine hundred and seventy-eight IBD patients (women 58.9%) from every Italian region completed the questionnaire. Among the respondents, 87 (8.9%) personally had a telemedicine experience; 153 reported that their Centre performed a telemedicine service during the COVID-19 pandemic (24.2% televisits, 39.2% e-mails, 24.8% phone-calls, 3.9 % dedicated website, 7.9% others). Overall, 707 (72.3%) would trust a telemedicine service, 760 (77.7%) would like to have it also with another HCP (e.g., nutritionist, psychologist) and 778/961 (81%) would like to use telemedicine in the future (17 did not answer to this specific question); 792 (81%) stated they thought useful to have the possibility to use telemedicine and 847 (86.6%) would like their Centre to offer them this facility. Considering this last question as the output at the DT, the variable which have been found to influence the most this patients’ willingness is patient’s perception of the usefulness of telemedicine in treating their disease, since it represented the root of the tree explaining the results. The RF rankings confirmed that this variable influenced the most patients’ perception with the highest levels of %IncMSE and IncNodePurity(Figure 1). Conclusion The practice of telemedicine in the management of IBD patients has not been very relevant throughout Italy so far (less than 10%), but more than four every five respondents would like to use telemedicine. Machine learning analysis shows that the perceived usefulness of telemedicine service is the key point for patients who would like it was a part of usual clinical practice.\n",
            "----------------------------------------\n",
            "Title: MACHINE LEARNING APPROACH FOR LUNG CANCER DETECTION AND STAGES PREDICTION\n",
            "Abstract: - Diagnosing the patients correctly and administering treatments are a major challenge for medical practitioners as critical decisions are made based on diagnosis. The proposed framework is intended to identify lung malignancy in untimely stage in two phases. The proposed framework comprises of numerous steps, for example, image extraction, pre-processing, binarization, thresholding, Division, feature extraction, and neural system identification. In our system we will develop Lung Cancer detection system based on machine learning and neural network. It decreases the chances of getting harm to human by early detection of cancer. In recent past, there has been a lot of progress on data mining and machine learning techniques to predict the various types of diseases.The proposed model is a tool which will take input as the CT scan images and it will predict the possibilities of the disease and its stages. Thus we will try to provide a direction to medical practitioners to make quick intelligent clinical decisions which can help in prophylaxis of the disease and thereby reduce any treatment costs.\n",
            "----------------------------------------\n",
            "Title: Radiomics based Machine Learning Models for Classification of Prostate Cancer Grade Groups from Multi Parametric MRI Images\n",
            "Abstract: Purpose: This study aimed to investigate the performance of multiparametric magnetic resonance imaging (mpMRI) radiomic feature-based machine learning (ML) models in classifying the Gleason grade group (GG) of prostate cancer. Methods: In this retrospective study, a total of 203 patients with histopathologically confirmed prostate cancer who underwent mpMRI before prostate biopsy were included. After manual segmentation, radiomic features (RFs) were extracted from T2-weighted, apparent diffusion coefficient, and high b-value diffusion-weighted magnetic resonance imaging (DWMRI). Patients were split into training sets and testing sets according to a ratio of 8:2. A pipeline considering combinations of two feature selection (FS) methods and six ML classifiers was developed and evaluated. The performance of models was assessed using the accuracy, sensitivity, precision, F1-measure, and the area under curve (AUC). Results: On high b-value DWMRI-derived features, a combination of FS method recursive feature elimination (RFE) and classifier random forest achieved the highest performance for classification of prostate cancer into five GGs, with 97.0% accuracy, 98.0% sensitivity, 98.0% precision, and 97.0% F1-measure. The method also achieved an average AUC for GG of 98%. Conclusion: Preoperative mpMRI radiomic analysis based on ML, as a noninvasive approach, showed good performance for classification of prostate cancer into five GGs. Advances in Knowledge: Herein, radiomic models based on preoperative mpMRI and ML were developed to classify prostate cancer into 5 GGs. Our study provides evidence that analysis of quantitative RFs extracted from high b-value DWMRI images based on a combination of FS method RFE and classifier random forest can be applied for multiclass grading of prostate cancer with an accuracy of 97.0%.\n",
            "----------------------------------------\n",
            "Title: (Sk)2: Saadaali Salamti fi Kidney Kanceri – predicting survivability of kidney cancer using a multi – tier classification framework\n",
            "Abstract: Kidney cancer is known as one of the deadliest cancers, with high morbidity and mortality rate. Survivability from cancers is always the patient's first concern. Thus, methods need to be devised to find the survivability rate. To achieve this goal, machine learning models are effective at providing aid to clinicians because of their accuracy. In this research paper SEER (Surveillance, Epidemiology, and End Results) database was used to provide information on cancer statistics. Three different approaches were used in this paper. The first experiment used regression models, the second included multi-class classification models to predict the survivability rate, and the third used multi-tier classification. In the end, we achieved 71% accuracy through our models to predict the survivability of a patient\n",
            "----------------------------------------\n",
            "Title: Public perception on active aging after COVID-19: an unsupervised machine learning analysis of 44,343 posts\n",
            "Abstract: Introduction To analyze public perceptions of active aging in China on mainstream social media platforms to determine whether the “14th Five Year Plan for the Development of the Aging Career and Older Adult Care System” issued by the CPC in 2022 has fully addressed public needs. Methods The original tweets posted on Weibo between January 1, 2020, and June 30, 2022, containing the words “aging” or “old age” were extracted. A bidirectional encoder representation from transformers (BERT)-based model was used to generate themes related to this perception. A qualitative thematic analysis and an independent review of the theme labels were conducted by the researchers. Results The findings indicate that public perceptions revolved around four themes: (1) health prevention and protection, (2) convenient living environments, (3) cognitive health and social integration, and (4) protecting the rights and interests of the older adult. Discussion Our study found that although the Plan aligns with most of these themes, it lacks clear planning for financial security and marital life.\n",
            "----------------------------------------\n",
            "Title: Toward Verifiable Phrase Search Over Encrypted Cloud-Based IoT Data\n",
            "Abstract: Phrase search encryption, as an important technique in cloud-based IoT system, allows users to retrieve encrypted IoT data that contains a set of consecutive keywords. It plays an important role in cloud-based e-healthcare diagnosis system, machine learning applications for cloud-based IoT system, etc. However, to the best of our knowledge, the existing phrase search encryption schemes cannot achieve the complete verification for search results. They either cannot verify whether the returned files correctly containing the query phrase or cannot verify whether all files containing this query phrase are returned. Result verification is very important for some cloud-based IoT applications. If the search result is incorrect in the cloud-based e-healthcare diagnosis system, it will lead to misdiagnosis even endanger the patient’s life. In order to deal with this problem, this article explores how to achieve verifiable phrase search over encrypted cloud-based IoT data. Specifically, we design novel look-up tables which can be utilized to determine and verify the position relationship among keywords. Meanwhile, we adopt a two-phase query strategy. In the first query phase, the data user can know the identifiers of files containing the keywords in the query phrase, and generate the search trapdoor based on these identifiers for the next phase. In the second query phase, the data user can obtain the verification information to check whether all files containing the query phrase are correctly returned. We present the security analysis of our scheme and conduct extensive experiments. The results prove the high security and efficiency of our proposed scheme.\n",
            "----------------------------------------\n",
            "Title: Physical Security Using Machine Learning to Detect Lock Picking at Traffic Cabinets\n",
            "Abstract: Traffic systems are filled with essential traffic control equipment and can cause massive infrastructural damage and driver safety if hacked. We explore a machine learning method to detect real-time lock picking to thwart unauthorized access to the electronics. We gather accelerometer and gyroscopic data to train a decision tree model for detecting lock picking. Analysis reveals that a standard deviation feature for only two accelerometer axes is adequate for achieving robust performance. We deployed an real-time decision tree model to an offsite test cabinet that achieves an accuracy of over 95 %.\n",
            "----------------------------------------\n",
            "Title: Tailoring Household Disaster Preparedness Interventions to Reduce Health Disparities: Nursing Implications from Machine Learning Importance Features from the 2018–2020 FEMA National Household Survey\n",
            "Abstract: Tailored disaster preparedness interventions may be more effective and equitable, yet little is known about specific factors associated with disaster household preparedness for older adults and/or those with African American/Black identities. This study aims to ascertain differences in the importance features of machine learning models of household disaster preparedness for four groups to inform culturally tailored intervention recommendations for nursing practice. A machine learning model was developed and tested by combining data from the 2018, 2019, and 2020 Federal Emergency Management Agency National Household Survey. The primary outcome variable was a composite readiness score. A total of 252 variables from 15,048 participants were included. Over 10% of the sample self-identified as African American/Black and 30.3% reported being 65 years of age or older. Importance features varied regarding financial and insurance preparedness, information seeking and transportation between groups. These results reiterate the need for targeted interventions to support financial resilience and equitable resource access. Notably, older adults with Black racial identities were the only group where TV, TV news, and the Weather Channel was a priority feature for household disaster preparedness. Additionally, reliance on public transportation was most important among older adults with Black racial identities, highlighting priority needs for equity in disaster preparedness and policy.\n",
            "----------------------------------------\n",
            "Title: Anomaly Detection System for Video Data Using Machine Learning\n",
            "Abstract:  Abstract —We are developing an anomaly detection system for video data that uses machine learning. The proposed system has two subsystems: feature extraction and anomaly detection. We developed two feature extraction systems. One uses traditional manual steps and the other uses machine learning, i.e., a neural network. For the anomaly detection system, we employ machine learning technology that we have developed for a cyber-attack detection system. Results confirm that both prototypes can detect anomalous events in experimental video data.\n",
            "----------------------------------------\n",
            "Title: Diabetic Detection from Images of the Eye\n",
            "Abstract: This cross-sectional study aims to detect Diabetic Retinopathy (DR) in patients who have had retinal scans and ophthalmological exams. The research makes use of tailored retinal images together with the OPF (Optimum-Path Forest) and RBM (Restricted Boltzmann Machine) models to categorize images according to the presence or absence of DR. In this work, features were extracted from the retinal images using both the RBM and OPF models. In particular, after a thorough system training phase, RBM was able to extract between 500 and 1000 features from the images. The study included fifteen distinct trial series, each with thirty cycles of repetition. The research comprised 122 eyes, or 73 diabetic patients, with a gender distribution that was reasonably balanced and an average age of 59.7 years. Remarkably, the RBM-1000 model stood out as the top performer, with the highest overall accuracy of 89.47% in diagnosis. In terms of specificity, the RBM-1000 and OPF-1000 models surpassed the competition, correctly categorizing all images free of DR symptoms. These findings highlight the potential of machine learning, particularly the RBM model, for self-identifying illnesses. The potential of machine learning models—in particular, RBM and OPF—to automate the diagnosis of diabetic retinopathy is demonstrated by this work. The results show how well the RBM model diagnoses, how sensitive it is, and how well it can be applied for efficient DR screening and diagnosis. This information may be used to improve the effectiveness of systems that identify retinal illnesses\n",
            "----------------------------------------\n",
            "Title: Artificial Intelligence Tools for Suicide Prevention in Adolescents and Young Adults\n",
            "Abstract: \n",
            "\n",
            "Artificial Intelligence is making a significant transformation in human lives. Its application in the medical and healthcare field has been also observed making an impact and improving overall outcomes. There has been a quest for similar processes in mental health due to the lack of observable changes in the areas of suicide prevention. In the last five years, there has been an emerging body of empirical research applying the technology of artificial intelligence (AI) and machine learning (ML) in mental health.\n",
            "\n",
            "\n",
            "\n",
            "To review the clinical applicability of the AI/ML-based tools in suicide prevention.\n",
            "\n",
            "\n",
            "\n",
            "The compelling question of predicting suicidality has been the focus of this research. \n",
            "We performed a broad literature search and then identified 36 articles relevant to meet the objectives of this review. We review the available evidence and provide a brief overview of the advances in this field.\n",
            "\n",
            "\n",
            "\n",
            "In the last five years, there has been more evidence supporting the implementation of these algorithms in clinical practice. Its current clinical utility is limited to using electronic health records and could be highly effective in conjunction with existing tools for suicide prevention. Other potential sources of relevant data include smart devices and social network sites. There are some serious questions about data privacy and ethics which need more attention while developing these new modalities in suicide research.\n",
            "\n",
            "----------------------------------------\n",
            "Title: CanDrivR-CS: A Cancer-Specific Machine Learning Framework for Distinguishing Recurrent and Rare Variants\n",
            "Abstract: Motivation Missense variants play a crucial role in cancer development, and distinguishing between those that frequently occur in cancer genomes and those that are rare may provide valuable insights into important functional mechanisms and consequences. Specifically, if common variants confer growth advantages, they may have undergone positive selection across different patients due to similar selection pressures. Moreover, studies have demonstrated the significance of rare mutations that arise as resistance mechanisms in response to drug treatment. This highlights the importance of understanding the role of both recurrent and rare variants in cancer. In addition to this, most existing tools for variant prediction focus on distinguishing variants found in normal and disease populations, often without considering the specific disease contexts in which these variants arise. Instead, they typically build predictors that generalise across all diseases. Here, we introduce CanDrivR-CS, a set of cancer-specific gradient boosting models designed to distinguish between rare and recurrent cancer variants. Results We curated missense variant data from the International Cancer Genome Consortium (ICGC). Cancer-type-specific models significantly outperformed a baseline pan-cancer model, achieving a maximum leave-one-group-out cross-validation (LOGO-CV) F1 score of up to 90% for CanDrivRSKCM (Skin Cutaneous Melanoma) and 89% for CanDrivR-SKCA (Skin Adenocarcinoma), compared to 79.2% for the baseline model. Notably, DNA shape properties consistently ranked among the top features for distinguishing recurrent and rare variants across all cancers. Specifically, recurrent missense variants frequently occurred in DNA bends and rolls, potentially implicating regions prone to DNA replication errors and acting as mutational hotspots. Availability and Implementation All training and test data, and Python code are available in our CanDrivR-CS GitHub repository: https://github.com/amyfrancis97/CanDrivR-CS.\n",
            "----------------------------------------\n",
            "Title: Uma solução de aprendizagem de máquina para detecção de ceratocone\n",
            "Abstract: Keratoconus is a problem that causes changes in the shape and thickness of the cornea, making it thinner and less resistant. Patients who underwent refractive surgery (Laser) have a higher chance of developing the disease by corneal thinning, which can cause blindness and require corneal transplantation. This paper presents a proposal to detect early stages of keratoconus in refractive surgery candidates by applying machine-learning algorithms to corneal biomechanical data to differentiate normal corneas from keratoconus carriers. This solution aims to assist in the medical diagnosis, enabling the identification of patients with a potential risk of developing the disease, and greater accuracy in decision-making. Resumo. Ceratocone é um problema que provoca alterações no formato e espessura da córnea, deixando-a mais fina e menos resistente. Pacientes que foram submetidos a cirurgia refrativa a laser tem uma chance maior de desenvolver a doença pelo afinamento corneano, podendo causar cegueira e exigir o transplante de córnea. Este artigo apresenta uma proposta para detectar estágios iniciais de ceratocone em pacientes candidatos a cirurgia refrativa, aplicando algoritmos de aprendizagem de máquina em dados oculares e biomecânicos da córnea de forma a diferenciar córneas normais de portadores de ceratocone. 1. Introdução Ceratocone, do grego keratohorn, córnea; e konos cone, é um problema na córnea do olho humano, com incidência de aproximadamente 1 em 2.000 casos (0,5%) na população mundial, e caracteriza-se pelo afinamento progressivo e assimétrico da córnea, com formato cônico e irregular. Nos Estados Unidos, cerca de 54,5 em 100.000 pessoas desenvolvem a doença [Kennedy et al. 1986]. De acordo com o Conselho Brasileiro de Oftalmologia, 20% dos transplantes de córnea feitos no Brasil são decorrência do ceratocone. A ceratocone é uma das características mais importantes a se considerar na avaliação pré-operatória de pacientes candidatos para cirurgia refrativa [Kanellopoulos et al. 2007]. A ectasia ocular é o nome dado para a presença de alterações na curvatura da córnea. Há muitos métodos conhecidos na literatura para detecção da ectasia. Os principais são a análise de índices/indicadores topográficos, tomográficos e biomecânicos [Randleman et al. 2008]. Estudos recentes indicam que os índices biomecânicos são medidas essenciais para analisar fatores de risco para a ectasia, e podem ajudar a detectar a doença de forma precoce, antes mesmo da evolução para os estágios mais avançados da doença, levando a mudanças na córnea. O objetivo desta pesquisa é investigar características oftalmológicas com base nas medidas biomecânicas e oculares disponibilizadas por uma clínica de oftalmologia no Rio de Janeiro. A contribuição esperada inclui o desenvolvimento de um modelo de aprendizagem de máquina de alta precisão para detecção de ceratocone. O classificador proposto baseia-se no treinamento dos dados oriundos de olhos normais e portadores de ceratocone, aplicando variações nas técnicas e metodologias já exploradas na literatura. A descoberta de conhecimento em base de dados, também conhecida como KDD (knowledge discovery on databases), é uma das áreas de maior relevância para a aplicação de mineração de dados, e várias abordagens (Suport Vector Machine, Random Forest, Redes Neurais) vêm sendo amplamente aplicadas na medicina e bioinformática na previsão de diagnósticos [Rohm et al. 2015]. A aprendizagem de máquina tornou-se popular na medicina, dada a sua capacidade de lidar com dados e de auxiliar no diagnóstico médico [Oh et al. 2015]. A detecção de ceratocone é chave para identificação de candidatos a cirurgia refrativa [Jiménez et al. 2016]. 2. Apresentação do Problema A cirurgia LASIK (Ceratomileose a laser in situ) é um procedimento de cirurgia refrativa indicado para a correção da miopia, astigmatismo e hipermetropia de comprovada segurança e eficácia [Kanellopoulos, 2007]. Entretanto, como qualquer outro tipo de procedimento cirúrgico, envolve complicações. Uma complicação rara, mas bastante séria que acomete os pacientes no pós-operatório é a ectasia pós-LASIK, conhecida como ceratocone [Klein et al. 2006]. A cirurgia LASIK resulta na remoção de tecido corneano. Ou seja, reformula a superfície da córnea para corrigir o erro de refração. A quantidade de tecido da córnea que é removida do estroma é chamada de profundidade da ablação (ablation depth). O restante do tecido corneano subjacente é chamado de leito estromal residual. Existem três camadas a serem consideradas ao realizar o LASIK: o retalho (flap tickness), a profundidade da ablação (ablation depth) e o leito estromal residual (RSB). As medidas das três camadas precisam ser analisadas antes que o LASIK possa ser executado. O conjunto de dados disponibilizado contém 3.383 registros de pacientes com informações biomecânicas oculares distribuídas em 20 variáveis. O conjunto de dados informa a presença ou não da ectasia ocular, sendo 3.278 registros de olhos saudáveis e 105 registros de olhos portadores de ceratocone. 3. Proposta de Solução A proposta da pesquisa é desenvolver um modelo classificador para auxiliar na detecção de pacientes com risco de desenvolver ectasia ocular no pós-operatório da cirurgia de refração. Esta proposta de solução visa utilizar técnicas de aprendizagem de máquina para extrair padrões ocultos nas medidas coletadas. A solução possibilitará prever com maior eficácia a probabilidade de pacientes desenvolverem a ectasia corneana nos estágios iniciais (graus I e II) da tabela de classificação de Amsler -Krumeich, identificando as características mais decisivas para o desenvolvimento da doença. A metodologia proposta para alcance dos objetivos da pesquisa consiste nas etapas a seguir: (1) caracterização do problema, (2) teorização, (3) construção do modelo classificador e (4) avaliação experimental. 4. Avaliação experimental do modelo A avaliação da solução a partir da construção do modelo ocorre na etapa de experimetação. Considerando-se que apenas 3.2% das instâncias observadas desenvolveram ceratocone, serão aplicadas técnicas de Undersampling ou Oversampling para tratar o desbalanceamento dos dados. A técnica de Undersampling diminui a quantidade de observações com maior número de instâncias (olhos normais), e a técnica de Oversampling replica as observações em menor quantidade (olhos com ceratocone). A partir da equalização das observações, o classificador será avaliado quanto à sua matriz de confusão e medidas de sensibilidade, especificidade, acurácia, curva ROC (Receiver Operating Characteristic) e AUC (Area Under the Curve). A matriz de confusão relaciona os valores de entrada com os resultados previstos pelo classificador, segregando em quatro quadrantes os verdadeiros positivos, verdadeiros negativos, falsos positivos e falsos negativos. A sensibilidade mede a proporção de casos positivos identificados corretamente. A especificidade mede a proporção de casos negativos identificados corretamente. A acurácia mede a proporção de casos corretamente previstos. A curva ROC mede a taxa de falsos positivos no eixo X e taxa de verdadeiros positivos no eixo Y. O esquema abaixo representa o fluxo proposto para treinamento do classificador. Figura 4: Fluxo para o treinamento do classificador proposto A partir dos resultados obtidos, serão aplicados testes estatísticos para comparar o desempenho dos modelos propostos. O teste de Kruskal-Wallis (1952) possibilitará observar se existe diferença estatística relevante entre os algoritmos utilizados em cada modelo. Confirmando esta hipótese, os testes de Scott-Knott e effect size de Cohen’s d (1977) permitirão analisar a magnitude desta diferença, possibilitando ranquear os modelos que melhor contribuem com o classificador. 5. Atividades Realizadas A pesquisa encontra-se na fase inicial, correspondente a contextualização do problema e levantamento de estudos semelhantes extraídos da literatura. Embora estes trabalhos indiquem elevado desempenho no diagnóstico de ceratocone por meio da aplicação de distintas técnicas de aprendizagem de máquina, esta pesquisa propõe-se em combinar a acurácia de técnicas supervisionadas na detecção de classes previamente conhecidas com a adaptabilidade de técnicas não-supervisionadas na detecção de novas classes. O quadro abaixo apresenta uma amostra do levantamento realizado. Quadro 4. Amostra de trabalhos realizados para diagnóstico de ceratocone Autor Técnica AUC Parâmetros Alexandru Lavric et al. CNN 99.33% topografia das imagens R. Ambrósio et al. RF+LOOCV 99.6% dados tomográficos (Pentacam HR) + biomecânicos(Corvis ST) Accardo et al. NN 96.4% dados topográficos Legenda: NN: Neural Networks; CNN (Convolution Neural Networks); RF (Random Forest); LOOCV (Leave-one-out cross-validation) 6. Considerações finais A aplicação de técnicas de aprendizagem de máquina vem se consolidado como estratégia fundamental no diagnóstico de ceratocone. O desenvolvimento de um modelo analítico de dados para detectar estágios iniciais de ceratocone permite que ferramentas de apoio a decisão utilizem como insumo seus dados para garantir uma maior assertividade no diagnóstico médico. Aliado ao alto desempenho esperado em termos de sensibilidade, acurácia, e especificidade da solução, espera-se minimizar as chances de complicações no pós-operatório em pacientes de risco candidatos a cirurgia refrativa.\n",
            "----------------------------------------\n",
            "Title: An empirical analysis of ESG and financial performance of clean energy companies through unsupervised machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Tensor Decomposition Based Approach for Training Extreme Learning Machines\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: An Efficient Way for Satellite Interference Signal Recognition Via Incremental Learning\n",
            "Abstract: In satellite communication systems, it is necessary to implement fast and effective interference suppression for unknown interference signals to ensure the safety and reliability of satellite communication, and successful recognition of the types of interference is a prerequisite for ensuring high-efficiency anti-interference. In this paper, the incremental learning method is introduced into the process of satellite interference signals recognition to lower the hardware conditions required by the machine learning algorithm, reduce the memory consumption and shorten the computing time. Firstly, a variety of frequency domain features are extracted from five kinds of interference signals that often appear in satellite communication systems as classification feature parameters. Secondly, the incremental support vector machine learning model proposed by Gert Cauwenberghs et al. is extended to a multiclass model by one-versus-one, decision tree and directed acyclic graph respectively. Then the three improved models are used to train the characteristic parameters of the interference signals to obtain the recognition results. Simulation experiments show that compared with the conventional multi-category support vector machine model, the proposed models have little difference in recognition accuracy, but the computing time and the memory occupation of the training models are greatly reduced. These results are consistent with the actual requirements of satellite communication systems.\n",
            "----------------------------------------\n",
            "Title: Neural-Response-Based Extreme Learning Machine for Image Classification\n",
            "Abstract: This paper proposes a novel and simple multilayer feature learning method for image classification by employing the extreme learning machine (ELM). The proposed algorithm is composed of two stages: the multilayer ELM (ML-ELM) feature mapping stage and the ELM learning stage. The ML-ELM feature mapping stage is recursively built by alternating between feature map construction and maximum pooling operation. In particular, the input weights for constructing feature maps are randomly generated and hence need not be trained or tuned, which makes the algorithm highly efficient. Moreover, the maximum pooling operation enables the algorithm to be invariant to certain transformations. During the ELM learning stage, elastic-net regularization is proposed to learn the output weight. Elastic-net regularization helps to learn more compact and meaningful output weight. In addition, we preprocess the input data with the dense scale-invariant feature transform operation to improve both the robustness and invariance of the algorithm. To evaluate the effectiveness of the proposed method, several experiments are conducted on three challenging databases. Compared with the conventional deep learning methods and other related ones, the proposed method achieves the best classification results with high computational efficiency.\n",
            "----------------------------------------\n",
            "Title: Machine learning practices in accounting and auditing\n",
            "Abstract: In the current technological era, Machine Learning applications are becoming popular every day. This research paper provides information about the effectiveness of the ML technique in accounting as well as the auditing process. To get proper results, different ML libraries are utilized, concluding seaborn, matplotlib, NumPy and so on. In the introduction section, the research purpose and this research objectives have been developed, through which the entire research process will be developed. “Logistic Regression Machine Learning Model” is built. Literary sources have been analyzed in the literature review section, through which it can be easy to gain different perceptions based on the research context. The effectiveness of different types of machine learning algorithms in accounting and auditing has been evaluated properly. To develop a knowledge level, it is important to increase proper attention, and this research paper will provide proper information based on ML effectiveness.\n",
            "----------------------------------------\n",
            "Title: Advancing source reactor-type discrimination using machine learning techniques and SFCOMPO-2.0 experimental database\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Smart Diagnosis of Disease Using Machine Learning\n",
            "Abstract: The impact of the morbidity in the long term leads to chronic disease and high mortality rates. Majority of the people suffering realize the chronic nature at the end stage. Machine learning can be integrated with the physician to deliver better solutions in identifying the nature of disease at early stages. The patients are diagnosed with the help of machine learning techniques and algorithms. Machine learning algorithms like Naïve Bayesian network, decision tree, random forest and support vector machine are integrated with the patient data to diagnose the disease and give the result of the patient's condition as normal or abnormal. After the diagnosis, medications are suggested for the disease. The general methods used for diagnosis are not affordable by the major population and machine learning methods can overcome the above limits.\n",
            "----------------------------------------\n",
            "Title: THE CONCEPT OF AN INFORMATION SYSTEM FOR FORECASTING THE TEMPERATURE REGIME OF THE EARTH’S SURFACE BASED ON MACHINE LEARNING\n",
            "Abstract: The paper presents the concept of an information system for forecasting the temperature regime of the Earth’s surface using machine learning. Forecasting is based on historical data for a specific area. In order to increase the accuracy of forecasting results, an analysis of the features of climatic zones was carried out to identify patterns. A comparison of the dependence of the average monthly temperatures of the earth’s surface in countries depending on their location in climate zones was carried out. \n",
            "The analysis of sources and scientific publications confirmed the relevance of the chosen research topic. Historical aspects of forecasting changes in climatic indicators are considered. Modern methods and approaches to temperature forecasting, their advantages and disadvantages are analyzed. An overview of the subject area was conducted and the regularities of temperature changes according to climate features were determined. \n",
            "A comparison of temperature regimes for countries located in different climate zones was made. For clarity, graphs of temperature changes were plotted and average indicators were calculated for each climate zone. \n",
            "The results of the study confirm the need to adjust the temperature forecast for certain areas, taking into account their location in a specific climate zone. The revealed regularities in the temperature regime of the countries indicate the need for an individual approach to forecasting and the use of such machine learning methods that are best adapted to the dependencies observed in the climate zone. \n",
            "The architecture of the information system for forecasting future temperatures depending on the climatic features of the studied territories is proposed. A concept has been formed for further research to find more accurate and effective approaches to predicting climate parameters and achieving the goals of sustainable development. \n",
            "  \n",
            " \n",
            "----------------------------------------\n",
            "Title: An Improved Transfer Learning Model for Cyanobacterial Bloom Concentration Prediction\n",
            "Abstract: The outbreak of cyanobacterial blooms is a serious water environmental problem, and the harm it brings to aquatic ecosystems and water supply systems cannot be underestimated. It is very important to establish an accurate prediction model of cyanobacterial bloom concentration, which is a challenging issue. Machine learning techniques can improve the prediction accuracy, but a large amount of historical monitoring data is needed to train these models. For some waters with an inconvenient geographical location or frequent sensor failures, there are not enough historical data to train the model. To deal with this problem, a fused model based on a transfer learning method is proposed in this paper. In this study, the data of water environment with a large amount of historical monitoring data are taken as the source domain in order to learn the knowledge of cyanobacterial bloom growth characteristics and train the prediction model. The data of the water environment with a small amount of historical monitoring data are taken as the target domain in order to load the model trained in the source domain. Then, the training set of the target domain is used to participate in the inter-layer fine-tuning training of the model to obtain the transfer learning model. At last, the transfer learning model is fused with a convolutional neural network to obtain the prediction model. Various experiments are conducted for a 2 h prediction on the test set of the target domain. The results show that the proposed model can significantly improve the prediction accuracy of cyanobacterial blooms for the water environment with a low data volume.\n",
            "----------------------------------------\n",
            "Title: Deep Learning for Education\n",
            "Abstract: The main topic of our project is: Deep Learning on Education. Deep Learning is a method of Machine Learning, it can be supervised, semi-supervised or unsupervised. The problem we are trying to solve is to tweak and improve several neural networks for prediction of student correctness on questions. The approach we adopt to solve the problem is to compare different features (drop rate, number of hidden layers, hidden nodes, with/without autoencoder, optimize function, batch size, fully connected or not) in the neural network so that we can improve AUC (Area under Curve) to get the better prediction results. The results obtained in this research include all the AUC data from all the different neural networks. Our obtained results are great basics of following working on the neural network and succeeding studies in the field of education. The highest accuracy of our single output network reached 87%. We also found the optimized parameters having efficient running time without losing performance. In conclusion, we think that the network is efficient but still need improvement in performance.\n",
            "----------------------------------------\n",
            "Title: Distributed Stochastic Gradient MCMC\n",
            "Abstract: Probabilistic inference on a big data scale is becoming increasingly relevant to both the machine learning and statistics communities. Here we introduce the first fully distributed MCMC algorithm based on stochastic gradients. We argue that stochastic gradient MCMC algorithms are particularly suited for distributed inference because individual chains can draw mini-batches from their local pool of data for a flexible amount of time before jumping to or syncing with other chains. This greatly reduces communication overhead and allows adaptive load balancing. Our experiments for LDA on Wikipedia and Pubmed show that relative to the state of the art in distributed MCMC we reduce compute time from 27 hours to half an hour in order to reach the same perplexity level.\n",
            "----------------------------------------\n",
            "Title: Early Detection of Aphid Infestation and Insect-Plant Interaction Assessment in Wheat Using a Low-Cost Electronic Nose (E-Nose), Near-Infrared Spectroscopy and Machine Learning Modeling\n",
            "Abstract: Advances in early insect detection have been reported using digital technologies through camera systems, sensor networks, and remote sensing coupled with machine learning (ML) modeling. However, up to date, there is no cost-effective system to monitor insect presence accurately and insect-plant interactions. This paper presents results on the implementation of near-infrared spectroscopy (NIR) and a low-cost electronic nose (e-nose) coupled with machine learning. Several artificial neural network (ANN) models were developed based on classification to detect the level of infestation and regression to predict insect numbers for both e-nose and NIR inputs, and plant physiological response based on e-nose to predict photosynthesis rate (A), transpiration (E) and stomatal conductance (gs). Results showed high accuracy for classification models ranging within 96.5–99.3% for NIR and between 94.2–99.2% using e-nose data as inputs. For regression models, high correlation coefficients were obtained for physiological parameters (gs, E and A) using e-nose data from all samples as inputs (R = 0.86) and R = 0.94 considering only control plants (no insect presence). Finally, R = 0.97 for NIR and R = 0.99 for e-nose data as inputs were obtained to predict number of insects. Performances for all models developed showed no signs of overfitting. In this paper, a field-based system using unmanned aerial vehicles with the e-nose as payload was proposed and described for deployment of ML models to aid growers in pest management practices.\n",
            "----------------------------------------\n",
            "Title: Evaluation of Convolutional Neural Network Model and Various Machine Learning Models for Decision-Making in the Health Care Industry\n",
            "Abstract: Numerous diseases nowadays should be recognized from the get-go to start viable treatments. If not, they may be lethal and incurable. Thus, it is important to examine convoluted clinical information, reports, and photos quicker while maintaining a more significant precision level. In different cases., certain peculiarities are unpretentious to such an extent that individuals can't promptly distinguish them. At the point when a basic information examination on clinical information is expected to distinguish stowed-away connections or irregularities that are not obvious to people, AI innovations are being utilized in medical services for computational navigation. It is trying to execute algorithms to do such positions in any of them, yet it is considerably harder to develop calculation precision further while decreasing execution time. The meaning of preventive and productive medical services utilizing enormous information scattered through different loT gadgets is underlined in medical care and IT because of the late expanded interest. Medical care data investigation fundamentally includes forecast by utilizing a client's essential data and static information from a knowledge base. This research study proposes a Convolutional Neural Network (CNN) and machine learning-based unique model for health care predictions.\n",
            "----------------------------------------\n",
            "Title: Clustering and Correlation Methods for Predicting Coronavirus COVID-19 Risk Analysis in Pandemic Countries\n",
            "Abstract: An extraordinary outbreak of pneumonia in Wuhan City, China, was subsequently termed as COVID-19 emerged in December 2019. The virus is also known as an infectious disease inherited from a novel coronavirus. This study exposed the beginning of the unprecedented COVID-19 confirmed cases spike exponentially in the United States and 200 countries globally. Epidemiologists usually utilize conventional spread prediction via the classic clustering method. A suspected patient is likely to blow out the disease to a potential agglomerative of cases grouped in place and time. In the era of cutting edge, outbreak prediction can also generate accurate techniques to utilize unsupervised machine learning methods. We apply two prominent unsupervised learning methods, namely K-means clustering and correlation on a set Coronavirus Outbreak COVID-19 data collection dated March 27 and August 16, 2020. The K-means automatically search for unknown clusters of many countries infected with the COVID-19 rapidly. It shows that a group of $m = 5$ produces an accuracy of about 97% with [The United States and Italy], [Iran, France], [Spain, German], [Indonesia, Malaysia, Philippine] as clusters. At the same time, it predicts a pertinent relationship between the total deaths and critical patients' attributes of 0.85 while correlating COVID-19 characteristics.\n",
            "----------------------------------------\n",
            "Title: Advanced geochemical exploration knowledge using machine learning: Prediction of unknown elemental concentrations and operational prioritization of Re-analysis campaigns\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: At the Confluence of Artificial Intelligence and Edge Computing in IoT-Based Applications: A Review and New Perspectives\n",
            "Abstract: Given its advantages in low latency, fast response, context-aware services, mobility, and privacy preservation, edge computing has emerged as the key support for intelligent applications and 5G/6G Internet of things (IoT) networks. This technology extends the cloud by providing intermediate services at the edge of the network and improving the quality of service for latency-sensitive applications. Many AI-based solutions with machine learning, deep learning, and swarm intelligence have exhibited the high potential to perform intelligent cognitive sensing, intelligent network management, big data analytics, and security enhancement for edge-based smart applications. Despite its many benefits, there are still concerns about the required capabilities of intelligent edge computing to deal with the computational complexity of machine learning techniques for big IoT data analytics. Resource constraints of edge computing, distributed computing, efficient orchestration, and synchronization of resources are all factors that require attention for quality of service improvement and cost-effective development of edge-based smart applications. In this context, this paper aims to explore the confluence of AI and edge in many application domains in order to leverage the potential of the existing research around these factors and identify new perspectives. The confluence of edge computing and AI improves the quality of user experience in emergency situations, such as in the Internet of vehicles, where critical inaccuracies or delays can lead to damage and accidents. These are the same factors that most studies have used to evaluate the success of an edge-based application. In this review, we first provide an in-depth analysis of the state of the art of AI in edge-based applications with a focus on eight application areas: smart agriculture, smart environment, smart grid, smart healthcare, smart industry, smart education, smart transportation, and security and privacy. Then, we present a qualitative comparison that emphasizes the main objective of the confluence, the roles and the use of artificial intelligence at the network edge, and the key enabling technologies for edge analytics. Then, open challenges, future research directions, and perspectives are identified and discussed. Finally, some conclusions are drawn.\n",
            "----------------------------------------\n",
            "Title: 550P Predicting factors for psychological distress of breast cancer survivors using machine learning techniques\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Retracted: Review on Epileptic Seizure Prediction: Machine Learning and Deep Learning Approaches\n",
            "Abstract: [This retracts the article DOI: 10.1155/2022/7751263.].\n",
            "----------------------------------------\n",
            "Title: Facial Expression Recognition Method Based on Multi-feature Decision-level Fusion\n",
            "Abstract: In order to perform advantages of complementary multisource features and fuse decision results of multiple classifiers,a multi-feature facial expression recognition method based on decision-level fusion is proposed.Shape Feature(SF)of expression is attained by chain code and deformation feature is built to depict facial geometric changes.Meanwhile,Gabor feature fusion diagram is applied to describe local texture details of facial expression.The posterior probability of three kinds of features,which is obtained by Support Vector Machine(SVM)classifier respectively,is constructed for multiple classifiers fusion in decision-level.In order to solve the optimal fusion weights,a weight optimization strategy based on Particle Swarm Optimization(PSO)under the condition of supervised learning is put forward.Experimental results on Cohn-Kanade database show that the proposed method has better performance for average recognition rate and robustness than single classifier recognition method.Compared with existed multiple classifiers fusion methods,the weight optimization strategy has advantages in terms of recognition rate and reliability.\n",
            "----------------------------------------\n",
            "Title: Impact of a machine learning algorithm on time to palliative care in a primary care population: protocol for a stepped-wedge pragmatic randomized trial\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Edge Sampling of Graphs: Graph Signal Processing Approach With Edge Smoothness\n",
            "Abstract: Finding important edges in a graph is a crucial problem for various research fields, such as network epidemics, signal processing, machine learning, and sensor networks. In this paper, we tackle the problem based on sampling theory on graphs. We convert the original graph to a line graph where its nodes and edges, respectively, represent the original edges and the connections between the edges. We then perform node sampling of the line graph based on the edge smoothness assumption: This process selects the most critical edges in the original graph. We present a general framework of edge sampling based on graph sampling theory and reveal a theoretical relationship between the degree of the original graph and the line graph. We also propose an acceleration method for edge sampling in the proposed framework by using the relationship between two types of Laplacian of the node and edge domains. Experimental results in synthetic and real-world graphs validate the effectiveness of our approach against some alternative edge selection methods.\n",
            "----------------------------------------\n",
            "Title: A security vulnerability predictor based on source code metrics\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning Techniques for Modelling and Simulation of Metabolic Networks\n",
            "Abstract: Metabolomics is increasingly becoming an important field. The fundamental task in this area is to measure and interpret complex time and condition dependent parameters such as the activity or flux of metabolites in cells, their concentration, tissues elements and other biosamples. The careful study of all these elements has led to important insights in the functioning of metabolism. Recently, however, there is a growing interest towards an intagrated approach to studying biological systems. This is the main goal in Systems Biology where a combined investigation of several components of a biological system is thought to produce a thorough understanding of such systems. Metabolic networks are not only structurally complex but behave also in a stochastic fashion. Therefore, it is necessary to express structure and handle uncertainty to construct complete dynamics of these networks. In this paper we describe how stochastic modeling and simulation can be performed in a symbolic-statistical machine learning (ML) framework. We show that symbolic ML deals with structural and relational complexity while statistical ML provides principled approaches to uncertainty modeling. Learning is used to analyze traces of biochemical reactions and model the dynamicity through parameter learning, while inference is used to produce stochastic simulation of the network.\n",
            "----------------------------------------\n",
            "Title: Finding fault types of BLDC motors within UAVs using machine learning techniques\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Spontaneous Activity Predicts Survival of Developing Cortical Neurons\n",
            "Abstract: Spontaneous activity plays a crucial role in brain development by coordinating the integration of immature neurons into emerging cortical networks. High levels and complex patterns of spontaneous activity are generally associated with low rates of apoptosis in the cortex. However, whether spontaneous activity patterns directly encode for survival of individual cortical neurons during development remains an open question. Here, we longitudinally investigated spontaneous activity and apoptosis in developing cortical cultures, combining extracellular electrophysiology with calcium imaging. These experiments demonstrated that the early occurrence of calcium transients was strongly linked to neuronal survival. Silent neurons exhibited a higher probability of cell death, whereas high frequency spiking and burst behavior were almost exclusively detected in surviving neurons. In local neuronal clusters, activity of neighboring neurons exerted a pro-survival effect, whereas on the functional level, networks with a high modular topology were associated with lower cell death rates. Using machine learning algorithms, cell fate of individual neurons was predictable through the integration of spontaneous activity features. Our results indicate that high frequency spiking activity constrains apoptosis in single neurons through sustained calcium rises and thereby consolidates networks in which a high modular topology is reached during early development.\n",
            "----------------------------------------\n",
            "Title: Introduction to the Special Section on Big Data and Artificial Intelligence for Network Technologies\n",
            "Abstract: The papers in this special section examines the deployment of Big Data and artificial intelligence for network technologies. The eneration of huge amounts of data, called big data, is creating the need for efficient tools to manage those data. Artificial intelligence (AI) has become the powerful tool in dealing with big data with recent breakthroughs at multiple fronts in machine learning, including deep learning. Meanwhile, information networks are becoming larger and more complicated, generating a huge amount of runtime statistics data such as traffic load, resource usages. The emerging big data and AI technologies may include a bunch of new requirements, applications and scenarios such as e-health, Intelligent Transportation Systems (ITS), Industrial Internet of Things (IIoT), and smart cities in the term of computing networks. The big data and AI driven network technologies also provide an unprecedented patient to discover new features, to characterize user demands and system capabilities in network resource assignment, security and privacy, system architecture, modeling and applications, which needs more explorations. The focus of this special section is to address the big data and artificial intelligence for network technologies. We appreciate contributions to this special section and the valuable and extensive efforts of the reviewers. The topics of this special section range from big data and AI algorithms, models, architecture for networks and systems to network architecture,\n",
            "----------------------------------------\n",
            "Title: Challenges Faced During Implementation of Digital Twin in Construction Project Monitoring\n",
            "Abstract: Digital Twins (DTs) are gaining popularity because they provide precise digital copies of assets, processes, and systems. This is especially true when these DTs are paired with real-time simulation models that make use of modern technologies like machine learning, artificial intelligence, and data analytics. These combinations can provide a comprehensive and dynamic view of the monitored systems. Digital twin (DT) has shown tremendous potential to bring about revolutionary improvements in the field of construction site surveillance. There is, however, a notable paucity of empirical research identifying the constant elements affecting DT adoption in this industry. This research tries to fill that void by identifying the important elements that determine the usage of DT in construction. The study adopts a complete framework with the goal of increasing the use of DT in building site monitoring. The elements influencing the adoption and effectiveness of distributed ledger technology (DT) are divided into three categories: technological, organizational, and economic. Technological factors include the system's appropriateness and the robustness of the data infrastructure. Organizational considerations include the company's openness to innovation and leadership support. Economic aspects include things like return on investment (ROI) and cost-effectiveness. The research technique combines case studies and literature reviews to examine the benefits and drawbacks of DT in construction monitoring. This study's expected output is a comprehensive framework that aids construction businesses in optimizing the use of DT in site monitoring. This would allow for more efficient, data-driven, and forward-thinking processes. The study's ultimate purpose is to provide critical knowledge that will assist the building sector in adopting cutting-edge methods. The industry may better plan for the integration of this sophisticated technology into their operations by knowing the potential of DT and the variables driving its adoption. This, in turn, can lead to more efficiency, lower risks, and improved overall performance\n",
            "----------------------------------------\n",
            "Title: Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem\n",
            "Abstract: Training data for NLP tasks often exhibits gender bias in that fewer sentences refer to women than to men. In Neural Machine Translation (NMT) gender bias has been shown to reduce translation quality, particularly when the target language has grammatical gender. The recent WinoMT challenge set allows us to measure this effect directly (Stanovsky et al, 2019) Ideally we would reduce system bias by simply debiasing all data prior to training, but achieving this effectively is itself a challenge. Rather than attempt to create a ‘balanced’ dataset, we use transfer learning on a small set of trusted, gender-balanced examples. This approach gives strong and consistent improvements in gender debiasing with much less computational cost than training from scratch. A known pitfall of transfer learning on new domains is ‘catastrophic forgetting’, which we address at adaptation and inference time. During adaptation we show that Elastic Weight Consolidation allows a performance trade-off between general translation quality and bias reduction. At inference time we propose a lattice-rescoring scheme which outperforms all systems evaluated in Stanovsky et al, 2019 on WinoMT with no degradation of general test set BLEU. We demonstrate our approach translating from English into three languages with varied linguistic properties and data availability.\n",
            "----------------------------------------\n",
            "Title: Data-driven Digital Twins for Real-Time Machine Monitoring: A Case Study on a Rotating Machine\n",
            "Abstract: \n",
            " In this work, we present a framework for data-driven digital twins for real-time machine monitoring. Data-driven digital twins are gaining prominence in a variety of industrial applications owing to their ability to capture complex relationships between sensor data and system behavior. The computational efficiency gained by using such twins is critical for real-time machine monitoring and diagnostics with timely and interactive human intervention. One of the fundamental challenges in the current data-driven digital twins is a lack of understanding of how different data synthesis strategies of the same sensor data affect the predictive power of the twin models typically obtained through statistical learning. As a result, the interactive support for enabling human intervention and machine health monitoring is not generalized for different machine configurations and fault conditions. Using turbo-machinery as a concrete demonstrative context, we investigate two fundamentally different data synthesis strategies, namely, integrated and combinatorial, as digital twins for a rotating machine. Specifically, we consider a rotor kit as a machine component, develop a synthetic dataset using simulations, and conduct systematic studies on the predictive performance of reduced order models trained using the different data data synthesis strategies. Our experiments show that the combinatorial dataset offers higher prediction accuracy in comaprison to randomized data generation. To demonstrate a practical application of our methodology, we develop a cloud-based Augmented Reality (AR) mobile tool that extracts functional information in real-time using raw data and maps to respective parts of the machine.\n",
            "----------------------------------------\n",
            "Title: UAV-Based Multispectral Winter Wheat Growth Monitoring with Adaptive Weight Allocation\n",
            "Abstract: Comprehensive growth index (CGI) more accurately reflects crop growth conditions than single indicators, which is crucial for precision irrigation, fertilization, and yield prediction. However, many current studies overlook the relationships between different growth parameters and their varying contributions to yield, leading to overlapping information and lower accuracy in monitoring crop growth. Therefore, this study focuses on winter wheat and constructs a comprehensive growth monitoring index (CGIac), based on adaptive weight allocation of growth parameters’ contribution to yield, using data such as leaf area index (LAI), soil plant analysis development (SPAD) values, plant height (PH), biomass (BM), and plant water content (PWC). Using UAV data on vegetation indices, feature selection was performed using the Elastic Net. The growth inversion model was then constructed using machine learning methods, including linear regression (LR), random forest (RF), gradient boosting (GB), and support vector regression (SVR). Based on the optimal growth inversion model for winter wheat, spatial distribution of wheat growth in the study area is obtained. The findings demonstrated that CGIac outperforms CGIav (constructed using equal weighting) and CGIcv (built using the coefficient of variation) in yield correlation and prediction accuracy. Specifically, the yield correlation of CGIac improved by up to 0.76 compared to individual indices, while yield prediction accuracy increased by up to 23.14%. Among the evaluated models, the RF model achieved the best performance, with a coefficient of determination (R2) of 0.895 and a root mean square error (RMSE) of 0.0058. A comparison with wheat orthophotos from the same period confirmed that the inversion results were highly consistent with actual growth conditions in the study area. The proposed method significantly improved the accuracy and applicability of winter wheat growth monitoring, overcoming the limitations of single parameters in growth prediction. Additionally, it provided new technological support and innovative solutions for regional crop monitoring and precision farming operations.\n",
            "----------------------------------------\n",
            "Title: Parallel Problem Solving from Nature — PPSN IV\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Artificial intelligence and machine learning in cardiotocography: A scoping review.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Cloud Approach to Automated Crop Classification Using Sentinel-1 Imagery\n",
            "Abstract: For accurate crop classification, it is necessary to use time-series of high-resolution satellite data to better discriminate among certain crop types. This task brings the following challenges: a large amount of satellite data for download, Big data processing and computational resources for utilization of state-of-the-art classification approaches. For solving these problems, we have developed an automated crop classification workflow, which is based on machine-learning techniques. By deployment of the workflow on the cloud platform, we can overcome challenges of Big data downloading and processing. In this paper, we present the system architecture and describe the experiments on structural and parametric identification of machine learning models utilized in the system.\n",
            "----------------------------------------\n",
            "Title: Approaching beyond reality to connect realism in the library\n",
            "Abstract: Purpose\n",
            "The purpose of this study is to investigate how libraries adopt beyond reality technologies like virtual reality, augmented reality, mixed reality and extended reality to provide an engaging environment and transform user service provision.\n",
            "\n",
            "Design/methodology/approach\n",
            "The study explained different facets of beyond reality. It surveyed various library websites and analysed literature dealing with varying forms of beyond reality technology to gain an idea of how libraries perceive the relevance of this emerging technology for incorporation in its workflow.\n",
            "\n",
            "Findings\n",
            "The study presented some use case studies to give an overview of the adoption of this technology in libraries. The study also outlines the scope of future possibilities for the expansion of applications.\n",
            "\n",
            "Originality/value\n",
            "The practical examples will help improve the understanding of practicing librarians who are contemplating implementation or preparing to cover more areas under this technology in libraries and encourage researchers to explore the integration of artificial intelligence and machine learning with this technology in a cloud infrastructure to leverage maximum outcome in a broader perspective from this immersive technology.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Special issue on advances in applied artificial intelligence\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Feature Selection Using Genetic Algorithm and Bayesian Hyper-parameter Optimization for LSTM in Short-Term Load Forecasting\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Detection of Brain Tumor Using YOLOv5 Algorithm\n",
            "Abstract: In order to provide quick, efficient treatment, disease prediction in the healthcare industry must be exceedingly accurate. The overall goal of this project is to predict brain tumors at early stages using a deep learning model. The Brain is the most important organ in the human body since it controls how all other organs function and helps us make decisions. The tumor is an unchecked growth of unwanted tissue inside of our brain that has developed into a fibrous mesh. The main objective of this study is to identify brain tumors early on. The research would offer a prognosis identifying the presence or absence of a tumor. Among all machine learning algorithms, the YOLO (You Only Look Once) deep learning method is employed because it has a greater degree of precision, produces results more quickly, and is easy to train on large datasets. Another benefit of the deep learning method is that it permits parallelization and has higher testing accuracy than other algorithms. This technique makes it possible to diagnose brain tumors quickly and precisely (96% of the time), which helps with patient care.\n",
            "----------------------------------------\n",
            "Title: St John's wort and depression.\n",
            "Abstract: St Johns Wort And Depression FREE DOWNLOAD ST JOHNS WORT AND DEPRESSION Find loads of the book catalogues in this site as the choice of you visiting this page. You can also join to the website book library that will show you numerous books from any types. Literature, science, politics, and many more catalogues are presented to offer you the best book to find. The book that really makes you feels satisfied. Or that's the book that will save you from your job deadline. Now, we come to offer you the right catalogues of book to open. st johns wort and depression is one of the literary work in this world in suitable to be reading material. That's not only this book gives reference, but also it will show you the amazing benefits of reading a book. Developing your countless minds is needed; moreover you are kind of people with great curiosity. So, the book is very appropriate for you. Growing up from elementary to the adult, reading books will let different reasons to believe. Sometime, we need the book because of the job deadline. But in other time, you can read again this st johns wort and depression, for not only the job deadline need but also for eager. So, is reading this book your great eager to read. When you have enough to seek for another book that can't make you feel pleased, you will always look for other sources, won't you? This is why we come to you to help in finding the right book. Finding this st johns wort and depression as the right book really makes you feel relieved. Even this is just a book; you can find some goodness that can't be got from any other sources. Fulfilling the curious it is sometime very easy, but sometime it needs the big effort. As here, before finding this website to get the book, you may feel so confused. Why? It's because you really need this awesome book to read as soon as possible. Get Another Ebooks Related With St Johns Wort And Depression That Can Be Interesting on You : 2001 fiat seicento owners manual triumph tr4a workshop manual manual autocad 2008 tinker afb itt frontier city tickets tvs scooty pep plus service manual itbs practice test 7th grade fun ideas for 6th grade orientation maretron user manual sponsorship sample letter for rodeo how to clean a self clean oven manually atcn021js atcn041js atcn081js data manual v0 teacher websites or grammar pretest 8th grades monitor kerosene heater manual 2007 honda accord hybrid owners manual 1995 ford mustang gt owners manua briggs and stratton single cylinder l head repair manual asko t731 dryer manual veterinary liability waiver form manual flash vs auto flash 2010 acura rl dash trim manual citroen c4 picasso manual usuario 1993 am general hummer ac compressor bearing manua spelling words for wonders grade 3 daily grammar review 6th grade hydraulic design manual ingenieros de minas alberta millwright red seal test questions dunban arts manual schnucks discount six flags tickets 2014 exemplars grade 12 mathematics june operating manual saab tankradar g3 introduction to combustion solution manual 2008 mazda3 manual operator s manual 345 350 yamaha yzf r1 manual owner s manual vectra vauxhall accounting exam paper 2014 grade 12 75 harley davidson shovelhead service manual memorandum for criminology exam papers 2013 eligibility worker 1 sample test california udec dynamic manual merit award comments daewoo lacetti 2010 manual lg 9000 btu portable air conditioner manual 2006 ford ranger owners manual the mysterious giant of barletta comprehension test cogic men effeminate 2010 toyota camry xle owners manual manual book of honda city 6th grade staar social studies review pontiac montana sv6 2006 service manual pressure ulcer soap notes example prometric exam question papers in oman aventa learning world history answers bible hidden pictures for caleb and joshua mazda 626 mx 6 ford probe haynes repair manual mirage minisplit owners manual 5th grade long division lesson plans diahatsu modle dm950d repair manual honda xr80 service manual huawei e5331 user manual safety craft preschool zte blade instruction manual jeep compass repair manual pontiac vibe owner manual manual service opel vectra apex geography unit 5 jzz30 manual instrument cluster ms excel for investment banking instruction manuals untitled document honda civic2004 and wiring diagram and free manual predicted paper june 2014 higher tier 2006 jeep cherokee manual stanford picc line dressing change ford 3910 repair manual dcoty 2009 ford fiesta manual canon eos 500d manual english volvo v50 repair manual audi a6 service manual 1998 2004 free nfpa 25 fire hydrant inspection frequencies poetry for 7th grade manual sony z1 espanol flamenco guitar tabs insignia surround sound repair manual bc60xlt 1 manual johnson outboard motors manual 15 hp 2003 dmc zs10 owners manual mariner 40 hp outboard manual dremel 1731 manual toshiba 19sl410u owners manual uniden dect 1560 2 manual olympian generator manual gep30 jss3 question paper and answer 2014 canon rebel 2ti manual abaqus random response example 1990 toyota corolla service manual pd hp 5520 printer manual ford escape 2003 owners manual ford fiesta 2001 haynes manual honda crf150f service manual vl commodore manual enlarging a picture grid worksheet nsc preliminary exam timetable 2013 example of numeracy and literacy tests of bus drivers engine manual for vt275 international common core kindergarten first quarter 2000 acura tl fuel cap tester adapter manual 2004 kia sorento manual panasonic lumix tz6 manual lesson plan template editable ford focus 2007 manual 2009 yaris repair manual honda odyssey owners manuals owners manual samsung tv whirlpool wher25 installation manual idrivesafely final exam answers life on earth dot point answers principles of engineering pltw final exam 2013 love story guitar sheet mercedes r230 manualfree paragraph unity and coherence exercises 70 hp evinrude manual marcy home gym assembly manual peter pan wendy monologues 2011 ford escape manual toshiba satellite a40 repair manual engineering math n2 question papers grand vitara manual propietario chemistry density word problems worksheet critical and inferential comprehension questions little green machine instructions manual classic car manuals for sale htc titan 2 user manual leappad explorer manual renault 21 service manual 2006 cobalt manual example for physical science 2014 grade 11 bullet express manual opel combo servce manual 580ex ii service manual polaris sportsman 400 manual kubota gh170 manual mercury grand marquis 2004 owners manual 2011 acura rdx winch manual tata indica vista quadrajet user manual danfoss vlt 2020 manual free online motorcycle owners manuals lessons on the nicene creed 2006 sonata service manual volvo d1 13b owner manual hitachi ultravision manual panorama supersite leccion 3 answers mercury 150 hp 4 stroke service manual answers of biotechnology concept map repair manuals truck entering kindergarten math chevy equinox owners manual word 2003 training manual jsc math suggestion world of ice and fire high level questioning stems hockey registration form template kodak easyshare mini m200 manual quadratic applications tesccc answer key cadd solis vip operator manual harmony 890 remote manual emc aventura workbook answer key manual canon 500d espanol summer packets for 2nd graders 2011 kia warranty and consumer information manual nikon d700 user manual free sample literary essays for grade 5 activity on grandmother spider brings the sun pearson mastering physics solution manual phet color vision answers mcq of general surgery corrections officer ontario cognitive testing minolta maxxum htsi plus manual lesson plans realidades 3 question paper for economics grade 11 term 3 2014 alice in wonderland lamda piece essential of investment 9th edition test bank fisher paykel washer diagnostic manual gw712 manual maptek vulcan google maps easter eggs coordinates mini service manual sample student growth objectives free repair manuals new holland tractor manuals free manual fokker f27 2008 nissan sentra repair manual grd11 agric example 2013 understanding statistics 10th edition brase ergo metrix promotional test prep toro 14 38 hxl workshop manual mercury thunderbolt 650 manual bobcat s250 owners manual c2 01 service manual whirlpool awm 5100 service manual haynes repair manual mitsubishi colt 1400 free ebook 50 states project 5th grade wais iv technical manual kubota l2550 service manual story of three little pigs for children star test sample questions for 5th grade wizard 211 digital readout operations manual 2003 toyota matrix repair manual manual jetta 2004 bose sounddock series ii user manual 2004 acura tl fuel cap tester adapter manual outgoing head boy speech in graduation ceremony mygig manual english foundations 1 apex honda cr500 service manual the startup owners manual free hilux workshop manual agricultural science p1 june question paper 2013 volume of pyramid exam questions denon avr 889 manual toro 20065 manual free 1988 jeep 40 manual jewish life cycle lesson plans kyle xy nowhere to hide june jim king predicted paper 2014 rca visys 60 phone manual physical science grade 11 parts catalog manual manual focus film camera personal narrative lesson plans 6th grade renault 5 haynes service and repair manual 1985 1996 honda vf750c manual yamaha road star warrior manual 2000 subaru legacy repair manual pdf tvm50 programming manual volvo l150f wheel loader service manual summary of the novel kusinda kwehlela endodeni alup compressor manual kubota l3400 owners manual 1990 volvo wagon workshop manual free pd economie manual xi humanitas nissan frontier d22 2004 service manual fundamentals of database systems laboratory manual1 car manuals for free chevy sonic service repair manual solution of n5 paper memorandum ford 3600 tractor repair manual canon 1000d manual maytag epic z user manual exempler 2014 life orientation number chart 1 50 blank free katana repair manual st jo h s w o t d d ep re ssi o\n",
            "----------------------------------------\n",
            "Title: F-BLEAU: Fast Black-Box Leakage Estimation\n",
            "Abstract: We consider the problem of measuring how much a system reveals about its secret inputs. We work in the black-box setting: we assume no prior knowledge of the system's internals, and we run the system for choices of secrets and measure its leakage from the respective outputs. Our goal is to estimate the Bayes risk, from which one can derive some of the most popular leakage measures (e.g., min-entropy leakage). The state-of-the-art method for estimating these leakage measures is the frequentist paradigm, which approximates the system's internals by looking at the frequencies of its inputs and outputs. Unfortunately, this does not scale for systems with large output spaces, where it would require too many input-output examples. Consequently, it also cannot be applied to systems with continuous outputs (e.g., time side channels, network traffic). In this paper, we exploit an analogy between Machine Learning (ML) and black-box leakage estimation to show that the Bayes risk of a system can be estimated by using a class of ML methods: the universally consistent learning rules; these rules can exploit patterns in the input-output examples to improve the estimates' convergence, while retaining formal optimality guarantees. We focus on a set of them, the nearest neighbor rules; we show that they significantly reduce the number of black-box queries required for a precise estimation whenever nearby outputs tend to be produced by the same secret; furthermore, some of them can tackle systems with continuous outputs. We illustrate the applicability of these techniques on both synthetic and real-world data, and we compare them with the state-of-the-art tool, leakiEst, which is based on the frequentist approach.\n",
            "----------------------------------------\n",
            "Title: Impact of Narrow Lanes on Arterial Road Vehicle Crashes: A Machine Learning Approach\n",
            "Abstract: In this paper we adopted state-of-the-art machine learning algorithms, namely: random forest (RF) and least squares boosting, to model crash data and identify the optimum model to study the impact of narrow lanes on the safety of arterial roads. Using a ten-year crash dataset in four cities in Nebraska, two machine learning models were assessed based on the prediction error. The RF model was identified as the best model. The RF was used to compute the importance of the lane width predictors in our regression model based on two different measures. Subsequently, the RF model was used to simulate the crash rate for different lane widths. The Kruskal-Wallis test, was then conducted to determine if simulated values from the four lane width groups have equal means. The test null hypothesis of equal means for simulated values from the four lane width groups was rejected. Consequently, it was concluded that the crash rates from at least one lane width group was statistically different from the others. Finally, the results from the pairwise comparisons using the Tukey and Kramer test showed that the changes in crash rates between any two lane width conditions were statistically significant.\n",
            "----------------------------------------\n",
            "Title: Backward-Forward Algorithm: An Improvement towards Extreme Learning Machine\n",
            "Abstract: The extreme learning machine needs a large number of hidden nodes to generalize a single hidden layer neural network for a given training data-set. The need for more number of hidden nodes suggests that the neural-network is memorizing rather than generalizing the model. Hence, a supervised learning method is described here that uses Moore-Penrose approximation to determine both input-weight and output-weight in two epochs, namely, backward-pass and forward-pass. The proposed technique has an advantage over the back-propagation method in terms of iterations required and is superior to the extreme learning machine in terms of the number of hidden units necessary for generalization.\n",
            "----------------------------------------\n",
            "Title: Physics-informed machine learning model for prediction of ground reflected wave peak overpressure\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Contour analysis of external images\n",
            "Abstract: Image recognition occupies a special place in the science of computer vision. Contour analysis particular important in pattern recognition. In this paper, we consider the structure of the contour analysis of external images. Active contour method shows the possibilities of using the minimum energy curve. The energy function that defines boundaries without first isolating the boundaries of an image object. Therefore, the Canny Boundary Detector algorithm is used to detect the contours of an object in an image. This algorithm smooths out image blur and eliminates noise, eliminates errors or interference in the picture. The path tracking method crosses out the boundaries between the subject and the background. Algorithms such as machine learning are needed in order to reflect its performance and the need for recognition. Clustering is used as a machine learning method to find the nearest neighbor criteria. The mathematical model of clustering has its own uniqueness and application for identifying borders or contours in the image. The contour detection and linking approach uses graph analysis, which works and does not lose efficiency in the presence of noise. The convexity defects contour analysis algorithm is able to determine the size of borders, and also uses the search for contour recesses and the introduction of key features when calculating object parameters.\n",
            "----------------------------------------\n",
            "Title: Predicting EURO Games Using an Ensemble Technique Involving Genetic Algorithms and Machine Learning\n",
            "Abstract: This paper summarizes our first attempt to use an ensemble technique to predict soccer games. We chose to represent the games by converting the difference of the teams' statistics into the values -1,0, and 1. This conversion was done using tolerance values that “zero-out” some of the differences. We used a genetic algorithm to find the tolerance values. 101 tolerance vectors produced by the genetic algorithm were used to create game representations on which various machine learning algorithms were trained to create an ensemble technique. Our approach had an accuracy of 70% predicting the Women's Euro 2022 and an accuracy of 67% predicting the men's Euro 2020.\n",
            "----------------------------------------\n",
            "Title: Unraveling the role of low-density lipoprotein-related genes in lung adenocarcinoma: Insights into tumor microenvironment and clinical prognosis.\n",
            "Abstract: BACKGROUND\n",
            "The hypothesized link between low-density lipoprotein (LDL) and oncogenesis has garnered significant interest, yet its explicit impact on lung adenocarcinoma (LUAD) remains to be elucidated. This investigation aims to demystify the function of LDL-related genes (LRGs) within LUAD, endeavoring to shed light on the complex interplay between LDL and carcinogenesis.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Leveraging single-cell transcriptomics, we examined the role of LRGs within the tumor microenvironment (TME). The expression patterns of LRGs across diverse cellular phenotypes were delineated using an array of computational methodologies, including AUCell, UCell, singscore, ssGSEA, and AddModuleScore. CellChat facilitated the exploration of distinct cellular interactions within LDL_low and LDL_high groups. The findmarker utility, coupled with Pearson correlation analysis, facilitated the identification of pivotal genes correlated with LDL indices. An integrative approach to transcriptomic data analysis was adopted, utilizing a machine learning framework to devise an LDL-associated signature (LAS). This enabled the delineation of genomic disparities, pathway enrichments, immune cell dynamics, and pharmacological sensitivities between LAS stratifications.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Enhanced cellular crosstalk was observed in the LDL_high group, with the CoxBoost+Ridge algorithm achieving the apex c-index for LAS formulation. Benchmarking against 144 extant LUAD models underscored the superior prognostic acuity of LAS. Elevated LAS indices were synonymous with adverse outcomes, diminished immune surveillance, and an upsurge in pathways conducive to neoplastic proliferation. Notably, a pronounced susceptibility to paclitaxel and gemcitabine was discerned within the high-LAS cohort, delineating prospective therapeutic corridors.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "This study elucidates the significance of LRGs within the TME and introduces an LAS for prognostication in LUAD patients. Our findings accentuate putative therapeutic targets and elucidate the clinical ramifications of LAS deployment.\n",
            "----------------------------------------\n",
            "Title: Innovation and Governance of Corporate Social Responsibility in the Digital and Intelligent Era\n",
            "Abstract: The essence of the digital and intelligent era is a round of economic and social changes driven by digital information technology. Human beings have moved from the traditional industrial economy era to the platform economy and intelligent algorithm society. Digital intelligence enterprises（Internet platform enterprises and artificial intelligence enterprises）driven by digital information technology have become micro organizations leading the new economic form to evolve continuously. Driven by artificial intelligence technology, products and services based on algorithm embedding have become important application scenarios of intelligent production and intelligent decision-making. Based on machine learning, intelligent data mining, and algorithm distribution, intelligent technology provides technical and organizational support for automatic production, automatic decision-making and automatic sales of all kinds of organizations. “Intelligent robot” has become a new “behavior subject”, which is different from the traditional moral subject and legal subject. The supervision and control of “intelligent robot” with independent analysis, reasoning and decision-making is becoming extremely urgent. However, the digital and intelligent technology in the digital society has not only reshaped the production efficiency and social productivity, but also caused a series of prominent social problems. The prominent problems are the lack and alienation of social responsibility of platform enterprises in the digital economy, the leakage of individual privacy caused by the application of intelligent algorithm, the ambiguity of the subject of enterprise ethics and responsibility, and the intensification of social inequality and social contradictions derived from data monopoly and algorithm discrimination. A series of new social problems need to be paid attention to in the digital and intelligent era. We believe that in the digital and intelligent era, corporate social responsibility faces all-round innovation, which is reflected in the fact that “intelligent robot” has become the new subject of CSR management and practice, platform enterprises and artificial intelligence enterprises（digital and intelligent enterprises）have become the new organizational carrier of CSR practice, platform business ecosystem has become the practice paradigm of corporate social responsibility, and algorithm governance has become the new focus of corporate social responsibility governance. Furthermore, based on the fact that algorithmic governance has become the key content of corporate social responsibility governance in the digital and intelligent era, this paper further studies three basic paradigms of algorithmic governance from the perspective of corporate social responsibility governance, namely, individual empowerment governance based on algorithm design and developers, traction governance based on digital and intelligent platform enterprises, and collaborative governance based on stakeholders（government, AI Association and application algorithm enterprises）, which reshape the new logic of algorithmic governance, and realize the sustainable and comprehensive value in the digital and intelligent era.\n",
            "----------------------------------------\n",
            "Title: News\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Modern types of machine vision for vehicle inspection\n",
            "Abstract: In this scientific article, modern types of machine vision are examined, which are widely used in the process of inspecting vehicles at various stages of their production and operation. Machine vision serves as an important tool that enhances the quality and safety of vehicles, as well as optimizes production processes. The article discusses key technologies such as lighting technologies that provide the necessary illumination for accurate image analysis, as well as image processing, which allows for the extraction of useful information from visual data.\n",
            "\n",
            "Additionally, special attention is given to machine learning algorithms that enable machine vision systems to adapt and improve their accuracy over time. Stereovision, as a method, is also considered in the context of creating three-dimensional models of objects, significantly increasing the accuracy of defect detection. The article emphasizes automated quality control methods, including the use of high-resolution cameras capable of detecting defects, damages, and discrepancies in the design and finish of vehicles. These technologies play a crucial role in ensuring high standards of quality and reliability in vehicles, which, in turn, contributes to increasing consumer trust in manufacturers.\n",
            "----------------------------------------\n",
            "Title: Context Awareness for Semantic Mobile Computing\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Learning To Predict Reaction Conditions: Relationships between Solvent, Molecular Structure, and Catalyst\n",
            "Abstract: Reaction databases provide a great deal of useful information to assist planning of experiments, but do not provide any interpretation or chemical concepts to accompany this information. In this work reactions are labeled with experimental conditions and network analysis shows that consistencies within clusters of data points can be leveraged to organize this information. In particular, this analysis shows how particular experimental conditions (specifically solvent) are effective in enabling specific organic reactions (Friedel-Crafts, Aldol addition, Claisen condensation, Diels-Alder, and Wittig), including variations within each reaction class. An example of network analysis is shown in the graphical abstract, where data points for a Claisen condensation reaction break into clusters that depend on the catalyst and chemical structure. This type of clustering, which mimics how a chemist reasons, is derived directly from the network. Therefore the findings of this work could augment synthesis planning by providing predictions in a fashion that mimics human chemists. To numerically evaluate solvent prediction ability, three methods are compared: network analysis (through the k-nearest neighbor algorithm), a support vector machine, and a deep neural network. The most accurate method in 4 of the 5 test cases is the network analysis, with deep neural networks also showing good prediction scores. The network analysis tool was evaluated by an expert panel of chemists, who generally agreed that the algorithm produced accurate solvent choices while simultaneously being transparent in the underlying reasons for its predictions.\n",
            "----------------------------------------\n",
            "Title: Gradient Estimators for Implicit Models\n",
            "Abstract: Implicit models, which allow for the generation of samples but not for point-wise evaluation of probabilities, are omnipresent in real-world problems tackled by machine learning and a hot topic of current research. Some examples include data simulators that are widely used in engineering and scientific research, generative adversarial networks (GANs) for image synthesis, and hot-off-the-press approximate inference techniques relying on implicit distributions. The majority of existing approaches to learning implicit models rely on approximating the intractable distribution or optimisation objective for gradient-based optimisation, which is liable to produce inaccurate updates and thus poor models. This paper alleviates the need for such approximations by proposing the Stein gradient estimator, which directly estimates the score function of the implicitly defined distribution. The efficacy of the proposed estimator is empirically demonstrated by examples that include meta-learning for approximate inference, and entropy regularised GANs that provide improved sample diversity.\n",
            "----------------------------------------\n",
            "Title: Pattern discovery in UTM library circulation database\n",
            "Abstract: Huge databases are being used in organizations to store data. These databases contain hidden patterns which can be discovered and used in the organizations. In this project, we applied data mining techniques to uncover the patterns in the circulation database of UTM library. In order to discover worthwhile patterns we followed knowledge discovery process (KDD) to transform row data to suitable format. Weka machine learning software was applied to do the data mining task. In this project, we studied two association rules mining algorithms, Apriori and FPGrowth. The later was used to discover some patterns among borrowed books. These patterns which are presented in a list can be used to make recommendations to patrons who are searching for a certain topic based on items that previously were borrowed together. In addition, a novel rule matrix was presented to store the found rules for future use. Both the list for recommendation and rule matrix are useful to construct a recommender system for users of UTM library.\n",
            "----------------------------------------\n",
            "Title: A preliminary attempt of an intelligent system predicting users' correctness of notifications' sender speculation\n",
            "Abstract: Prior interruptibility research has focused on identifying interruptible or opportune moments for users to handle notifications. Yet, users may not want to attend to all notifications even at these moments. Research has shown that users' current practices for selective attendance are through speculating about notification sources. Yet, sometimes the above information is insufficient, making speculations difficult. This paper describes the first research attempt to examine how well a machine learning model can predict the moments when users would incorrectly speculate the sender of a notification. We built a machine learning model that can achieve an recall: 84.39%, precision: 56.78%, and F1-score of 0.68. We also show that important features for predicting these moments.\n",
            "----------------------------------------\n",
            "Title: Development of vocational science learning devices to improve project based soft skills\n",
            "Abstract: This study aims to produce a Vocational High School Natural Science learning tool to improve project-based soft skills that are valid, practical and effective in developing student soft skills. The method used is Research and Development (R&D) referring to the 4-D model suggested by Thiagarajan with the stages namely define, design, develop, and disseminate. The population in this study were students of class XI in the machine technology group of SMK Negeri 2 Kudus in the academic year 2019/2020 (N = 61). The sample in the study were students of class XI with the expertise of machine technology (n = 34) who were taken by random sampling technique. The data were collected using the device validation sheet, the implementation observation sheet, the teacher's response questionnaire and the student response questionnaire. Data about the validity and practicality of the device in developing learning tools to improve project-based soft skills were analyzed using the right-hand t-test with ? of 0.05. \n",
            "----------------------------------------\n",
            "Title: A machine learning approach to risk assessment for alcohol withdrawal syndrome\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Fusion of Text and Audio Semantic Representations Through CCA\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Modern Applications of Game-Theoretic Principles (Invited Paper)\n",
            "Abstract: Game theory is the study of the strategic behavior of rational decision makers who are aware that their decisions aﬀect one another. Its simple but universal principles have found applications in the most diverse disciplines, including economics, social sciences, evolutionary biology, as well as logic, system science and computer science. Despite its long-standing tradition and its many advances, game theory is still a young and developing science. In this paper, we describe some recent and exciting applications in the ﬁelds of machine learning and privacy.\n",
            "----------------------------------------\n",
            "Title: A Novel Approach for Optimizing Muscle Activation Level and Localization With Vibro-Acoustic DEA Feedback Capability\n",
            "Abstract: \n",
            " Thermal imaging is progressively being used nowadays to investigate a wide range of muscle disorders or irregularities causing increased or decreased blood flow. Furthermore, the activation of the muscle tissue can accurately be detected using electromyography technique by measuring the electrical activity produced during muscular contraction and relaxation. In combination with smart material-based actuators and sensors, which are versatile and appropriate for integration, a multisensor feedback unit for human interaction can be developed. This research presents a novel approach for investigating muscle activation level and localization using surface temperature based on low-cost surface electromyography and thermal sensor that incorporates multi-mode dielectric elastomer actuator feedback capability. We have implemented a deep learning algorithm to make prediction on muscle activation and localization for the purpose of optimization. A graphical user interface is developed to make predictions and forecast on the go. The deep learning model exhibits high evaluation scores across accuracy metrics with an accuracy of 92% on the test set. The study explores the potential applications of this approach in fields of biomechanics, rehabilitation, and human-machine interfaces.\n",
            "----------------------------------------\n",
            "Title: Computational Trust Models and Machine Learning\n",
            "Abstract: Computational Trust Models and Machine Learning provides a detailed introduction to the concept of trust and its application in various computer science areas, including multi-agent systems, online social networks, and communication systems. Identifying trust modeling challenges that cannot be addressed by traditional approaches, this book: Explains how reputation-based systems are used to determine trust in diverse online communities Describes how machine learning techniques are employed to build robust reputation systems Explores two distinctive approaches to determining credibility of resourcesone where the human role is implicit, and one that leverages human input explicitly Shows how decision support can be facilitated by computational trust models Discusses collaborative filtering-based trust aware recommendation systems Defines a framework for translating a trust modeling problem into a learning problem Investigates the objectivity of human feedback, emphasizing the need to filter out outlying opinions Computational Trust Models and Machine Learning effectively demonstrates how novel machine learning techniques can improve the accuracy of trust assessment.\n",
            "----------------------------------------\n",
            "Title: Modelling high-frequency limit order book dynamics with support vector machines\n",
            "Abstract: We propose a machine learning framework to capture the dynamics of high-frequency limit order books in financial equity markets and automate real-time prediction of metrics such as mid-price movement and price spread crossing. By characterizing each entry in a limit order book with a vector of attributes such as price and volume at different levels, the proposed framework builds a learning model for each metric with the help of multi-class support vector machines. Experiments with real data establish that features selected by the proposed framework are effective for short-term price movement forecasts.\n",
            "----------------------------------------\n",
            "Title: The Machine Prediction of the Mutual Trade between the PRC and the Czech Republic in the Global Extraordinary Situation\n",
            "Abstract: Research background: International trade is a substantial constituent of the global and regional economic development. The analysis of mutual trade serves as a tool for a monetary expression of economic transactions between a particular country and its foreign partners for a specific period. For the Czech Republic (CR), the People’s Republic of China (PRC) is the biggest exporter and the second biggest importer. The USA, however, imposes a number of economic sanctions against the PRC that do not have any significant impact on the trade between both countries and the overall growth of the Chinese economy, yet they affect the behavior of consumers and producers both in the USA and in the PRC.\n",
            "Purpose of the article: The aim of this paper is to use machine learning for predicting the future values of the mutual trade between the CR and the PRC for one calendar year (i.e. 12 months).\n",
            "Methods: Monthly data of these two states´ import and export are used to predict bilateral trade flow. The time series begins in January 2005 and ends in April 2020. Thus, the time series contains 184 data lines. Artificial intelligence - artificial neural networks - is used to predict bilateral trade flow between the PRC and the CR. The development of trade is then compared with the mutual sanctions of the PRC and the USA.\n",
            "Findings & Value added: This is expected that the mutual trade balance to be negative from the perspective of the CR. COVID-19 or the sanctions imposed in the international trade will not significantly affect the development of the mutual trade between the CR and the PRC.\n",
            "----------------------------------------\n",
            "Title: Author response: DIPPER, a spatiotemporal proteomics atlas of human intervertebral discs for exploring ageing and degeneration dynamics\n",
            "Abstract: The spatiotemporal proteome of the intervertebral disc (IVD) underpins its integrity and function. We present DIPPER, a deep and comprehensive IVD proteomic resource comprising 94 genome-wide profiles from 17 individuals. To begin with, protein modules defining key directional trends spanning the lateral and anteroposterior axes were derived from high-resolution spatial proteomes of intact young cadaveric lumbar IVDs. They revealed novel region-specific profiles of regulatory activities and displayed potential paths of deconstruction in the leveland location-matched aged cadaveric discs. Machine learning methods predicted a ‘hydration matrisome’ that connects extracellular matrix with MRI intensity. Importantly, the static proteome used as point-references can be integrated with dynamic proteome (SILAC/degradome) and transcriptome data from multiple clinical samples, enhancing robustness and clinical relevance. The data, findings, and methodology, available on a web interface (http://www.sbms.hku.hk/dclab/ DIPPER/), will be valuable references in the field of IVD biology and proteomic analytics. Introduction The 23 intervertebral discs (IVDs) in the human spine provide stability, mobility, and flexibility. IVD degeneration (IDD), most common in the lumbar region (Saleem et al., 2013; Teraguchi et al., 2014), is associated with a decline in function and a major cause of back pain, affecting up to 80% of the world’s population at some point in life (Rubin, 2007), presenting significant socioeconomic burdens. Multiple interacting factors such as genetics, influenced by ageing, mechanical and other stress factors, contribute to the pathobiology, onset, severity, and progression of IDD (Munir et al., 2018). IVDs are large, avascular, extracellular matrix (ECM)-rich structures comprising three compartments: a hydrated nucleus pulposus (NP) at the centre, surrounded by a tough annulus fibrosus (AF) at the periphery, and cartilaginous endplates of the adjoining vertebral bodies (Humzah and Soames, 1988). The early adolescent NP is populated with vacuolated notochordal-like cells, which are gradually replaced by small chondrocyte-like cells (Risbud et al., 2015). Blood vessels terminate Tam, Chen, et al. eLife 2020;9:e64940. DOI: https://doi.org/10.7554/eLife.64940 1 of 37 TOOLS AND RESOURCES\n",
            "----------------------------------------\n",
            "Title: Information-theoretic Generalization Analysis for Expected Calibration Error\n",
            "Abstract: While the expected calibration error (ECE), which employs binning, is widely adopted to evaluate the calibration performance of machine learning models, theoretical understanding of its estimation bias is limited. In this paper, we present the first comprehensive analysis of the estimation bias in the two common binning strategies, uniform mass and uniform width binning. Our analysis establishes upper bounds on the bias, achieving an improved convergence rate. Moreover, our bounds reveal, for the first time, the optimal number of bins to minimize the estimation bias. We further extend our bias analysis to generalization error analysis based on the information-theoretic approach, deriving upper bounds that enable the numerical evaluation of how small the ECE is for unknown data. Experiments using deep learning models show that our bounds are nonvacuous thanks to this information-theoretic generalization analysis approach.\n",
            "----------------------------------------\n",
            "Title: Applying Automated Machine Learning to Predict Mode of Delivery Using Ongoing Intrapartum Data in Laboring Patients\n",
            "Abstract: Abstract Objective  This study aimed to develop and validate a machine learning (ML) model to predict the probability of a vaginal delivery (Partometer) using data iteratively obtained during labor from the electronic health record. Study Design  A retrospective cohort study of deliveries at an academic, tertiary care hospital was conducted from 2013 to 2019 who had at least two cervical examinations. The population was divided into those delivered by physicians with nulliparous term singleton vertex (NTSV) cesarean delivery rates <23.9% (Partometer cohort) and the remainder (control cohort). The cesarean rate among this population of lower risk patients is a standard metric by which to compare provider rates; <23.9% was the Healthy People 2020 goal. A supervised automated ML approach was applied to generate a model for each population. The primary outcome was accuracy of the model developed on the Partometer cohort at 4 hours from admission to labor and delivery. Secondary outcomes included discrimination ability (receiver operating characteristics–area under the curve [ROC-AUC]), precision-recall AUC, and calibration of the Partometer. To assess generalizability, we compared the performance and clinical predictors identified by the Partometer to the control model. Results  There were 37,932 deliveries during the study period; after exclusions, 9,385 deliveries were included in the Partometer cohort and 19,683 in the control cohort. Accuracy of predicting vaginal delivery at 4 hours was 87.1% for the Partometer (ROC-AUC: 0.82). Clinical predictors of greatest importance in the stacked Intrapartum Partometer Model included the Admission Model prediction and ongoing measures of dilatation and station which mirrored those found in the control population. Conclusion  Using automated ML and intrapartum factors improved the accuracy of prediction of probability of a vaginal delivery over both previously published models based on logistic regression. Harnessing real-time data and ML could represent the bridge to generating a truly prescriptive tool to augment clinical decision-making, predict labor outcomes, and reduce maternal and neonatal morbidity. Key Points Our ML-based model yielded accurate predictions of mode of delivery early in labor. Predictors for models created on populations with high and low cesarean rates were the same. A ML-based model may provide meaningful guidance to clinicians managing labor.\n",
            "----------------------------------------\n",
            "Title: KIT's campus computer system by virtual machine technology and integrated identity service\n",
            "Abstract: We replaced our Campus Computer System this March. Our new system has two new features: (1) all services are running in Virtual Machines (VMware vSphere) including DNS, E-Mail, Web, e-Learning, Remote access, File server and Network boot servers. Moreover, each service is provided by more than one guest OS and load balancer, so we can easily to maintain the OS image because the service is still available when one guest OS is shutdown for maintenance. Of course, load balancing is also redundant (active-standby). (2) All our university members' electric Identities are provided from our new system. In addition, several Web-based systems are shibbolized (Web-based Single Sign On system produced by Internet2) such as account management service, e-Learning system and network outlets. Thus, our system consists of only 12 real servers mounted on 4 racks and over 200 PCs are booted from Network boot servers. Moreover, about 5,000 users can use our system and federated systems by integrated Identity service (LDAP, RADIUS, Active Directory and Shibboleth).\n",
            " This paper describes the benefits and problems of these features from the point of view of Total Cost of Ownership (TCO)\n",
            "----------------------------------------\n",
            "Title: Prediction of cancer cell sensitivity to natural products based on genomic and chemical properties\n",
            "Abstract: Natural products play a significant role in cancer chemotherapy. They are likely to provide many lead structures, which can be used as templates for the construction of novel drugs with enhanced antitumor activity. Traditional research approaches studied structure-activity relationship of natural products and obtained key structural properties, such as chemical bond or group, with the purpose of ascertaining their effect on a single cell line or a single tissue type. Here, for the first time, we develop a machine learning method to comprehensively predict natural products responses against a panel of cancer cell lines based on both the gene expression and the chemical properties of natural products. The results on two datasets, training set and independent test set, show that this proposed method yields significantly better prediction accuracy. In addition, we also demonstrate the predictive power of our proposed method by modeling the cancer cell sensitivity to two natural products, Curcumin and Resveratrol, which indicate that our method can effectively predict the response of cancer cell lines to these two natural products. Taken together, the method will facilitate the identification of natural products as cancer therapies and the development of precision medicine by linking the features of patient genomes to natural product sensitivity.\n",
            "----------------------------------------\n",
            "Title: Deep Learning based Effective Steganalysis\n",
            "Abstract: There is an evident paradigm shift in steganalysis techniques with discovery of deep learning networks. As steganalysis is a classification task, it is done by machine learning classifiers and ensembles of them. But with the proliferation of deep learning and Convolutional Neural Networks in many areas, the performance of steganalysis techniques have jumped up to a another high, because of the application of Convolutional Neural Networks. The traditional steganalysis techniques consists two important steps, i.e., feature extraction and classification; where as deep learning networks learn the features automatically, eliminating the need of extraction of handcrafted features. Because of this feature CNNs were highly successful in image recognition and image classification techniques. In addition to that, feature extraction and classification are combined together in deep learning hence classification would be more effective because of the learning of the features which are really important for classification. But in Steganalysis the task is to detect very subtle and weak noise created by the hidden data with steganography techniques. We have designed a deep CNN architecture customized for steganalysis task based on existing residual neural networks frame. We have introduced a descriptor to capture the inter pixel dependencies and which acts as an indicator for weightage of a particular feature maps. Thus the classifier can give more weightage to effective feature maps instead of treating all the feature maps equally. We have also used a gating mechanism by using sigmoid function after nonlinear activation function sandwiched between two fully connected layers. This enhancement to the existing deep residual neural networks has given better results in terms of error detection rate compared to the other deep learning based steganalysis techniques.\n",
            "----------------------------------------\n",
            "Title: Biology-inspired optimization algorithms applied to intelligent input weights selection of an extreme learning machine in regression problems\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Comparative Analysis of Rough Set Based Intelligent Techniques for Unsupervised Gene Selection\n",
            "Abstract: As the micro array databases increases in dimension and results in complexity, identifying the most informative genes is a challenging task. Such difficulty is often related to the huge number of genes with very few samples. Research in medical data mining addresses this problem by applying techniques from data mining and machine learning to the micro array datasets. In this paper Unsupervised Tolerance Rough Set based Quick Reduct U-TRS-QR, a diverse feature selection algorithm, which extends the existing equivalent rough sets for unsupervised learning, is proposed. Genes selected by the proposed method leads to a considerably improved class predictions in wide experiments on two gene expression datasets: Brain Tumor and Colon Cancer. The results indicate consistent improvement among 12 classifiers.\n",
            "----------------------------------------\n",
            "Title: Using Multi-Class Machine Learning Methods to Predict Major League Baseball Pitches.\n",
            "Abstract: SIDLE, GLENN DANIEL. Using Multi-Class Machine Learning Methods to Predict Major League Baseball Pitches. (Under the direction of Hien Tran.) As the field of machine learning and its applications grow, there is a need to expand the ability to classify and predict beyond just being able to handle a binary problem. While the ability to predict a yes or no answer is still valuable, in a world of increasing complexity, machine learning methods are now employed in a multi-class problem setting more than ever. Major League Baseball provides a rich and detailed data set with its PITCHf/x system that tracks every baseball pitch thrown in every stadium in every game. Pitch prediction has been a topic of previous research that has mostly focused on the binary split between fastballs and other pitch types. We extend the binary problem to a multi-class one that involves up to seven unique pitch types. The work done with baseball pitches can be used as a template to expand a wide variety of other binary predictions into accommodating more than a simple two class approach. To accomplish the multi-class prediction, we examine multiple machine learning methods to find the most efficient and accurate algorithm. In this dissertation, we first explore the results given by each of three different methods: Linear Discriminant Analysis, Support Vector Machines, and bagged random forests of Classification Trees. Our feature set is created from both categorical and continuous data, with features that can be taken from the observation of a game used alongside synthetic features generated from historical data. Using the same methods, we explore adaptive feature selection methods in a novel approach, using Decision Directed Acyclic Graphs to allow for the use of binary techniques to reduce the feature set. We then employ post processing methods to determine a measure of variable importance to find what inputs are the most informative for our model. Finally, we implement the prediction method in a live game environment, presenting the results of the different construction of the model and discussing the difficulties associated with the time limitations. © Copyright 2017 by Glenn Daniel Sidle\n",
            "----------------------------------------\n",
            "Title: Exploring the application of machine‐learning techniques in the next generation of long‐term hydropower‐thermal scheduling\n",
            "Abstract: This paper introduces a shape‐based inflow scenarios reduction framework applied in long‐term hydro‐thermal scheduling. This scheduling problem involves strategically managing the limited stored hydro energy in coordination with the electricity system. The scenario fan problem, selected as a long‐term hydro‐thermal scheduling approach, can effectively represent the individual hydropower plants and their short‐term flexibility within the long‐term scheduling process, making it well‐suited for capturing the disaggregated physical characteristics of hydro stations. However, the computational burden of scenario fan problem increases due to the complexity of the cascaded system and the large number of inflow scenarios. To tackle these challenges, a machine learning clustering method is developed for extracting shape‐based features to capture the energy and shape attributes of hydro inflows. A comparative analysis was conducted to evaluate the effectiveness of the proposed method, comparing it with four established clustering methods. This evaluation was carried out on a hydro‐thermal test case, utilizing both in‐sample and out‐of‐sample data analysis. The findings demonstrate that the proposed framework outperforms other methods in terms of computational time by 42.6% and optimal reservoir trajectories by 12.1% considering K‐means using Euclidean distance as the benchmark. Additionally, this study showcases the feasibility of performing long‐term hydro‐thermal scheduling at a granular level, with detailed topological information and a shorter time scale. This expanded approach opens up new possibilities for addressing the integration of renewable energy resources within the realm of long‐term hydro‐thermal scheduling.\n",
            "----------------------------------------\n",
            "Title: Personalized Federated Learning by Domain-Aware Network Pruning and Re-growth\n",
            "Abstract: Federated learning (FL) is a machine learning paradigm where multiple clients train their local machine learning models collaboratively (without sharing private data). One of the main challenges in FL is statistical heterogeneity of the data distributions across clients. Personalized FL (PFL) mitigates statistical heterogeneity by collaborative model training across homogeneous clients. In this paper, we propose a novel personalized federated learning by domain-aware network pruning and re-growth, called FedDNPR, that is more accurate as compared to existing PFL methods while maintaining high efficiency. This is achieved by 1) introducing a regularization term capturing heterogeneity of weights in iterative network pruning in order to reduce network sharing among unrelated clients, and 2) iterative network re-growing only from weights of related clients to increase network sharing among related clients. With FedDNPR, model clustering is performed considering the similarity between gradient updates in the last layers of the networks, with cosine as the similarity measure to achieve both accuracy and efficiency in model personalization. With extensive experimental evaluation, we show that FedDNPR significantly outperforms the state-of-the-art PFL approaches, while maintaining comparable efficiency.\n",
            "----------------------------------------\n",
            "Title: Combining Machine Learning with Knowledge Engineering to detect Fake News in Social Networks - A Survey\n",
            "Abstract: Due to extensive spread of fake news on social and news media it became an emerging research topic now a days that gained attention. In the news media and social media the information is spread highspeed but without accuracy and hence detection mechanism should be able to predict news fast enough to tackle the dissemination of fake news. It has the potential for negative impacts on individuals and society. Therefore, detecting fake news on social media is important and also a technically challenging problem these days. We knew that Machine learning is helpful for building Artificial intelligence systems based on tacit knowledge because it can help us to solve complex problems due to real word data. On the other side we knew that Knowledge engineering is helpful for representing experts knowledge which people aware of that knowledge. Due to this we proposed that integration of Machine learning and knowledge engineering can be helpful in detection of fake news. In this paper we present what is fake news, importance of fake news, overall impact of fake news on different areas, different ways to detect fake news on social media, existing detections algorithms that can help us to overcome the issue, similar application areas and at the end we proposed combination of data driven and engineered knowledge to combat fake news. We studied and compared three different modules text classifiers, stance detection applications and fact checking existing techniques that can help to detect fake news. Furthermore, we investigated the impact of fake news on society. Experimental evaluation of publically available datasets and our proposed fake news detection combination can serve better in detection of fake news.\n",
            "----------------------------------------\n",
            "Title: Optimization of metal-forming process via a hybrid intelligent optimization technique\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: RLBEEP: Reinforcement-Learning-Based Energy Efficient Control and Routing Protocol for Wireless Sensor Networks\n",
            "Abstract: One of the most important topics in the field of wireless sensor networks is the development of approaches to improve network lifetime. In this paper, an energy-efficient control and routing protocol for wireless sensor networks is presented. This algorithm is based on reinforcement learning for energy management in the network. This protocol seeks to optimize routing policies to maximize the long-term reward received by each node, using reinforcement learning, which is a machine learning approach. In order to improve the lifetime of wireless sensor network, three energy management approaches have been proposed. The first approach is to navigate correctly using reinforcement learning to reduce the length of the routes and to improve energy consumption. The second approach is to exploit a sleep scheduling technique to improve node energy consumption. The last approach is used to restrict data transmission of each node based on the received data change rate. Simulation results show that in terms of network lifespan, the proposed method significantly outperforms previous reported methods.\n",
            "----------------------------------------\n",
            "Title: Unraveling the role of ADAMs in clinical heterogeneity and the immune microenvironment of hepatocellular carcinoma: insights from single-cell, spatial transcriptomics, and bulk RNA sequencing\n",
            "Abstract: Background Hepatocellular carcinoma (HCC) is a prevalent and heterogeneous tumor with limited treatment options and unfavorable prognosis. The crucial role of a disintegrin and metalloprotease (ADAM) gene family in the tumor microenvironment of HCC remains unclear. Methods This study employed a novel multi-omics integration strategy to investigate the potential roles of ADAM family signals in HCC. A series of single-cell and spatial omics algorithms were utilized to uncover the molecular characteristics of ADAM family genes within HCC. The GSVA package was utilized to compute the scores for ADAM family signals, subsequently stratified into three categories: high, medium, and low ADAM signal levels through unsupervised clustering. Furthermore, we developed and rigorously validated an innovative and robust clinical prognosis assessment model by employing 99 mainstream machine learning algorithms in conjunction with co-expression feature spectra of ADAM family genes. To validate our findings, we conducted PCR and IHC experiments to confirm differential expression patterns within the ADAM family genes. Results Gene signals from the ADAM family were notably abundant in endothelial cells, liver cells, and monocyte macrophages. Single-cell sequencing and spatial transcriptomics analyses have both revealed the molecular heterogeneity of the ADAM gene family, further emphasizing its significant impact on the development and progression of HCC. In HCC tissues, the expression levels of ADAM9, ADAM10, ADAM15, and ADAM17 were markedly elevated. Elevated ADAM family signal scores were linked to adverse clinical outcomes and disruptions in the immune microenvironment and metabolic reprogramming. An ADAM prognosis signal, developed through the utilization of 99 machine learning algorithms, could accurately forecast the survival duration of HCC, achieving an AUC value of approximately 0.9. Conclusions This study represented the inaugural report on the deleterious impact and prognostic significance of ADAM family signals within the tumor microenvironment of HCC.\n",
            "----------------------------------------\n",
            "Title: Application of Wearable Inertial Sensors and A New Test Battery for Distinguishing Retrospective Fallers from Non-fallers among Community-dwelling Older People\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Hip and Wrist-Worn Accelerometer Data Analysis for Toddler Activities\n",
            "Abstract: Although accelerometry data are widely utilized to estimate physical activity and sedentary behavior among children age 3 years or older, for toddlers age 1 and 2 year(s), accelerometry data recorded during such behaviors have been far less examined. In particular, toddler’s unique behaviors, such as riding in a stroller or being carried by an adult, have not yet been examined. The objective of this study was to describe accelerometry signal outputs recorded during participation in nine types of behaviors (i.e., running, walking, climbing up/down, crawling, riding a ride-on toy, standing, sitting, riding in a stroller/wagon, and being carried by an adult) among toddlers. Twenty-four toddlers aged 13 to 35 months (50% girls) performed various prescribed behaviors during free play in a commercial indoor playroom while wearing ActiGraph wGT3X-BT accelerometers on a hip and a wrist. Participants’ performances were video-recorded. Based on the video data, accelerometer data were annotated with behavior labels to examine accelerometry signal outputs while performing the nine types of behaviors. Accelerometer data collected during 664 behavior assessments from the 21 participants were used for analysis. Hip vertical axis counts for walking were low (median = 49 counts/5 s). They were significantly lower than those recorded while a toddler was “carried” by an adult (median = 144 counts/5 s; p < 0.01). While standing, sitting, and riding in a stroller, very low hip vertical axis counts were registered (median ≤ 5 counts/5 s). Although wrist vertical axis and vector magnitude counts for “carried” were not higher than those for walking, they were higher than the cut-points for sedentary behaviors. Using various accelerometry signal features, machine learning techniques showed 89% accuracy to differentiate the “carried” behavior from ambulatory movements such as running, walking, crawling, and climbing. In conclusion, hip vertical axis counts alone may be unable to capture walking as physical activity and “carried” as sedentary behavior among toddlers. Machine learning techniques that utilize additional accelerometry signal features could help to recognize behavior types, especially to differentiate being “carried” from ambulatory movements.\n",
            "----------------------------------------\n",
            "Title: Towards a machine learning-aided metaheuristic framework for a production/distribution system design problem\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Transferability of datasets between Machine-Learning Interaction Potentials\n",
            "Abstract: With the emergence of Foundational Machine Learning Interatomic Potential (FMLIP) models trained on extensive datasets, transferring data between different ML architectures has become increasingly important. In this work, we examine the extent to which training data optimised for one machine-learning forcefield algorithm may be re-used to train different models, aiming to accelerate FMLIP fine-tuning and to reduce the need for costly iterative training. As a test case, we train models of an organic liquid mixture that is commonly used as a solvent in rechargeable battery electrolytes, making it an important target for reactive MLIP development. We assess model performance by analysing the properties of molecular dynamics trajectories, showing that this is a more stringent test than comparing prediction errors for fixed datasets. We consider several types of training data, and several popular MLIPs - notably the recent MACE architecture, a message-passing neural network designed for high efficiency and smoothness. We demonstrate that simple training sets constructed without any ab initio dynamics are sufficient to produce stable models of molecular liquids. For simple neural-network architectures, further iterative training is required to capture thermodynamic and kinetic properties correctly, but MACE performs well with extremely limited datsets. We find that configurations designed by human intuition to correct systematic model deficiencies transfer effectively between algorithms, but active-learned data that are generated by one MLIP do not typically benefit a different algorithm. Finally, we show that any training data which improve model performance also improve its ability to generalise to similar unseen molecules. This suggests that trajectory failure modes are connected with chemical structure rather than being entirely system-specific.\n",
            "----------------------------------------\n",
            "Title: Embedding-Based Deep Neural Network and Convolutional Neural Network Graph Classifiers\n",
            "Abstract: One of the most significant graph data analysis tasks is graph classification, as graphs are complex data structures used for illustrating relationships between entity pairs. Graphs are essential in many domains, such as the description of chemical molecules, biological networks, social relationships, etc. Real-world graphs are complicated and large. As a result, there is a need to find a way to represent or encode a graph’s structure so that it can be easily utilized by machine learning models. Therefore, graph embedding is considered one of the most powerful solutions for graph representation. Inspired by the Doc2Vec model in Natural Language Processing (NLP), this paper first investigates different ways of (sub)graph embedding to represent each graph or subgraph as a fixed-length feature vector, which is then used as input to any classifier. Thus, two supervised classifiers—a deep neural network (DNN) and a convolutional neural network (CNN)—are proposed to enhance graph classification. Experimental results on five benchmark datasets indicate that the proposed models obtain competitive results and are superior to some traditional classification methods and deep-learning-based approaches on three out of five benchmark datasets, with an impressive accuracy rate of 94% on the NCI1 dataset.\n",
            "----------------------------------------\n",
            "Title: Scenario optimization for interactive category search\n",
            "Abstract: Most of the existing work in interactive content based retrieval concentrates on machine learning methods for effective use of relevance feedback. On the other end of the spectrum, the information visualization community focusses on effective methods for conveying information to the user. What lacks is research considering the information visualization and interactive content based retrieval as truly integrated parts of one search system. In such an integrated system there are many degrees of freedom like the number of images to display, the image size, different visualization modes, and possible feedback modes. To find optimal values for all of those using user studies is unfeasible. We therefore develop scenarios in which tasks and user actions are simulated. These are then optimized based on objective constraints and evaluation criteria. In such a manner the degrees of freedom are reduced and the remaining degrees can be evaluated in user studies. In this paper we present a system which integrates advanced similarity based visualization with active learning. We have performed extensive scenario based experimentation on an interactive category search task. The results show that indeed the use of advanced visualization and active learning pays off.\n",
            "----------------------------------------\n",
            "Title: An Optimal Solution to the Overfitting and Underfitting Problem of Healthcare Machine Learning Models\n",
            "Abstract: In the current technological era, artificial intelligence is becoming increasingly popular.  Machine learning, as the branch of AI is taking charge in every field such as healthcare, the Stock market, Automation, Robotics, Image Processing, and so on. In the current scenario, machine learning and/or deep learning are becoming very popular in medical science for disease prediction. Much research is underway in the form of disease prediction models by machine learning. To ensure the performance and accuracy of the machine learning model, it is important to keep some basic things in mind during training. The machine learning model has several issues which must be rectified duration of the training of the model so that the learning model works efficiently such as model selection, parameter tuning, dataset splitting, cross-validation, bias-variance tradeoff, overfitting, underfitting, and so on. Under- and over-fitting are the two main issues that affect machine learning models. This research paper mainly focuses on minimizing and/or preventing the problem of overfitting and underfitting machine learning models.\n",
            "----------------------------------------\n",
            "Title: Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Survival prediction in intensive-care units based on aggregation of long-term disease history and acute physiology a retrospective study of the Danish National Patient Registry and electronic patient records\n",
            "Abstract: Summary Background Intensive-care units (ICUs) treat the most critically ill patients, which is complicated by the heterogeneity of the diseases that they encounter. Severity scores based mainly on acute physiology measures collected at ICU admission are used to predict mortality, but are non-specific, and predictions for individual patients can be inaccurate. We investigated whether inclusion of long-term disease history before ICU admission improves mortality predictions. Methods Registry data for long-term disease histories for more than 230 000 Danish ICU patients were used in a neural network to develop an ICU mortality prediction model. Long-term disease histories and acute physiology measures were aggregated to predict mortality risk for patients for whom both registry and ICU electronic patient record data were available. We compared mortality predictions with admission scores on the Simplified Acute Physiology Score (SAPS) II, the Acute Physiologic Assessment and Chronic Health Evaluation (APACHE) II, and the best available multimorbidity score, the Multimorbidity Index. An external validation set from an additional hospital was acquired after model construction to confirm the validity of our model. During initial model development data were split into a training set (85%) and an independent test set (15%), and a five-fold cross-validation was done during training to avoid overfitting. Neural networks were trained for datasets with disease history of 1 month, 3 months, 6 months, 1 year, 2⋅5 years, 5 years, 7⋅5 years, 10 years, and 23 years before ICU admission. Findings Mortality predictions with a model based solely on disease history outperformed the Multimorbidity Index (Matthews correlation coefficient 0⋅265 vs 0⋅065), and performed similarly to SAPS II and APACHE II (Matthews correlation coefficient with disease history, age, and sex 0·326 vs 0·347 and 0·300 for SAPS II and APACHE II, respectively). Diagnoses up to 10 years before ICU admission affected current mortality prediction. Aggregation of previous disease history and acute physiology measures in a neural network yielded the most precise predictions of in-hospital mortality (Matthews correlation coefficient 0⋅391 for in-hospital mortality compared with 0⋅347 with SAPS II and 0⋅300 with APACHE II). These results for the aggregated model were validated in an external independent dataset of 1528 patients (Matthews correlation coefficient for prediction of in-hospital mortality 0⋅341). Interpretation Longitudinal disease-spectrum-wide data available before ICU admission are useful for mortality prediction. Disease history can be used to differentiate mortality risk between patients with similar vital signs with more precision than SAPS II and APACHE II scores. Machine learning models can be deconvoluted to generate novel understandings of how ICU patient features from long-term and short-term events interact with each other. Explainable machine learning models are key in clinical settings, and our results emphasise how to progress towards the transformation of advanced models into actionable, transparent, and trustworthy clinical tools.\n",
            "----------------------------------------\n",
            "Title: Designing a User-Centric AI-Driven Mobile App for Personalized Time Management: Integrating Machine Learning and Design Thinking\n",
            "Abstract: Recent advancements in artificial intelligence (AI) have led to the development of innovative personalized intelligent assistants such as Google Home and Siri. Despite these technological strides, the integration of established design frameworks and user experience (UX) principles in user-centric AI applications remains insufficiently explored. This study utilizes the design thinking methodology-emphasizing empathy, ideation, and prototype testing-and existing UX laws to develop ‘TimeSync,’ an AI-based smart time management application university students in Thailand. ‘TimeSync’ employs a machine learning model to customize schedules and alarms by incorporating variables such as preparation time, weather, and traffic conditions, ensuring users arrive on time. Usability testing based on specific user satisfaction and usability metrics revealed that ‘TimeSync’ offers an intuitive interface and enhances user experience, promoting consistent utilization for effective time management. These findings demonstrate the significant potential of design thinking and UX principles in crafting user-centric AI applications, providing valuable insights and a robust framework for future AI development.\n",
            "----------------------------------------\n",
            "Title: Physical information-enhanced graph neural network for predicting phase separation\n",
            "Abstract: \n",
            " Although phase separation is a ubiquitous phenomenon, the interactions between multiple components make it difficult to accurately model and predict. In recent years, machine learning has been widely used in physics simulations. Here, we present a physical information-enhanced graph neural network (PIENet) to simulate and predict the evolution of phase separation. The accuracy of our model in predicting particle positions is improved by 40.3% and 51.77% compared with CNN and SVM respectively. Moreover, we design an order parameter based on local density to measure the evolution of phase separation and analyze the systematic changes with different repulsion coefficients and different Schmidt numbers. The results demonstrate that our model can achieve long-term accurate predictions of order parameters without requiring complex handcrafted features. These results prove that graph neural networks can become new tools and methods for predicting the structure and properties of complex physical systems.\n",
            "----------------------------------------\n",
            "Title: Ion Migration‐Modulated Flexible MXene Synapse for Biomimetic Multimode Afferent Nervous System: Material and Motion Cognition\n",
            "Abstract: The biomimetic afferent nervous system (ANS) is significant for transporting external stimuli into intelligent robots; however, it is still far from bionics due to traditional multisensor and single‐cognition strategies. Herein, a flexible biomimetic ANS with multimode fuzzy perception and brain‐like cognition is developed, by fusing the ion migration‐modulated MXene synapse and machine learning (ML). First of all, the elementary perceptual ability to mimic biological neuroreceptors is demonstrated. Motion artifact in the ionic conductive elastomer (ICE) current is eliminated. Furthermore, the multimode perception and brain‐like cognition are accomplished by synaptic currents (SCs) and nine ML algorithms. Finally, the cognitions of materials, gestures, and motions are conducted by distributing the ANS devices across body joints, and with the optimal ML method, the accuracies can reach 80%, 100%, and 90%, respectively. This synapse‐based ANS may provide a new idea for developing next‐generation neuromorphic intelligent robots.\n",
            "----------------------------------------\n",
            "Title: EVlncRNA-Dpred: improved prediction of experimentally validated lncRNAs by deep learning\n",
            "Abstract: Abstract Long non-coding RNAs (lncRNAs) played essential roles in nearly every biological process and disease. Many algorithms were developed to distinguish lncRNAs from mRNAs in transcriptomic data and facilitated discoveries of more than 600 000 of lncRNAs. However, only a tiny fraction (<1%) of lncRNA transcripts (~4000) were further validated by low-throughput experiments (EVlncRNAs). Given the cost and labor-intensive nature of experimental validations, it is necessary to develop computational tools to prioritize those potentially functional lncRNAs because many lncRNAs from high-throughput sequencing (HTlncRNAs) could be resulted from transcriptional noises. Here, we employed deep learning algorithms to separate EVlncRNAs from HTlncRNAs and mRNAs. For overcoming the challenge of small datasets, we employed a three-layer deep-learning neural network (DNN) with a K-mer feature as the input and a small convolutional neural network (CNN) with one-hot encoding as the input. Three separate models were trained for human (h), mouse (m) and plant (p), respectively. The final concatenated models (EVlncRNA-Dpred (h), EVlncRNA-Dpred (m) and EVlncRNA-Dpred (p)) provided substantial improvement over a previous model based on support-vector-machines (EVlncRNA-pred). For example, EVlncRNA-Dpred (h) achieved 0.896 for the area under receiver-operating characteristic curve, compared with 0.582 given by sequence-based EVlncRNA-pred model. The models developed here should be useful for screening lncRNA transcripts for experimental validations. EVlncRNA-Dpred is available as a web server at https://www.sdklab-biophysics-dzu.net/EVlncRNA-Dpred/index.html, and the data and source code can be freely available along with the web server.\n",
            "----------------------------------------\n",
            "Title: Machine Learning in Manufacturing: Processes Classification Using Support Vector Machine and Horse Optimization Algorithm\n",
            "Abstract: The classification of the manufacturing processes in processes that pass the in-line testing and processes that fail the in-line testing is a challenging research problem as the manufacturing processes data is characterized by many features that correspond to the different steps of the manufacturing processes. This research article proposes a method in which: (1) the manufacturing processes classification is performed using the Support Vector Machine (SVM) algorithm, (2) the regularization parameter value and the gamma coefficient value of the SVM algorithm are optimized using Horse Optimization Algorithm (HOA), (3) the HOA based SVM results are compared to Particle Swarm Optimization (PSO) based SVM results and Chicken Swarm Optimization (CSO) based SVM results, and (4) the data used in experiments is the open source public dataset SECOM.\n",
            "----------------------------------------\n",
            "Title: AlphaCode and “data-driven” programming\n",
            "Abstract: Is ignoring everything that is known about code the best way to write programs? Competitive programming problems represent a challenging task for even skilled programmers: Given a short natural language description of an algorithmic problem, contestants must quickly write a program that solves the task. On page 1092 of this issue, Li et al. (1) present the AlphaCode system, which represents a substantial step forward in the development of machine learning (ML) models that can synthesize computer programs to solve these types of challenging problems. But what is perhaps most surprising about the system is what AlphaCode does not do: AlphaCode contains no explicit built-in knowledge about the structure of computer code. Instead, AlphaCode relies on a purely “data-driven” approach to writing code, learning the structure of computer programs by simply observing lots of existing code.\n",
            "----------------------------------------\n",
            "Title: Analyzing Hong Kong's Legal Judgments from a Computational Linguistics point-of-view\n",
            "Abstract: Analysis and extraction of useful information from legal judgments using computational linguistics was one of the earliest problems posed in the domain of information retrieval. Presently, several commercial vendors exist who automate such tasks. However, a crucial bottleneck arises in the form of exorbitant pricing and lack of resources available in analysis of judgements mete out by Hong Kong's Legal System. This paper attempts to bridge this gap by providing several statistical, machine learning, deep learning and zero-shot learning based methods to effectively analyze legal judgments from Hong Kong's Court System. The methods proposed consists of: (1) Citation Network Graph Generation, (2) PageRank Algorithm, (3) Keyword Analysis and Summarization, (4) Sentiment Polarity, and (5) Paragrah Classification, in order to be able to extract key insights from individual as well a group of judgments together. This would make the overall analysis of judgments in Hong Kong less tedious and more automated in order to extract insights quickly using fast inferencing. We also provide an analysis of our results by benchmarking our results using Large Language Models making robust use of the HuggingFace ecosystem.\n",
            "----------------------------------------\n",
            "Title: Fe-Based Superconducting Transition Temperature Modeling through Gaussian Process Regression\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Revealing high-fidelity phase selection rules for high entropy alloys: A combined CALPHAD and machine learning study\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Applying Machine Learning Techniques to Improve Linux Process Scheduling\n",
            "Abstract: In this work we use Machine Learning (ML) techniques to learn the CPU time-slice utilization behavior of known programs in a Linux system. Learning is done by an analysis of certain static and dynamic attributes of the processes while they are being run. Our objective was to discover the most important static and dynamic attributes of the processes that can help best in prediction of CPU burst times which minimize the process TaT (Turn-around-Time). In our experimentation we modify the Linux Kernel scheduler (version 2.4.20-8) to allow scheduling with customized time slices. The \"Waikato Environment for Knowledge Analysis\" (Weka), an open source machine-learning tool is used to find the most suitable ML method to characterize our programs. We experimentally find that the C'4.5 Decision Tree algorithm most effectively solved the problem. We find that predictive scheduling could reduce TaT in the range of 1.4% to 5.8%. This was due to a reduction in the number of context switches needed to complete the process execution. We find our result interesting in the context that generally operating systems presently never make use of a program's previous execution history in their scheduling behavior.\n",
            "----------------------------------------\n",
            "Title: An Intelligent Area Localization Framework for Rotating Machine Vision Vibration Measurement\n",
            "Abstract: Vision-based vibration measurement technology has received extensive attention due to its advantages of non-contact, high spatial resolution, and no-load effect. However, with the complexity of measurement objects and measurement tasks, the existing visual measurement technology is gradually showing greater limitations. Specifically, due to the uncertainty of actual working conditions, not all pixels in the field of view can measure vibration. Therefore, the selection of measurement points needs to rely on prior structural information and artificial experience. Frequent manual point selection tests bring a lot of resource consumption, which greatly reduces the automation degree of visual vibration measurement. This paper focuses on an intelligent area localization method for vibration measurement of rotating machine vision and designs a deep learning-based vibration measurement area localization framework to directly feedback all reliable measurement pixels from image data, which is called the VMAL framework. Firstly, the sub-pixel physical feature information associated with vibration in the data is analyzed through an unsupervised image decomposition network, and then a regularized regional localization network is used to cluster and output reliable regional pixels. Experimental results on a medium-sized single-span rotor platform verify the effectiveness of the proposed method.\n",
            "----------------------------------------\n",
            "Title: Handwriting Styles: Benchmarks and Evaluation Metrics\n",
            "Abstract: Extracting styles of handwriting is a challenging problem, since the style themselves are not well defined. It is a key component to develop systems with more personalized experiences for humans. In this paper, we propose baseline benchmarks, in order to set anchors to estimate the relative quality of different handwriting style methods. This will be done using deep learning techniques, which have shown remarkable results in different machine learning tasks, learning classification, regression, and most relevant to our work, generating temporal sequences. We discuss the challenges associated with evaluating our methods, which is related to evaluation of generative models in general. We then propose evaluation metrics, which we find relevant to this problem, and we discuss how we evaluate the performance metrics. In this study, we use IRON-OFF dataset [1]. To the best of our knowledge, no existing benchmarks or evaluation metrics for this task exit yet, and this dataset has not been used before in the context of handwriting synthesis.\n",
            "----------------------------------------\n",
            "Title: C2H5NO Isomers: From Acetamide to 1,2-Oxazetidine and Beyond\n",
            "Abstract: This work documents the properties of a number of isomers of molecular formula C2H5NO from the most stable, acetamide, through 1,2-oxazetidine and including even higher energy species largely of a dipolar nature. Only two of the isomers have been detected in emissions from the interstellar medium (ISM); possible further candidates are identified, and the likelihood of their being detectable is considered. In general, hardly any of these compounds have been discussed in the existing chemical literature, so this work represents an important contribution extending the canon of chemical bonding which can contribute to machine learning, providing a more exacting test of AI applications. The presence in the ISM of acetamide, CH3C(O)NH2, is the subject of current debate with no clear and obvious paths to its formation; it is shown that a 1,3-[H]-transfer from (E,Z)-ethanimidic acid, CH3C(OH)=NH, is feasible in spite of an energy barrier of 130 kJ mol–1. It is speculated that imidic acid can itself be formed from abundant precursors, H2O and CH3C≡N, in an acid-induced, water addition, autocatalytic reaction on water–ice grains. H3CC≡NH3CC≡NH+ + H2OH3CC(O+H2)=NHH3CC(OH)=NH + H3O+\n",
            "----------------------------------------\n",
            "Title: An algorithm for characterizing skin moles using image processing and machine learning\n",
            "Abstract: Melanoma, the most serious type of skin cancer, forms in cells (melanocytes) that produce melanin, the pigment that gives color to the skin. There are low-income regions that lack specialized dermatologists, causing skin cancer to be diagnosed in advanced stages. In Peru, in high Andean communities with low resources, the problem is aggravated by the high incidence of ultraviolet radiation and lack of medical resources to make the diagnosis. Normally, mole images are obtained from dermatoscopes. The present work seeks to use mole images obtained from smartphones to make the classification of them as suspected or not suspected of being melanoma, by means of a feature extraction algorithm. The first step is to make color and lighting corrections. After this, the image is segmented using the K-Means algorithm, and we obtain the areas of the mole and skin. With the segmented mole we proceed to extract the main visual characteristics and then use classification algorithms such as support vector machine (SVM), random forest and naive bayes, which obtained an accuracy of 0.9473, 0.7368 and 0.6842, respectively. These results show that it is possible to use images obtained from smartphones to develop a classification algorithm with 94.73% accuracy to detect melanoma in skin moles.\n",
            "----------------------------------------\n",
            "Title: Automatic red eye correction and its quality metric\n",
            "Abstract: The red eye artifacts are troublesome defect of amateur photos. Correction of red eyes during printing without user intervention and making photos more pleasant for an observer are important tasks. The novel efficient technique of automatic correction of red eyes aimed for photo printers is proposed. This algorithm is independent from face orientation and capable to detect paired red eyes as well as single red eyes. The approach is based on application of 3D tables with typicalness levels for red eyes and human skin tones and directional edge detection filters for processing of redness image. Machine learning is applied for feature selection. For classification of red eye regions a cascade of classifiers including Gentle AdaBoost committee from Classification and Regression Trees (CART) is applied. Retouching stage includes desaturation, darkening and blending with initial image. Several versions of approach implementation using trade-off between detection and correction quality, processing time, memory volume are possible. The numeric quality criterion of automatic red eye correction is proposed. This quality metric is constructed by applying Analytic Hierarchy Process (AHP) for consumer opinions about correction outcomes. Proposed numeric metric helped to choose algorithm parameters via optimization procedure. Experimental results demonstrate high accuracy and efficiency of the proposed algorithm in comparison with existing solutions.\n",
            "----------------------------------------\n",
            "Title: High-Dimensional Analog Circuit Sizing via Bayesian Optimization in the Variational Autoencoder Enhanced Latent Space\n",
            "Abstract: High-dimensional analog circuit sizing with machine learning-based surrogate models suffers from the high sampling cost of evaluating expensive black-box objective functions in huge design spaces. This work addresses the sampling efficiency challenge by elaborately reducing the dimensionality of the input spaces, enabling efficient optimization for automated analog circuit sizing. We propose a latent space optimization method that includes an iteratively updated generative model based on a variational autoencoder to embed the solution manifold of analog circuits to a low-dimensional and continuous space, where the latent variables are optimized using Bayesian optimization. The effectiveness of the proposed method has been verified on two real-world analog circuits with 18 and 59 design variables. In comparison with BO in the original high-d spaces or latent low-d spaces assisted by other embedding strategies, the proposed method achieves 23%~73% improvements in optimization per-formance within the same runtime limitations. We also conduct a technology migration experiment using the pre-trained variational autoencoder model, which demonstrates the necessity of pre-training and the scalability of the proposed method.\n",
            "----------------------------------------\n",
            "Title: Combining Multiple RNA-Seq Data Analysis Algorithms Using Machine Learning Improves Differential Isoform Expression Analysis\n",
            "Abstract: RNA sequencing has become the standard technique for high resolution genome-wide monitoring of gene expression. As such, it often comprises the first step towards understanding complex molecular mechanisms driving various phenotypes, spanning organ development to disease genesis, monitoring and progression. An advantage of RNA sequencing is its ability to capture complex transcriptomic events such as alternative splicing which results in alternate isoform abundance. At the same time, this advantage remains algorithmically and computationally challenging, especially with the emergence of even higher resolution technologies such as single-cell RNA sequencing. Although several algorithms have been proposed for the effective detection of differential isoform expression from RNA-Seq data, no widely accepted golden standards have been established. This fact is further compounded by the significant differences in the output of different algorithms when applied on the same data. In addition, many of the proposed algorithms remain scarce and poorly maintained. Driven by these challenges, we developed a novel integrative approach that effectively combines the most widely used algorithms for differential transcript and isoform analysis using state-of-the-art machine learning techniques. We demonstrate its usability by applying it on simulated data based on several organisms, and using several performance metrics; we conclude that our strategy outperforms the application of the individual algorithms. Finally, our approach is implemented as an R Shiny application, with the underlying data analysis pipelines also available as docker containers.\n",
            "----------------------------------------\n",
            "Title: Forecasting Stock Market Prices Using Machine Learning and Deep Learning Models: A Systematic Review, Performance Analysis and Discussion of Implications\n",
            "Abstract: The financial sector has greatly impacted the monetary well-being of consumers, traders, and financial institutions. In the current era, artificial intelligence is redefining the limits of the financial markets based on state-of-the-art machine learning and deep learning algorithms. There is extensive use of these techniques in financial instrument price prediction, market trend analysis, establishing investment opportunities, portfolio optimization, etc. Investors and traders are using machine learning and deep learning models for forecasting financial instrument movements. With the widespread adoption of AI in finance, it is imperative to summarize the recent machine learning and deep learning models, which motivated us to present this comprehensive review of the practical applications of machine learning in the financial industry. This article examines algorithms such as supervised and unsupervised machine learning algorithms, ensemble algorithms, time series analysis algorithms, and deep learning algorithms for stock price prediction and solving classification problems. The contributions of this review article are as follows: (a) it provides a description of machine learning and deep learning models used in the financial sector; (b) it provides a generic framework for stock price prediction and classification; and (c) it implements an ensemble model—“Random Forest + XG-Boost + LSTM”—for forecasting TAINIWALCHM and AGROPHOS stock prices and performs a comparative analysis with popular machine learning and deep learning models.\n",
            "----------------------------------------\n",
            "Title: DROPLET: Distributed Operator placement and Resource Provisioning for IoT applications spanning Edge and Cloud Resources\n",
            "Abstract: —Internet of Things (IoT) applications generate massive amounts of real-time data. Owners of such data strive to make predictions/inference from large streams of complex input such as video feeds, often by deploying applications that involve machine learning and image processing operations. A typical deployment of IoT applications includes edge devices to acquire the input data and provide processing/storage capacity closer to the location where the data is captured. An important challenge for IoT applications is deciding which operations to be executed on an edge device and which operations should be carried out on the cloud. In this paper we propose a dynamic programming algorithm called Droplet, to scalably partition operations in IoT applications across shared edge and cloud resources, while jointly minimizing the completion time of all operations and resource consumption. We evaluate Droplet using several real-world applications to show that it is able to model their execution time within an error of 0.42%. It ﬁnds partitioning of operations to within about 4% of optimal application completion time, while scaling up to thousand operations. We analyze Droplet to show it scales linearly in the total number of operations ( n o ) with complexity O ( n o · ( L ! ) 2 · L ) , where L is the number of edge devices and the cloud (L=2 in typical deployments with one edge and one cloud).\n",
            "----------------------------------------\n",
            "Title: Certiﬁed Convergent Perceptron Learning\n",
            "Abstract: Frank Rosenblatt invented the Perceptron algorithm in 1957 as part of an early attempt to build “brain models” – artiﬁcial neural networks. In this paper, we apply tools from symbolic logic – dependent type theory as implemented in the interactive theorem prover Coq – to prove that one-layer perceptrons for binary classiﬁcation converge when trained on linearly separable datasets (the Perceptron convergence theorem). We perform experiments to evaluate the performance of our Coq Perceptron vs. a C++ implementation and against a hybrid implementation in which separators learned in C++ are certiﬁed in Coq. We ﬁnd that by carefully optimizing the extraction of our Coq perceptron, we can meet – and occasionally exceed – the performance of the C++ implementation. Our work is both proof engineering and intellectual archaeology: Even classic machine learning algorithms (and to a lesser degree, termination proofs) are under-studied in the interactive theorem proving literature. At the same time, recasting Perceptron and its convergence proof in the language of 21st century human-assisted theorem provers may illuminate, for a fresh audience, a small but interesting corner of the history of ideas.\n",
            "----------------------------------------\n",
            "Title: A Spatio-Temporal Graph Convolutional Network for Gesture Recognition from High-Density Electromyography\n",
            "Abstract: Accurate hand gesture prediction is crucial for effective upper-limb prosthetic limbs control. As the high flexibility and multiple degrees of freedom exhibited by human hands, there has been a growing interest in integrating deep networks with high-density surface electromyography (HD-sEMG) grids to enhance gesture recognition capabilities. However, many existing methods fall short in fully exploit the specific spatial topology and temporal dependencies present in HD-sEMG data. Additionally, these studies are often limited number of gestures and lack generality. Hence, this study introduces a novel gesture recognition method, named STGCN-GR, which leverages spatio-temporal graph convolution networks for HD-sEMG-based human-machine interfaces. Firstly, we construct muscle networks based on functional connectivity between channels, creating a graph representation of HD-sEMG recordings. Subsequently, a temporal convolution module is applied to capture the temporal dependences in the HD-sEMG series and a spatial graph convolution module is employed to effectively learn the intrinsic spatial topology information among distinct HD-sEMG channels. We evaluate our proposed model on a public HD-sEMG dataset comprising a substantial number of gestures (i.e., 65). Our results demonstrate the remarkable capability of the STGCN-GR method, achieving an impressive accuracy of 91.07% in predicting gestures, which surpasses state-of-the-art deep learning methods applied to the same dataset.\n",
            "----------------------------------------\n",
            "Title: Towards Accurate Scene Text Detection with Bidirectional Feature Pyramid Network\n",
            "Abstract: Scene text detection, this task of detecting text from real images, is a hot research topic in the machine vision community. Most of the current research is based on an anchor box. These methods are complex in model design and time-consuming to train. In this paper, we propose a new Fully Convolutional One-Stage Object Detection (FCOS)-based text detection method that can robustly detect multioriented and multilingual text from natural scene images in a per pixel prediction approach. Our proposed text detector employs an anchor-free approach, unlike state-of-the-art text detectors that do not rely on a predefined anchor box. In order to enhance the feature representation ability of FCOS for text detection tasks, we apply the Bidirectional Feature Pyramid Network (BiFPN) as the backbone network, enhancing the model learning capacity and increasing the receptive field. We demonstrate the superior performance of our method on multioriented (ICDAR-2015, ICDAR-2017 MLT) and horizontal (ICDAR-2013) text detection benchmark tasks. Moreover, our method has an f-measure of 88.65 and 86.32 for the benchmark datasets ICDAR 2013 and ICDAR 2015, respectively, and 80.75 for the ICDAR-2017 MLT dataset.\n",
            "----------------------------------------\n",
            "Title: Cluster-analytic classification of facial expressions using infrared measurements of facial thermal features\n",
            "Abstract: In previous research, scientists were able to use transient facial thermal features extracted from \n",
            "Thermal Infra-Red Images (TIRIs) for making binary distinction between the affective states. \n",
            "For example, thermal asymmetries localised in facial TIRIs have been used to distinguish \n",
            "anxiety and deceit. Since affective human-computer interaction would require machines to \n",
            "distinguish between the subtle facial expressions of affective states, computers’ able to make \n",
            "such binary distinctions would not suffice a robust human-computer interaction. This work, for \n",
            "the first time, uses affective-state-specific transient facial thermal features extracted from TIRIs \n",
            "to recognise a much wider range of facial expressions under a much wider range of conditions. \n",
            "Using infrared thermal imaging within the 8-14 μm, a database of 324 discrete, time-sequential, \n",
            "visible-spectrum and thermal facial images was acquired, representing different facial \n",
            "expressions from 23 participants in different situations. A facial thermal feature extraction and \n",
            "pattern classification approach was developed, refined and tested on various Gaussian mixture \n",
            "models constructed using the image database. Attempts were made to classify: neutral and \n",
            "pretended happy and sad faces; multiple positive and negative facial expressions; six \n",
            "(pretended) basic facial expressions; partially covered or occluded faces; and faces with evoked \n",
            "happiness, sadness, disgust and anger. \n",
            "The cluster-analytic classification in this work began by segmentation and detection of \n",
            "thermal faces in the acquired TIRIs. The affective-state-specific temperature distributions on the \n",
            "facial skin surface were realised through the pixel grey-level analysis. Examining the affectivestate- \n",
            "specific temperature variations within the selected regions of interest in the TIRIs led to \n",
            "the discovery of some significant Facial Thermal Feature Points (FTFPs) along the major facial \n",
            "muscles. Following a multivariate analysis of the Thermal Intensity values (TIVs) measured at \n",
            "the FTFPs, the TIRIs were represented along the Principal Components (PCs) of a covariance \n",
            "matrix. The resulting PCs were ranked in the order of their effectiveness in the between-cluster \n",
            "separation. Only the most effective PCs were retained to construct an optimised eigenspace. A \n",
            "supervised learning algorithm was invoked for linear subdivision of the optimised eigenspace. \n",
            "The statistical significance levels of the classification results were estimated for validating the \n",
            "discriminant functions. \n",
            "The main contribution of this research has been to show that: the infrared imaging of facial \n",
            "thermal features within the 8-14 μm bandwidth may be used to observe affective-state-specific \n",
            "thermal variations on the face; the pixel-grey level analysis of TIRIs can help localise FTFPs \n",
            "along the major facial muscles of the face; cluster-analytic classification of transient thermal \n",
            "features may help distinguish between the facial expressions of affective states in an optimized \n",
            "eigenspace of input thermal feature vectors. The Gaussian mixture model with one cluster per \n",
            "affect worked better for some facial expressions than others. This made the influence of the \n",
            "Gaussian mixture model structure on the accuracy of the classification results obvious. \n",
            "However, the linear discrimination and confusion patterns observed in this work were consistent \n",
            "with the ones reported in several earlier studies. \n",
            "This investigation also unveiled some important dimensions of the future research on use of \n",
            "facial thermal features in affective human-computer interaction.\n",
            "----------------------------------------\n",
            "Title: Comparison of Classically and Machine Learning Generated Survival Prediction Models for Patients With Spinal Metastasis - A meta-Analysis of Two Recently Developed Algorithms.\n",
            "Abstract: STUDY DESIGN\n",
            "A systemic review and a meta-analysis. We also provided a retrospective cohort for validation in this study.\n",
            "\n",
            "\n",
            "OBJECTIVE\n",
            "(1) Using a meta-analysis to determine the pooled discriminatory ability of The Skeletal Oncology Research Group (SORG) classical algorithm (CA) and machine learning algorithms (MLA); and (2) test the hypothesis that SORG-CA has less variability in performance than SORG-MLA in non-American validation cohorts as SORG-CA does not incorporates regional-specific variables such as body mass index as input.\n",
            "\n",
            "\n",
            "METHODS\n",
            "After data extraction from the included studies, logit-transformation was applied for extracted AUCs for further analysis. The discriminatory abilities of both algorithms were directly compared by their logit (AUC)s. Further subgroup analysis by region (America vs non-America) was also conducted by comparing the corresponding logit (AUC).\n",
            "\n",
            "\n",
            "RESULTS\n",
            "The pooled logit (AUC)s of 90-day SORG-CA was .82 (95% confidence interval [CI], .53-.11), 1-year SORG-CA was 1.11 (95% CI, .74-1.48), 90-day SORG-MLA was 1.36 (95% CI, 1.09-1.63), and 1-year SORG-MLA was 1.57 (95% CI, 1.17-1.98). All the algorithms performed better in United States than in Taiwan (P < .001). The performance of SORG-CA was less influenced by a non-American cohort than SORG-MLA.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "These observations might highlight the importance of incorporating region-specific variables into existing models to make them generalizable to racially or geographically distinct regions.\n",
            "----------------------------------------\n",
            "Title: Systematic transesophageal echocardiographic examination in mitral valve repair: the evolution of a discipline into the twenty-first century.\n",
            "Abstract: M itral valve repair was first suggested in 1902 by Sir Thomas Brunton (1) as a surgical approach to patients with rheumatic mitral valve disease. However, it was not until after the introduction of the heart-lung machine in 1953 by Gibbons (2) that techniques for the repair of pure mitral valve regurgitation were first introduced by Lillehei et al. (3) in 1957. Because of the development of prosthetic valves, however, further investigation into these techniques was not continued until the limitations of mechanical and bioprosthetic valves became apparent and mitral valve repair became a more viable alternative. In the 1970s, the field was revolutionized when Carpentier et al. (4) presented data detailing the anatomic changes in patients with mitral insufficiency and introduced a physiologic classification of the causes of mitral insufficiency. This provided the foundation of our current understanding of the echocardiographic patterns and anatomic mechanisms of mitral valve regurgitation. Both Carpentier et al. (4), in France, and Duran et al. (5), in Spain, developed mitral valve repair techniques primarily for the management of patients with rheumatic mitral disease. These procedures were attractive to surgeons in the United States who foresaw potential benefits for an older patient population with mitral regurgitation as a result of myxomatous degeneration and ischemia (6,7). From the beginning of the 20th century to the turn of the 21st century, mitral valve repair procedures have developed from a surgical suggestion to a therapeutic intervention used in .2000 patients annually in the United States (8). Valve repair for the management of mitral regurgitation offers the advantages of less perioperative morbidity and mortality, preservation of the mitral tensor apparatus with better maintenance of ventricular function, freedom from anticoagulation, long-term durability, and freedom from reoperation (9). However, the surgical valve repair technique is more technically demanding for the surgeon. The development of improved myocardial protection during cardiopulmonary bypass and the technological advancements of intraoperative echocardiography have enhanced the development of innovative surgical techniques for reparative surgery. Both transesophageal and epicardial echocardiography provide an intraoperative safety net that helps to optimize surgical results with transference of real-time information to the surgical team regarding the underlying valve structure, physiologic abnormality, mechanism, and pathologic process. Intraoperative echocardiography has the added advantage of shortening the learning curve for those surgeons who are incorporating the valve repair techniques into their practice, which translates to benefits for patients. The article by Lambert et al. (10) serves as a reminder of the importance of a comprehensive and systematic transesophageal echocardiographic (TEE) evaluation of the mitral valve apparatus in patients undergoing reparative procedures for mitral regurgitation. Their evaluation included a multiplane segment by segment characterization of leaflet structure and mobility, anatomy of the commissure and subvalvular apparatus, annular and ventricular size, and severity and direction of the regurgitant jet. Successful valve repair requires an understanding of the etiology and mechanism of valve regurgitation. This knowledge is a major determinant of the probability of successful repair, which may vary from 98% in patients with a flail middle scallop of the posterior leaflet to 20% in patients with severe rheumatic valvular disease and restricted bileaflet motion. In their prospective study, Lambert et al. (10) report a small population of 13 patients who underwent surgery for significant mitral regurgitation. The mechanism of regurgitation and location of pathology was identified by using this systematic echocardiographic examination in 12 patients (92%) compared with a Accepted for publication February 26, 1999. Address correspondence and reprint requests to Robert M. Savage, MD, FACC, Department of Anesthesiology, The Cleveland Clinic Foundation, 9500 Euclid Ave., Cleveland, OH 44195.\n",
            "----------------------------------------\n",
            "Title: Analyzing the impact of socioeconomic indicators on gender inequality in Sri Lanka: A machine learning-based approach\n",
            "Abstract: This study conducts a comprehensive analysis of gender inequality in Sri Lanka, focusing on the relationship between key socioeconomic factors and the Gender Inequality Index (GII) from 1990 to 2022. By applying machine learning techniques, including Decision Trees and Ensemble methods, the study investigates the influence of economic indicators such as GDP per capita, government expenditure, government revenue, and unemployment rates on gender disparities. The analysis reveals that higher GDP and government revenues are associated with reduced gender inequality, while greater unemployment rates exacerbate disparities. Explainable AI techniques (SHAP) further highlight the critical role of government policies and economic development in shaping gender equality. These findings offer specific insights for policymakers to design targeted interventions aimed at reducing gender gaps in Sri Lanka, particularly by prioritizing economic growth and inclusive public spending.\n",
            "----------------------------------------\n",
            "Title: Multiple priority dispatching rules for the job shop scheduling problem\n",
            "Abstract: In this paper we focus on the Job Shop Scheduling Problem (JSSP) using Priority Dispatching Rules. Simulation model for makespan optimization is proposed using different Dispatching Rules (DR) for each machine in the shop floor. Collected results are used for learning base construction. This database will be used to develop an inference model able to select the best DR for every new scheduling problem. This preliminary study shows advantages of using different DR and also saving progress JSSP data.\n",
            "----------------------------------------\n",
            "Title: Machine-Learning-Assisted Hybrid Earth System Modelling\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Unified Deep Learning Diagnostic Architecture for Big Data Healthcare Analytics\n",
            "Abstract: Healthcare automation is evolving rapidly as can been seen in the recent popularity of e-health or digital health systems. The massive amount of health related data produced by these systems has given rise to the field of health informatics. The World Health organization (WHO) decomposes SMARThealth as Standards-based, Machine-readable, Adaptive, Requirementsbased, and Testable, and provides guidelines for digital health. Heterogeneous and big health data health that flows into the cloud requires considerations for uniformity of structure to allow for interoperability and generalizability for universal use and analysis. This research proposes a deep-learning architecture for disease diagnosis that considers Diabetes Mellitus (DM) as a case study. Three corpuses containing DM patient data are considered which are prepared and processed using extensive data warehousing techniques and labeled with ICD-10-CM diagnostic codes. Extraction of desired health data is through a unified data model for healthcare that is in compliance with HL7 FHIR v4.0 schema. Our contributions are two-fold: First, three big data cloud analytical models are proposed and validated on the unified corpora and second the maximum possible diseases specific to a single or multiple DM patients have been diagnosed with a 100% accuracy using deep multinomial/multi-label distribution learning (DMDL).\n",
            "----------------------------------------\n",
            "Title: Spectrum Sensing based on an improved deep learning classification for cognitive radio\n",
            "Abstract: Cognitive Radio (CR) technology enables the efficient exploit of radio spectrum by utilizing existing unused frequencies. Spectrum Sensing is the most important process in CR by allowing users to detect unused communication channels. The paper proposes an enhancement of a Deep Learning (DL) classification approach for Spectrum Sensing. This approach introduces the Linear Support Vector Machine (SVM) as a classification layer in the DetectNet based DL technique. Simulation results of the proposed approach provide better performance in term of detection at low signal-to-noise ratio (SNR) compared to the DetectNet technique.\n",
            "----------------------------------------\n",
            "Title: Cloud-Based Reconfigurable Hardware Accelerator for the KNN Classification Algorithm\n",
            "Abstract: The K-Nearest Neighbor algorithm is a supervised machine learning algorithm that is used for classification problems. The execution time of this algorithm could be extremely high, especially for huge and high-dimensional datasets. The objective of this work is to design and implement efficient parallel hardware architectures to accelerate the KNN classifier. The proposed architectures are implemented using FPGA on Intel DevCloud. Experimental results show that the proposed hardware implementation of the algorithm is 10.7 times faster than the software implementation with 96.6% classification accuracy for a benchmark classification dataset.\n",
            "----------------------------------------\n",
            "Title: Interpretability of deep neural networks\n",
            "Abstract: —This paper gives an entry point to the problem of interpreting machine learning models. It includes an introduction to machine learning models and their complexity, followed by general aspects of interpretability. The focus, however, is put on deep neural networks and modern techniques to increase their interpretability.\n",
            "----------------------------------------\n",
            "Title: Analisis Performa Algoritma Stochastic Gradient Descent (SGD) Dalam Mengklasifikasi Tahu Berformalin\n",
            "Abstract: Tahu berformalin adalah salah satu jenis makanan yang sering mengandung bahan-bahan kimia yang dapat mengawetkan daripada tahu tanpa formalin. Pada tahu berformalin dapat memberikan tekstur lebih kenyal dan berwarna putih bersih. Penelitian ini bertujuan untuk mengklasifikasikan tahu berformalin dan tahu tidak berformalin. Pada paper ini menggunakan algoritma Stochastic Gradient Descent atau dalam penerapannya lebih dikenal dengan SGD Classifier yang merupakan bagian dari algoritma machine learning untuk klasifikasi, regresi maupun jaringan syaraf tiruan serta algoritma ini sangat efisien pada dataset berskala besar. Penelitian ini mencoba menerapkan algoritma SGD pada dataset tahu berformalin dengan jumlah dataset yakni 11000 yang dimana 5500 data tahu berformalin dan 5500 data tahu tidak berformalin. Setelah dilakukan beberapa tahapan dalam pengujian dengan algoritma SGD maka diperolah hasil akurasi, presisi, recall, f1-score pada model yang masing-masing 82.6% untuk akurasi, 81.7% untuk presisi, 84.1% untuk recall, 83.5% untuk f1-score dan dilakukan pengujian menggunakan 10 data yang tidak termasuk dalam data latih memperoleh performansi rata-rata akurasi sebesar 70%, presisi 71%, recall 70% dan f1-score 70%.\n",
            "----------------------------------------\n",
            "Title: Developmental Prediction of Poststroke Patients in Activities of Daily Living by Using Tree-Structured Parzen Estimator–Optimized Stacking Ensemble Approaches\n",
            "Abstract: Poststroke injuries limit the daily activities of patients and cause considerable inconvenience. Therefore, predicting the activities of daily living (ADL) results of patients with stroke before hospital discharge can assist clinical workers in formulating more personalized and effective strategies for therapeutic intervention, and prepare hospital discharge plans that suit the patients needs. This study used the leave-one-out cross-validation procedure to evaluate the performance of the machine learning models. In addition, testing methods were used to identify the optimal weak learners, which were then combined to form a stacking model. Subsequently, a hyperparameter optimization algorithm was used to optimize the model hyperparameters. Finally, optimization algorithms were used to analyze each feature, and features of high importance were identified by limiting the number of features to be included in the machine learning models. After various features were fed into the learning models to predict the Barthel index (BI) at discharge, the results indicated that random forest (RF), adaptive boosting (AdaBoost), and multilayer perceptron (MLP) produced suitable results. The most critical prediction factor of this study was the BI at admission. Machine learning models can be used to assist clinical workers in predicting the ADL of patients with stroke at hospital discharge.\n",
            "----------------------------------------\n",
            "Title: Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China\n",
            "Abstract: The digital media, identified as computational propaganda provides a pathway for propaganda to expand its reach without limit. State-backed propaganda aims to shape the audiences' cognition toward entities in favor of a certain political party or authority. Furthermore, it has become part of modern information warfare used in order to gain an advantage over opponents. Most of the current studies focus on using machine learning, quantitative, and qualitative methods to distinguish if a certain piece of information on social media is propaganda. Mainly conducted on English content, but very little research addresses Chinese Mandarin content. From propaganda detection, we want to go one step further to provide more fine-grained information on propaganda techniques that are applied. In this research, we aim to bridge the information gap by providing a multi-labeled propaganda techniques dataset in Mandarin based on a state-backed information operation dataset provided by Twitter. In addition to presenting the dataset, we apply a multi-label text classification using fine-tuned BERT. Potentially this could help future research in detecting state-backed propaganda online especially in a cross-lingual context and cross platforms identity consolidation.\n",
            "----------------------------------------\n",
            "Title: A Comprehensive Study of Supervised Machine Learning Assisted Approaches for IoT Device Identification\n",
            "Abstract: Device identification is a fundamental issue in the Internet of Things. A few studies in modern literature indicate that machine learning approaches could be used for device identification. However, the hypothesis that device behavior could be characterized by machine learning techniques for device identification has not been thoroughly investigated. Therefore, we conduct a comprehensive study to examine this hypothesis. We create both a trusted and untrusted environment for experimental testing scenarios. That contains four testing cases, including intra-network, network perimeter, cryptojacking, and DOS. Six supervised machine learning classifiers are selected and evaluated. Among the six classifiers, the AdaBoost classifier with 200 features achieves testing accuracies of 88.23% and is chosen for the testing cases. Our evaluation results show that the AdaBoost classifier is promising for a trusted environment. However, the accuracies of the AdaBoost classifier drop dramatically to less than 20% in both cryptojacking and DOS cases. While the results do not support the hypothesis, the challenges faced by machine learning-assisted approaches in device identification could be complemented by other safeguards such as whitelists and intrusion detection and prevention systems. This paper further discusses future work, including using features from physical layers to examine the hypothesis.\n",
            "----------------------------------------\n",
            "Title: Development and validation of radiology-clinical statistical and machine learning model for stroke-associated pneumonia after first intracerebral haemorrhage\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: MACHINE LEARNING O F FAUiL9' CHARACTERISTICS FROM ROCKET ENGINE SIMULATION DATA\n",
            "Abstract: Transformation of data into knowledge through conceptual induction has been the focus of our research described in this paper. We have developed a Machine Learning System (MLS) to analyze the rocket engine simulation data. MLS can provide to its users fault analysis, characteristics, and conceptual descriptions of faults, and the relationships of attributes and sensors. All the results are critically important in identifying faults.\n",
            "----------------------------------------\n",
            "Title: Feature Selection and Blind Source Separation in an EEG-Based Brain-Computer Interface\n",
            "Abstract: Most EEG-based BCI systems make use of well-studied patterns of brain activity. However, those systems involve tasks that indirectly map to simple binary commands such as \"yes\" or \"no\" or require many weeks of biofeedback training. We hypothesized that signal processing and machine learning methods can be used to discriminate EEG in a direct \"yes\"/\"no\" BCI from a single session. Blind source separation (BSS) and spectral transformations of the EEG produced a 180-dimensional feature space. We used a modified genetic algorithm (GA) wrapped around a support vector machine (SVM) classifier to search the space of feature subsets. The GA-based search found feature subsets that outperform full feature sets and random feature subsets. Also, BSS transformations of the EEG outperformed the original time series, particularly in conjunction with a subset search of both spaces. The results suggest that BSS and feature selection can be used to improve the performance of even a \"direct,\" single-session BCI.\n",
            "----------------------------------------\n",
            "Title: Detection of Diseases in Plants using Convolutional Neural Networks\n",
            "Abstract: Most of the global population depends on agriculture and consider agricultural activities as their primary source of occupation to earn their income. If any problem occurs in this primary sector, then it is going to affect the livelihood and lives of the population seriously. Henceforth, it is important to keep up balance in the agricultural area by preventing it from something similar like the adverse effect of plant diseases. The area of artificial intelligence has taken an interesting turn in present times, with the growth of the Neural Networks based Intelligence and Machine Learning. These organically roused computational models can far outshines the presentation of past types of human-made consciousness in like manner artificial intelligence errands. One of the most amazing forms of Artificial Neural Network engineering is CNN. CNN is basically utilized to tackle troublesome picture-driven pattern recognition tasks and with their exact yet straightforward construction, provide a untangle method for starting with ANNs.A new strategy for identification of diseases in plants using CNN is proposed in this paper. The dataset utilized contains around 70,000 images including training and testing dataset. This paper gives a short prologue to CNNs, discussing lately expressed documents and newly framed strategies in evolving these brilliantly tremendous picture recognition models.\n",
            "----------------------------------------\n",
            "Title: Advanced control of membrane fouling in filtration systems using artificial intelligence and machine learning techniques: A critical review\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: An Integrated Nanocomposite Proximity Sensor: Machine Learning-Based Optimization, Simulation, and Experiment\n",
            "Abstract: This paper utilizes multi-objective optimization for efficient fabrication of a novel Carbon Nanotube (CNT) based nanocomposite proximity sensor. A previously developed model is utilized to generate a large data set required for optimization which included dimensions of the film sensor, applied excitation frequency, medium permittivity, and resistivity of sensor dielectric, to maximize sensor sensitivity and minimize the cost of the material used. To decrease the runtime of the original model, an artificial neural network (ANN) is implemented by generating a one-thousand samples data set to create and train a black-box model. This model is used as the fitness function of a genetic algorithm (GA) model for dual-objective optimization. We also represented the 2D Pareto Frontier of optimum solutions and scatters of distribution. A parametric study is also performed to discern the effects of the various device parameters. The results provide a wide range of geometrical data leading to the maximum sensitivity at the minimum cost of conductive nanoparticles. The innovative contribution of this research is the combination of GA and ANN, which results in a fast and accurate optimization scheme.\n",
            "----------------------------------------\n",
            "Title: Application of Nonhierarchical Cluster Analysis in the Machine Learning\n",
            "Abstract: The paper presents a method for nonhierarchical clustering. The method is called method of the minimal spanning tree. Two algorithms for constructing a minimal spanning tree are described. Based on the proposed algorithm, a program for nonhierarchical clustering has been developed, which possesses a huge variety of possibilities for visualizing the obtained results.\n",
            "----------------------------------------\n",
            "Title: METHODS OF FORECASTING GRAIN CROP YIELD INDICATORS TAKING INTO ACCOUNT THE INFLUENCE OF METEOROLOGICAL CONDITIONS IN THE INFORMATION-ANALYTICAL SUBSYSTEM\n",
            "Abstract: Forecasting crop yields is one of the key challenges for the agricultural sector, especially in the context of a changing climate and unstable weather conditions. Kazakhstan, possessing significant territories suitable for growing grain crops, faces many challenges related to the effective management of agricultural activities. In this regard, yield forecasting becomes an integral part of planning and decision-making processes in agriculture. Information and analytical subsystems that integrate yield forecasting methods allow agribusinesses to estimate future production more accurately, minimise risks associated with climate change and optimise resource use. An important component of such systems is the consideration of weather conditions, as weather factors have a direct impact on crop growth and development. The purpose of this article is to develop and evaluate modern methods of forecasting grain yields taking into account the influence of weather conditions, as well as their integration into information-analytical subsystems to improve the accuracy of agricultural forecasting. To achieve this goal, the article addresses the following tasks: to analyse existing methods of yield forecasting and identify their advantages and disadvantages, to develop forecasting models, including machine learning methods such as gradient bousting and recurrent neural networks, to validate the developed models on the basis of historical data using cross-validation methods, to evaluate the effectiveness of the proposed methods and compare them with basic models such as linear regression and simple average, to evaluate the effectiveness of the proposed methods and to compare them with the basic models such as linear regression and simple average. This article reviews modern methods of forecasting grain crop yields in Kazakhstan, as well as technologies used in information-analytical subsystems. Particular attention is paid to the analysis of the influence of meteorological conditions on yields and the development of models that take this factor into account. The presented review and research results are aimed at improving the existing approaches to the management of agricultural processes under conditions of growing uncertainty caused by climate change. The article explores an important scientific task related to the development of methods for step-by-step forecasting of agrometeorological factors and grain yields, relying on the principle of analogy.\n",
            "----------------------------------------\n",
            "Title: Crop Yield Prediction Using Machine-Learning\n",
            "Abstract: This study examines the utilization of machine learning techniques for forecasting agricultural yields. This is critical because it helps to improve farm productivity and food security. Agriculture is the backbone of Pakistan’s economy, and accurate crop yield prediction can greatly assist in economic planning and allocation of resources. “Several ML algorithms, including K-Nearest Neighbor, Lasso regression, Ridge Regression, Decision Tree, and Linear Regression,” were used in this research to forecast crop yield using historical data and climate variables. Among all the models developed, the KNN algorithm was the most effective, with MAE=108023825.91 and R2=0.98494, meaning that it had the highest accuracy. These results suggest that ML has a large potential to give good predictions about crop yields, which would be useful for decision-making in agriculture and crop management or strategy development. The paper also enlightens on the limitations of some algorithms, like Decision Trees, known for their low-performance abilities; it suggests other ensemble models as better alternatives to increase predictive power. Machine learning integration with big data platforms and advanced computational methods offers a promising approach toward smart agriculture, ensuring food security.\n",
            "----------------------------------------\n",
            "Title: Semi-Supervised Learning Based Acoustic NLOS Identification for Smartphone Indoor Positioning\n",
            "Abstract: As the NLOS (non-line-of-sight) phenomenon poses a great challenge for practical application of sound-based smart-phone indoor positioning, the research of NLOS identification is becoming more and more important. Although the accuracy of NLOS identification based on full-supervised learning is satisfactory, the difficulty of obtaining a large amount of the labeled acoustic signal makes it very hard to be used in the real scenarios. In this paper, we study the acoustic NLOS identification using SSL (Semi-Supervised Learning) method, in order to pave the way for the application of acoustic indoor positioning and navigation for smartphone. Based on the features extracted from the characteristics of the acoustic channel, SSL method has been introduced to realize acoustic NLOS identification. By using the accuracy metric as an evaluation criterion, the performance of three SSL classifiers are evaluated and compared. At the same time, the comparison results show that the accuracy of the SSL classifier based on S4VM (Safe semi-supervised support vector machines) is higher than Co-Training and LPA (Label propagation algorithm). And the optimal classifier is S4VM with RBF kernel function. In addition, by investigating the relationship between the identification accuracy and the kernel function parameter value, we can obtain that when γ= 0.3, the identification accuracy is the highest, and the accuracy is 84.80 %.\n",
            "----------------------------------------\n",
            "Title: Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning\n",
            "Abstract: Smart speaker voice assistants (VAs) such as Amazon Echo and Google Home have been widely adopted due to their seamless integration with smart home devices and the Internet of Things (IoT) technologies. These VA services raise privacy concerns, especially due to their access to our speech. This work considers one such use case: the unaccountable and unauthorized surveillance of a user's emotion via speech emotion recognition (SER). This paper presents DARE-GP, a solution that creates additive noise to mask users' emotional information while preserving the transcription-relevant portions of their speech. DARE-GP does this by using a constrained genetic programming approach to learn the spectral frequency traits that depict target users' emotional content, and then generating a universal adversarial audio perturbation that provides this privacy protection. Unlike existing works, DARE-GP provides: a) real-time protection of previously unheard utterances, b) against previously unseen black-box SER classifiers, c) while protecting speech transcription, and d) does so in a realistic, acoustic environment. Further, this evasion is robust against defenses employed by a knowledgeable adversary. The evaluations in this work culminate with acoustic evaluations against two off-the-shelf commercial smart speakers using a small-form-factor (raspberry pi) integrated with a wake-word system to evaluate the efficacy of its real-world, real-time deployment.\n",
            "----------------------------------------\n",
            "Title: Using a document classification task to introduce machine learning\n",
            "Abstract: We present an automated document classification task from the field of machine learning and argue that from both a conceptual and technical standpoint, this task can be addressed using algorithms accessible to first year students. Additionally, we provide some guidance to instructors in how to select a dataset to reinforce a particular learning objective within this simple machine learning project.\n",
            "----------------------------------------\n",
            "Title: Predicting a Stock Portfolio with the Multivariate Bayesian Structural Time Series Model: Do News or Emotions Matter?\n",
            "Abstract: In this paper, we provide methods for creatively incorporating information from financial news and Twitter feeds into predicting the prices of a portfolio of stocks, using the framework of the Multivariate Bayesian Structural Time Series (MBSTS) model. MBSTS is a Bayesian machine learning model designed to capture correlations among multiple target time series, while using a number of contemporaneous predictors. As an illustration of the current model, we use data on two leading online commerce companies, namely Amazon and eBay, and run extensive empirical experiments to examine which if any, text mining predictors would add to the predictability of a stock price. Evaluation of competing models such as the autoregressive integrated moving average (ARIMA) model, and the recurrent\n",
            "neural network (RNN) model with long short term memory (LSTM), in terms of their performances with respect to cumulative one-step-ahead forecast errors with and without sentimental predictors, were carried out. Our contributions are threefold: Firstly, our model is the first one that successfully incorporated the online text mining to an advanced multivariate Bayesian machine learning time series model, which opens the door of applying both text mining and machine learning simultaneously in modern quantitative finance research; Secondly, under the presence of both modern and classical predictors in both fundamental and technical sense, the polarity of news still adds on a complementary effect; Thirdly, we discover that all models under investigation with sentimental predictors do outperform models without these sentimental predictors, and the MBSTS model with sentimental predictors outperforms all the other models.\n",
            "----------------------------------------\n",
            "Title: The combine will tell the truth: On precision agriculture and algorithmic rationality\n",
            "Abstract: Recent technological and methodological changes in farming have led to an emerging set of claims about the role of digital technology in food production. Known as precision agriculture, the integration of digital management and surveillance technologies in farming is normatively presented as a revolutionary transformation. Proponents contend that machine learning, Big Data, and automation will create more accurate, efficient, transparent, and environmentally friendly food production, staving off both food insecurity and ecological ruin. This article contributes a critique of these rhetorical and discursive claims to a growing body of critical literature on precision agriculture. It argues precision agriculture is less a revolution than an evolution, an effort to shore up and intensify the conventional farming system responsible for generating many of the social and environmental problems precision agriculture is presented as solving. While precision agriculture advocates portray it as a radical, even democratic epistemological break with the past, this paper locates truth claims surrounding datafication and algorithmic control in farming within deeper historical contexts of the capitalist rationalization of production and efforts to quantify and automate physical and mental labor. Abjuring the growing cultural tendency to treat algorithmic systems as revolutionary in favor of social and historical dimensions of precision agriculture, can help re-frame the discussion about its design and use around real, socially and ecologically oriented change in farming, and so ensure that the possibilities and benefits of precision agriculture are as evenly and effectively shared as possible.\n",
            "----------------------------------------\n",
            "Title: Literature Survey Paper on Epilepsy and Autism Spectrum Disorder Detection and Analysis Using Machine Learning\n",
            "Abstract: The detection and cure of epilepsy and autism spectrum disorder (ASD) are significantly complicated by their co-occurrence. This survey research investigates an integrated method for identifying ASD using behavioural characteristic questionnaires and epilepsy using EEG corpus inside a single system. We provide an overview of all the relevant research, emphasizing the difficulties in diagnosing each of these disorders separately and in combination. Our suggested approach combines behavioural questionnaire assessments for ASD with EEG-based analysis for epilepsy detection in an effort to improve diagnostic accuracy and expedite the evaluation process. This study examines the approaches, difficulties, and developments in both domains, providing perspectives on possible overlaps and prospects for further investigation. So, an attempt has been made to review on the pattern detection methods for epilepsy seizure detection from EEG signals. More than 150 research papers have been discussed to determine the techniques for detecting epileptic seizures. Further, the literature review confirms that the pattern recognition techniques required to detect epileptic seizures varies across the electroencephalogram (EEG) datasets of different conditions. This is mostly owing to the fact that EEG detected under different conditions have different characteristics.\n",
            "----------------------------------------\n",
            "Title: Protein disorder prediction by condensed PSSM considering propensity for order or disorder\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Conditional Synthetic Data Generation for Personal Thermal Comfort Models\n",
            "Abstract: Personal thermal comfort models aim to predict an individual's thermal comfort response, instead of the average response of a large group. Recently, machine learning algorithms have proven to be having enormous potential as a candidate for personal thermal comfort models. But, often within the normal settings of a building, personal thermal comfort data obtained via experiments are heavily class-imbalanced. There are a disproportionately high number of data samples for the\"Prefer No Change\"class, as compared with the\"Prefer Warmer\"and\"Prefer Cooler\"classes. Machine learning algorithms trained on such class-imbalanced data perform sub-optimally when deployed in the real world. To develop robust machine learning-based applications using the above class-imbalanced data, as well as for privacy-preserving data sharing, we propose to implement a state-of-the-art conditional synthetic data generator to generate synthetic data corresponding to the low-frequency classes. Via experiments, we show that the synthetic data generated has a distribution that mimics the real data distribution. The proposed method can be extended for use by other smart building datasets/use-cases.\n",
            "----------------------------------------\n",
            "Title: A flexible evolutionary model of machine learning of the most successful strategies of human capital development\n",
            "Abstract: As a result of research, the concept of a flexible evolutionary model is proposed, which with the help of machine learning allows obtaining the most successful strategy for the development of human capital. The proposed conceptual and methodological approach to machine learning of the process of assessing human capital of enterprises, taking into account the cognitive psychology of man and reflective attitudes in the human environment, can increase the effectiveness of decision-making in the field of human capital development management. The training involves indicators of return on investment in the individual, in the types of components of human capital, which are characterized by properties (creativity, competence, purposefulness, communication, motivation), where between their varieties there are appropriate reflective relationships. The main difficulty of this approach to the choice of alternative solutions for finding options for the use of human capital is the correct selection of indicators of significance (return) of contributions to the development of types of human capital, on the basis of which cycles occur of systemic learning. This approach can simplify the search for and developments of human capital development strategies, present alternative ways, and simplify management decisions.\n",
            "----------------------------------------\n",
            "Title: Doc Query: Intelligent Document Analysis and Question Answering Software\n",
            "Abstract: Intelligent Document Analysis and Question Answering (IDAQA) software automates literature searches and provides accurate answers to user questions. The IDAQA system uses natural language processing and machine learning, extracts key information from documents, and improves accessibility. The IDAQA system smartly extracts the necessary information required for the user from diverse documents enhancing accessibility and comprehension.This system has wide use-case especially in the academic field, as well as beneficial to extract certain part of information present in the pdf which necessary for the user. This paper analyses the importance, technique, and aftereffects of IDAQA, tending to difficulties and future possibilities for transforming narrative discussions. This paper discusses about the significance of the system, proposed model and also the result analysis.\n",
            "----------------------------------------\n",
            "Title: Social Media Monitoring of the COVID-19 Pandemic and Influenza Epidemic With Adaptation for Informal Language in Arabic Twitter Data: Qualitative Study\n",
            "Abstract: Background: Twitter is a real-time messaging platform widely used by people and organizations to share information on many topics. Systematic monitoring of social media posts (infodemiology or infoveillance) could be useful to detect misinformation outbreaks as well as to reduce reporting lag time and to provide an independent complementary source of data compared with traditional surveillance approaches. However, such an analysis is currently not possible in the Arabic-speaking world owing to a lack of basic building blocks for research and dialectal variation. Objective: We collected around 4000 Arabic tweets related to COVID-19 and influenza. We cleaned and labeled the tweets relative to the Arabic Infectious Diseases Ontology, which includes nonstandard terminology, as well as 11 core concepts and 21 relations. The aim of this study was to analyze Arabic tweets to estimate their usefulness for health surveillance, understand the impact of the informal terms in the analysis, show the effect of deep learning methods in the classification process, and identify the locations where the infection is spreading. Methods: We applied the following multilabel classification techniques: binary relevance, classifier chains, label power set, adapted algorithm (multilabel adapted k-nearest neighbors [MLKNN]), support vector machine with naive Bayes features (NBSVM), bidirectional encoder representations from transformers (BERT)\n",
            "----------------------------------------\n",
            "Title: Identification of Instantaneous Anomalies in General Aviation Operations Using Energy Metrics\n",
            "Abstract: The quantification and improvement of safety is one of the most important objectives among the general aviation community. In recent years, machine learning techniques have emerged as an important ...\n",
            "----------------------------------------\n",
            "Title: An Adversarial Attack Analysis on Malicious Advertisement URL Detection Framework\n",
            "Abstract: Malicious advertisement URLs pose a security risk since they are the source of cyber-attacks, and the need to address this issue is growing in both industry and academia. Several attempts have been made in recent years for malicious URL detection using machine learning (ML). The most widely used techniques extract linguistic features of URL string to extract features like bag-of-words (BoW) before applying ML model. Existing malicious URL detection techniques require effective manual feature engineering that can handle unseen features and generalise to test data. In this study, we extract a novel set of lexical and Web-scrapped features and employ ML techniques for fraudulent advertisement URL detection. The combination set of six different kinds of features precisely overcomes the obfuscation in fraudulent URL classification. Based on distinct statistical properties, we use twelve differently formatted datasets for detection, prediction and classification task. We extend our prediction analysis for mismatched and unlabelled datasets. For this framework, we analyze the performance of four ML techniques: Random Forest, Gradient Boost, XGBoost and AdaBoost in the detection part. With our proposed method, we achieve a false negative rate up to 0.0037 while maintaining high detection accuracy of 99.63%. Moreover, we employ an unsupervised learning technique for data clustering using the ${K}$ -Means algorithm for the visual analysis. This paper analyses the vulnerability of decision tree-based models using the limited knowledge attack scenario. We considered the exploratory attack during the test phase and implemented Zeroth Order Optimization adversarial attack on the detection models.\n",
            "----------------------------------------\n",
            "Title: Early Diagnosis of Alzheimer’s Disease Based on Multimodal Hypergraph Attention Network\n",
            "Abstract: Alzheimer’s disease (AD) is a typical neurodegenerative disease involving multiple pathogenic factors. Early detection is the key to effective treatment of AD. However, most methods are developed based on data from a single modality, and ignore the relationships among subjects. In machine learning problems, hypergraph can be used to express the relationships between objects. In light of this, a framework for early diagnosis of Alzheimer’s disease based on multimodal hypergraph attention network is proposed in this paper. Specifically, we combine multimodal features to construct cross modal hypergraph, which represents the high-order structural relationships among subjects. Finally, a hypergraph attention network is used to fuse hypergraphs and perform the final classification. Our experimental results on the Alzheimer Disease Neuroimaging Initiative (ADNI) database show that our proposed method has better classification performance than the most advanced methods.\n",
            "----------------------------------------\n",
            "Title: Comparison of Residual Network-50 and Convolutional Neural Network Conventional Architecture For Fruit Image Classification\n",
            "Abstract: Classification of fruit images using machine learning technology has had a significant impact on human life by enabling accurate recognition of various fruits. With the advancements in technology, machine learning architectures have become increasingly diverse and sophisticated, providing enhanced capabilities for fruit image classification. However, previous studies have primarily focused on classifying fruits at a basic level. Therefore, there is a growing need for the development and application of Fruit Image Classification systems within the community, particularly in the field of agriculture. Such applications can play a pivotal role in leveraging technology to benefit the agricultural sector, empowering users to gain satisfaction and knowledge regarding different fruits through the utilization of these applications. In this study, we employ both a conventional Convolutional Neural Network (CNN) architecture and a Residual Network-50 for fruit image classification. To ensure robust performance evaluation, the dataset is divided into training and testing subsets, with fruits categorized into specific classes. Furthermore, identical preprocessing and optimization techniques are applied to both architectures to maintain consistency and fairness during the evaluation process. The results of our classification experiments on a dataset consisting of 17 different fruit classes reveal that the conventional CNN architecture achieves an impressive accuracy of 0.998 (99%) with a minimal loss of 0.009. On the other hand, the Residual Network-50 demonstrates a slightly lower accuracy of 0.994 (99%) but with a slightly higher loss of 0.02. Despite the higher loss, the Residual Network-50's accuracy remains comparable to that of the conventional architecture, showcasing its potential for fruit image classification. By leveraging the power of machine learning and these advanced architectures, fruit image classification systems can provide valuable insights and assistance to users. They can facilitate informed decision-making in various domains, including agriculture, food production, and consumer education.\n",
            "----------------------------------------\n",
            "Title: Applications of Reinforcement Learning and its Extension to Tactical Simulation Technologies\n",
            "Abstract: - Reinforcement Learning (RL) is a branch of machine learning that is used in many areas, from robotics to natural language processing, from game technologies to medical fields and finance. It is widely used in systems containing large data, where instantaneous data flow is intense and where data tagging is arduous or impossible. RL is a preferred approach for exploring new strategies or combinations due to its convenient nature to real life control problems where sequential decision-making is crucial. In the early stages of its development, RL was mainly prevalent in game technologies. However, recently applications of RL have diversified and extended to a plethora of new fields. As HAVELSAN, the leading Turkish defence industry software and simulation company, we investing this technique to take the eye-catching advantages. In this study, we elaborate on the fundamentals of reinforcement learning technology with an emphasis of its novel applications and future projections in the light of existing research findings. We then cover the RL specifically from simulation technologies perspective and introduce the FIVE-ML project of HAVELSAN which aims a transition from rule-based behaviour modelling to learning-based smart behaviour modelling in order to provide more effective and more dynamic pilot training environment.\n",
            "----------------------------------------\n",
            "Title: Random Rotation Ensembles\n",
            "Abstract: In machine learning, ensemble methods combine the predictions of multiple base learners to construct more accurate aggregate predictions. Established supervised learning algorithms inject randomness into the construction of the individual base learners in an effort to promote diversity within the resulting ensembles. An undesirable side effect of this approach is that it generally also reduces the accuracy of the base learners. In this paper, we introduce a method that is simple to implement yet general and effective in improving ensemble diversity with only modest impact on the accuracy of the individual base learners. By randomly rotating the feature space prior to inducing the base learners, we achieve favorable aggregate predictions on standard data sets compared to state of the art ensemble methods, most notably for tree-based ensembles, which are particularly sensitive to rotation.\n",
            "----------------------------------------\n",
            "Title: Interactive comment on “Data efficient Random Forest model for avalanche forecasting” by\n",
            "Abstract: Fast downslope release of snow (avalanche) is a serious hazard to people living in snow bound mountains. Released snow mass can gain sufficient momentum on its down slope path to kill humans, uproot trees and rocks, destroy buildings. Direct reduction of avalanche threat is done by building control structures to add mechanical support to snowpack and reduce or deflect downward avalanche flow. On large terrains it is economically infeasible to use these methods on each hazard site. Therefore forecasting and avoiding avalanches is the only feasible method to reduce hazard, but sufficient snow stability data for accurate forecasting is generally unavailable and difficult to collect. Forecasters infer snow stability from their knowledge of local weather, terrain and sparsely available snowpack observations. This inference process is vulnerable to human bias therefore machine learning models are used to find patterns from past data and generate helpful outputs to minimise and quantify uncertainty in forecasting process. These machine learning techniques require long past records of avalanches which are difficult to obtain. In this paper we propose a data efficient Random Forest model to address this problem. The model can generate a descriptive forecast showing reasoning and patterns which are difficult to observe manually. Our model advances the field by being inexpensive and convenient for operational forecasting due to its data efficiency, amenable to automation and ability to describe its decisions.\n",
            "----------------------------------------\n",
            "Title: Approaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Study of machine learning methods for optimization and reliability improvements of high power linacs. (Etude de la modélisation des accélérateurs de particules par des méthodes de «machine learning» pour optimiser et fiabiliser l'opération d'un linac de forte puissance)\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Learning the Effective Dynamics of Complex Multiscale Systems\n",
            "Abstract: Simulations of complex multiscale systems are essential for science and technology ranging from weather forecasting to aircraft design. The predictive capabilities of simulations hinges on their capacity to capture the governing system dynamics. Large scale simulations, resolving all spatiotemporal scales, provide invaluable insight at a high computational cost. In turn, simulations using reduced order models are affordable but their veracity hinges often on linearisation and/or heuristics. Here we present a novel systematic framework to extract and forecast accurately the effective dynamics (LED) of complex systems with multiple spatio-temporal scales. The framework fuses advanced machine learning algorithms with equation-free approaches. It deploys autoencoders to obtain a mapping between fine and coarse grained representations of the system and learns to forecast the latent space dynamics using recurrent neural networks. We compare the LED framework with existing approaches on a number of benchmark problems and demonstrate reduction in computational efforts by several orders of magnitude without sacrificing the accuracy of the system.\n",
            "----------------------------------------\n",
            "Title: Cross Project Defect Prediction using Dropout Regularized Deep Learning and Unique Matched Metrics\n",
            "Abstract: The primary goal of software defect prediction (SDP) is to predict the software defects for a specific software using historical data or data from past releases of software projects. The existing state of arts on SDP primarily discusses two prediction scenarios: Within Project Defect Prediction (WPDP) and Cross Project Defect Prediction (CPDP). The prediction model belongs to the WPDP scenario, which means that the model is trained and tested on different parts of the same dataset or trained on the dataset belonging to the previous version of the same project. While in the CPDP scenario, training and testing occur on different software project datasets. Due to the unavailability of historical datasets or prior releases of software defect datasets, CPDP is more useful in real-life scenarios. So, CPDP analysis is a very challenging issue in the SDP domain. Sometimes, machine learning (ML) models perform poorly due to inadequate training in the CPDP scenario. To support better CPDP performance, we must carefully build an ML model focusing on lower training error and overfitting issues. To address these issues, we have proposed a cross-project data preprocessing method to correlate the metrics of different project datasets, namely Unique Selection of Matched Metrics (USMM), using the KS test and Hungarian method. To further improve the CPDP performance, we have also used the dropout regularized deep learning (DRDL) model. We have deployed 34 software defect datasets to validate the DRDL model and USMM method. The experimental results demonstrate that the DRDL model using the USMM method (DRDL-USMM) is a promising model to enhance the prediction accuracy, and an improvement in the range of 3.3% to 8.5% as compared to the existing works in the CPDP scenario has been found.\n",
            "----------------------------------------\n",
            "Title: Reddit sentiment analysis for natural language processing\n",
            "Abstract: In the Internet age, social media has fully penetrated into people's lives. As one of the well-developed online platforms with a large user base, Reddit allows users to independently publish current news, life experiences, and interesting life stories. However, sometimes it sends a negative tone that affects the brand of a company or individual and destroys profits and it is necessary to prevent Twitter by identifying hate words. The biggest innovation of this post is that we use reddit data to compare various methods simultaneously. As we process more data, trying deep learning will yield good results. Compared to other machine learning classifiers, the transformer classifier achieves the best results.\n",
            "----------------------------------------\n",
            "Title: Unsupervised Denoising and Super-Resolution of Vascular Flow Data by Physics-informed Machine Learning.\n",
            "Abstract: PURPOSE\n",
            "We present an unsupervised deep learning method to perform flow denoising and super-resolution without high resolution labels. We demonstrate the ability of this model to reconstruct 3D stenosis and aneurysm flows, with varying geometries, orientations, and boundary conditions.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Ground truth data was generated using computational fluid dynamics, and then corrupted with multiplicative Gaussian noise. Autoencoders were used to compress the representations of the flow domain geometry and the (possibly noisy and low-resolution) flow field. These representations were used to condition a physics-informed neural network. A physics-based loss was implemented to train the model to recover lost information from the noisy input by transforming the flow to a solution of the Navier-Stokes equations.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Our experiments achieved mean squared errors in the true flow reconstruction of order 1.0e-4, and root mean squared residuals of order 1.0e-2 for the momentum and continuity equations. Our method yielded correlation coefficients of 0.971 for the pressure field and 0.82 for the wall shear stress magnitude field.\n",
            "\n",
            "\n",
            "CONCLUSION\n",
            "By performing point-wise predictions of the flow, the model was able to robustly denoise and super-resolve the field to 20x the input resolution.\n",
            "----------------------------------------\n",
            "Title: Enhancing Lung Cancer Diagnosis with Machine Learning Methods and Systematic Review Synthesis\n",
            "Abstract: Lung cancer is the leading cause of death in the USA It is caused for various reasons, such as malignant tumors that grow spontaneously in the lung and spread to other parts of the body, where they can be devastating. Other than that, there are so many external reasons why smoking is the primary factor that gradually creates lung problems that lead to lung cancer. However, we can prevent this deadly cancer by detecting it at an early stage. A machine learning-based detection model has the potential to detect lung cancer, which helps to predict the early stage of cancer. So, we aim to build some powerful machine learning algorithms to predict this cancer that can help physicians make decisions about the diagnosis process of a particular patient, whether the patient needs a high or a regular diagnosis level. This can reduce the treatment cost of a patient because the physician knows from the result how many doses are needed for a patient, so it can avoid unnecessary treatment, which saves money and brings an efficient diagnosis system. We aimed to build a sustainable model that could predict the disease accurately, and finally, our models, such as XGBoost, achieved the highest value of other models. According to the accuracy level, XGBoost performed up to 95.92%, LightGBM, AdaBoost, Logistic Regression, and Support vector machine achieved 91.50%, 93.32%, 57.41 %, and 89.32% accuracy, respectively.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Methods for Dialysis Therapy Decision Problem - Comparative Study\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Stochastic Grammars to Learn Robotic Tasks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Revealing Vulnerabilities of Neural Networks in Parameter Learning and Defense Against Explanation-Aware Backdoors\n",
            "Abstract: Explainable Artificial Intelligence (XAI) strategies play a crucial part in increasing the understanding and trustworthiness of neural networks. Nonetheless, these techniques could potentially generate misleading explanations. Blinding attacks can drastically alter a machine learning algorithm's prediction and explanation, providing misleading information by adding visually unnoticeable artifacts into the input, while maintaining the model's accuracy. It poses a serious challenge in ensuring the reliability of XAI methods. To ensure the reliability of XAI methods poses a real challenge, we leverage statistical analysis to highlight the changes in CNN weights within a CNN following blinding attacks. We introduce a method specifically designed to limit the effectiveness of such attacks during the evaluation phase, avoiding the need for extra training. The method we suggest defences against most modern explanation-aware adversarial attacks, achieving an approximate decrease of ~99\\% in the Attack Success Rate (ASR) and a ~91\\% reduction in the Mean Square Error (MSE) between the original explanation and the defended (post-attack) explanation across three unique types of attacks.\n",
            "----------------------------------------\n",
            "Title: Global urban data gaps : Machine learning, earth observation and deprived urban areas\n",
            "Abstract: Earth observation data in support of poor communities against COVID-19 - OpenStreetMap Data Day UFBA\n",
            "----------------------------------------\n",
            "Title: Fake News Detection Regarding COVID-19 Tweets Using Machine Learning Approaches\n",
            "Abstract: The pervasiveness of misinformation surrounding the COVID-19 pandemic has garnered heightened attention due to its implications, as a noteworthy proportion of the populace is being exposed to spurious and unsubstantiated narratives concerning the crisis. This research utilizes a dataset sourced from Codalab, comprising 8,560 tweets, with 4,480 labelled as real and 4,080 as fake. The research explores the effectiveness of different machine learning models, including logistic regression (LR), random forest (RF), and deep learning models such as Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory (Bi-LSTM). In addition to model comparison, experiments were conducted to analyze the impact of different data splits (70:30, 80:20, and 90:10), batch sizes (16, 32, and 64), and the number of epochs (5, 10, and 15) on model performance. The experiments provided insights into the optimal configurations for the models. The results showcase the model's capabilities, with high accuracy achieved across the different models. Specifically, logistic regression achieved an accuracy of 92%, random forest 91%, Bi-LSTM 93%, and CNN 95%. These findings highlight the potential of deep learning models, particularly CNN, in accurately detecting fake news from COVID-19-related tweets.\n",
            "----------------------------------------\n",
            "Title: Identification of Immune-Related Risk Genes in Osteoarthritis Based on Bioinformatics Analysis and Machine Learning\n",
            "Abstract: In this research, we aimed to perform a comprehensive bioinformatic analysis of immune cell infiltration in osteoarthritic cartilage and synovium and identify potential risk genes. Datasets were downloaded from the Gene Expression Omnibus database. We integrated the datasets, removed the batch effects and analyzed immune cell infiltration along with differentially expressed genes (DEGs). Weighted gene co-expression network analysis (WGCNA) was used to identify the positively correlated gene modules. LASSO (least absolute shrinkage and selection operator)-cox regression analysis was performed to screen the characteristic genes. The intersection of the DEGs, characteristic genes and module genes was identified as the risk genes. The WGCNA analysis demonstrates that the blue module was highly correlated and statistically significant as well as enriched in immune-related signaling pathways and biological functions in the KEGG and GO enrichment. LASSO-cox regression analysis screened 11 characteristic genes from the hub genes of the blue module. After the DEG, characteristic gene and immune-related gene datasets were intersected, three genes, PTGS1, HLA-DMB and GPR137B, were identified as the risk genes in this research. In this research, we identified three risk genes related to the immune system in osteoarthritis and provide a feasible approach to drug development in the future.\n",
            "----------------------------------------\n",
            "Title: Machine Learning and Deep Learning Based Phishing Websites Detection: The Current Gaps and Next Directions\n",
            "Abstract: There are many phishing websites detection techniques in literature, namely white-listing, black-listing, visual-similarity, heuristic-based, and others. However, detecting zero-hour or newly designed phishing website attacks is an inherent property of machine learning and deep learning techniques. By considering a promising solution of machine learning and deep learning techniques, researchers have made a great deal of effort to tackle the this problem, which persists due to attackers constantly devising novel strategies to exploit vulnerability or gaps in existing anti-phishing measures. In this study, an extensive effort has been made to rigorously review recent studies focusing on Machine Learning and Deep Learning Based Phishing Websites Detection to excavate the root cause of the aforementioned problems and offer suitable solutions. The study followed the significant criterion to search, download, and screen relevant studies, then to evaluate criterion-based selected studies. The findings show that significant research gaps are available in the rigorously reviewed studies. These gaps are mainly related to imbalanced dataset usage, improper selection of dataset source(s), the unjustified reason for using specific train-test dataset split ratio, scientific disputes on website features inclusion and exclusion, lack of universal consensus on phishing website lifespans and on what is defining a small dataset size, and run-time analysis issues. The study clearly presented a summary of the comparative analysis performed on each reviewed research work so that future researchers could use it as a structured guideline to develop a novel solution for anti-phishing website attacks.\n",
            "----------------------------------------\n",
            "Title: Path Synthesis of Planar Linkage Mechanisms Using Deep Generative Models\n",
            "Abstract: The problem of path generation of planar mechanisms, or determining their motion as traced by a coupler curve, has been almost exclusively met with analytical solutions, leading to high run-time and low efficiency. In contrast, our approach utilizes a Machine Learning model, implementing a novel approach combining a generative AI model known as a Variational Autoencoder with a Fully Connected Neural Network to produce four-bar, six-bar, and eight-bar mechanisms to fit a desired path. We also determine which representations of the input coupler curve lead to the most accurate mechanisms. This work significantly improves the efficiency and automation of mechanism design.\n",
            "----------------------------------------\n",
            "Title: River flow prediction based on improved machine learning method: Cuckoo Search-Artificial Neural Network\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Prediction on compressive strength of Engineered Cementitious composites using Machine learning approach\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Research on Prediction of EPB Shield Tunneling Parameters Based on LGBM\n",
            "Abstract: At present, the determination of tunnel parameters mainly rely on engineering experience and human judgment, which leads to the subjective decision of parameters and an increased construction risk. Machine learning algorithms could provide an objective theoretical basis for tunnel parameter decision making. However, due to the limitations of a machine learning model’s performance and parameter selection methods, the prediction model had poor prediction results and low reliability for parameter research. To solve the above problems, based on a large number of construction parameters of a composite section subway in Shenzhen, this paper combined dimensionality reduction data with service analysis to optimize the selection process of shield tunneling parameters, and determined the total propulsion force, cutter head torque, cutter head speed, and advance rate as key tunneling parameters. Based on an LGBM algorithm and Bayesian optimization, the prediction model of key tunneling parameters of an earth pressure balance shield was established. The results showed that the average error of the LGBM model on the test set was 8.18%, the average error of the cutter head torque was 13.93%, the average error of the cutter head speed was 3.16%, and the average error of advance rate was 13.35%. Compared with the RF model, the prediction effect and the generalization on the test set were better. Therefore, an LGBM algorithm could be used as an effective prediction method for tunneling parameters in tunnel construction and provide guidance for the setting of tunneling parameters.\n",
            "----------------------------------------\n",
            "Title: OP0327 EVALUATION OF THE ARTIFICIAL INTELLIGENCE SYSTEM ACCURACY IN DETERMINING THE RADIOGRAPHIC STAGE OF KNEE OSTEOARTHRITIS\n",
            "Abstract: Within the last decade, rapid development of artificial neural networks and machine reading programs and their introduction into medical practice is reported [1,2,3]. Recently, an innovative program, based on the artificial intelligence (AI) technologies (a neural network and machine reading) that analyses knee X-ray images for determining the radiographic stage of OA was created. It was launched on the Osteoscan.ru website and is available for use by patients and doctors.to validate the system ability to accurately stage OA through machine interpretation of standard knee radiographs.Initially, 1300 x-rays of both knee joints where used to teach the neural network. Of these, 350 were presented in the form of film scans, 950 in the DICOM format.The accuracy of the system in recognition of OA stage by knee radiographs was evaluated on a quality control sample of 130 cases (of all 1300). Independently, the radiographs were assessed by certified radiologists (considered the “gold standard”) and the System.In 124 out of 130 cases the conclusion of a specialist and the System was the same, which represents 95.4% predictive power. Coincidence or discrepancy is a qualitative attribute, so, the accuracy of the estimation was calculated. Assuming a discrepancy of 0, and coincidence - of 1, µ = 0,954, the standard error sp= 1.8%. It can be concluded that in 95% of cases the accuracy of the system assessment will be in the range from 91.8% to 99%.Osteosan is a program developed on the base of AI technologies, analyzes radiographic images of the knee joints for determining OA stage. It provides high accuracy in OA stage determining by assessing knee radiographs, in 95% of cases, the accuracy of the system varies from 91.8% to 99%.[1]Fischl B, Salat DH, van der Kouwe AJ, Makris N, Ségonne F, Quinn BT, Dale AM. Sequence-independent segmentation of magnetic resonance images. Neuroimage. 2004;23 Suppl 1:S69-84[2]Faust O, Acharya U R, Ng EY, Ng KH, Suri JS. Algorithms for the automated detection of diabetic retinopathy using digital fundus images: a review. J Med Syst. 2012; 36(1): 145-57.[3]Balyen L, Peto T. Promising Artificial Intelligence-Machine Learning-Deep Learning Algorithms in Ophthalmology. Asia Pac J Ophthalmol (Phila). 2019; 8(3): 264-272.Olga Georginova Speakers bureau: GlaxoSmithKline Consumer Healthcare, Margarita Kobzar Employee of: GSK Consumer Healthcare\n",
            "----------------------------------------\n",
            "Title: Self-Optimization of Training Dataset Improves Forecasting of Cyanobacterial Bloom by Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Political Opinion Analysis in Social Networks: Case of Twitter and Facebook\n",
            "Abstract: The 21st century has been characterized by an increased attention to social networks. Nowadays, going 24 hours without getting in touch with them in some way has become difficult. Facebook and Twitter, these social platforms are now part of everyday life. Thus, these social networks have become important sources to be aware of frequently discussed topics or public opinions on a current issue. A lot of people write messages about current events, give their opinion on any topic and discuss social issues more and more. The emergence and enormous popularity of these social networks have led to the emergence of several types of analysis to take advantage of them. One of them is the analysis of opinions in texts. It aims at automatically classifying opinions in order to position them on a sentiment scale, thus allowing to characterize a set of opinions without having to rely on a human to read them. Currently, opinion analysis offers us a lot of information related to public opinion, either in the commercial world or in the political world. Many studies have shown that machine learning techniques, such as the support vector machine (SVM) and the naive Bayes classifier (NB), perform well in this type of classification. In our study, we first propose an approach for tracking and analyzing political opinions in social networks. Then, we propose a trained and evaluated machine learning model for political opinion classification. And finally, the study aims at setting up a web interface to collect and analyze in real time political opinions from social networks\n",
            "----------------------------------------\n",
            "Title: A systematic review on the requirements on BIM maturity and formal representation of sequencing knowledge for automated construction scheduling\n",
            "Abstract: Planning and scheduling is the centerpiece of every commercial and industrial building project. Despite significant effort that goes into planning and scheduling, still many projects end up behind schedule and are over budget. The reasons for this are myriad, and the ability to plan and schedule a project lies near the heart of them all. While research has focused on developing techniques for automated planning and BIM-driven schedule generation, these methods do not scale to real projects as they still require manual generation of work templates and do not intuitively account for all project constraints. This paper offers a close examination on the problems underpinning construction scheduling theory and practice such as sequencing logic and activity description by offering a systematic review on: 1) the way in which BIM-driven schedules are formalized; and 2) the challenges of tying in Building Information Modeling (BIM) with project schedules and/or BIM-driven schedule creation techniques. The requirement on maturity and granularity of BIM and a path forward for automated construction scheduling, purely based on machine learning and inference from BIM as well as historical schedule data, are presented in detail.\n",
            "----------------------------------------\n",
            "Title: Predictive Analytics for Roadway Maintenance: A Review of Current Models, Challenges, and Opportunities\n",
            "Abstract: With the pressing need to improve the poorly rated transportation infrastructure, asset managers leverage predictive maintenance strategies to lower the life cycle costs while maximizing or maintaining the performance of highways. Hence, the limitations of prediction models can highly impact prioritizing maintenance tasks and allocating budget. This study aims to investigate the potential of different predictive models in reaching an effective and efficient maintenance plan. This paper reviews the literature on predictive analytics for a set of highway assets. It also highlights the gaps and limitations of the current methodologies, such as subjective assumptions and simplifications applied in deterministic and probabilistic approaches. This article additionally discusses how these shortcomings impact the application and accuracy of the methods, and how advanced predictive analytics can mitigate the challenges. In this review, we discuss how advancements in technologies coupled with ever-increasing computing power are creating opportunities for a paradigm shift in predictive analytics. We also propose new research directions including the application of advanced machine learning to develop extensible and scalable prediction models and leveraging emerging sensing technologies for collecting, storing and analyzing the data. Finally, we addressed future directions of predictive analysis associated with the data-rich era that will potentially help transportation agencies to become information-rich.\n",
            "----------------------------------------\n",
            "Title: Review for \"Study becomes insight: Ecological learning from machine learning\"\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: COMPARISON OF LINEAR REGRESSION MODELS OF THERMOPHYSICAL PROPERTIES WITH MODELS BASED ON MACHINE LEARNING\n",
            "Abstract: The paper compares classical models for determining the thermophysical properties of steels based primarily on empirical equations derived using linear regression methods with models created using machine learning methods. The selected investigated quantities include phase transformation temperatures, specific heat capacity, coefficient of thermal expansion. The results of both approaches are verified on the measured data by methods of thermal analysis such as differential scanning calorimetry, differential thermal analysis and dilatometry. The methods are evaluated both in terms of the accuracy of predictions and in terms of the adequacy of use for a specific purpose, or in terms of the complexity of creating and using the model.\n",
            "----------------------------------------\n",
            "Title: A comparison of ℓ1-regularizion, PCA, KPCA and ICA for dimensionality reduction in logistic regression\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Efficient Distributed Learning for Large-Scale Expectile Regression With Sparsity\n",
            "Abstract: High-dimensional datasets often display heterogeneity due to heteroskedasticity or other forms of non-location-scale covariance effects. When the size of datasets becomes very large, it may be infeasible to store all of the high-dimensional datasets on one machine, or at least to keep the datasets in memory. In this paper, we consider penalized expectile regression using smoothly clipped absolute deviation (SCAD) and adaptive LASSO penalties, which can effectively detect the heteroskedasticity of high-dimensional data. We propose a communication-efficient approach for distributed sparsity learning, where observations are randomly partitioned across machines. By selecting the appropriate tuning parameters, we show that the proposed estimators display oracle properties. Extensive numerical experiments on both synthetic and real data validate the theoretical results and demonstrate the superior performance of our proposed method.\n",
            "----------------------------------------\n",
            "Title: Online nonlinear modeling for big data applications\n",
            "Abstract: ONLINE NONLINEAR MODELING FOR BIG DATA APPLICATIONS Farhan Khan Ph.D. in Electrical and Electronics Engineering Advisor: Suleyman Serdar Kozat December 2017 We investigate online nonlinear learning for several real life, adaptive signal processing and machine learning applications involving big data, and introduce algorithms that are both efficient and effective. We present novel solutions for learning from the data that is generated at high speed and/or have big dimensions in a non-stationary environment, and needs to be processed on the fly. We specifically focus on investigating the problems arising from adverse real life conditions in a big data perspective. We propose online algorithms that are robust against the non-stationarities and corruptions in the data. We emphasize that our proposed algorithms are universally applicable to several real life applications regardless of the complexities involving high dimensionality, time varying statistics, data structures and abrupt changes. To this end, we introduce a highly robust hierarchical trees algorithm for online nonlinear learning in a high dimensional setting where the data lies on a time varying manifold. We escape the curse of dimensionality by tracking the subspace of the underlying manifold and use the projections of the original high dimensional regressor space onto the underlying manifold as the modified regressor vectors for modeling of the nonlinear system. By using the proposed algorithm, we reduce the computational complexity to the order of the depth of the tree and the memory requirement to only linear in the intrinsic dimension of the manifold. We demonstrate the significant performance gains in terms of mean square error over the other state of the art techniques through simulated as well as real data. We then consider real life applications of online nonlinear learning modeling, such as network intrusions detection, customers’ churn analysis and channel estimation for underwater acoustic communication. We propose sequential and online learning methods that achieve significant performance in terms of detection accuracy, compared to the state-of-the-art techniques. We specifically introduce structured and deep learning methods to develop robust learning algorithms. Furthermore, we improve the performance of our proposed online nonlinear learning\n",
            "----------------------------------------\n",
            "Title: Keynote: Adventures in Annotation: Providing High Quality Labels for Supervised Machine Learning\n",
            "Abstract: Ground truth annotation is a crucial prerequisite for the application of supervised classification methods for both, training and evaluation. To this end, the quality of the labels plays a significant role for the final ability of the trained system to recognize the concepts of interest. This talk addresses the problem of creating high quality labels by manual annotation and their application in downstream classification tasks. To this end, three studies will be reviewed that relied on the quality of the collected ground truth annotation and the procedure for ground truth annotation will be discussed. The first study applies planning operators and inverse planning to ensure that annotations of human behavior are causally correct [1] and, thus, can be used for downstream plan and intention recognition [2] . In the second study, an annotation scheme is derived from a clinical observation tool [3] and used as ground truth labels for the automated detection of challenging behavior in advanced stages of dementia [4] . In the third study, the annotation of named entities and their relations is discussed [5] that serves as reliable ground truth annotation for large scale information extraction [6] . Finally, the key factors of all studies will be summarized and discussed.\n",
            "----------------------------------------\n",
            "Title: Semantic Search and Visual Exploration of Computational Notebooks\n",
            "Abstract: Code search is an important and frequent activity for developers using computational notebooks (e.g., Jupyter). The flexibility of notebooks brings challenges for effective code search, where classic search interfaces for traditional software code may be limited. In this paper, we propose, NBSearch, a novel system that supports semantic code search in notebook collections and interactive visual exploration of search results. NBSearch leverages advanced machine learning models to enable natural language search queries and intuitive visualizations to present complicated intraand inter-notebook relationships in the returned results. We developed NBSearch through an iterative participatory design process with two experts from a large software company. We evaluated the models with a series of experiments and the whole system with a controlled user study. The results indicate the feasibility of our analytical pipeline and the effectiveness of NBSearch to support code search in large notebook collections. As one important aspect of the future directions, the search quality of NBSearch was further improved by incorporating the impact of markdowns in notebooks, and its performance was evaluated by comparing to the original implementation.\n",
            "----------------------------------------\n",
            "Title: A neural network strategy for supervised classification via the Learning Under Privileged Information paradigm\n",
            "Abstract: Devising new methodologies to handle and analyse Big Data has become a fundamental task in our increasingly service-oriented and interconnected society. One of the problems arising while handling such data is that, for a given set of entities, not all the entities may be described at the same level of detail, i.e., the number of features describing each entity may vary. In general cases, in order to apply classic data science methods, it is necessary to have a common features set over a data set. This will then correspond to the maximum number of common features among the entities, resulting in a loss of information for the entities for which additional information may be available. In order to exploit such additional information, the Learning Using Privileged Information (LUPI) paradigm has been proposed, based on the use of the teacher role in the learning process. In this schema the teacher acquires a strategic position, by exploiting at the training stage some additional privileged information about the entities, which will not be available at the test stage. In this work, we apply this paradigm in the context of neural networks, by proposing a LUPI based deep learning architecture able to exploit a larger set of attributes at training time, with the aim to improve classification performances on a set of entities associated to a reduced attribute set. Experimental results show how the proposed approach improves upon the ones applying the same schema to classic machine learning methods (e.g., SVM).\n",
            "----------------------------------------\n",
            "Title: Science Magazine\n",
            "Abstract: SCIENCE sciencemag.org T echnological innovations are penetrating all areas of science, making predominantly human activities a principal bottleneck in scientific progress while also making scientific advancement more subject to error and harder to reproduce. This is an area where a new generation of artificial intelligence (AI) systems can radically transform the practice of scientific discovery. Such systems are showing an increasing ability to automate scientific data analysis and discovery processes, can search systematically and correctly through hypothesis spaces to ensure best results, can autonomously discover complex patterns in data, and can reliably apply small-scale scientific processes consistently and transparently so that they can be easily reproduced. We discuss these advances and the steps that could help promote their development and deployment. Applying AI to the practice of science is not new. AI pioneer and Nobel laureate Herbert Simon hypothesized that cognitive mechanisms involved in scientific discovery are a special case of general human capabilities for problem-solving and, with colleagues, developed systems in the 1970s and 1980s that demonstrated reasoning capabilities for analyzing scientific data ( 1). Also in the 1970s, Joshua Lederberg (another Nobel winner) and colleagues developed the DENDRAL system for analyzing mass spectrometry data in order to hypothesize molecular structures ( 2). More recent breakthroughs, such as robot scientists and software that formulates laws for complex dynamical systems, demonstrate broader applicability of AI techniques for scientific discovery ( 3). Over the past two decades, AI has seen accelerating scientific advances and concomitant commercial-sector successes because of advances on three fronts: steady scholarly advances, especially as success has increased the numbers of interested participants; Moore’s law and steady exponential increases in computing power; and exponential increases in, and broad availability of, relevant data in volumes never previously seen. Those scientific efforts that have leveraged AI advances have largely harnessed sophisticated machine-learning techniques to create correlative predictions from large sets of “big data.” Such work aligns well with the current needs of petaand exascale science. However, AI has far broader capacity to ac-\n",
            "----------------------------------------\n",
            "Title: The simulation of verbal learning behavior\n",
            "Abstract: An information processing model of elementary human symbolic learning is given a precise statement as a computer program, called Elementary Perceiver and Memorizer (EPAM). The program simulates the behavior of subjects in experiments involving the rote learning of nonsense syllables. A discrimination net which grows is the basis of EPAM's associative memory. Fundamental information processes include processes for discrimination, discrimination learning, memorization, association using cues, and response retrieval with cues. Many well-known phenomena of rote learning are to be found in EPAM's experimental behavior, including some rather complex forgetting phenomena. EPAM is programmed in Information Processing Language V.\n",
            " H. A. Simon has described some current research in the simulation of human higher mental processes and has discussed some of the techniques and problems which have emerged from this research. The purpose of this paper is to place these general issues in the context of a particular problem by describing in detail a simulation of elementary human symbolic learning processes.\n",
            " The information processing model of mental functions employed is realized by a computer program called Elementary Perceiver and Memorizer (EPAM). The EPAM program is the precise statement of an information processing theory of verbal learning that provides an alternative to other verbal learning theories which have been proposed. It is the result of an attempt to state quite precisely a parsimonious and plausible mechanism sufficient to account for the rote learning of nonsense syllables. The critical evaluation of EPAM must ultimately depend not upon the interest which it may have as a learning machine, but upon its ability to explain and predict the phenomena of verbal learning.\n",
            " I should like to preface my discussion of the simulation of verbal learning with some brief remarks about the class of information processing models of which EPAM is a member.\n",
            " a. These are models of mental processes, not brain hardware. They are <u>psychological</u> models of mental function. No physiological or neurological assumptions are made, nor is any attempt made to explain information processes in terms of more elementary neural processes.\n",
            " b. These models conceive of the brain as an <u>information processor</u> with sense organs as input channels, effector organs as output devices, and with internal programs for testing, comparing, analyzing, rearranging, and storing information.\n",
            " c. The central processing mechanism is assumed to be serial; i.e., capable of doing only one (or a very few) things at a time.\n",
            " d. These models use as a basic unit the <u>information symbol</u>; i.e., a pattern of bits which is assumed to be the brain's internal representation of environmental data.\n",
            " e. These models are essentially <u>deterministic</u>, not probabilistic. Random variables play no fundamental role in them.\n",
            "----------------------------------------\n",
            "Title: A MACHINE LEARNING ALGORITHM FOR OPTIMIZATION OF REINFORCED CONCRETE STRUCTURES SUBJECTED TO BLAST\n",
            "Abstract: The analysis and design of a 4-story reinforced concrete (RC) frame that is subjected to blast loadings derived from an internal explosion experiment was presented as an optimization problem. An innovative algorithm combining multi-criterion decision-making (DM) and Particle Swarm Optimization (PSO) and Machine learning (ML), called DMPSO-ML, was used for expediting convergence toward the optimum solution. The main objective function in the study included minimizing the cost or mass of the four-story RC frame subjected to blast loadings while simultaneously satisfying all requirements established by building design principles. A blast load emanating from an internal explosion experiment was considered. The modular sizes of members, standard steel bar diameters, steel bar spacing rules, architectural provisions and additional constructability requirements were obtained directly from the output of DMPSO-ML yielding automatic final designs. The results from this study established the validity of the presented DMPSO-ML algorithm for obtaining optimum results in structural optimization problems involving blast effects.\n",
            "----------------------------------------\n",
            "Title: Developing a Testing Framework for Intrusion Detection Algorithms Using Software Defined Networking\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Software Behavior: Automatic Classification and its Applications\n",
            "Abstract: A program’s behavior is ultimately the collection of all its executions. This collection is diverse, unpredictable, and generally unbounded. Thus it is especially suited to statistical analysis and machine learning techniques. We explore the thesis that 1stand 2nd-order Markov models of event-transitions are effective predictors of program behavior. We present a technique that models program executions as Markov models, and a clustering method for Markov models that aggregates multiple program executions, yielding a statistical description of program behaviors. With this approach, we can train classifiers to recognize specific behaviors emitted by an execution without knowledge of inputs or outcomes. We evaluate an application of active learning to the efficient refinement of our classifiers by conducting three empirical studies that explore a scenario illustrating automated test plan augmentation. We present a set of potential research questions and applications that our work suggests.\n",
            "----------------------------------------\n",
            "Title: An enhanced machine learning tool for cis‐eQTL mapping with regularization and confounder adjustments\n",
            "Abstract: Many expression quantitative trait loci (eQTL) studies have been conducted to investigate the biological effects of variants in gene regulation. However, these eQTL studies may suffer from low or moderate statistical power and overly conservative false‐discovery rate. In practice, most algorithms for eQTL identification do not model the joint effects of multiple genetic variants with weak or moderate influence. Here we present a novel machine‐learning algorithm, lasso least‐squares kernel machine (LSKM‐LASSO) that model the association between multiple genetic variants and phenotypic traits simultaneously with the existence of nongenetic and genetic confounding. With a more general and flexible framework for the estimation of genetic confounding, LSKM‐LASSO is able to provide a more accurate evaluation of the joint effects of multiple genetic variants. Our simulations demonstrate that our approach outperforms three state‐of‐the‐art alternatives in terms of eQTL identification and phenotype prediction. We then apply our method to genotype and gene expression data of 11 tissues obtained from the Genotype‐Tissue Expression project. Our algorithm was able to identify more genes with eQTL than other algorithms. By incorporating a regularization term and combining it with least‐squares kernel machine, LSKM‐LASSO provides a powerful tool for eQTL mapping and phenotype prediction.\n",
            "----------------------------------------\n",
            "Title: A Matlab Toolbox for Feature Importance Ranking\n",
            "Abstract: More attention is paid for the feature importance ranking (FIR), in particular when high-throughput features can be extracted for intelligent diagnosis and personalized medicine. A large number of FIR methods have been proposed, while few are integrated for comparison and real-life applications. In this study, a matlab toolbox is presented and a total of 30 algorithms are collected. Moreover, the toolbox is evaluated on a database of 163 ultrasound images. To each breast lesion, 15 features are handcrafted. And to Figure out an optimal subset of features for classification, all combinations of features are tested and linear support vector machine is used for the malignancy prediction of lesions annotated in ultrasound images. At last, the effectiveness of FIR is analyzed according to performance comparison. The toolbox is available (https://github.com/NicoYuCN/matFIR). In the future work, more FIR methods, feature selection methods and machine learning classifiers will be integrated.\n",
            "----------------------------------------\n",
            "Title: Prediction of Anemia using Machine Learning Algorithms\n",
            "Abstract: Anemia is a state of poor health where there is presence of low amount of red blood cell in blood stream. This research aims to design a model for prediction of Anemia in children under 5 years of age using Complete Blood Count reports. Data are collected from Kanti Children Hospital which consist of 700 data records. Then they are preprocessed, normalized, balanced and selected machine learning algorithms were applied. It is followed by verification, validation along with result analysis. Random Forest is the best performer which showed accuracy of 98.4%. Finally, Feature Selection as well as Ensemble Learning methods, Voting, Stacking, Bagging and Boosting were applied to improve the performance of algorithms. Selecting the best performer algorithm, stacking with other algorithms, bagging it, boosting it are very much crucial to improve accuracy despite of any time issue for prediction of anemia in children below 5 years of age.\n",
            "----------------------------------------\n",
            "Title: MP41-02 NOVEL ROBOTIC-ASSISTED ELECTROMAGNETIC GUIDANCE FOR PRECISION PERCUTANEOUS ACCESS: A CADAVERIC STUDY OF NOVICES VERSUS AN EXPERT\n",
            "Abstract: INTRODUCTION AND OBJECTIVE: High quality nerve-spare (NS) is essential for the preservation of erectile function (EF) after robot-assisted radical prostatectomy (RARP). In a previous study, we developed an assessment tool for tissue dissection, Dissection Assessment for Robotic Technique (DART). Herein, we further apply DART scores to the NS step and evaluate whether DART can predict 1-year EF recovery after RARP. METHODS: RARP cases from 2016-2019 with preoperative EF and (cid:1) 1 year postoperative follow up were included. Non-nerve-sparing procedures were excluded. Phase 1 : After standardized training, 5 independent assessors used DART to evaluate de-identi ﬁ ed NS videos. Inter-rater reliability (IRR) was evaluated by prevalence- adjusted and bias-adjusted Kappa (PABAK). DART scores of surgeons with different experience levels were compared by Kruskal- Wallis test. Phase 2 : DART scores were used to predict 1 year EF recovery after RARP. EF was de ﬁ ned as erections suf ﬁ cient for intercourse greater than half the time, which corresponds to an answer of 4 or 5 to the third question of the International Index of Erectile Function. 12 clinical features (e.g. age, comorbidities) and 6 domains of DART scores were used to construct a machine learning model (XGBoost) to predict EF recovery. We leveraged 4-fold cross- validation to train and evaluate the model, and reported the mean and standard deviation (SD) of area under the curve (AUC) across the 4 folds on a held-out test set. INTRODUCTION AND OBJECTIVE: A precise puncture into the exact location in the renal collecting system is an essential skill for successful percutaneous nephrolithotomy (PCNL). The consequences of a suboptimal puncture and tract dilation can result in bleeding or the inability to treat stone burden ef ﬁ ciently or completely. This pro ﬁ ciency is developed over time and can be challenge for novices. The purpose of this study was to determine if a novel technology, robotic-assisted electromagnetic (EM) guidance, can impact the success of percutaneous renal access in a cadaveric model. METHODS: INTRODUCTION AND OBJECTIVE: Real-time detection of errors during robot-assisted surgery (RAS) currently requires supervision from experienced surgeons. Herein, we attempt to automate surgical error detection through machine learning (ML)-based computer vision. METHODS: We use RAS data from 23 surgeons performing a simulated dry-lab tissue dissection task on a live daVinci Xi surgical robot. The data contains video and per-second Index of Cognitive Activity (ICA), derived from pupillary change and tracked by Tobii Eyetrackers. In this data, 172 error instances, representing 11 error types, have been previously annotated. Of these, Tissue tears (n [ 70, 40.7%) and Tissue punctures (n [ 62; 36%) are the 2 most common error types. We extract 5 sec windows around an error (positive label) and randomly sample the remaining data (negative label). We train 3 variations of ML architectures on a 80/20 train-test random split strati ﬁ ed by label and participant. Our base 1-stream Long Short-term Memory (LSTM) ML model relies on RGB (red green blue) video input only Our 2-stream model expands on the base model to include movement information via Optical Flow and a Spatial Attention Mechanism may indicate the importance of the surgeon's state of mind while committing this type of error. In contrast, detection of “ Tissue punctures ” degrades from 0.71 to 0.57 with addition of attention mechanism and movement data. This suggests con ﬂ icting information added or due to these errors being less visually apparent, which may make it challenging for the ML attention mechanism to identify them. CONCLUSIONS: We have demonstrated the feasibility of ML- based automated error detection in RAS. Our exploration demonstrates the positive value of including additional information in certain tasks. Future work will explore better mechanisms of combining multiple information sources and also expand the setup to detection and possibly prediction of a broader set of errors.\n",
            "----------------------------------------\n",
            "Title: \"My Very Subjective Human Interpretation\": Domain Expert Perspectives on Navigating the Text Analysis Loop for Topic Models\n",
            "Abstract: Practitioners dealing with large text collections frequently use topic models such as Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization (NMF) in their projects to explore trends. Despite twenty years of accrued advancement in natural language processing tools, these models are found to be slow and challenging to apply to text exploration projects. In our work, we engaged with practitioners (n=15) who use topic modeling to explore trends in large text collections to understand their project workflows and investigate which factors often slow down the processes and how they deal with such errors and interruptions in automated topic modeling. Our findings show that practitioners are required to diagnose and resolve context-specific problems with preparing data and models and need control for these steps, especially for data cleaning and parameter selection. Our major findings resonate with existing work across CSCW, computational social science, machine learning, data science, and digital humanities. They also leave us questioning whether automation is actually a useful goal for tools designed for topic models and text exploration.\n",
            "----------------------------------------\n",
            "Title: Face identification for Law Enforcement\n",
            "Abstract: We all recognize that face detection is a sort of synthetic intelligence (AI) era that has grow to be an imperative a part of our normal lives, with results on nearly each element of our lives. In diverse fields, there may be a want for better accuracy and better pace for detection and popularity. However, the accuracy of the identity isn't always precisely dependable in lots of cases. In this paper we gift a incredibly correct face popularity version the use of OpenCV and dlib libraries. One of the very best methods to become aware of someone's individuality is to examine their face. Face popularity is a machine for figuring out someone with the aid of using the use of private traits of the person. An individual's face is diagnosed with the aid of using a system such as phases, specifically face detection, in which this system happens in no time in humans, besides in situations in which the item could be very near with the aid of using, and the introduction, which identifies a face as a unmarried individual. Here, we've additionally mentioned approximately detecting faces in a video frame. The most important difficulty in identity and popularity of faces is the storage, on this paper we've additionally addressed that problem with the aid of using handiest storing the facial capabilities in place of storing faces directly. Key words – dlib, face detection, artificial intelligence, machine learning, deep learning, CNN.\n",
            "----------------------------------------\n",
            "Title: Malaysian Community College Graduates Employability Prediction Model Using Machine Learning Approach\n",
            "Abstract: Community College, as TVET institution under the Ministry of Higher Education, offers industry-relevant skills training to ensure graduates' employability in the global labor market. However, producing graduates who meet industry demands remains a challenge, and industries continue to face difficulties in obtaining skilled graduates. In Malaysia, there is limited research on predictive models for employability rates among graduates of TVET Malaysian institutions. This research utilizes Python to investigate the significant factors influencing employability among Malaysian Community College graduates, determined by a specific indicator of whether they will be employed. Our contribution lies in developing an accurate employability prediction model using machine learning algorithms such as Logistic Regression, Neural Networks, and Random Forest. The dataset used consisted of 10,427 instances and 14 attributes, from which six significant factors were identified. Among the models, Random Forest outperformed the other machine learning models, and hyperparameter tuning using RandomizedSearch further improved the accuracy of the model to 84.8%. This study aims to identify the most accurate and interpretable model, providing valuable insights for educational institutions to enhance their employability strategies.\n",
            "----------------------------------------\n",
            "Title: Predictive Modeling of Recurrent Implantation Failure and Pre-eclampsia Using Machine Learning and Gene Expression Profiling\n",
            "Abstract: A pregnancy complication is any medical condition that arises during pregnancy that impacts the health of the mother, the fetus, or both. Recurrent implantation failure and pre-eclampsia are two such prenatal medical disorders. Machine learning systems can accurately predict high-risk prenatal medical conditions like recurrent implantation failure and pre-eclampsia. This study aimed to analyze differentially expressed genes for both pregnancy complications and develop a Machine learning model for the early prognosis of recurrent implantation failure and pre-eclampsia. Differentially expressed genes for recurrent implantation failure consisted of 2486 downregulated genes and 809 upregulated genes, and pre-eclampsia, consisted of 13 downregulated genes and 10 upregulated genes followed by gene set enrichment analysis. Gene expression prolife of recurrent implantation failure and pre-eclampsia were used to develop the machine learning model. Random Forest performed best for recurrent implantation failure with a model accuracy of 96.47%, while the generalized linear model performed best for pre-eclampsia with a model accuracy of 80%.\n",
            "----------------------------------------\n",
            "Title: Informing action for United Nations SDG target 8.7 and interdependent SDGs: Examining modern slavery from space\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Hybrid Rough Set and Heterogeneous Ensemble Classifiers Model for Cancer Classification\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Smoothed Analysis of Belief Propagation for Minimum-Cost Flow and Matching\n",
            "Abstract: Belief propagation (BP) is a message-passing heuristic for statistical inference in graphical models such as Bayesian networks and Markov random fields. BP is used to compute marginal distributions or maximum likelihood assignments and has applications in many areas, including machine learning, image processing, and computer vision. However, the theoretical understanding of the performance of BP is unsatisfactory. Recently, BP has been applied to combinatorial optimization problems. It has been proved that BP can be used to compute maximum-weight matchings and minimum-cost flows for instances with a unique optimum. The number of iterations needed for this is pseudo-polynomial and hence BP is not efficient in general. We study belief propagation in the framework of smoothed analysis and prove that with high probability the number of iterations needed to compute maximum-weight matchings and minimum-cost flows is bounded by a polynomial if the weights/costs of the edges are randomly perturbed. To prove our upper bounds, we use an isolation lemma by Beier and Vocking (SIAM J. Comput., 2006) for matching and generalize an isolation lemma for min-cost flow by Gamarnik, Shah, and Wei (Oper. Res., 2012). We also prove almost matching lower tail bounds for the number of iterations that BP needs to converge.\n",
            "----------------------------------------\n",
            "Title: Publication\n",
            "Abstract: Unveiling Music Structure Via PLSA Similarity Fusion Arenas-García, J., Meng, A., Petersen, K. B., Lehn-Schiøler, T., Hansen, L. K. & Larsen, J. 2007 2007 IEEE International Workshop on MACHINE LEARNING FOR SIGNAL PROCESSING. Formerly the IEEE Workshop on Neural Networks for Signal Processing, August 27-29, 2007, Thessaloniki, Greece. IEEE, p. 419-424 Publication: Research peer-review › Article in proceedings – Annual report year: 2007\n",
            "----------------------------------------\n",
            "Title: Multi-Attacks Detection in Distributed System using Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Forecasting solar photosynthetic photon flux density under cloud cover effects: novel predictive model using convolutional neural network integrated with long short-term memory network\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: NCS based ultra low power optimized machine learning techniques for image classification\n",
            "Abstract: In recent years there has been an extensive development in the field of convolutional neural network-based image classification because of the human-like inference results obtained, but these massive networks are resource intensive and have high memory and computational requirements. Intel’s Neural Compute Stick brings real time inference, prototyping and deployment of these DNNs to the network edge. In this paper we will discuss the development of a model for classification of book cover images into genres, and subsequently compiling the trained model for use with the Neural Compute Stick, so as to receive the optimized results in constrained environments thus ultimately leading to a system to judge a book by its cover which can be used even within a low power environment like a mobile device or Raspberry Pi, as the stick runs on power values as low as 1.2W.\n",
            "----------------------------------------\n",
            "Title: Evolutionary Extreme Learning Machine Based Weighted Nearest-Neighbor Equality Classification\n",
            "Abstract: Feature significance plays an important role in the classification tasks. The performance of a classifier would be degraded due to the existence of the irrelevant features, which are often inevitable in the real applications. In order to distinguish the impacts implicated in the features and improve the performances of the classification methods, this paper presents a hybrid learning approach, entitled evolutionary extreme learning machine based weighted nearest-neighbor equality algorithm (EE-WNNE). In such method, the measure of the significance levels of the features are induced by the weights on the related links associated with the individual input nodes in the evolutionary extreme learning machine (E-ELM) algorithm. These feature weights are utilized to implement a weighted nearest-neighbor equality method to perform the subsequent classification tasks. Systematic experimental results demonstrate that the proposed approach generally outperform many state-of-the-art classification techniques.\n",
            "----------------------------------------\n",
            "Title: Thermal Degradation Evaluation of Polyethylene Terephthalate Microplastics: Insights from Kinetics and Machine Learning Algorithms Using Non-isoconversional TGA Data\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Can a Bayesian Oracle Prevent Harm from an Agent?\n",
            "Abstract: Is there a way to design powerful AI systems based on machine learning methods that would satisfy probabilistic safety guarantees? With the long-term goal of obtaining a probabilistic guarantee that would apply in every context, we consider estimating a context-dependent bound on the probability of violating a given safety specification. Such a risk evaluation would need to be performed at run-time to provide a guardrail against dangerous actions of an AI. Noting that different plausible hypotheses about the world could produce very different outcomes, and because we do not know which one is right, we derive bounds on the safety violation probability predicted under the true but unknown hypothesis. Such bounds could be used to reject potentially dangerous actions. Our main results involve searching for cautious but plausible hypotheses, obtained by a maximization that involves Bayesian posteriors over hypotheses. We consider two forms of this result, in the iid case and in the non-iid case, and conclude with open problems towards turning such theoretical results into practical AI guardrails.\n",
            "----------------------------------------\n",
            "Title: Prediction of Northern Polar ionospheric scintillation Using the Random Forest and LSTM Machine Learning Methods\n",
            "Abstract: Ionospheric scintillation is one of the most important space weather phenomena in the polar ionosphere, which is clo sely related to people's lives, especially to the widely used satellite navigation and positioning system with unavoidable impacts, so the prediction of ionospheric scintillation needs to be addressed. Nowadays, a network of multiple Global Navigation Satellite System (GNSS) receivers has been established in the Arctic, and the sc intillation index data provided by the GNSS receivers make the prediction of northern polar ionospheric scintillation possible. To predict the polar scintillation events, we developed a new deep le arning method. Based on the 2011–2016 dataset from the Eureka station (79.99°N,274.09°E), by using a random forest approach to regressively analyze the physical covariates that characterize the solar-terrestrial environment, we evaluate the correlation of 24 different parameters with the phase scintillation index (σφ), filter out the five covariates with the highest correlation as inputs to the long-short time memory (LSTM) algorithm, and make a prediction of σφ one hour in advance. The results show that the model can accurately predict polar ionospheric scintillation, demonstrating that the deep learning method has a wide range of prospects in the field of predicting polar scintillation.\n",
            "----------------------------------------\n",
            "Title: Using Electric Vehicle Driver's Driving Mode for Trip Planning and Routing\n",
            "Abstract: With the increasing adoption of electric vehicles worldwide, some limitations have emerged in their usage. The main limitations include low autonomy and a scarcity of charging points. In this work, we describe a software architecture for planning a stop at charging stations along a trip, by prediction of battery charge to be spent along the path. We describe the main components of this architecture and evaluate regression methods for the car consumption prediction module. We also use a real dataset built from an electric vehicle usage to validate the architecture concept and its viability analyzing multiple linear regression machine learning models. To further validate the architecture, we make comparisons between simulated and a real trips.\n",
            "----------------------------------------\n",
            "Title: A Study on GPS GDOP Approximation Using Support-Vector Machines\n",
            "Abstract: Global Positioning System (GPS) has extensively been used in various fields. Geometric Dilution of Precision (GDOP) is an indicator showing how well the constellation of GPS satellites is geometrically organized. GPS positioning with a low GDOP value usually gains better accuracy. However, the calculation of GDOP is a time- and power-consuming task that involves complicated transformation and inversion of measurement matrices. When selecting from many GPS constellations the one with the lowest GDOP for positioning, methods that can fast and accurately obtain GPS GDOP are imperative. Previous studies have shown that numerical regression on GPS GDOP can get satisfactory results and save many calculation steps. This paper deals with the approximation of GPS GDOP using statistics and machine learning methods. The technique of support vector machines (SVMs) is mainly focused. This study compares the performance of several methods, such as linear regression, pace regression, isotonic regression, SVM, artificial neural networks, and genetic programming (GP). The experimental results show that SVM and GP have better performance than others.\n",
            "----------------------------------------\n",
            "Title: Computer vision-based predictive analysis of chronic cardiovascular disease using heartbeat features\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine Learning for Predicting Cognitive Diseases: Methods, Data Sources and Risk Factors\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Fine-Grained Named Entity Recognition Using a Multi-Stacked Feature Fusion and Dual-Stacked Output in Korean\n",
            "Abstract: Named entity recognition (NER) is a natural language processing task to identify spans that mention named entities and to annotate them with predefined named entity classes. Although many NER models based on machine learning have been proposed, their performance in terms of processing fine-grained NER tasks was less than acceptable. This is because the training data of a fine-grained NER task is much more unbalanced than those of a coarse-grained NER task. To overcome the problem presented by unbalanced data, we propose a fine-grained NER model that compensates for the sparseness of fine-grained NEs by using the contextual information of coarse-grained NEs. From another viewpoint, many NER models have used different levels of features, such as part-of-speech tags and gazetteer look-up results, in a nonhierarchical manner. Unfortunately, these models experience the feature interference problem. Our solution to this problem is to adopt a multi-stacked feature fusion scheme, which accepts different levels of features as its input. The proposed model is based on multi-stacked long short-term memories (LSTMs) with a multi-stacked feature fusion layer for acquiring multilevel embeddings and a dual-stacked output layer for predicting fine-grained NEs based on the categorical information of coarse-grained NEs. Our experiments indicate that the proposed model is capable of state-of-the-art performance. The results show that the proposed model can effectively alleviate the unbalanced data problem that frequently occurs in a fine-grained NER task. In addition, the multi-stacked feature fusion layer contributes to the improvement of NER performance, confirming that the proposed model can alleviate the feature interference problem. Based on this experimental result, we conclude that the proposed model is well-designed to effectively perform NER tasks.\n",
            "----------------------------------------\n",
            "Title: Conditional noise deep learning for parameter estimation of gravitational wave events\n",
            "Abstract: We construct a Bayesian inference deep learning machine for parameter estimation of gravitational wave events of binaries of black hole coalescence. The structure of our deep Bayesian machine adopts the conditional variational autoencoder scheme by conditioning on both the gravitational wave strains and the variations of the amplitude spectral density (ASD) of the detector noise. We show that our deep Bayesian machine is capable of yielding posteriors compatible with the ones from the nested sampling method and better than the one without conditioning on the ASD. Our result implies that the process of parameter estimation can be accelerated significantly by deep learning even with large ASD drifting/variation. We also apply our deep Bayesian machine to the LIGO/Virgo O3 events, the result is compatible with the one by the traditional Bayesian inference method for the gravitational wave events with signal-to-noise ratios higher than typical threshold value. We also discuss some possible ways for future improvement.\n",
            "----------------------------------------\n",
            "Title: Irish Minerva Writers and the Affordances of Big Data: Some Preliminary Findings\n",
            "Abstract: This article explores how big data – or very large collections of data that are too extensive to be evaluated in any meaningful way by conventional literary analysis – and machine learning can help us to recover the cultural impact of Irish-authored texts published by London’s Minerva Press, the most prolific – and critically decried – publisher of popular fiction in Romantic-era Britain. In particular, it outlines how Named-Entity Recognition and Natural Language Processing can facilitate an analysis of intertextual references to Minerva’s Irish-authored works in the British Library’s open access Nineteenth-Century Literature Dataset, which comprises approximately 68,000 digitized volumes of text originally published between 1789 and 1900. Identifying and exploring these allusions helps to reveal the ongoing influence of Minerva texts in the long nineteenth century despite critical condemnation both then and now. Quantitative data invites qualitative exploration of authorial engagement with these publications and with the Minerva Press more generally in nineteenth-century Anglophone literature. In this, the article argues, machine learning provides a useful tool in recovering the network of textual relations fundamentally linked to Minerva’s Irish writers and indicative of their long-lasting impact – both negatively and positively construed – on literary production of the period.\n",
            "----------------------------------------\n",
            "Title: A Hybrid Feature Selection Algorithm Based on Collision Principle and Adaptability\n",
            "Abstract: Feature selection plays a significant role in machine learning and data mining, where the goal is to screen out the most representative and relevant subset of features from a large collection of features to improve the performance and generalization ability of the model. In this paper, a hybrid feature selection algorithm that combines a filter algorithm and an improved particle swarm optimization algorithm is proposed, that is, the Information Gain and Maximum Pearson Minimum Mutual Information improved Adaptive Particle Swarm Optimization algorithm (IGMPMMIAPSO). First, combined with the characteristics of the Pearson correlation coefficient and mutual information, a filter algorithm called Maximum Pearson Minimum Mutual Information (MPMMI) is proposed. The algorithm balances the relevance and redundancy between the features by adjusting two weight parameters ( $w_{p1}$ and $w_{p2}$ ). Second, Adaptive Adjustment of Control (AAC) is introduced to update the particle swarm optimization algorithm, so that the particle velocity has a higher searching ability, and the diversity of population position changes is increased. The improved algorithm was used as the wrapper algorithm. Simultaneously, the concepts of the No Continuous Change (NCC) times and collision distance values are proposed. According to these, the IGMPMMIAPSO algorithm is proposed by combining the filter algorithm and wrapper algorithm. To verify the performance of the proposed algorithm, we experimented with other state-of-the-art hybrid algorithms using eight datasets. The experimental results show that the classification accuracy of the proposed algorithm is at least 0.1% higher than that of the other five algorithms, and the feature subset length is shorter.\n",
            "----------------------------------------\n",
            "Title: Photorealistic Monocular Gaze Redirection Using Machine Learning\n",
            "Abstract: We propose a general approach to the gaze redirection problem in images that utilizes machine learning. The idea is to learn to re-synthesize images by training on pairs of images with known disparities between gaze directions. We show that such learning-based re-synthesis can achieve convincing gaze redirection based on monocular input, and that the learned systems generalize well to people and imaging conditions unseen during training. We describe and compare three instantiations of our idea. The first system is based on efficient decision forest predictors and redirects the gaze by a fixed angle in real-time (on a single CPU), being particularly suitable for the videoconferencing gaze correction. The second system is based on a deep architecture and allows gaze redirection by a range of angles. The second system achieves higher photorealism, while being several times slower. The third system is based on real-time decision forests at test time, while using the supervision from a “teacher” deep network during training. The third system approaches the quality of a teacher network in our experiments, and thus provides a highly realistic real-time monocular solution to the gaze correction problem. We present in-depth assessment and comparisons of the proposed systems based on quantitative measurements and a user study.\n",
            "----------------------------------------\n",
            "Title: Study on Structural Health Monitoring Practice Using Artificial Intelligence\n",
            "Abstract: Given the rise of artificial intelligence, there are numerous intra-discipline studies taking place driven by the AI's powerful data mining and analysis capability. In the field of civil structure engineering, this new trend for the past decade has inspired many researchers to develop novel and powerful engineering methodologies for the studies in civil structural design, analysis and rehabilitation. Structural Health Monitoring (SHM), as a key branch of structural engineering, has undoubtedly attracts favors from the academics due to its characteristics that require massive dataset processing and continuous monitoring. This paper reviews the focus of SHM, compares the new wireless sensor network (WSN) with traditional wired sensor networks; and regarding AI in the structural engineering practices as its most important branch in structural engineering: Machine Learning (ML), the mostly used ML coding system Python and relative libraries. Finally, a series of studies with novel perspectives or approaches are reviewed, all of which feature AI-assisted and intelligent sensing.\n",
            "----------------------------------------\n",
            "Title: Categorizing Touch-Input Locations from Touchscreen Device Interfaces via On-Board Mechano-Acoustic Transducers\n",
            "Abstract: Many mobile electronics devices, including smartphones and tablets, require the user to interact physically with the device via tapping the touchscreen. Conveniently, these compact devices are also equipped with high-precision transducers such as accelerometers and microphones, integrated mechanically and designed on-board to support a range of user functionalities. However, unintended access to these transducer signals (bypassing normal on-board data access controls) may allow sensitive user interaction information to be detected and thereby exploited. In this study, we show that acoustic features extracted from the on-board microphone signals, supported with accelerometer and gyroscope signals, may be used together with machine learning techniques to successfully determine the user’s touch input location on a touchscreen: our ensemble model, namely the random forest model, predicts touch input location with up to 86% accuracy in a realistic scenario. Accordingly, we present the approach and techniques used, the performance of the model developed, and also discuss limitations and possible mitigation methods to thwart possible exploitation of such unintended signal channels.\n",
            "----------------------------------------\n",
            "Title: Machine learning-based infection diagnostic and prognostic models in post-acute care settings: a systematic review\n",
            "Abstract: OBJECTIVES\n",
            "This study aims to (1) review machine learning (ML)-based models for early infection diagnostic and prognosis prediction in post-acute care (PAC) settings, (2) identify key risk predictors influencing infection-related outcomes, and (3) examine the quality and limitations of these models.\n",
            "\n",
            "\n",
            "MATERIALS AND METHODS\n",
            "PubMed, Web of Science, Scopus, IEEE Xplore, CINAHL, and ACM digital library were searched in February 2024. Eligible studies leveraged PAC data to develop and evaluate ML models for infection-related risks. Data extraction followed the CHARMS checklist. Quality appraisal followed the PROBAST tool. Data synthesis was guided by the socio-ecological conceptual framework.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Thirteen studies were included, mainly focusing on respiratory infections and nursing homes. Most used regression models with structured electronic health record data. Since 2020, there has been a shift toward advanced ML algorithms and multimodal data, biosensors, and clinical notes being significant sources of unstructured data. Despite these advances, there is insufficient evidence to support performance improvements over traditional models. Individual-level risk predictors, like impaired cognition, declined function, and tachycardia, were commonly used, while contextual-level predictors were barely utilized, consequently limiting model fairness. Major sources of bias included lack of external validation, inadequate model calibration, and insufficient consideration of data complexity.\n",
            "\n",
            "\n",
            "DISCUSSION AND CONCLUSION\n",
            "Despite the growth of advanced modeling approaches in infection-related models in PAC settings, evidence supporting their superiority remains limited. Future research should leverage a socio-ecological lens for predictor selection and model construction, exploring optimal data modalities and ML model usage in PAC, while ensuring rigorous methodologies and fairness considerations.\n",
            "----------------------------------------\n",
            "Title: Flight Data of Airplane for Wind Forecasting\n",
            "Abstract: Understanding and predicting weather behavior is vital for informing pilots about changing flight conditions. This paper presents a new approach towards forecasting one component of weather information, wind speed, from data captured by airplanes in flight. We compare two datasets for prediction suitability, and a collinearity analysis between these datasets reveals a better model performance with smaller test error with one of them. We then apply machine learning and a genetic algorithm to process this data further and arrive at a competitive error rate. Finally, we create an offline software for wind prediction using the best performing classifier.\n",
            "----------------------------------------\n",
            "Title: Regularization techniques for fine-tuning in neural machine translation\n",
            "Abstract: We investigate techniques for supervised domain adaptation for neural machine translation where an existing model trained on a large out-of-domain dataset is adapted to a small in-domain dataset. In this scenario, overfitting is a major challenge. We investigate a number of techniques to reduce overfitting and improve transfer learning, including regularization techniques such as dropout and L2-regularization towards an out-of-domain prior. In addition, we introduce tuneout, a novel regularization technique inspired by dropout. We apply these techniques, alone and in combination, to neural machine translation, obtaining improvements on IWSLT datasets for English→German and English→Russian. We also investigate the amounts of in-domain training data needed for domain adaptation in NMT, and find a logarithmic relationship between the amount of training data and gain in BLEU score.\n",
            "----------------------------------------\n",
            "Title: Molecular dynamics simulation of metallic Al-Ce liquids using a neural network machine learning interatomic potential.\n",
            "Abstract: Al-rich Al-Ce alloys have the possibility of replacing heavier steel and cast irons for use in high-temperature applications. Knowledge about the structures and properties of Al-Ce alloys at the liquid state is vital for optimizing the manufacture process to produce desired alloys. However, reliable molecular dynamics simulation of Al-Ce alloy systems remains a great challenge due to the lack of accurate Al-Ce interatomic potential. Here, an artificial neural network (ANN) deep machine learning (ML) method is used to develop a reliable interatomic potential for Al-Ce alloys. Ab initio molecular dynamics simulation data on the Al-Ce liquid with a small unit cell (∼200 atoms) and on the known Al-Ce crystalline compounds are collected to train the interatomic potential using ANN-ML. The obtained ANN-ML model reproduces well the energies, forces, and atomic structure of the Al90Ce10 liquid and crystalline phases of Al-Ce compounds in comparison with the ab initio results. The developed ANN-ML potential is applied in molecular dynamics simulations to study the structures and properties of the metallic Al90Ce10 liquid, which would provide useful insight into the guiding experimental process to produce desired Al-Ce alloys.\n",
            "----------------------------------------\n",
            "Title: PREDICTION OF BITCOIN PRICE USING MACHINE LEARNING ALGORITHMS\n",
            "Abstract: This project is implemented to predict the Bitcoin price accurately taking into consideration various parameters that affects the Bitcoin value. Bitcoins are put away in an advanced wallet which is essentially similar to a virtual financial balance. it is important to anticipate the estimation of Bitcoin so right venture choices can be made. The cost of Bitcoin doesn’t rely upon the business occasions or mediating government not at all like securities exchange. Most measurable procedures pursue the worldview of deciding a specific probabilistic model that best portrays watched information among a class of related models. Likewise, most AI systems are intended to discover models that best fit information. By gathering information from different reference papers and applying in real time. Each and every project has its own set of methodologies of bitcoin price prediction. Machine learning models can likely give us the insight we need to learn about the future of Crypto currency. It will not tell us the future but it might tell us the general trend and direction to expect the prices to move.\n",
            "----------------------------------------\n",
            "Title: Current status in spatiotemporal analysis of contrast‐based perfusion MRI\n",
            "Abstract: In perfusion MRI, image voxels form a spatially organized network of systems, all exchanging indicator with their immediate neighbors. Yet the current paradigm for perfusion MRI analysis treats all voxels or regions‐of‐interest as isolated systems supplied by a single global source. This simplification not only leads to long‐recognized systematic errors but also fails to leverage the embedded spatial structure within the data. Since the early 2000s, a variety of models and implementations have been proposed to analyze systems with between‐voxel interactions. In general, this leads to large and connected numerical inverse problems that are intractible with conventional computational methods. With recent advances in machine learning, however, these approaches are becoming practically feasible, opening up the way for a paradigm shift in the approach to perfusion MRI. This paper seeks to review the work in spatiotemporal modelling of perfusion MRI using a coherent, harmonized nomenclature and notation, with clear physical definitions and assumptions. The aim is to introduce clarity in the state‐of‐the‐art of this promising new approach to perfusion MRI, and help to identify gaps of knowledge and priorities for future research.\n",
            "----------------------------------------\n",
            "Title: Investigating the association of CD36 gene polymorphisms (rs1761667 and rs1527483) with T2DM and dyslipidemia: Statistical analysis, machine learning based prediction, and meta-analysis\n",
            "Abstract: CD36 (cluster of differentiation 36) is a membrane protein involved in lipid metabolism and has been linked to pathological conditions associated with metabolic disorders, such as diabetes and dyslipidemia. A case-control study was conducted and included 177 patients with type-2 diabetes mellitus (T2DM) and 173 control subjects to study the involvement of CD36 gene rs1761667 (G>A) and rs1527483 (C>T) polymorphisms in the pathogenesis of T2DM and dyslipidemia among Jordanian population. Lipid profile, blood sugar, gender and age were measured and recorded. Also, genotyping analysis for both polymorphisms was performed. Following statistical analysis, 10 different neural networks and machine learning (ML) tools were used to predict subjects with diabetes or dyslipidemia. Towards further understanding of the role of CD36 protein and gene in T2DM and dyslipidemia, a protein-protein interaction network and meta-analysis were carried out. For both polymorphisms, the genotypic frequencies were not significantly different between the two groups (p > 0.05). On the other hand, some ML tools like multilayer perceptron gave high prediction accuracy (≥ 0.75) and Cohen’s kappa (κ) (≥ 0.5). Interestingly, in K-star tool, the accuracy and Cohen’s κ values were enhanced by including the genotyping results as inputs (0.73 and 0.46, respectively, compared to 0.67 and 0.34 without including them). This study confirmed, for the first time, that there is no association between CD36 polymorphisms and T2DM or dyslipidemia among Jordanian population. Prediction of T2DM and dyslipidemia, using these extensive ML tools and based on such input data, is a promising approach for developing diagnostic and prognostic prediction models for a wide spectrum of diseases, especially based on large medical databases.\n",
            "----------------------------------------\n",
            "Title: Recognition method of unspecified face expressions based on machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Automatic drusen quantification and risk assessment of age-related macular degeneration on color fundus images.\n",
            "Abstract: PURPOSE\n",
            "To evaluate a machine learning algorithm that allows for computer-aided diagnosis (CAD) of nonadvanced age-related macular degeneration (AMD) by providing an accurate detection and quantification of drusen location, area, and size.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Color fundus photographs of 407 eyes without AMD or with early to moderate AMD were randomly selected from a large European multicenter database. A machine learning system was developed to automatically detect and quantify drusen on each image. Based on detected drusen, the CAD software provided a risk assessment to develop advanced AMD. Evaluation of the CAD system was performed using annotations made by two blinded human graders.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "Free-response receiver operating characteristics (FROC) analysis showed that the proposed system approaches the performance of human observers in detecting drusen. The estimated drusen area showed excellent agreement with both observers, with mean intraclass correlation coefficients (ICC) larger than 0.85. Maximum druse diameter agreement was lower, with a maximum ICC of 0.69, but comparable to the interobserver agreement (ICC = 0.79). For automatic AMD risk assessment, the system achieved areas under the receiver operating characteristic (ROC) curve of 0.948 and 0.954, reaching similar performance as human observers.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "A machine learning system capable of separating high-risk from low-risk patients with nonadvanced AMD by providing accurate detection and quantification of drusen, was developed. The proposed method allows for quick and reliable diagnosis of AMD, opening the way for large dataset analysis within population studies and genotype-phenotype correlation analysis.\n",
            "----------------------------------------\n",
            "Title: Establishing the Correlation between Parkinson's and Heart Disease using Machine Learning Algorithm\n",
            "Abstract: Rhythmic shaking or tremors in a limb are symptoms of the medical condition known as Parkinson's Disease(PD) that affects the nervous system. A person with PD manifests PD-related symptoms. The condition slows down movement, affects speech, and the ability to perform a task, and writing becomes time-consuming for a person suffering from it. The prevalence of PD is 1-2 per 1000 people at any time. Parkinson's Disease cases rise with age and affect 1% of those over the age of 60. Even in this day and age, despite the numerous technological developments and advancements that have been made, the process of early disease detection is still challenging to achieve. As a result of this, it is important to develop automatic methods that are based on machine learning and that assist clinicians in accurately identifying this disease in its early phases. Literature supports the link between Parkinson's disease and the cardiovascular system. In research, the main objective is to establish the correlation between PD and heart disease by using a Machine learning algorithm named Extreme Gradient Boosting. The experiments were run utilizing python libraries such as Numpy, Pandas, and Scikit Learn. The study and experiment suggested that the PD in patients suffering from heart disease (HD) is comparatively less than in patients with a healthy heart.\n",
            "----------------------------------------\n",
            "Title: Linear Classifiers that Encourage Constructive Adaptation\n",
            "Abstract: Machine learning systems are often used in settings where individuals adapt their features to obtain a desired outcome. In such settings, strategic behavior leads to a sharp loss in model performance in deployment. In this work, we aim to address this problem by learning classifiers that encourage decision subjects to change their features in a way that leads to improvement in both predicted and true outcome. We frame the dynamics of prediction and adaptation as a two-stage game, and characterize optimal strategies for the model designer and its decision subjects. In benchmarks on simulated and real-world datasets, we find that classifiers trained using our method maintain the accuracy of existing approaches while inducing higher levels of improvement and less manipulation.\n",
            "----------------------------------------\n",
            "Title: Comparative Quality Estimation for Machine Translation Observations on Machine Learning and Features\n",
            "Abstract: Abstract A deeper analysis on Comparative Quality Estimation is presented by extending the state-of-the-art methods with adequacy and grammatical features from other Quality Estimation tasks. The previously used linear method, unable to cope with the augmented features, is replaced with a boosting classifier assisted by feature selection. The methods indicated show improved performance for 6 language pairs, when applied on the output from MT systems developed over 7 years. The improved models compete better with reference-aware metrics. Notable conclusions are reached through the examination of the contribution of the features in the models, whereas it is possible to identify common MT errors that are captured by the features. Many grammatical/fluency features have a good contribution, few adequacy features have some contribution, whereas source complexity features are of no use. The importance of many fluency and adequacy features is language-specific.\n",
            "----------------------------------------\n",
            "Title: Research on Insulator Detection Method Based on Scene Recognition\n",
            "Abstract: Target recognition of insulators is the prerequisite for the condition assessment of insulator equipment. Accurate identification of insulators is of great significance to insulator maintenance. This paper combines infrared images and machine learning to propose an infrared image insulator detection method for scene recognition including image preprocessing, model prediction and image fusion; construct a target detection model through the structure of encoding and decoding in semantic segmentation, which can accurately identify insulators. The accuracy of the insulator detection method based on scene recognition proposed in this paper has reached 99.6%, while the traditional target recognition method is 44%. It provides solutions for field applications in the field of embedded devices and intelligent robots.\n",
            "----------------------------------------\n",
            "Title: Towards more flexible human-machine speech communication\n",
            "Abstract: The research presented in the paper addresses challenges related to the development of more flexible systems for speech communication between humans and machines. Specifically, the paper presents the main results of the speech technology research group at the Faculty of Technical Sciences, University of Novi Sad, Serbia, in the development of a multilingual human-machine communication system. The approach, which fully exploits recent advances in the area of machine learning and artificial intelligence, extends the basic functionality of a text-to-speech system by increasing its flexibility with respect to the speaking style, speaker identity and even language, by means of neural network embedding. At the same time, the performance of automatic speech recognition is improved in terms of its adaptability to different channels and speakers based on machine learning algorithms originally used in image processing. Domain transfer, as well as creation of dynamic dictionaries have played a crucial role in most recent developments in the area of speech recognition. The focus of the research presented in the paper is on the cases when the available quantity of adaptation data is very small, which corresponds to an increased practical usability of proposed approaches in many real world scenarios.\n",
            "----------------------------------------\n",
            "Title: Addressing Overchoice: Automatically Generating Meaningful Filters from Hotel Reviews\n",
            "Abstract: In this paper we present a hotel filter recommendation method designed to address the cognitive load users face in an overchoice scenario. As online products and services are continuously diversifying, user needs are also becoming increasingly sophisticated. However, with more items to choose from, grasping the entire choice set and differentiating among all matching options becomes increasingly difficult, leading to sub-optimal outcomes. Conventional hotel reservation platforms provide with a limited set of additional filters, but these can not accommodate all intricate user needs. Employing natural language processing and machine learning techniques, we provide a simple framework that identifies meaningful filters from customer reviews. We define criteria and scoring methods to acquire relevant and interesting filters that may help customers refine their needs or even identify hidden, previously unknown ones. Our simulated user experiments show that our proposal is capable of identifying intricate and useful filters, leading to increased customer satisfaction.\n",
            "----------------------------------------\n",
            "Title: Multi-spectral and Topographic Fusion for Automated Road Extraction\n",
            "Abstract: Abstract Road geometry is pertinent information in various GIS studies. Reliable and updated road information thus calls for conventional on-site survey being replaced by more accurate and efficient remote sensing technology. Generally, this approach involves image enhancement and extraction of relevant features, such as elongate gradient and intersecting corners. Thus far, its implication is often impeded by wrongly extraction of other urban peripherals with similar pixel characteristics. This paper therefore proposes the fusion of THEOS satellite image and topographic derivatives, obtained from underlying Digital Surface Models (DSM). Multi-spectral indices in thematic layers and surface properties of designated roads were both fed into state-of-the-art machine learning algorithms. The results were later fused, taken into account consistently leveled road surface. The proposed technique was thus able to eliminate irrelevant urban structures such as buildings and other constructions, otherwise left by conventional index based extraction. The numerical assessment indicates recall of 84.64%, precision of 97.40% and overall accuracy of 97.78%, with 0.89 Kappa statistics. Visual inspection reported herewith also confirms consistency with ground truth reference.\n",
            "----------------------------------------\n",
            "Title: Deep Learning Algorithms for Detecting and Mitigating DDoS Attacks\n",
            "Abstract: Raising the threat of Distributed Denial of Service (DDoS) attacks means that high and adapted detection tools are required now more than ever. This research focuses on exploring the latest solutions in preventing DDoS attacks and emphasizes how Artificial Intelligence (AI) is involved in enhancing end-to-end detection techniques. Through the analysis of several key approaches, this work notes that AI-guided models quickly identify and counteract any unusual traffic patterns that may indicate an oncoming DDoS attack. Essential aspects towards creating more resilient networks against such attacks include machine learning algorithms, sophisticated data analytics together with AI based detection systems for traffic pattern recognition. Importantly, AI does well in behavioral analysis because it can distinguish and adapt to changing attack vectors. Additionally, it puts AI into perspective as making positive mitigation strategies possible that contain quick interferences such as temporary halt of traffic, rerouting and targeted block listing with real time control panel operations. On the contrary, current DDoS detection prevention techniques remain critically addressed of persistent challenges and limitations fundamental to them. From what emerges, they should always be ready for innovation and improvement because of how attacks might evolve over time. This paper aligns itself with the position that AI-driven detection mechanisms are natural to network security against DDoS attacks. It underlines the importance of integrating AI-based solutions with conventional practices in order to enhance network resilience and efficiently counteract cyber threats that are evolving all the time.\n",
            "----------------------------------------\n",
            "Title: Implicit softmax transforms for dimensionality reduction\n",
            "Abstract: This paper develops implicit softmax transforms (IST) which are dimensionality reducing transforms that are defined implicitly by minimisation of a weighted sum of Kullback-Leib- ler distances (WKL). The parameters of an IST are trained in combination with the parameters of the polynomial exponents of softmax functions. The resulting gradient of the WKL can be efficiently calculated and the computational effort scales well with the size of the training set. The paper compares IST's to PCA and LDA in classification experiments with two different types of classifiers on three different datasets, two of them from the UCI machine learning repository. It is shown that IST's outperform PCA and LDA in a majority of the cases. In one case reducing the dimension with an IST even gives an improvement over the high dimensional baseline system.\n",
            "----------------------------------------\n",
            "Title: On the Co-evolution of ML Pipelines and Source Code - Empirical Study of DVC Projects\n",
            "Abstract: The growing popularity of machine learning (ML) applications has led to the introduction of software engineering tools such as Data Versioning Control (DVC), MLFlow and Pachyderm that enable versioning ML data, models, pipelines and model evaluation metrics. Since these versioned ML artifacts need to be synchronized not only with each other, but also with the source and test code of the software applications into which the models are integrated, prior findings on co-evolution and coupling between software artifacts might need to be revisited. Hence, in order to understand the degree of coupling between ML-related and other software artifacts, as well as the adoption of ML versioning features, this paper empirically studies the usage of DVC in 391 Github projects, 25 of which in detail. Our results show that more than half of the DVC files in a project are changed at least once every one-tenth of the project’s lifetime. Furthermore, we observe a tight coupling between DVC files and other artifacts, with 1/4 pull requests changing source code and 1/2 pull requests changing tests requiring a change to DVC files. As additional evidence of the observed complexity associated with adopting ML-related software engineering tools like DVC, an average of 78% of the studied projects showed a non-constant trend in pipeline complexity.\n",
            "----------------------------------------\n",
            "Title: A Systematic Review of Machine Learning Approaches for Classifying Indian Sign Language Gestures and Facial Expressions\n",
            "Abstract: Indian Sign Language is the primary mode of communication known to persons who use Indian Sign Language for people who have hearing or language deficits. Different types of machine learning models are used to broaden the scope of communication for those with impairments and illiteracy. There are numerous machine learning models for analyzing gestures, postures, and facial recognition in Indian Sign Language for single-handed and double-handed signals. The present study on hand gestures, recognition, and translation intends to build an essential foundation for developing a platform to facilitate communication for the s pecially-abled with anyone. Machine learning algorithms generally focus on letter recognition or a few fundamental indicators. Communication is essential for exchanging ideas, thoughts, and feelings. Sign language is a kind of communication that uses hand motions. This is aimed toward those with impairments such as muteness and deafness. Machine learning, a branch of artificial intelligence, will aid in identifying various hand motions and predicting the language created by those inputs based on those inputs[2]. Sign language has a grammar that is unique from and independent of English. When compared to English, SL allows for far more freedom in word order. Tense is marked morphologically on verbs in English, but SL (like many other languages, such as Indian Sign Language) communicates tense lexically using temporal adverbs. The structure of ISL and English differs at the phonological level as well. Signed languages, like spoken languages, include a degree of sublexical structure that includes segments and combinatorial rules; however, phonological elements are manual rather than vocal. The way spatial information is conveyed in English and ISL differs substantially. All Deaf people are illiterate in written English. As an output, the SL text can be produced. SL is just physically executed English, where English and SL share the identical linguistic structure-that one is a straight encoding of the other. Many software designers mistakenly believe that deaf users can always access printed the English language in a user interface. Many designers feel that if auditory information is also supplied as written English, the deaf user's demands will be addressed. Prepositions such as “in,” “on,” and “under” are used to indicate locative information in English, as in many other spoken languages. On the other hand, SL encodes locative and motion information via verbal classifier formulations in which hand shape morphemes define item type, and the location of the hands in signing space schematically depicts the spatial relationship between two things. Thus, English and ASL differ significantly in phonological, morphological, and syntactic areas.\n",
            "----------------------------------------\n",
            "Title: Two-stage extreme learning machine for regression\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Trending Algorithms in Machine Learning and issues along with Big data Context in real time Data Processing\n",
            "Abstract: Machine Learning (ML) is booming up and mandatory for many domains like banking, retail social media and online shopping platforms like amazon and flip kart. The article describes the importance of various algorithms along with the fundamental concept with simple code and the corresponding issues. The other dimension of this work is summary of various applications based on the algorithms and some of the observations which may help the researchers in the area of ML to come up with suitable methodologies and corrective measures. The work involves the description of regression, classification and recommender systems with suitable snippets of the coding in R programming. The discussion also provides various issues identified in the regression, classification and recommender systems which may be leading to the future scope for the researchers in the area of ML. We believe that the work helps to know the basic algorithms in the said context with the application areas and issues based on the application domains like social media (Facebook, Twitter), banking sector classification of the customers based on the Cibil score and recommender systems along with product recommendation to the customers while working with amazon and flip kart kind of the online shopping sites. The outcome of the work is a clear specification of algorithms with the help of R programming and working with issues which leads to the new research trends in ML. Integration of Hadoop and R is the best combination in the field of distributed computing and analytics point of view. The algorithms regression and classification along with the specific packages allows making use of the algorithms in the simple manner.\n",
            "----------------------------------------\n",
            "Title: Classification Of Chest X-ray Images Of Covid-19 By Deep Learning Based CNN Model and Attention Mechanism\n",
            "Abstract: Covid-19 is a highly infectious viral disease that has been found in a broad range of animal species, including humans. This fatal virus threatens not just people’s lives, but also their health and the country’s economy. Although Covid-19 is a serious and widespread disease, there is presently no vaccine available to protect against it. Clinical research conducted on people who contracted COVID-19 found that the respiratory system was the most common location of infection after exposure to the virus. When it comes to the diagnosis of lung-related illnesses, imaging modalities such as chest CT and chest x-ray (also known as radiography) are superior. The cost of a chest CT scan is more than that of a thorough chest x-ray, but the latter is much cheaper. When it comes to machine learning, deep learning provides the most impressive results. It provides valuable insight that may be used to the investigation of a large number of chest x-ray images, which may have a substantial impact on the Covid19 screening procedure. Specifically, this research will apply the attention method on the resnet50 features. Six thousand four hundred thirty-two chest x-ray scan samples were generated once the feature learning process was finished using the Xgboost method for validation in the Kaggle repository. These were split between 965 validation examples and 5467 training examples. The proposed model (resnet-attention-xgboost) obtained 98.34 percent, while the supplemented dataset reached 99 percent, when it came to identifying chest X-ray pictures. This is in comparison to earlier models. This study is purely concerned with prospective categorization methodologies for patients infected with covid-19.\n",
            "----------------------------------------\n",
            "Title: Comparison of the Use of Support Vector Machine (SVM) & Random Forest Algorithms (RF) for DDOS Attack Detection\n",
            "Abstract: DDoS attack is one of the major challenges to network security in today’s time, destroying services and creating huge losses. The study here presents an assessment of the performance of Support Vector Machine and Random Forest algorithms on DDoS detection based on the DDoS-SDN datasets. Key metrics that were considered for performance evaluation include accuracy, precision, recall, and F1-score. The results indicate that RF outperforms SVM in complex, high-dimensional datasets such as DDoS-SDN, using its ensemble learning approach to attain greater robustness and accuracy. This research also explores the role of feature selection techniques, such as Genetic Algorithm (GA) and Recursive Feature Elimination (RFE), to enhance model efficiency and accuracy. This paper discusses the strengths and limitations of both algorithms to provide insight into the optimization of machine learning models toward efficient DDoS detection for secure and resilient network systems.\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Title: Comparative Analysis between Supervised Machine Learning and Time Series Models for stock price prediction\n",
            "Abstract: Share markets are considered as an important part of a country’s economy and efficiently functioning stock markets give companies the ability to quickly access capital from the public. This paper aims at identifying the best potential method to predict the adjusted close prices of stocks, through a comparative analysis among Supervised Learning and Time Series models. Techniques like Sliding Window, Forward Fill and Linear Interpolation have been used to preprocess the data. Predictions using Linear Regression, Random Forests, Support Vector Machines, Auto Regressive Integrated Moving Average and Auto Regressive Integrated Moving Average with Exogenous variables, were performed and evaluated based on their prediction accuracies. After the individual evaluation of all the methods, Support Vector Machines are found to give better results for stock price prediction.\n",
            "----------------------------------------\n",
            "Title: Climate adaptation scenarios for a resilient future at UBC Botanical Garden:\n",
            "Abstract: As anthropogenic climate change continues to disrupt forests and species’ ecological niches, there is increasing urgency to create plans surrounding adaptation and mitigation for especially vulnerable species. The University of British Columbia’s Botanical Garden (UBCBG) wants to understand species responses to climate change and whether species within their collection will be able to survive in the Garden, given the effects of climate change. One especially important collection UBCBG curates is maple ( Acer ) trees, currently leading the global consortium of Acer and housing over 50 different species. This study examined the survival probability of four Acer species UBCBG curates including: five-fingered Maple ( Acer pentaphyllum Diels), considered critically endangered; paperbark/bloodbark Maple ( Acer griseum (Franch.) Pax), considered endangered; bigleaf maple ( Acer macrophyllum Pursh), not endangered; and vine maple ( Acer circinatum Pursh), not endangered. Maxent, a popular machine-learning algorithm, was used with open- source WorldClim’s 19 bioclimatic variables and provided presence -only occurrence data to conduct species distribution models for each tree species. Each model was evaluated using area under the curve (AUC). AUC scores were considered ‘good’ for each model; A. griseum - 0.95; A. pentaphyllum - 0.877; A. macrophyllum - 0.986; A. circinatum - 0.976. However, future distribution maps contain questionable results due to insufficient field data to inform the model, such as in-field temperature, moisture, elevation, and surrounding vegetation data. Though results can be interpreted as binary regarding whether or not UBCBG will be suitable for each species, they should be taken as preliminary ideas where management plans for mitigation and adaptation can be developed. This study concludes by detailing the importance of field data collection and provides future directions for research that UBCBG may consider when conducting similar analysis.\n",
            "----------------------------------------\n",
            "Title: A Review of Machine Learning Algorithms and Feature Selection Techniques for Cardiovascular Disease Prediction: Insights and Implications\n",
            "Abstract: Cardiovascular disease (CVD) is a formidable public health challenge across the globe and is the most prevalent cause of mortality. Early detection and accurate prediction of CVD can help prevent disease progression and reduce the risk of complications. Machine learning (ML) techniques show promising results in improving the accuracy and efficiency of CVD prediction to precision. However, the effectiveness of machine learning algorithms in CVD prediction largely depends on the selection of relevant features from complex datasets. The performance and interpretability of ML models are improved by feature selection strategies, which attempt to identify significant attributes while eliminating duplicate or irrelevant features. The feature selection and ML algorithms for CVD are thoroughly reviewed in this publication. The review provides insight into the selection of appropriate feature selection techniques and machine learning algorithms for accurate CVD prediction and evaluates the effectiveness and performance of these methods on cardiovascular datasets. Insights from the findings of this study can be used for interpreting the selection of optimal feature selection methods and ML algorithms for the precise prediction of cardiovascular disease, thereby improving patient outcomes and reducing healthcare costs.\n",
            "----------------------------------------\n",
            "Title: Mapping global distributions of clay-size minerals via soil properties and machine learning techniques.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Data-Driven Models to Predict Hydrocarbon Production From Unconventional Reservoirs by Thermal Recovery\n",
            "Abstract: \n",
            " In the numerical simulations of thermal recovery for unconventional resources, reservoir models involve complex multicomponent-multiphase flow in non-isothermal conditions, where spatial heterogeneity necessitates the huge number of discretized elements. Proxy modeling approaches have been applied to efficiently approximate solutions of reservoir simulations in such complex problems. In this study, we apply machine learning technologies to the thermal recovery of unconventional resources, for the efficient computation and prediction of hydrocarbon production. We develop data-driven models applying artificial neural network (ANN) to predict hydrocarbon productions under heterogeneous and unknown properties of unconventional reservoirs. We study two different thermal recovery methods—expanding solvent steam-assisted gravity drainage for bitumen and in-situ upgrading of oil shale. We obtain training datasets by running high-fidelity simulation models for these two problems. As training datasets of ANN models, diverse input and output data of phase and component productions are generated, by considering heterogeneity and uncertainty. In the bitumen reservoirs, diverse permeability anisotropies are considered as unknown properties. Similarly, in the oil shale reservoirs, diverse kerogen decomposition kinetics are considered. The performance of data-driven models is evaluated with respect to the position of the test dataset. When the test data is inside of the boundary of training datasets, the developed data-driven models based on ANN reliably predict the cumulative productions at the end of the recovery processes. However, when the test data is at the boundary of training datasets, physical insight plays a significant role to provide a reliable performance of data-driven models.\n",
            "----------------------------------------\n",
            "Title: Cognitive Artiﬁcial Intelligence: Learning and reasoning by analogy\n",
            "Abstract: . Analogies are an important part of how we process information. New information is abstracted and matched to information we acquired previously, generating insight and allowing the transfer of skills and expectations through abductive reasoning. This paper sums up research by Patrick H. Winston described in his papers ”Learning structural descriptions from examples” and ”Learning and reasoning by analogy: The details”, wherein he presents theories of analogical reasoning and explores how a machine might also learn those capabilities\n",
            "----------------------------------------\n",
            "Title: A rapid selection strategy for umami peptide screening based on machine learning and molecular docking.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Asymmetric and Sample Size Sensitive Entropy Measures for Supervised Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Unsupervised methods for finding protein complexes from PPI networks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Assessing Anomaly Detection Algorithms in Mobile Networks\n",
            "Abstract: Accurate and timely anomaly detection is critical for ensuring the reliable performance of modern telecommunication networks. However, monitoring vast amounts of operational data in real-time poses challenges for both human experts and traditional rule-based detection systems. This paper empirically evaluates several contemporary machine learning-based algorithms using a real-world dataset capturing metrics from EUtranCell. Models are assessed based on their detection of anomalies previously identified by domain experts. Additionally, this paper conducts an in-depth analysis of total cases flagged to evaluate calibration beyond reported matches. Results show that while some models detect most known anomalies, histogram examination reveals these models tend to label numerous observations near operating thresholds as outliers. Overall, the study examines the capabilities and limitations of different anomaly detection techniques for supporting cognitive telecom network operations.\n",
            "----------------------------------------\n",
            "Title: Thermal and Energy Management Based on Bimodal Airflow-Temperature Sensing and Reinforcement Learning\n",
            "Abstract: Multi-physical field sensing and machine learning have drawn great attention in various fields such as sensor networks, robotics, energy devices, smart buildings, intelligent system and so on. In this paper, we present a novel efficient method for thermal and energy management based on bimodal airflow-temperature sensing and reinforcement learning, which expedites an exploration process by self-learning and adjusts action policy only through actuators interacting with the environment, being free of the controlled object model and priori experiences. In general, training of reinforcement learning requires a large amount of data iterations, which takes a long time and is not suitable for real-time control. Here, we propose an approach to speed up the learning process by indicating the action adjustment direction. We adopt tailor-designed bimodal sensors to simultaneously detect airflow and temperature field, which provides comprehensive information for reinforcement learning. The proposed thermal and energy management incorporates bimodal parametric sensing with an improved actor-critic algorithm to realize self-learning control. Experiments of thermal and energy management in a multi-module integrated system validate the effectiveness of the proposed methodology, which demonstrate high efficiency, fast response, and good robustness in various control scenarios. The proposed methodology can be widely applied to thermal and energy management of diverse integrated systems.\n",
            "----------------------------------------\n",
            "Title: Functional Connectivity-Based Prediction of Autism on Site Harmonized ABIDE Dataset\n",
            "Abstract: Objective: The larger sample sizes available from multi-site publicly available neuroimaging data repositories makes machine-learning based diagnostic classification of mental disorders more feasible by alleviating the curse of dimensionality. However, since multi-site data are aggregated post-hoc, i.e. they were acquired from different scanners with different acquisition parameters, non-neural inter-site variability may mask inter-group differences that are at least in part neural in origin. Hence, the advantages gained by the larger sample size in the context of machine-learning based diagnostic classification may not be realized. Methods: We address this issue using harmonization of multi-site neuroimaging data using the ComBat technique, which is based on an empirical Bayes formulation to remove inter-site differences in data distributions, to improve diagnostic classification accuracy. Specifically, we demonstrate this using ABIDE (Autism Brain Imaging Data Exchange) multi-site data for classifying individuals with Autism from healthy controls using resting state fMRI-based functional connectivity data. Results: Our results show that higher classification accuracies across multiple classification models can be obtained (especially for models based on artificial neural networks) from multi-site data post harmonization with the ComBat technique as compared to without harmonization, outperforming earlier results from existing studies using ABIDE. Furthermore, our network ablation analysis facilitated important insights into autism spectrum disorder pathology and the connectivity in networks shown to be important for classification covaried with verbal communication impairments in Autism. Conclusion: Multi-site data harmonization using ComBat improves neuroimaging-based diagnostic classification of mental disorders. Significance: ComBat has the potential to make AI-based clinical decision-support systems more feasible in psychiatry.\n",
            "----------------------------------------\n",
            "Title: Massive MIMO Channel Prediction Using Machine Learning: Power of Domain Transformation\n",
            "Abstract: To compensate the loss from outdated channel state information in wideband massive multiple-input multipleoutput (MIMO) systems, channel prediction can be performed by leveraging the temporal correlation of wireless channels. Machine learning (ML)-based channel predictors for massive MIMO systems were designed recently; however, the time overhead to collect a large amount of training data directly affects the latency of the system. In this paper, we propose a novel ML-based channel prediction technique, which can reduce the time overhead to collect the training data by transforming the domain of channels from subcarrier to antenna in wideband massive MIMO systems. Numerical results show that the proposed technique can not only reduce the time overhead but also give additional performance gain compared to the ML-based channel prediction techniques without the domain transformation.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Based Mobile Traffic Forecasting for Large Scale 5G Networks\n",
            "Abstract: In this study, we extract and simulate traffic patterns from more than 9,000 base station cells installed in different metropolitan areas per the need that the service provider must comprehend and forecast mobile traffic in large scale cellular networks to govern and manage base station placement, load balancing, and network planning mechanisms. To accomplish this, we create, implement, and assess a method in which cells are first categorized by their point of interest and then clustered based on their temporal distribution in each region. The proposed model has been tested using real world 5G mobile traffic datasets collected over 31 weeks in various cities. Our proposed model is capable of predicting mobile traffic patterns up to 2 weeks in advance and outperforms the naive baseline method by 2.5% overall.\n",
            "----------------------------------------\n",
            "Title: Boosting Weather Prediction with Machine Learning\n",
            "Abstract: WeatherBench is a data set compiled to serve as a standard for evaluating new approaches to artificial intelligence–driven weather forecasting.\n",
            "----------------------------------------\n",
            "Title: Automated Cell Recognition using Single-cell RNA Sequencing with Machine Learning\n",
            "Abstract: This paper investigates the superiority and limitations of different dimensionality reduction schemes and classification methods in specific single-cell RNA sequencing (scRNA-seq) data sets. With systematic analysis as well as variables-controlled experiments, a pipeline was constructed from rpkm data to final cell type recognition and multiple dimension reduction methods are applied (including PCA, AutoEncoder, ISOMAP, and the combination algorithm of PCA+t-SNE) and multiple classifiers (Random Forest and Support Vector Machine, etc.) to obtain the accuracy difference of multiple solutions. By comparing the variation of different models and parameters on the final classification accuracy, this paper summarizes and outlook the information loss and classification effects of different processing schemes on the data set and seeks to find the best combination from them. Using the combination of PCA+SVM, this work obtained 53.13% global maximum accuracy and based on this result to further explore the possibility of improving accuracy and model transfer learning in a wider range of applications.\n",
            "----------------------------------------\n",
            "Title: Application of Machine Learning in Early Detection of Parkinson's disease Using Vocal Features\n",
            "Abstract: Parkinson's disease (PD) is a neurodegenerative disorder that significantly impacts motor functions. Early and accurate detection of PD is crucial for effective treatment and management. This research explores the application of machine learning techniques to detect Parkinson's disease using vocal features from the UCI Parkinson's Disease Data Set. The study compares the performance of four machine learning models: Logistic Regression, Random Forest Classifier, Decision Tree Classifier, and Support Vector Machine (SVM). The dataset was split into training and testing sets, with each model evaluated based on accuracy and confusion matrix metrics. The Decision Tree Classifier and Random Forest Classifier achieved perfect accuracy on the training set, while the SVM model demonstrated the highest accuracy (89.74%) on the test set with a recall rate of 96.77%. These findings indicate that machine learning models, particularly SVM, can effectively contribute to the early detection of Parkinson's disease.\n",
            "----------------------------------------\n",
            "Title: Doubly robust, machine learning eﬀect estimation in real-world clinical sciences: A practical evaluation of performance in molecular epidemiology cohort settings\n",
            "Abstract: Modern eﬃcient estimators such as AIPW and TMLE facilitate the application of ﬂexible, non-parametric machine learning algorithms to improve treatment and outcome model ﬁt, allowing for some model misspeciﬁcation while still maintaining desired bias and variance properties. Recent simulation work has pointed to essential conditions for eﬀective application including: the need for cross-ﬁtting, using of a broad library of well-tuned, ﬂexible learners (Naimi et al. (2021)), and suﬃciently large sample sizes (Zivich and Breskin (2021), Pang et al. (2016)). In these settings, cross-ﬁt, doubly robust estimators ﬁt with machine learning appear to be clearly superior to conventional alternatives. However, commonly simulated conditions diﬀer in important ways from settings in which these estimators may be most useful, namely in high-dimensional, observational settings (Pang et al. (2016)) where: costs of measurements limit sample size, high numbers of covariates may only contain a subset of true confounders, and where model misspeciﬁcation may include the omission of essential biological interactions. In such settings, computationally-intensive and challenging to optimize cross-ﬁt, ensemble learning-based estimators may have less of a practical advantage. Traditional best practices for simulation studies and recent work (Stokes et al. (2020)) stress the importance of mimicking the settings for application as closely as possible. Here we present extensive simulation results drawing data on 331 covariates from 1178 subjects of a multi-omic, longitudinal birth cohort while ﬁxing treatment and outcome eﬀects. We ﬁt models under various conditions including under-and over-(e.g. excess orthogonal covariates) speciﬁcation, and missing interactions using both state-of-the-art and less-computationally intensive (e.g. singly-ﬁt, parametric) estimators. In real data structures, we ﬁnd in nearly every scenario (e.g. model misspeciﬁcation, single-or cross-ﬁt-estimators), that eﬃcient estimators ﬁt with parametric learner outperform those that include non-parametric learners on the basis of bias and coverage. For the typical setting where correct model speciﬁcation is unlikely, we ﬁnd the use of double cross-ﬁt eﬃcient estimators using simple smooth, parametric learners to be the optimal solution, taking 2-5 times less computation time than models ﬁt with non-smooth algorithms while having equal or better performance.\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Approach For The Identification Of Olive Fruit Fly in Greece\n",
            "Abstract: Contemporary agriculture faces critical challenges to maintain a future that meets global food demand. Precise and early detection of plantations’ pest and disease threats is crucial for controlling their spread, maintaining production quality and volume, minimizing costs, and reducing trade disruptions, sometimes even lessening human health risks. Pest management in agriculture benefits significantly from the application of deep learning (DL) techniques for more efficient detection and monitoring, overcoming the inefficiencies of traditional labor-intensive methods. This study develops a convolutional neural network (CNN) and benchmarks it against state-of-the-art (SOTA) DL models to identify the primary threat to olive trees, Bactrocera oleae (also known as Dacus). Using a data set composed of images that span 102 insect categories, CNN demonstrated a high accuracy of 96. 32% to distinguish Dacus from other insect species.\n",
            "----------------------------------------\n",
            "Title: Guest editorial: Special issue on Extreme learning machine and applications (I)\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Deep Learning and Social Network Analysis to Understand and Manage Extreme Flooding\n",
            "Abstract: Combining machine learning with social network analysis (SNA) can leverage vast amounts of social media data to better respond to crises. We present a case study using Twitter data from the March 2019 Nebraska floods in the United States, which caused over $1 billion in damage in the state and widespread evacuations of residents. We use a subset of machine learning, deep learning (DL), to classify text content of 11,982 tweets, and we integrate that with SNA to understand the structure of tweet interactions. Our DL approach pre&#8208;trains our model with a DL language technique, BERT, and then trains the model using the standard training dataset to sort a dataset of tweets into classes tailored to crisis events. Several performance measures demonstrate that our two&#8208;tiered trained model improves domain adaptation and generalization across different extreme weather event types. This approach identifies the role of Twitter during the damage containment stage of the flood. Our SNA identifies accounts that function as primary sources of information on Twitter. Together, these two approaches help crisis managers filter large volumes of data and overcome challenges faced by simple statistical models and other computational techniques to provide useful information during crises like flooding.\n",
            "----------------------------------------\n",
            "Title: Voxel-wise prostate cell density prediction using multiparametric magnetic resonance imaging and machine learning\n",
            "Abstract: Abstract Background: There are currently no methods to estimate cell density in the prostate. This study aimed to develop predictive models to estimate prostate cell density from multiparametric magnetic resonance imaging (mpMRI) data at a voxel level using machine learning techniques. Material and methods: In vivo mpMRI data were collected from 30 patients before radical prostatectomy. Sequences included T2-weighted imaging, diffusion-weighted imaging and dynamic contrast-enhanced imaging. Ground truth cell density maps were computed from histology and co-registered with mpMRI. Feature extraction and selection were performed on mpMRI data. Final models were fitted using three regression algorithms including multivariate adaptive regression spline (MARS), polynomial regression (PR) and generalised additive model (GAM). Model parameters were optimised using leave-one-out cross-validation on the training data and model performance was evaluated on test data using root mean square error (RMSE) measurements. Results: Predictive models to estimate voxel-wise prostate cell density were successfully trained and tested using the three algorithms. The best model (GAM) achieved a RMSE of 1.06 (± 0.06) × 103 cells/mm2 and a relative deviation of 13.3 ± 0.8%. Conclusion: Prostate cell density can be quantitatively estimated non-invasively from mpMRI data using high-quality co-registered data at a voxel level. These cell density predictions could be used for tissue classification, treatment response evaluation and personalised radiotherapy. Graphical Abstract\n",
            "----------------------------------------\n",
            "Title: Evolving Applications of Artificial Intelligence and Machine Learning in Infectious Diseases Testing\n",
            "Abstract: Abstract Background Artificial intelligence (AI) and machine learning (ML) are poised to transform infectious disease testing. Uniquely, infectious disease testing is technologically diverse spaces in laboratory medicine, where multiple platforms and approaches may be required to support clinical decision-making. Despite advances in laboratory informatics, the vast array of infectious disease data is constrained by human analytical limitations. Machine learning can exploit multiple data streams, including but not limited to laboratory information and overcome human limitations to provide physicians with predictive and actionable results. As a quickly evolving area of computer science, laboratory professionals should become aware of AI/ML applications for infectious disease testing as more platforms are become commercially available. Content In this review we: (a) define both AI/ML, (b) provide an overview of common ML approaches used in laboratory medicine, (c) describe the current AI/ML landscape as it relates infectious disease testing, and (d) discuss the future evolution AI/ML for infectious disease testing in both laboratory and point-of-care applications. Summary The review provides an important educational overview of AI/ML technique in the context of infectious disease testing. This includes supervised ML approaches, which are frequently used in laboratory medicine applications including infectious diseases, such as COVID-19, sepsis, hepatitis, malaria, meningitis, Lyme disease, and tuberculosis. We also apply the concept of “data fusion” describing the future of laboratory testing where multiple data streams are integrated by AI/ML to provide actionable clinical knowledge.\n",
            "----------------------------------------\n",
            "Title: Hybrid Enriched Stacked Auto Encoder and FFO-MPARCNN Algorithm for the Multispectral Image LULC Classification\n",
            "Abstract: \n",
            " The satellite imagery classification task is fundamental to spatial knowledge discovery. Land Cover and Land usage (LULC) maps are created using a variety of image classification techniques, making it easier to conduct research on spatial and ecological processes as well as human activities. One of the most well-known applications of geographical monitoring is LULC classification. Owing to its improved feature learning and feature expression capacity, the convolutional neural network (CNN) has made several breakthroughs in feature extraction as well as classification of multispectral images in recent times as compared with conventional machine learning approaches. But on the other hand, standard CNN models have certain disadvantages, for instance, a large number of layers, which contribute to difficult computing costs. The Hybrid Enriched Stacked Auto Encoder and Pre-Activated Residual Convolutional Neural Network combined with a Fruit Fly Optimization Algorithm (HESAE-FFO-MPARCNN) has formulated where FFO used to optimise parameters and thus enhance the accuracy of classification in this work to tackle this issue. The designed FFO-MPARCNN model with its modified hyperparameters produces higher classical models as PB-RNN, ResNet and FHS-DBN for computational efficiency and accuracy of classification.\n",
            "----------------------------------------\n",
            "Title: DQAT: An Online Machine Learning Framework for Real-Time Data Quality Assurance in IoT\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Connecting People to Avail the Resources During Crisis Through Twitter Using Machine Learning\n",
            "Abstract: Although social media has become the most widely utilized and active form of communication, research on its usage in crisis management is still in its early stages. As a result, this research examines the rising body of knowledge on social media and crisis management. [1] Between October 2017 and January 2018, a review was conducted, which included locating and retrieving records from an electronic database. The outcomes of this study indicated that the rise of social media has altered the landscape of crisis communication by allowing for greater engagement. However, due to its nature, social media might also be used to spark a crisis. This means that the crisis can be both produced and disseminated through social media. Nonetheless, social media's promise as a crisis-resolution tool is undeniable. It has the capability of proving a claim, dispelling false rumors, or just demonstrating a fact. As a result, practitioners should understand how social media works and how to best use it to interact with their stakeholders. This study also includes other findings, limits, and useful suggestions for scholars and practitioners interested in learning more about the role of social media on crisis communication and management. As most of the crisis problem were reported via twitter. However, most of the problem reported and corresponding responses via twitter were not successfully exchanged between victim’s and resource organization. As a result, most of the tweets were not getting help. Thus, we designed a platform where people can avail the resources of crisis through tweets matching concept using machine learning.\n",
            "----------------------------------------\n",
            "Title: How COVID-19 Impacted CO2 Emissions Based on Electricity Usage: A Machine Learning Approach\n",
            "Abstract: — The goal of this study is to determine the difference in CO2 emissions between 2019-2020 and 2020-2021, more specifically during lockdown periods during the COVID-19 pandemic. In the beginning of the pandemic, most countries were forced into lockdowns, and a countless number of people had to continue their daily work from home in isolation. Previously, people would go to an office or to school and leave their houses empty for eight hours, without having lights or any electronics on. Because of this, there should be a direct correlation between electricity usage before and during lockdowns, as a private residence should have higher electricity consumption during 2020-2021, when they are at home. Using machine learning, we will investigate to see if COVID-19 affected CO2 emissions as a result of more electricity usage in private residences. A model will be made to predict what the CO2 emissions would be for 2019-2020, based on electricity usage data from 2020-2021. Then, the real CO2 emissions from 2019-2020 will be compared with the model’s predicted values, and the difference will indicate if COVID-19 caused an inconsistency between actual and predicted CO2 emissions. Factors that were taken into account when making a model were independent variables relating to outdoor conditions, the number of people living in the house, and the temperature that the thermostat is set at, making the response variable CO2 emissions.\n",
            "----------------------------------------\n",
            "Title: The advantage of intergenic regions as genomic features for machine-learning-based host attribution of Salmonella Typhimurium from the USA\n",
            "Abstract: Salmonella enterica is a taxonomically diverse pathogen with over 2600 serovars associated with a wide variety of animal hosts including humans, other mammals, birds and reptiles. Some serovars are host-specific or host-restricted and cause disease in distinct host species, while others, such as serovar S. Typhimurium (STm), are generalists and have the potential to colonize a wide variety of species. However, even within generalist serovars such as STm it is becoming clear that pathovariants exist that differ in tropism and virulence. Identifying the genetic factors underlying host specificity is complex, but the availability of thousands of genome sequences and advances in machine learning have made it possible to build specific host prediction models to aid outbreak control and predict the human pathogenic potential of isolates from animals and other reservoirs. We have advanced this area by building host-association prediction models trained on a wide range of genomic features and compared them with predictions based on nearest-neighbour phylogeny. SNPs, protein variants (PVs), antimicrobial resistance (AMR) profiles and intergenic regions (IGRs) were extracted from 3883 high-quality STm assemblies collected from humans, swine, bovine and poultry in the USA, and used to construct Random Forest (RF) machine learning models. An additional 244 recent STm assemblies from farm animals were used as a test set for further validation. The models based on PVs and IGRs had the best performance in terms of predicting the host of origin of isolates and outperformed nearest-neighbour phylogenetic host prediction as well as models based on SNPs or AMR data. However, the models did not yield reliable predictions when tested with isolates that were phylogenetically distinct from the training set. The IGR and PV models were often able to differentiate human isolates in clusters where the majority of isolates were from a single animal source. Notably, IGRs were the feature with the best performance across multiple models which may be due to IGRs acting as both a representation of their flanking genes, equivalent to PVs, while also capturing genomic regulatory variation, such as altered promoter regions. The IGR and PV models predict that ~45 % of the human infections with STm in the USA originate from bovine, ~40 % from poultry and ~14.5 % from swine, although sequences of isolates from other sources were not used for training. In summary, the research demonstrates a significant gain in accuracy for models with IGRs and PVs as features compared to SNP-based and core genome phylogeny predictions when applied within the existing population structure. This article contains data hosted by Microreact.\n",
            "----------------------------------------\n",
            "Title: Implementasi deteksi objek pada fitur permainan tebak gambar di website kursus online bahasa inggris dengan Ml5.js\n",
            "Abstract: Penelitian ini bertujuan untuk meningkatkan pengalaman pengguna dalam pembelajaran bahasa Inggris pada website kursus online Hanna Hersop dengan mengusulkan penambahan fitur permainan tebak gambar yang dilengkapi dengan deteksi objek. Hanna Hersop adalah Lembaga Kursus dan Pelatihan (LKP) Bahasa Inggris, menyediakan materi pembelajaran bahasa Inggris secara offline maupun online. Hasil penelitian menunjukkan bahwa penambahan fitur permainan tebak gambar dengan objek deteksi secara signifikan meningkatkan pengalaman pembelajaran para pengguna. Fungsi deteksi objek pada permainan tebak gambar tidak hanya memberikan tantangan tambahan dalam pembelajaran, tetapi juga memberikan pengalaman interaktif yang lebih menarik. Permainan tebak gambar ini memanfaatkan M15.js sebagai library machine learning JavaScript yang menyediakan akses ke algoritma ML di browser yang dibangun di atas Tensorflow.js dan JavaScript, CSS, HTML sebagai kerangka untuk perancangan pada permainan tebak gambar pada website. Hasil dari penelitian ini memberikan wawasan berharga bagi pengembang dan penyelenggara kursus bahasa Inggris online, serta berkontribusi pada pemahaman lebih lanjut tentang bagaimana teknologi digital, khususnya deteksi objek, dapat digunakan secara efektif untuk meningkatkan kualitas pembelajaran. dengan begitu para peserta kursus dapat memperoleh manfaat tambahan dalam memahami dan mempraktikkan bahasa Inggris, menciptakan lingkungan pembelajaran yang inovatif dan efektif. Integrasi deteksi objek pada fitur permainan tebak gambar menjadi solusi inovatif dalam menciptakan lingkungan pembelajaran yang lebih menarik dan efektif.\n",
            "----------------------------------------\n",
            "Title: BCI Research at Inria Bordeaux: making BCI designs usable outside the lab\n",
            "Abstract: This paper presents an overview of the recent BCI research conducted by scientists from Inria Bordeaux. It aims at designing practical BCI systems and applications that could be used outside laboratories. More precisely we describe 1) our work on signal processing and machine learning to make BCI more efficient, robust to noise and with minimal calibration times, as well as 2) practical applications in the research fields of spatial cognition and gaming.\n",
            "----------------------------------------\n",
            "Title: Determination of Anti-SARS-CoV-2 Activity of Compounds Based on Machine Learning\n",
            "Abstract: In 2020, the outbreak of pneumonia caused by novel coronavirus spread rapidly all over the world. In the absence of a specific drug, novel coronavirus is still pandemic all over the world. In this paper, we proposed an improved molecular activity prediction model by adding feature selection method on the basis of comparing different methods to extract molecular features and machine learning models. We first used the anti-SARS-CoV-2 compounds reported in recent literatures to construct the data set, and then constructed three machine learning models. In addition, we tried to use three methods to extract molecular features in each model. In order to further improve the performance of the model, we add three feature selection methods. Through the comparison of different models, finally, we used FCFP to extract molecular features and added lasso feature selection method to establish the SVM model. Its test set accuracy is 90.0%, and the AUC value is 0.961, which could well predict the anti-SARS-CoV-2 activity of the compound. Our model can be used to speed up the research and discovery of anti-SARS-CoV-2 drugs.\n",
            "----------------------------------------\n",
            "Title: Kernel-Based Regularized Learning for Time-Invariant Detection of Paddy Growth Stages from MODIS Data\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Fraudulent E-Commerce Websites Detection Through Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Exploiting augmented intelligence in the modeling of safety-critical autonomous systems\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Formative writing assessment for change – introduction to the special issue\n",
            "Abstract: This current special issue centres on formative writing assessment with children in the elementary grades. Participants in the investigations included in this special issue represent a span from the very youngest students just learning to write to students in fifth and sixth grades who generally have overcome the barriers of knowing how to encode writing, but who face increased demands for producing discursive, audience adapted texts. As editors, we limited papers in the special issue to include studies conducted with students in this grade span because it has been under-researched compared to other grade spans. That these grades have received less attention does not reflect on the importance of early writing instruction; becoming a skilled writer takes time, and the first writing instruction is essential. Becoming a good writer is the result of many complex interactions–including but not limited to–interactions between a writer’s attitude towards writing, her cognitive capacity, the kind of writing instruction she is exposed to, as well as the writer’s perception of textual norms in relation to the reader’s perception of the same norms, and thereby the reader’s textual expectations (Graham, 2018a; Rijlaarsdam et al., 2012; Skar & Aasen, 2021). To help children progress as writers, then, there is a need for tools that can elicit information about students’ writing skills in different domains (e.g. affective, cognitive, textual) and tools that help teachers transform that information into instruction. Such tools are often described as tools for formative assessment. Formative writing assessment has proven to be effective in increasing the writing skills of students. A review by (Graham, 2018b) reported positive effect sizes for text response (d = 0.36), adult feedback (d = 0.87), peer feedback (0.58), self-feedback (d = 0.62) and computerised feedback (d = 0.38). An earlier study by Graham et al. (2011) reported an effect size of d = 1.01 for feedback from adults or peers. So, formative writing assessment can work, and it can lead to positive change. But what is it? Graham (2018b, pp. 145–147) suggested the following definition of formative writing assessment: ‘instructional feedback in writing as information provided by another person, group of people, agency, machine, self, or experience that allows a writer, one learning to write, or a writing teacher/mentor to compare some aspect of performance to an expected, desired, or idealized performance’ and that ‘Formative feedback is derived from assessments that involve collecting information or evidence about student learning, interpreting it in terms of learners’ needs, and using it to alter what happens.’ In other words, formative writing assessment concerns taking actions based on information about a writer’s skills in order to make that writer even more skilled. One might therefore say that formative writing assessment – in the end – is all about consequences. ASSESSMENT IN EDUCATION: PRINCIPLES, POLICY & PRACTICE 2022, VOL. 29, NO. 2, 121–126 https://doi.org/10.1080/0969594X.2022.2089488\n",
            "----------------------------------------\n",
            "Title: Cyberbullying Detection on Social Media Platforms Utilizing Different Machine Learning Approaches\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Characterization of immune microenvironment associated with medulloblastoma metastasis based on explainable machine learning\n",
            "Abstract: Medulloblastoma (MB) is the most common malignant brain tumor in children, with metastasis being the primary cause of recurrence and mortality. The tumor microenvironment (TME) plays a critical role in driving metastasis; however, the mechanisms underlying TME alterations in MB metastasis remain poorly understood.To develop and validate machine learning (ML) models for predicting patient outcomes in MB and to investigate the role of TME components, particularly immune cells and immunoregulatory molecules, in metastasis.ML models were constructed and validated to predict prognosis and metastasis in MB patients. Eight algorithms were evaluated, and the optimal model was selected. Lasso regression was employed for feature selection, and SHapley Additive exPlanations values were used to interpret the contribution of individual features to model predictions. Immune cell infiltration in tumor tissues was quantified using the microenvironment cell populations‐counter method, and immunohistochemistry was applied to analyze the expression and distribution of specific proteins in tumor tissues.The ML models identified metastasis as the strongest predictor of poor prognosis in MB patients, with significantly worse survival outcomes observed in metastatic cases. High infiltration of CD8+ T cells and cytotoxic T lymphocytes (CTLs), along with elevated expression of the TGFB1 gene encoding transforming growth factor beta 1 (TGF‐β1), were strongly associated with metastasis. Independent transcriptomic and immunohistochemical analyses confirmed significantly higher CD8+ T cell/CTL infiltration and TGF‐β1 expression in metastatic compared to nonmetastatic MB samples. Patients with both high CD8+ T cell/CTL infiltration and elevated TGFB1 expression in the context of metastasis exhibited significantly worse survival outcomes compared to patients with low expression and no metastasis.This study identifies metastasis as the key prognostic factor in MB and reveals the pivotal roles of CD8+ T cells, CTLs, and TGF‐β1 within the TME in promoting metastasis and poor outcomes. These findings provide a foundation for developing future therapeutic strategies targeting the TME to improve MB patient outcomes.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Based Strength Prediction of UHPC for Spatial Structures\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Neural Network Approaches to Classify Breast Cancer\n",
            "Abstract: Breast cancer, a fatal tumor that affects both women and men, can be detected early and treated effectively to save lives. In this article, we aim to categorize breast cancer data as either benign or malignant tumors using various techniques such as Deep Learning and Machine Learning. We employ Sequential Neural Networks, Logistic Regression, Random Forest, Decision Tree, and SVM for classification purposes. Upon comparing the results of each classifier, we determine that the Sequential Neural Network achieves the highest accuracy score of 98% in distinguishing between benign and malignant cancers. Accurate classification enables prompt detection of the disease, benefiting patients and doctors alike in their efforts to combat breast cancer.\n",
            "----------------------------------------\n",
            "Title: Improving depth-of-interaction resolution in pixellated PET detectors using neural networks\n",
            "Abstract: Parallax error is a common issue in high-resolution preclinical positron emission tomography (PET) scanners as well as in clinical scanners that have a long axial field of view (FOV), which increases estimation uncertainty of the annihilation position and therefore degrades the spatial resolution. A way to address this issue is depth-of-interaction (DOI) estimation. In this work we propose two machine learning-based algorithms, a dense and a convolutional neural network (NN), as well as a multiple linear regression (MLR)-based method to estimate DOI in depolished PET detector arrays with single-sided readout. The algorithms were tested on an 8× 8 array of 1.53× 1.53× 15 mm3 crystals and a 4× 4 array of 3.1× 3.1× 15 mm3 crystals, both made of Ce:LYSO scintillators and coupled to a 4× 4 array of 3× 3 mm3 silicon photomultipliers (SiPMs). Using the conventional linear DOI estimation method resulted in an average DOI resolution of 3.76 mm and 3.51 mm FWHM for the 8× 8 and the 4× 4 arrays, respectively. Application of MLR outperformed the conventional method with average DOI resolutions of 3.25 mm and 3.33 mm FWHM, respectively. Using the machine learning approaches further improved the DOI resolution, to an average DOI resolution of 2.99 mm and 3.14 mm FWHM, respectively, and additionally improved the uniformity of the DOI resolution in both arrays. Lastly, preliminary results obtained by using only a section of the crystal array for training showed that the NN-based methods could be used to reduce the number of calibration steps required for each detector array.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Reveals Source Compositions of Intraplate Basaltic Rocks\n",
            "Abstract: Recycling of crustal material is thought to introduce pyroxenite to the peridotite mantle. Mapping such lithological heterogeneity within the mantle is crucial to understanding the mantle's chemical evolution but remains challenging. By sampling the mantle source, intraplate basaltic melts provide a unique chance to reveal lithological heterogeneity within the mantle. We train machine learning (ML) models with major oxide data of experimental peridotite and pyroxenite melts to help reveal the mantle source lithology of basaltic rocks. The ML models can predict source lithologies from major oxide information with an accuracy larger than 94%. As a case study, we predict source lithology of the Cenozoic intraplate basaltic rocks in Northeast China. Our ML models suggest that pyroxenite dominates the mantle source of basaltic rocks sitting above the stagnant Pacific slab while peridotite dominates the source of the basaltic rocks located west of the slab tip, consistent with previous studies using other approaches. Our ML models could potentially be used to infer mantle source lithologies of basaltic rocks from other regions around the world.\n",
            "----------------------------------------\n",
            "Title: Multi-Rhythm Capsule Network Recognition Structure for Motor Imagery Classification\n",
            "Abstract: Existing machine learning methods for classification and recognition of EEG motor imagery usually suffer from reduced accuracy for limited training data. To address this problem, this paper proposes a multi-rhythm capsule network (FBCapsNet) that uses as little EEG information as possible with key features to classify motor imagery and further improves the classification efficiency. The network conforms to a small recognition model with only 3 acquisition channels but it can effectively use the limited data for feature learning. Based on the BCI Competition IV 2b data set, experimental results show that the proposed network can achieve 2.41% better performance than existing cutting-edge methods.\n",
            "----------------------------------------\n",
            "Title: Predicting the Compressive Strength of Recycled Concrete Using Ensemble Learning Model\n",
            "Abstract: This research proposes a stacking machine learning method to accurately predict the compressive strength of recycled concrete. The model integrates eXtreme Gradient Boosting (XGBoost), Extra Trees (ET), Decision Tree (DT), and Linear Regression (LR) models, aiming to maximize the prediction accuracy of concrete compressive strength. The model was evaluated using a combination of 63 self-made recycled concrete datasets and 1030 concrete datasets from the UCI Machine Learning Repository. Through optimization based on SHAP values, the new model achieved statistical metrics of RMSE = 1.969, MAE = 1.113, and R2 = 0.987. The comparison and analysis with the existing work show that this method has excellent performance. Additionally, the feature importance analysis based on SHAP values identified the key input variables affecting concrete compressive strength and improved the model’s prediction performance.\n",
            "----------------------------------------\n",
            "Title: Hand Gesture Recognition in Daily Life as an Additional Tool for Unobtrusive Data Labeling in Medical Studies\n",
            "Abstract: For many use cases, such as supervised machine learning, labeled data is needed. However, to collect information for labels in real-life contexts, scientists are confronted with the challenge of gathering labeled data over an extended period. Labeling this data can become problematic, as constant supervision, similar to a laboratory setting, is neither feasible nor desired. Therefore, participants of such studies have to label their data themselves via appropriate apps on a smartphone. Nevertheless, this process can become very obtrusive in daily life and might even influence the results, especially studies regarding emotions. For example, in studies where participants need to indicate their stress levels frequently, labels get missed in situations where it would be inappropriate to take the phone. Consequently, missing these labels presents a significant problem. This paper aims to provide an unobtrusive solution to labeling data in real-world studies. We recorded a dataset consisting of five gestures and data from daily life. Thereby, we provide a set of predefined gestures that can be distinguished from other everyday life activities by using accelerometer and gyroscope sensors of wearable devices on the wrist. The use of predefined hand gestures for labeling data can therefore serve as an additional tool for the labeling process. Two machine learning approaches were compared and achieved promising results with Matthews Correlation Coefficients of up to 0.789 for a Random Forest and up to 0.835 for a Convolutional Neural Network.\n",
            "----------------------------------------\n",
            "Title: Analysis of time-weighted LoRa-based positioning using machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A methodology for measuring the preservation durability of digital formats\n",
            "Abstract: It is now widely recognized that appropriate measures are required for digital preservation to ensure that digital data can be accessed and used currently and in the future. Among all the risks of digital preservation, format obsolescence is one of the most important. There have been several projects or initiatives dealing with the measurement method of format obsolescence risk, but there has been no mechanism to quantify the preservation risk or durability of digital formats based on a self-improving assessment model, executed with the aid of computers. This paper deals with a methodology for measuring the preservation durability of digital formats, especially for their risk assessment. This method is based on a quantitative assessment model for format risk, and can shift the non-quantifiable knowledge or experiences of field experts to a machine identifiable and processible form, or ‘risk scores’. Results can be recognized and communicated by computers automatically and formally, which can assist in the automatic/semi-automatic risk management for digital preservation, sharing this quantified knowledge among communities. Because technologies are changing quickly, the quantitative assessment model for risks will not be a status quo situation. Thus, also presented is a method to fine tune the quantitative assessment model for risk of formats through a self-learning and self-improving style.\n",
            "----------------------------------------\n",
            "Title: Twitter Sentiment Based Mining for Decision Making using Text Classifiers with Learning by Induction\n",
            "Abstract: The amount of data residing in social media currently untapped is certainly limitless as millions of people are constantly posting a message or the other to public forums on the internet. Twitter being one of the largest social media networks with over 336 million monthly active users has proven to be a fertile ground for harvesting opinion from multiple people. This work explores how opinion can be extracted from tweets to discover people’s view concerning a certain subject matter. It focuses mainly on overcoming the limitation of the current approach to social media sentiment based mining for decision making which is that opinions derived from multiple sources are limited to available connections on the social media platforms and lack of improved accuracy of mined opinions. In order to achieve this, the proposed framework provides a platform to mine opinions from more than the available friends and connections on the social media platform and in addition, improve the quality of the opinion mined by implementing supervised learning algorithms with learning by induction in Twitter data analysis. In this research, three different supervised machine learning algorithms were applied to a dataset curated by graduate students at Stanford in order to accurately classify tweets into either positive or negative sentiment based on its content. It was discovered that Maximum Entropy had the highest accuracy of 83.5% among the three algorithms. The research has provided a web application which would enable users such as CEOs, Market Analysts, and random users make quality decision based on others’ opinions.\n",
            "----------------------------------------\n",
            "Title: AN AUTOMATIC FRAMEWORK FOR DOCUMENT SPAM DETECTION USING ENHANCED CONTEXT FEATURE MATCHING\n",
            "Abstract: With the growth in the communication systems, opinions became the most used communication method in the corporates, research and education. Nevertheless, with the increasing popularity the challenge for all internet service providers is to keep matching the demand for bandwidth. The major challenge to keep the bandwidth up to the usage is dealing with the spam messages. A spam communication or review is something that the sender uses for promotion and for the received may be useless. Thus for the receiver the messages are mostly unimportant. The detection of the spam reviews cannot be done at the review server end and need to done at the receiver side. Failing in detecting the spam can easily overload the review communication channel and reduce the effective use of the bandwidth. A number of researchers are carried out in order to detect the spam messages by deploying the filters. The outcomes are partially satisfactory as most of the parallel researches have demonstrated the rejection of the documents based on the pre-defined keywords. Nonetheless, these methods are not satisfactory as the use of words for every review writer may vary. As a result influenced by certain keywords, the receiver may lose some important communications. Thus the demand of the modern research is to enhance the detection of the spam reviews by using enhanced techniques rather than only depending on the keywords. This work proposes a novel automated framework powered by machine learning technique to detect the keywords and improve the detection by deploying context detection methods. The major outcome of this work is to build and demonstrate an automated framework for review spam detection with review rejection filters. The work outcomes into a highly satisfactory detection rate and demonstrate a sustainable model.\n",
            "----------------------------------------\n",
            "Title: Physics-Driven PTV Interpolation Through Learned Regularization\n",
            "Abstract: This paper deals with spatial interpolation of instantaneous Particle Tracking Velocimetry (PTV) data. Such a task can be handled using generic signal processing tools like B-splines, radial basis functions (RBF) or Kriging. We deal with non time-resolved PTV as gathered by dual frame particle image velocimetry (PIV) systems followed by dual frame PTV algorithms. In such a dual frame context, Physics-based interpolation techniques typically rely on enforcement of divergence free constraints on the interpolated field. The aim of this communication is to explore the wider field of Physics-based PTV interpolators based on learning a deep neural network. These interpolators are learned on a database of flow examples that may be generated by high resolution PIV or DNS. We propose an instance of such a Physics-based PTV interpolator based on the machine learning concept of unrolled optimization. This concept is extended in order to deal with random measurement location, characteristic of PTV data. We also show how to use this concept to perform pressure estimation from PTV data, along with velocity interpolation. The concept is illustrated on a 2D laminar flow, DNS data is used to train and benchmark the proposed method against RBF interpolation. The proposed method is shown to be much more robust than RBF interpolation against low density seeding and noise.\n",
            "----------------------------------------\n",
            "Title: AI Based Predictive Maintenance as a Key Enabler for Circular Economy: The KYKLOS 4.0 Approach\n",
            "Abstract: Circular economy (CE) is a recent model of production and consumption. According to the European Parliament, this model simply extends the life cycles of products through sharing, leasing, reusing, repairing, refurbishing, and recycling existing materials as much as possible. Digitalization plays a crucial role in the transformation towards a sustainable circular economy. By providing accurate information about appliances and machines conditions, minimizing waste and promoting a longer life for them can be achieved. Predictive maintenance (PdM) is a service using data analytics and aiming at detecting machine failures, degraded performance, or a downtrend in product quality before one of these occur. Due to the advantages that artificial intelligence (AI) techniques currently offer, more and more predictive maintenance solutions start incorporating them in order to better analyse the gathered data. This paper gives an overview of the Deep Learning toolkit that has been developed within the European project KYKLOS 4.0, and which provides a bunch of functionalities including data collection and preprocessing, models definition, and models validation. This toolkit is also endowed with a graphical user interface facilitating its use. It has also been tested with publicly available datasets as well as datasets collected in manufacturing environments. In the current paper, the toolkit will be described in the context of a pilot where the data were collected from a shipyard located in the Astander city, in Spain.\n",
            "----------------------------------------\n",
            "Title: Detection and Prevention of Smishing Attacks\n",
            "Abstract: Phishing is an online identity theft technique where attackers steal users personal information, leading to financial losses for individuals and organizations. With the increasing adoption of smartphones, which provide functionalities similar to desktop computers, attackers are targeting mobile users. Smishing, a phishing attack carried out through Short Messaging Service (SMS), has become prevalent due to the widespread use of SMS-based services. It involves deceptive messages designed to extract sensitive information. Despite the growing number of smishing attacks, limited research focuses on detecting these threats. This work presents a smishing detection model using a content-based analysis approach. To address the challenge posed by slang, abbreviations, and short forms in text communication, the model normalizes these into standard forms. A machine learning classifier is employed to classify messages as smishing or ham. Experimental results demonstrate the model effectiveness, achieving classification accuracies of 97.14% for smishing and 96.12% for ham messages, with an overall accuracy of 96.20%.\n",
            "----------------------------------------\n",
            "Title: Learning vector quantization model for prediction of cerebral Aβ in non‐demented individuals using plasma biomarkers\n",
            "Abstract: Cerebral Aβ is the hallmark of the AD in the early therapeutic intervention as well as diagnosis of the disease. Detecting in‐vivo Aβ deposition, however, still have limited accessibility. In this respect, the current study aims to identify plasma markers related to cerebral Aβ status via simple machine learning approach.\n",
            "----------------------------------------\n",
            "Title: miRLocator: Machine Learning-Based Prediction of Mature MicroRNAs within Plant Pre-miRNA Sequences\n",
            "Abstract: MicroRNAs (miRNAs) are a class of short, non-coding RNA that play regulatory roles in a wide variety of biological processes, such as plant growth and abiotic stress responses. Although several computational tools have been developed to identify primary miRNAs and precursor miRNAs (pre-miRNAs), very few provide the functionality of locating mature miRNAs within plant pre-miRNAs. This manuscript introduces a novel algorithm for predicting miRNAs named miRLocator, which isbased on machine learning techniques and sequence and structural features extracted from miRNA:miRNA* duplexes. To address the class imbalance problem (few real miRNAs and a large number of pseudo miRNAs), the prediction models in miRLocator were optimized by considering critical (and often ignored) factors that can markedly affect the prediction accuracy of mature miRNAs, including the machine learning algorithm and the ratio between training positive and negative samples. Ten-fold cross-validation on 5854 experimentally validated miRNAs from 19 plant species showed that miRLocator performed better than the state-of-art miRNA predictor miRdup in locating mature miRNAs within plant pre-miRNAs. miRLocator will aid researchers interested in discovering miRNAs from model and non-model plant species.\n",
            "----------------------------------------\n",
            "Title: Identifying novel transcript biomarkers for hepatocellular carcinoma (HCC) using RNA-Seq datasets and machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Data Preprocessing for Machine Learning in Seismology\n",
            "Abstract: The problem of preliminary data processing on P, S arrivals of seismic waves has been formulated. Data preprocessing was carried out for further classification using machine learning models. A comparative analysis of the following neural networks has been carried out: GPD, EQTransformer, and PhaseNet. Demonstrated the automation process for machine learning methods of seismic waves detection.\n",
            "----------------------------------------\n",
            "Title: Formulating turbulence closures using sparse regression with embedded form invariance\n",
            "Abstract: A data-driven framework for formulation of closures of the Reynolds-Average Navier--Stokes (RANS) equations is presented. In recent years, the scientific community has turned to machine learning techniques to distill a wealth of highly resolved data into improved RANS closures. While the body of work in this area has primarily leveraged Neural Networks (NNs), we alternately leverage a sparse regression framework. This methodology has two important properties: (1) The resultant model is in a closed, algebraic form, allowing for direct physical inferences to be drawn and naive integration into existing computational fluid dynamics solvers, and (2) Galilean invariance can be guaranteed by thoughtful tailoring of the feature space. Our approach is demonstrated for two classes of flows: homogeneous free shear turbulence and turbulent flow over a wavy wall. This work demonstrates equivalent performance to that of modern NNs but with the added benefits of interpretability, increased ease-of-use and dissemination, and robustness to sparse training datasets.\n",
            "----------------------------------------\n",
            "Title: ReaLPrune: ReRAM Crossbar-Aware Lottery Ticket Pruning for CNNs\n",
            "Abstract: Training machine learning (ML) models at the edge (on-chip training on end user devices) can address many pressing challenges including data privacy/security, increase the accessibility of ML applications to different parts of the world by reducing the dependence on the communication fabric and the cloud infrastructure, and meet the real-time requirements of AR/VR applications. However, existing edge platforms do not have sufficient computing capabilities to support complex ML tasks such as training large CNNs. ReRAM-based architectures offer high-performance yet energy efficient computing platforms for on-chip CNN training/inferencing. However, ReRAM-based architectures are not scalable with the size of the CNN. Larger CNNs have more weights, which requires more ReRAM cells that cannot be integrated in a single chip. Moreover, training larger CNNs on-chip will require higher power, which cannot be afforded by these smaller devices. Pruning is an effective way to solve this problem. However, existing pruning techniques are either targeted for inferencing only, or they are not crossbar-aware. This leads to sub-optimal hardware savings and performance benefits for CNN training on ReRAM-based architectures. In this paper, we address this problem by proposing a novel crossbar-aware pruning strategy, referred as ReaLPrune, which can prune more than 90% of CNN weights. The pruned model can be trained from scratch without any accuracy loss. Experimental results indicate that ReaLPrune reduces hardware requirements by 77.2% and accelerates CNN training by ∼20× compared to unpruned CNNs. ReaLPrune also outperforms other crossbar-aware pruning techniques in terms of both performance and hardware savings. In addition, ReaLPrune is equally effective for diverse datasets and more complex CNNs.\n",
            "----------------------------------------\n",
            "Title: Intelligent Automation System for Energy Conservation Using IoT and Machine Learning\n",
            "Abstract: People's busy and comfortable lifestyles in our technological era have enabled communication technology to advance to the point where any information may be accessed from anywhere in the world. Technological revolutions such as the Internet of Things and machine learning have grown in popularity in recent years due to the benefits they represent in a variety of domains of expertise. It is worth noting that implementing these two technologies encourages the development of more and better-automated systems of control in the home automation area that adapt to the preferences of each user. Many instances occur at establishments as a result of negligence and forgetfulness, when electrical equipment is left on even when there is no human presence in the room. This is one of the most prominent examples of societal electrical waste. As a result, a smart system that ensures both efficacy and efficiency must be implemented. To solve this issue, a privacy-preserving and safe identification and verification methodology for Home Automation Systems that leverages strong current technologies such as IoT, Machine Learning (ML), and Image Processing are proposed. It additionally makes utilization of more efficient image processing technologies than IR sensor-based systems for home automation. The ML Algorithm is responsible for recognizing people in each frame captured by the camera. A robust machine learning system capable of accurately distinguishing diverse environmental variables and human activities is designed to manage challenging situations.\n",
            "----------------------------------------\n",
            "Title: Towards Trustworthy Human-AI Teaming under Uncertainty\n",
            "Abstract: This paper proposes to incorporate uncertainty and performance into AI-advised human decision making to boost user trust in AI. Motivated by the trial-to-trial approach in the adjustment of decision boundaries by humans in decision making, this paper presents a novel framework of human-AI teaming for trustworthy AI under uncertainty. The framework employs the trial-to-trial approach to simulate the trial to trial process for adjusting decision boundaries and provide an estimation of uncertainty in AI. An Uncertainty-Performance Interface (UPI) in the framework is then proposed to allow users access the quality and performance of machine learning models in AI at the same time. The proposed framework allows human and AI collaborate in a teaming environment for trustworthy decisions under uncertainty.\n",
            "----------------------------------------\n",
            "Title: INTEGRATIVE MACHINE LEARNING FOR CHARACTERIZATION OF NON-CODING DISEASE VARIANTS\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Deep Insight into Urban Air Quality Utilizing Neural Networks for Enhanced Prediction in Korean Cities Where Factories and Ecosystem Environments Coexists\n",
            "Abstract: Increased attention is being given to air pollution in recent times. This study investigated and analyzed particulate matter data from Yeosu, Gwangyang, and Suncheon in Jeollanam-do, with a particular focus on PM2.5. Descriptive statistics, box-and-whisker plots, correlation matrices, time variations, and trend analyses were performed for this purpose. Additionally, a prediction model for PM2.5 concentrations was developed using machine learning techniques, through which future changes in air quality were forecasted. \n",
            "Calculations were performed using R-based programs and R packages. Hourly PM2.5 data were obtained from air quality monitoring sites in Yeosu, Gwangyang, and Suncheon. After data preprocessing, the optimal prediction model was constructed using Random Forest and Gradient Boosting Machine from various machine learning algorithms. \n",
            "The research results showed that there was more PM2.5 pollution in Gwangyang compared to Yeosu and Suncheon. The PM2.5 concentrations varied significantly across each monitoring site. Among the monitoring sites, the Yeosu site showed a higher correlation in PM2.5 with each other than other sites. Late winter and early spring showed higher PM2.5 concentrations, while summer and autumn showed lower concentrations. Weekly PM2.5 concentration fluctuations were not significantly different. Daily fluctuations showed an increase in PM2.5 concentrations during times of traffic congestion and a decrease in the afternoon. During the research period, the trend of PM2.5 concentration was generally decreasing. \n",
            "The accuracy of the prediction model through machine learning was over 90%, and it is expected to assist in establishing effective response strategies for future changes in air quality. This study provided an updated and useful evaluation of recent PM2.5 air quality in Yeosu, Gwangyang, and Suncheon in Korea.\n",
            "----------------------------------------\n",
            "Title: Higher Order Polynomial Transformer for Fine-Grained Freezing of Gait Detection\n",
            "Abstract: Freezing of Gait (FoG) is a common symptom of Parkinson’s disease (PD), manifesting as a brief, episodic absence, or marked reduction in walking, despite a patient’s intention to move. Clinical assessment of FoG events from manual observations by experts is both time-consuming and highly subjective. Therefore, machine learning-based FoG identification methods would be desirable. In this article, we address this task as a fine-grained human action recognition problem based on vision inputs. A novel deep learning architecture, namely, higher order polynomial transformer (HP-Transformer), is proposed to incorporate pose and appearance feature sequences to formulate fine-grained FoG patterns. In particular, a higher order self-attention mechanism is proposed based on higher order polynomials. To this end, linear, bilinear, and trilinear transformers are formulated in pursuit of discriminative fine-grained representations. These representations are treated as multiple streams and further fused by a cross-order fusion strategy for FoG detection. Comprehensive experiments on a large in-house dataset collected during clinical assessments demonstrate the effectiveness of the proposed method, and an area under the receiver operating characteristic (ROC) curve (AUC) of 0.92 is achieved for detecting FoG.\n",
            "----------------------------------------\n",
            "Title: Classification of Children’s Sitting Postures Using Machine Learning Algorithms\n",
            "Abstract: Sitting on a chair in an awkward posture or sitting for a long period of time is a risk factor for musculoskeletal disorders. A postural habit that has been formed cannot be changed easily. It is important to form a proper postural habit from childhood as the lumbar disease during childhood caused by their improper posture is most likely to recur. Thus, there is a need for a monitoring system that classifies children’s sitting postures. The purpose of this paper is to develop a system for classifying sitting postures for children using machine learning algorithms. The convolutional neural network (CNN) algorithm was used in addition to the conventional algorithms: Naïve Bayes classifier (NB), decision tree (DT), neural network (NN), multinomial logistic regression (MLR), and support vector machine (SVM). To collect data for classifying sitting postures, a sensing cushion was developed by mounting a pressure sensor mat (8 × 8) inside children’s chair seat cushion. Ten children participated, and sensor data was collected by taking a static posture for the five prescribed postures. The accuracy of CNN was found to be the highest as compared with those of the other algorithms. It is expected that the comprehensive posture monitoring system would be established through future research on enhancing the classification algorithm and providing an effective feedback system.\n",
            "----------------------------------------\n",
            "Title: Learning random forests for ranking\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Introduction 1.1. Example: Polynomial Curve Fitting\n",
            "Abstract: The problem of searching for patterns in data is a fundamental one and has a long and successful history. For instance, the extensive astronomical observations of Tycho Brahe in the 16 th century allowed Johannes Kepler to discover the empirical laws of planetary motion, which in turn provided a springboard for the development of classical mechanics. Similarly, the discovery of regularities in atomic spectra played a key role in the development and verification of quantum physics in the early twentieth century. The field of pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories. Consider the example of recognizing handwritten digits, illustrated in Figure 1.1. Each digit corresponds to a 28×28 pixel image and so can be represented by a vector x comprising 784 real numbers. The goal is to build a machine that will take such a vector x as input and that will produce the identity of the digit 0,. .. , 9 as the output. This is a nontrivial problem due to the wide variability of handwriting. It could be 1 2 1. INTRODUCTION Figure 1.1 Examples of handwritten digits taken from US zip codes. tackled using handcrafted rules or heuristics for distinguishing the digits based on the shapes of the strokes, but in practice such an approach leads to a proliferation of rules and of exceptions to the rules and so on, and invariably gives poor results. Far better results can be obtained by adopting a machine learning approach in which a large set of N digits {x 1 ,. .. , x N } called a training set is used to tune the parameters of an adaptive model. The categories of the digits in the training set are known in advance, typically by inspecting them individually and hand-labelling them. We can express the category of a digit using target vector t, which represents the identity of the corresponding digit. Suitable techniques for representing categories in terms of vectors will be discussed later. Note that there is one such target vector t for each digit image x. The result of running the machine learning algorithm can be expressed as a function y(x) which takes a new digit image x as input and that generates an output vector y, encoded in …\n",
            "----------------------------------------\n",
            "Title: An Android Malware Detection System using a Knowledge-based Permission Counting Method\n",
            "Abstract: As the number of cases of damage caused by malicious apps increases, accurate detection is required through various detection conditions, not just detection using simple techniques. In this paper, we propose a knowledge-based machine learning method using authority information and adding its usage counting features. This method is classifying training apps and malicious apps through machine learning using permission features in manifest.xml of Android apps. As a result of the experiment, accuracy, recall, precision, F1 score are 99.01%, 97.70%, 100.0%, 99.01%, respectively. Since Recall is higher than other indicators, it accurately predicts malicious apps as malicious. In other words, the proposed system is effective in preventing the distribution of malicious apps.\n",
            "----------------------------------------\n",
            "Title: Quantifying Optimization Bias in Model Evaluation when using Cross-Validation in Psychological Science: A Monte Carlo Simulation Study\n",
            "Abstract: Psychological scientists are increasingly using machine learning to advance applied or basic science goals. Cross-validation is commonly used for training, selecting, and evaluating machine learning algorithms. Although cross-validation is often described as a tool that necessarily prevents overly optimistic estimates of a final model’s performance in new data, not all approaches to cross-validation offer accurate evaluation in all data contexts. Prior work in other fields has established that k-fold cross-validation can provide upwardly biased model evaluation. The extent of this optimization bias in data contexts typical of psychological science is not known. This Monte Carlo simulation study characterizes optimization bias in model evaluation when using three different approaches to cross-validation — k-fold cross-validation, k-fold cross-validation with a test set, and nested k-fold cross-validation — in factorial combinations of sample size (100; 500; 1,000), number of predictors (10; 100; 1,000), and outcome distribution (balanced, with a positive case probability of .50; unbalanced, with a positive case probability of .10). For each unique data context, 1,000 simulations were conducted by randomly sampling from multivariate normal predictor distributions and binomial outcome distributions such that predictors were known to have no population-level association with the outcome. We characterized the average, standard deviation, and maximum performance estimates resulting from model evaluation using each approach to cross-validation in each context, identifying biased evaluations as those with an Area Under the Receiver Operating Characteristic Curve (AUC) value greater than .50.\n",
            "----------------------------------------\n",
            "Title: Integration of ML Layer with GBC based Classifier for Better Recognition of Voice in Mobile\n",
            "Abstract: People can express their feelings through words and sentences in different languages during a speech. Spoken language frequently contains feelings including surprise, fear, indifference, contempt, fury, grief, and happiness. This essay explores the topic of identifying these feelings in speech. We performed an investigation to identify and categorize emotions present in speech by utilising machine learning methods, such as random forest, additional trees, gradient boosting, decision tree, and light gradient boosting classifiers. We were able to acquire informative findings by using the previously specified classifiers along with datasets.\n",
            "----------------------------------------\n",
            "Title: Concatenating or Averaging? Hybrid Sentences Representations for Sentiment Analysis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Semantic textual similarity for modern standard and dialectal Arabic using transfer learning\n",
            "Abstract: Semantic Textual Similarity (STS) is the task of identifying the semantic correlation between two sentences of the same or different languages. STS is an important task in natural language processing because it has many applications in different domains such as information retrieval, machine translation, plagiarism detection, document categorization, semantic search, and conversational systems. The availability of STS training and evaluation data resources for some languages such as English has led to good performance systems that achieve above 80% correlation with human judgment. Unfortunately, such required STS data resources are not available for many languages like Arabic. To overcome this challenge, this paper proposes three different approaches to generate effective STS Arabic models. The first one is based on evaluating the use of automatic machine translation for English STS data to Arabic to be used in fine-tuning. The second approach is based on the interleaving of Arabic models with English data resources. The third approach is based on fine-tuning the knowledge distillation-based models to boost their performance in Arabic using a proposed translated dataset. With very limited resources consisting of just a few hundred Arabic STS sentence pairs, we managed to achieve a score of 81% correlation, evaluated using the standard STS 2017 Arabic evaluation set. Also, we managed to extend the Arabic models to process two local dialects, Egyptian (EG) and Saudi Arabian (SA), with a correlation score of 77.5% for EG dialect and 76% for the SA dialect evaluated using dialectal conversion from the same standard STS 2017 Arabic set.\n",
            "----------------------------------------\n",
            "Title: Neuroimaging mechanisms of acupuncture on functional reorganization for post-stroke motor improvement: a machine learning-based functional magnetic resonance imaging study\n",
            "Abstract: Objective Motor recovery is crucial in stroke rehabilitation, and acupuncture can influence recovery. Neuroimaging and machine learning approaches provide new research directions to explore the brain functional reorganization and acupuncture mechanisms after stroke. We applied machine learning to predict the classification of the minimal clinically important differences (MCID) for motor improvement and identify the neuroimaging features, in order to explore brain functional reorganization and acupuncture mechanisms for motor recovery after stroke. Methods In this study, 49 patients with unilateral motor pathway injury (basal ganglia and/or corona radiata) after ischemic stroke were included and evaluated the motor function by Fugl–Meyer Assessment scores (FMA) at baseline and at 2-week follow-up sessions. Patients were divided by the difference between the twice FMA scores into one group showing minimal clinically important difference (MCID group, n = 28) and the other group with no minimal clinically important difference (N-MCID, n = 21). Machine learning was performed by PRoNTo software to predict the classification of the patients and identify the feature brain regions of interest (ROIs). In addition, a matched group of healthy controls (HC, n = 26) was enrolled. Patients and HC underwent magnetic resonance imaging examination in the resting state and in the acupuncture state (acupuncture at the Yanglingquan point on one side) to compare the differences in brain functional connectivity (FC) and acupuncture effects. Results Through machine learning, we obtained a balance accuracy rate of 75.51% and eight feature ROIs. Compared to HC, we found that the stroke patients with lower FC between these feature ROIs with other brain regions, while patients in the MCID group exhibited a wider range of lower FC. When acupuncture was applied to Yanglingquan (GB 34), the abnormal FC of patients was decreased, with different targets of effects in different groups. Conclusion Feature ROIs identified by machine learning can predict the classification of stroke patients with different motor improvements, and the FC between these ROIs with other brain regions is decreased. Acupuncture can modulate the bilateral cerebral hemispheres to restore abnormal FC via different targets, thereby promoting motor recovery after stroke. Clinical trial registration https://www.chictr.org.cn/showproj.html?proj=37359, ChiCTR1900022220.\n",
            "----------------------------------------\n",
            "Title: Studies on high-performance network intrusion detection system based on unsupervised machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Application of Deep Learning to Forecast the South African Unemployment Rate: A Multivariate Approach\n",
            "Abstract: Univariate models have been used successfully to forecast unemployment rates across the world. However, these models are inherently limited as they only use past values of a variable to forecast its future movements: ignoring the influence of external factors. Hence, multivariate models were introduced that generalize univariate models. The most commonly used version of multivariate models for unemployment rate forecasting is the vector autoregression (VAR) model. However, this model requires data to meet particular requirements before use, such as being white noise generated and stationary. This requirement adds a significant amount of overhead in preparing the data for use in the model. The model itself also assumes that features equally impact each other. Therefore, it does not enable the identification of the most impactful features. This model was applied to multivariate data from the South African Reserve Bank, and the model had an error rate twenty times higher than machine learning techniques. LSTM and GRU had the lowest error rate on the same data set with LASSO and elastic net identifying domestic output and government expenditure as important predictors of unemployment.\n",
            "----------------------------------------\n",
            "Title: CODA: Generalizing to Open and Unseen Domains with Compaction and Disambiguation\n",
            "Abstract: The generalization capability of machine learning systems degenerates notably when the test distribution drifts from the training distribution. Recently, Domain Generalization (DG) has been gaining momentum in enabling machine learning models to generalize to unseen domains. However, most DG methods assume that training and test data share an identical label space, ignoring the potential unseen categories in many real-world applications. In this paper, we delve into a more general but difficult problem termed Open Test-Time DG (OTDG), where both domain shift and open class may occur on the unseen test data. We propose Compaction and Disambiguation (CODA), a novel two-stage framework for learning compact representations and adapting to open classes in the wild. To meaningfully regularize the model’s decision boundary, CODA introduces virtual unknown classes and optimizes a new training objective to insert unknowns into the latent space by compacting the embedding space of source known classes. To adapt target samples to the source model, we then disambiguate the decision boundaries between known and unknown classes with a test-time training objective, mitigating the adaptivity gap and catastrophic forgetting challenges. Experiments reveal that CODA can significantly outperform the previous best method on standard DG datasets and harmonize the classification accuracy between known and unknown classes.\n",
            "----------------------------------------\n",
            "Title: Accelerator beam phase space tomography using machine learning to account for variations in beamline components\n",
            "Abstract: \n",
            " We describe a technique for reconstruction of the\n",
            " four-dimensional transverse phase space of a beam in an accelerator\n",
            " beamline, taking into account the presence of unknown errors on the\n",
            " strengths of magnets used in the data collection. Use of machine\n",
            " learning allows rapid reconstruction of the phase-space distribution\n",
            " while at the same time providing estimates of the magnet errors. The\n",
            " technique is demonstrated using experimental data from CLARA, an\n",
            " accelerator test facility at Daresbury Laboratory.\n",
            "----------------------------------------\n",
            "Title: News and notes\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Review of machine learning for optical imaging of burn wound severity assessment\n",
            "Abstract: Abstract. Significance Over the past decade, machine learning (ML) algorithms have rapidly become much more widespread for numerous biomedical applications, including the diagnosis and categorization of disease and injury. Aim Here, we seek to characterize the recent growth of ML techniques that use imaging data to classify burn wound severity and report on the accuracies of different approaches. Approach To this end, we present a comprehensive literature review of preclinical and clinical studies using ML techniques to classify the severity of burn wounds. Results The majority of these reports used digital color photographs as input data to the classification algorithms, but recently there has been an increasing prevalence of the use of ML approaches using input data from more advanced optical imaging modalities (e.g., multispectral and hyperspectral imaging, optical coherence tomography), in addition to multimodal techniques. The classification accuracy of the different methods is reported; it typically ranges from ∼70% to 90% relative to the current gold standard of clinical judgment. Conclusions The field would benefit from systematic analysis of the effects of different input data modalities, training/testing sets, and ML classifiers on the reported accuracy. Despite this current limitation, ML-based algorithms show significant promise for assisting in objectively classifying burn wound severity.\n",
            "----------------------------------------\n",
            "Title: Foundations of Lesion Detection Using Machine Learning in Clinical Neuroimaging.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Energy Minimization for Federated Learning with IRS-Assisted Over-the-Air Computation\n",
            "Abstract: This paper investigates the deployment of federated learning (FL) over an over-the-air computation (AirComp) and intelligent reflecting surface (IRS) based wireless network. In the considered system, devices transmit locally trained machine learning (ML) models to the base station (BS) which aggregates the received ML models and generates a shared global ML model. The devices can directly transmit ML models to the BS or using IRS. Meanwhile, AirComp is used to aggregate ML models that are transmitted from the devices to the BS. To minimize the energy consumption of devices, an energy minimization problem is formulated, which jointly optimizes the device selection, phase shift matrix, decoding vector, and power control. To seek the solution, the original optimization problem is divided into four sub-problems. Then the fractional program, greedy algorithm, matrix derivation, and weighted minimum mean square error methods are used to compute the phase shift matrix, device selection vector, decoding vector, and transmit power, respectively. Simulation results show that the proposed algorithm can reduce 11.2% energy consumption of devices compared to an FL algorithm that is implemented at a network without any IRSs.\n",
            "----------------------------------------\n",
            "Title: RAPID DESIGN OF R/C COLUMNS USING MACHINE LEARNING TECHNIQUES\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Heart Rate Variability Based Estimation of Maximal Oxygen Uptake in Athletes Using Supervised Regression Models\n",
            "Abstract: Wearable Heart Rate monitors are used in sports to provide physiological insights into athletes’ well-being and performance. Their unobtrusive nature and ability to provide reliable heart rate measurements facilitate the estimation of cardiorespiratory fitness of athletes, as quantified by maximum consumption of oxygen uptake. Previous studies have employed data-driven models which use heart rate information to estimate the cardiorespiratory fitness of athletes. This signifies the physiological relevance of heart rate and heart rate variability for the estimation of maximal oxygen uptake. In this work, the heart rate variability features that were extracted from both exercise and recovery segments were fed to three different Machine Learning models to estimate maximal oxygen uptake of 856 athletes performing Graded Exercise Testing. A total of 101 features from exercise and 30 features from recovery segments were given as input to three feature selection methods to avoid overfitting of the models and to obtain relevant features. This resulted in the increase of model’s accuracy by 5.7% for exercise and 4.3% for recovery. Further, post-modelling analysis was performed to remove the deviant points in two cases, initially in both training and testing and then only in training set, using k-Nearest Neighbour. In the former case, the removal of deviant points led to a reduction of 19.3% and 18.0% in overall estimation error for exercise and recovery, respectively. In the latter case, which mimicked the real-world scenario, the average R value of the models was observed to be 0.72 and 0.70 for exercise and recovery, respectively. From the above experimental approach, the utility of heart rate variability to estimate maximal oxygen uptake of large population of athletes was validated. Additionally, the proposed work contributes to the utility of cardiorespiratory fitness assessment of athletes through wearable heart rate monitors.\n",
            "----------------------------------------\n",
            "Title: Artificial intelligence in predicting early-onset adjacent segment degeneration following anterior cervical discectomy and fusion\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Approximation of Primary, Secondary and Tertiary Recovery Factors in Viscous Oil Reservoirs Deposited in Ugandan Sands\n",
            "Abstract: Limitations in availability of methods to estimate recovery factor at the initial stage of petroleum exploration pushes for investigation new ways of analysing available datasets. There are three oil fields databases that have been used in this work: C&C Reservoirs, TORIS and Oil and Gas Journal. This work investigates established petroleum industry empirical methods and volumetric method to estimate secondary recovery factor in Ugandan oil fields in the Lake Albert Basin. It also investigates newly available statistical method to estimate primary, secondary and tertiary recovery factor in aforementioned oil fields. Primary recovery factor was estimated based on field analogous mainly using C&C Reservoir database. Secondary recovery factor was calculated using empirical equations assuming that the recovery mechanism is water injection. An alternative method, to empirical equations, to estimate secondary recovery factor in waterflooded reservoirs is by applying the volumetric method. Primary, secondary and tertiary recovery factors were approximated using a machine learning/data mining approach to reveal eventual trends in conventional/heavy oil analogue databases. Rules extracted from several databases worldwide for viscous oil reservoirs were then applied to oil fields in Uganda. Primary recovery factor obtained from field analogous varies between 5 and 15%. The quality of the results for secondary recovery calculations obtained from empirical equations depends on whether they were derived for conventional or heavy oil reservoirs. The studies show that data mining approach can be successfully applied to approximate primary, secondary and tertiary recovery factors. This work finishes with recommendation on how to approach the recovery factor approximation in viscous oil fields in Uganda. Introduction The recovery factor is amongst the most important parameters that characterises oil and gas reservoirs and it influences many decisions that lead to successful field development plan. It enables estimation of future revenue as well as future costs of field operations. Knowledge of recoverable reserves allows effective facilities planning well ahead of time. Not to mention that a correctly estimated recovery factor enables a good development strategy, therefore better environmental protection. There can be a significant difference between what is called stock tank oil initially in place (STOIIP) and its recoverable amount, which is determined by the recovery factor. Three types of recovery factor can be distinguished depending on processes used in oil recovery and the stage of development: primary, secondary and tertiary recovery factor. The complexity of a petroleum system (fault pattern, facies, and heterogeneity) brings a high range of uncertainty associated with recovery factor estimation. Recovery factor is not an exact number, especially at the initial stage of the project when it has a lot of uncertainty (Fig. 1). Its range narrows in time when more data is available. Recovery factor becomes even more complicated mater when heavy oil reservoirs are involved, because more parameters need to be taken in to consideration. Recovery factor evolves over the lifetime of a reservoir and many times needs to be revised along the project. Conventional to heavy oil reservoirs in Uganda have been deposited in fluvial, unconsolidated sands. These sands, aside other worldwide heavy oil reservoirs deposited in fluvial sands, are characterised by excellent reservoirs properties (Dusseault 2001; Lu et al. 2010).They have high absolute permeability (0.5-10 darcies) and very high well test permeability (10-25 darcies), in some examples even reaching 30 darcies. Porosity is in the range of 25-35%. Fluid parameters, represented by viscosity and API gravity, range between 3 and 250 centipoises and 18-32 °API, respectively, for Ugandan oil fields. This study considers the Ugandan oil fields located in the Lake Albert Basin. When the exploration is in the incipient stage and reservoirs are at virgin condition, the correct recovery factor estimation is of paramount importance to ensure correct development. The Ugandan oil fields have only been appraised. Therefore, there is no production data available to date. Considering this, the range of methods available to estimate recovery factor narrows. The methods that are suitable at this stage of exploration are mainly based on field analogous, empirical equations and numerical simulations. Imperial College London 2 Approximation of primary, secondary and tertiary recovery factors in viscous oil reservoirs deposited in Ugandan sands The aim of this work is to investigate the different methodologies to approximate recovery factors in Ugandan viscous oil reservoirs at the appraisal stage. The firs objective is to estimate primary recovery factor in Ugandan oil fields based on field analogy. Subsequently to calculated secondary recovery factor for waterflooding in Ugandan viscous oil fields using empirical equations as well as volumetric method. One of the main objectives of this work is to investigate the potential of recovery factor approximations based on advanced screening methodology. The final stage of this work involves guidance on how to approach recovery factor estimation in viscous oil reservoirs at their initial stages of the project. To achieve specified objectives a number of various techniques were investigated: empirical correlations, volumetric calculations and a statistical approach. This work embraces primary recovery approximation mainly based on field analogues and partially on advanced screening methodology. Secondary recovery factor was estimated on the basis of empirical equations (Arps et al. 1967; Guthrie and Greenberger 1955) and compared with numerical simulations that have been performed by the Company. Advanced screening (expert maps) was used for screening of rock and fluid properties in conventional/heavy oil fields worldwide that most closely correspond to the oil fields in Uganda. Based on this (1) recovery factors were approximated by cluster analysis (CA) and (2) alternative method of classification tree analysis (CTA) was applied to extract rules from databases that were applied to approximate recovery factor in Ugandan viscous oil reservoirs. Advance screening: machine learning and data mining have broad applicability in the petroleum industry mainly for permeability determination and recovery mechanism identification (Nashavi and Malallah 2009; Alvarado and Manrique 2010). In this work aforementioned statistical methods were applied in an attempt to estimate recovery factors in the early stage of the project for viscous oil fields in Uganda. Recovery Factor The recovery factor is the recoverable part of the total amount of hydrocarbon initially in place. Recovery factor changes in time depending on the recovery mechanism applied and stage of production (Figs. 1&2). There are several recovery factors depending on the stage of production: primary, secondary and tertiary recovery factor. The figures below show ranges of recovery factor estimation depending on the stage of production and corresponding production profile. Fig. 1—Recovery factor estimation during reservoirs’ live cycles (left) Fig. 2—Production profile (right) Estimation of oil and gas reserves. Society of petroleum engineering. Petroleum engineering handbook (PEH Chapter 40). Pages (40-1)-(40-38). Forrest, A.G. and Smith, G.L. 1987. Why the recovery factor is important to the oil industry The reason why the recovery factor is important to the oil and gas industry is that it enables future planning the costs and operations involved in a field development. Correctly estimated recovery factor allows subsurface and surface facility planning well before the first oil starts to flow. Field operations involved in petroleum extraction are very complex and expensive. They require the cooperation of many groups involved in a project. Another inherent aspect of producing crude oil and natural gas are the environmental consideration. All of these factors make oil exploration a very expensive process. Final success of the operation depends on obtaining as much accurate data as possible that are close to the actual petroleum system. A correctly approximated recovery factor in the early appraisal stage of the reservoir life cycle enables more suitable planning, which saves time, energy and restricts and mitigates environmental impact of production to a minimum. Reservoir parameters affecting recovery factor Parameters that affect recovery factors can be divided on three groups: reservoir rock properties, fluid properties and development methods. Some of the main ones representing the first group are: reservoir depth, reservoir net pay, porosity and permeability of the rock formation. Another is grain distribution and their shape. Two main parameters of the fluid properties Approximation of primary, secondary and tertiary recovery factors in viscous oil reservoirs deposited in Ugandan sands 3 that influence recovery factor are API gravity and viscosity of the fluid. The last group mentioned represents well spacing and well pattern. Available methods to estimate recovery factor Several methods can be distinguished to estimate recovery factors depending on the available data, stage of the project and methodology used. In the initial/appraisal stage field analogous are commonly used. There are many statistical techniques available in this stage of development to estimate recovery factor. Preciseness of these methods increases with number of reservoirs taken under consideration. Empirical equations are the second group. When applied separately without any support from other methods, this does not always bring good results. However, the precision of recovery factor assessment narrows once production data is available and analytical methods (e.g. Material Balance) are incorporated. Further, in the subsequent stag\n",
            "----------------------------------------\n",
            "Title: Neurofeedback games using EEG-based brain–computer interface technology\n",
            "Abstract: Brain-computer interface (BCI) is relatively a new approach to communication between man and machine, which translates brain activity into commands for communication and control. As BCI is capable of detecting human intentions, it is a promising communication tool for paralyzed patients for communicating with external world. Many of the current BCI systems employ electroencephalogram (EEG) which is the most widely used noninvasive brain activity recording technique. EEG signal carries potential features to identify and decode human intentions and mental tasks. Recently, many researchers have started exploiting the possibilities of BCI in entertainment and cognitive skill enhancement. BCI-based games have been identified as a unique entertainment mechanism nowadays, “controlling a 2-D, 3-D or virtual computer game solely by player's brain waves.” BCI games work based on a neurofeedback paradigm which allows an individual to self-regulate his brain signal in response to the real-time visual or auditory feedback of his brain waves/features. This neurofeedback in a gaming environment motivates and trains the players to control his brain features toward the desired stage (self-regulation). This chapter explores the state-of-the-art BCI technology in neurofeedback games, employing EEG signal. It also provides a survey of the existing EEG-based neurofeedback games and evaluates their success rates, challenging factors and influence on players. In neurofeedback games, a number of features extracted from EEG accompanied with sustained attention, selective attention, visuospatial attention, motor imagery, eye movements, etc. have been employed as distinct control signals. We will briefly review and compare various signal processing methodologies and machine-learning techniques employed in those studies to extract and decode the brain features. Besides the structure and algorithms used in neurofeedback games, the therapeutic effects of neurofeedback training and its capabilities for the enhancement of cognitive skills will also be briefly discussed in this chapter. Neurofeedback training helps to rewire brain's underlying neural circuits and to improve brain functions. Therefore, it is considered as an effective tool for boosting cognitive skills of both healthy and the disabled. Specifically, neurofeedback has been considered as an efficient treatment modality for individuals with attention-deficit hyperactive disorder (ADHD). ADHD is characterized by three behavioral symptoms: inattention, hyperactivity and impulsivity. Along with the conventional intervention strategies such as medication, behavioral treatments, etc., neurofeedback in BCI games has also been emerging as a promising modality for treating the attention deficit. We will also discuss portable and economical EEG recording devices currently employed in BCI-based brain training modules/games. Finally, the chapter will be concluded with a brief overview of the neurofeedback developments in the context of BCI-based games until now, their potential impact on the healthy as well as on people with neurological disorders, challenges in transferring the successful protocols from laboratories into the market and hurdles in real-time BCI system design and development.\n",
            "----------------------------------------\n",
            "Title: Learning Criticality in an Embodied Boltzmann Machine\n",
            "Abstract: Many biological and cognitive systems do not operate deep into one or other regime of activity. Instead, they exploit critical surfaces poised at transitions in their parameter space. The pervasiveness of criticality in natural systems suggests that there may be general principles inducing this behaviour. However, there is a lack of conceptual models explaining how embodied agents propel themselves towards these critical points. In this paper, we present a learning model driving an embodied Boltzmann Machine towards critical behaviour by maximizing the heat capacity of the network. We test and corroborate the model implementing an embodied agent in the mountain car benchmark, controlled by a Boltzmann Machine that adjust its weights according to the model. We find that the neural controller reaches a point of criticality, which coincides with a transition point of the behaviour of the agent between two regimes of behaviour, maximizing the synergistic information between its sensors and the hidden and motor neurons. Finally, we discuss the potential of our learning model to study the contribution of criticality to the behaviour of embodied living systems in scenarios not necessarily constrained by biological restrictions of the examples of criticality we find in nature.\n",
            "----------------------------------------\n",
            "Title: Application of Artificial Intelligence in Project Planning to Solve Late and Over-Budgeted Construction Projects\n",
            "Abstract: Advance use of Artificial Intelligence (AI), has reduced the need of human intervention within several tasks that are repetitive and rule-based. AI can have a great impact on the workforce of a project within the construction industry. Use of Machine learning techniques within the project process can be beneficial for a project manager to manage financial aspects and time scheduling both. The major problem that construction project managers face is ineffective tracking process, cost management process. This is the main reason, the AI-based solution are needed within construction sites. The aim of this research is to identify the role of AI in time management as well as cost management of a construction project in India. Intelligence robotics is a major AI-based tool that is used within construction project for marinating cost. Some challenges are also found within construction project that might have a huge effect within its implementation process such as cultural barriers, high-cost of maintenance and unavailability of similar input parameters in all projects. As per the findings, ANN, SVM, Regression and many other AI-based are effective Ai-based machine learning tools that are used within construction project to replace various time consuming process by modern technologies. Construction delays are the major effective factor for cost overrun and time overrun within a project. As per this research article, it has been found that, use of AI, especially ANN model can reduce the tendency of delay in construction projects and mismanagement of costs.\n",
            "----------------------------------------\n",
            "Title: Activity Map and Transition Pathways of G Protein-Coupled Receptor Revealed by Machine Learning\n",
            "Abstract: Approximately, one-third of all FDA-approved drugs target G protein-coupled receptors (GPCRs). However, more knowledge of protein structure-activity correlation is required to improve the efficacy of the drugs targeting GPCRs. In this study, we developed a machine learning (ML) model to predict activation state and activity level of the receptors with high prediction accuracy. Furthermore, we applied this model to thousands of molecular dynamics trajectories to correlate residue-level conformational changes of a GPCR to its activity level. Finally, the most probable transition pathway between activation states of a receptor can be identified by using the state-activity information. In addition, with this model, we can associate the contribution of each amino acid to the activation process. Using this method we will be able to design drugs that mainly target principal amino acids driving the transition between activation states of GPCRs. Our advanced method is generalizable to all GPCR classes and provides mechanistic insight into the activation mechanism in the receptors.\n",
            "----------------------------------------\n",
            "Title: Regularized least-square object tracking based on ℓ2,1 minimization\n",
            "Abstract: In this paper, we propose a fast and long-term object tracking algorithm using the ℓ2,1 minimization to obtain a better tracking quality. Our method is based on Regularized Least-Squares Classification (RLSC), in which the target model is updated using an online learning process during object tracking. We construct an appearance model using saliency map, image intensity and position of the target and its surrounding regions. The Fourier analysis is adopted for fast learning and saliency map detection in this work. The proposed tracking algorithm runs at 165 frames-per-second(FPS) in MATLAB on an i5 machine. Extensive experimental results on challenging image sequences demonstrate the efficiency, accuracy and robustness of the proposed tracker in comparison with state-of-the-arts methods.\n",
            "----------------------------------------\n",
            "Title: Pre-processing Techniques for Offline Tamil Handwritten Character Recognition\n",
            "Abstract: Handwritten Character Recognition (HWCR) is one of the difficult tasks in the field of pattern recognition and machine learning. In the HWCR application, human handwritten characters are recognized by the computer. Moreover, this can also be utilized in other applications such as postal processing script recognition, banking security, and scripting language identification. In the Handwritten Character recognition, the preprocessing phase has a great significance to improve the character recognition accuracy. In this paper, various preprocessing techniques, used for offline handwritten character recognition are discussed. Additionally, the various challenges concerning offline handwritten recognition are also addressed in this paper. The primary objective of this is to explain the significance of preprocessing techniques for offline HWCR in Tamil script.\n",
            "----------------------------------------\n",
            "Title: UAV Remote Sensing applications and current trends in crop monitoring and diagnostics: A Systematic Literature Review\n",
            "Abstract: Crop monitoring and diagnosis are crucial for efficient agricultural production, and unmanned aerial vehicle (UAV) Remote Sensing can assist in achieving this goal. This article offers an automated Systematic Literature Review (SLR) of UAV Remote Sensing for crop monitoring and diagnosis. This review analyzes the primary scientific applications and trends in this area using Deep Learning techniques to automatically select relevant articles and validate them through full reading. The SLR collected over 800 papers, of which 64 met the selection process. The articles selected by Deep Learning classifiers were successfully cataloged with high accuracy in pre-selecting articles for review. F1 scores of 93% were achieved in tests with unpublished examples for the classifier model. The review of the 64 primary studies reported a peak in UAV Remote Sensing applications in 2020, attributed to the increasing diffusion of precision farming practices with technological equipment. The UAV Remote Sensing application objectives included crop monitoring, pest and disease detection, yield prediction, and plant nutrition. Artificial Intelligence, particularly Machine Learning and Deep Learning, are widely used for UAV Remote Sensing analysis. The NDVI is the most applied vegetation index for crop condition assessment and monitoring. The proposed solution for automating the literature selection process for precision agriculture-related scientific articles can be used in other areas that require extensive literature review.\n",
            "----------------------------------------\n",
            "Title: Innovation on User-Generated Content for Environmental Noise Monitoring and Analysis in the Context of Smart Cities\n",
            "Abstract: This work presents an approach based on the concept of Volunteered Geographic Information (VGI) to monitoring environmental noise; it is a problem that specially affects people's quality of life in urban areas. In this work, mobile devices are used to massively collect environmental noise measurements, which are used to generate maps of a specific area and then make a forecast. The difference of this approach with respect to the traditional methods based on monitoring stations is that it is much less costly, which is a major innovation in developing countries. This approach is based on a GIS approach that consists of an application for mobile devices and a web mapping application; including Geospatial Analysis and Machine Learning methods for the acoustic noise prediction using contextual information. With this approach it will be possible to define actions to mitigate the effects of environmental noise, it is aligned in the context of the smart cities. The proposed case study is based on collecting noise data of the Mexico City.\n",
            "----------------------------------------\n",
            "Title: Defending Against Byzantine Attacks in CRNs: PCA-Based Malicious User Detection and Weighted Cooperative Spectrum Sensing\n",
            "Abstract: Cognitive radio (CR) technology is a viable solution for assisting secondary users to share the licensed radio spectrum of primary users. Cooperative spectrum sensing (CSS) enhances the accuracy of spectrum sensing in a CR network. However, the effectiveness of CSS can be compromised by malicious users (MUs) who intentionally send false sensing information to the fusion center. This letter focuses on enhancing the CSS performance and detecting the MUs. We propose a machine learning technique to identify and classify MUs in a CR network using the Principal Component Analysis algorithm. The performance of the proposed algorithm in detecting MUs and enhancing CSS performance is validated through simulation experiments.\n",
            "----------------------------------------\n",
            "Title: Software Enhancement Effort Estimation using Stacking Ensemble Model within the Scrum Projects: A Proposed Web Interface\n",
            "Abstract: : The frequent changes in software projects may have an impact on the accuracy of the Software Enhancement Effort Estimation (SEEE) and hinder management of the software project. According to a survey on agile software estimation, the most common cost driver among effort estimation models is software size. In-deed, previous research works proved the effectiveness of the COSMIC Functional Size Measurement (FSM) method for efficiently measuring software functional size. It has been also observed that COSMIC sizing is an efficient standardized method for measuring not only software size but also the functional size of an enhancement that may occur during the scrum enhancement project. Intending to increase the SEEE accuracy the purpose of this paper is twofold. Firstly, it attempts to construct a stacking ensemble model. Secondly, it intends to develop a localhost web application to automate the SEEE process. The constructed stacking ensemble model takes the functional Size of an enhancement or a functional change, denoted as FS(FC), as a primary independent variable. The stacking ensemble model combines three Machine Learning (ML) techniques: Decision Tree Regression, Linear Support Vector Regression, and Random Forest Regression. Results show that the use of the FS(FC) as an input to SEEE using the stacking ensemble model provides significantly better results in terms of MAE (Mean Absolute Error) = 0.206, Mean Square Error (MSE) = 0.406, and Root Mean Square Error (RMSE) = 0.595.\n",
            "----------------------------------------\n",
            "Title: Machine learning–based approach to predict ice meltdown in glaciers due to climate change and solutions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Identification of Potential Sex-Specific Biomarkers in Pigs with Low and High Intramuscular Fat Content Using Integrated Bioinformatics and Machine Learning\n",
            "Abstract: Intramuscular fat (IMF) content is a key determinant of pork quality. Controlling the genetic and physiological factors of IMF and the expression patterns of various genes is important for regulating the IMF content and improving meat quality in pig breeding. Growing evidence has suggested the role of genetic factors and breeds in IMF deposition; however, research on the sex factors of IMF deposition is still lacking. The present study aimed to identify potential sex-specific biomarkers strongly associated with IMF deposition in low- and high-IMF pig populations. The GSE144780 expression dataset of IMF deposition-related genes were obtained from the Gene Expression Omnibus. Initially, differentially expressed genes (DEGs) were detected in male and female low-IMF (162 DEGs, including 64 up- and 98 down-regulated genes) and high-IMF pigs (202 DEGs, including 147 up- and 55 down-regulated genes). Moreover, hub genes were screened via PPI network construction. Furthermore, hub genes were screened for potential sex-specific biomarkers using the least absolute shrinkage and selection operator machine learning algorithm, and sex-specific biomarkers in low-IMF (troponin I (TNNI1), myosin light chain 9(MYL9), and serpin family C member 1(SERPINC1)) and high-IMF pigs (CD4 molecule (CD4), CD2 molecule (CD2), and amine oxidase copper-containing 2(AOC2)) were identified, and then verified by quantitative real-time PCR (qRT-PCR) in semimembranosus muscles. Additionally, the gene set enrichment analysis and single-sample gene set enrichment analysis of hallmark gene sets were collectively performed on the identified biomarkers. Finally, the transcription factor-biomarker and lncRNA-miRNA-mRNA (biomarker) networks were predicted. The identified potential sex-specific biomarkers may provide new insights into the molecular mechanisms of IMF deposition and the beneficial foundation for improving meat quality in pig breeding.\n",
            "----------------------------------------\n",
            "Title: Deep Learning Algorithm Design for Discovery and Dysfunction of Landmines\n",
            "Abstract: Deep Learning is a cutting-edge technology which has a noteworthy impact in the real-world applications. The multi-layer neural nets involved in the blueprint of deep learning enables it to deliver a comprehensive decision-making system with quality of “think alike human cerebrum”. Deep Learning assumes an essential part in various fields like horticulture, medication, substantial business and so forth. Deep Learning can be well prompted in the remote sensing applications especially in perilous military applications. The location of land mines can be detected using a deep learning algorithm design technique aided with distinctive machine learning tools and techniques. The intelligent system designed by the deep learning process involves a massive dataset including the assorted features of the landmines like size, sort, dampness, ground profundity and so on. Incorporation of Geographical Information System can give a prevalent statistical analysis of the varied landmines. The multiple layers present in the deep learning neural schema may increase the feature extraction and the knowledge representation through increase in the complexities of landmines’ input sets. The likelihood of brokenness of landmines can be increased by the utilization of deep learning prediction model which enormously helps the survival of militaries, creating a social effect.\n",
            "----------------------------------------\n",
            "Title: Effective Risk Prediction of Cardiovascular Disease Using Machine Learning Classifiers\n",
            "Abstract: Cardiovascular disease (CVD) is a leading motive of loss of life international, with threat factors together with circle of relative's history and way of life habits playing a chief position. Early identity of high-danger people is critical to save you and control CVD. Present day strategies for CVD threat evaluation rely frequently on traditional hazard elements and are restrained in their accuracy. This challenge proposes to develop a system getting to know (ML) version to discover excessive-hazard individuals for CVD using a mixture of affected person data, including demographics, scientific records, and way of life behavior. The model will use ML techniques to analyze patterns and discover hidden relationships among risk elements and CVD effects. This could identify high-threat patients with high accuracy and assist healthcare companies make informed choices for personalized prevention and remedy plans. With the aid of utilizing ML, this challenge aims to enhance CVD hazard prediction and reduce the load of CVD by enabling early prognosis and intervention.\n",
            "----------------------------------------\n",
            "Title: Automated Multi-Scale and Multivariate Geological Logging from Drill-Core Hyperspectral Data\n",
            "Abstract: Hyperspectral drill-core scanning adds value to exploration campaigns by providing continuous, high-resolution mineralogical data over the length of entire boreholes. However, multivariate mineralogical data must be transformed into lithological domains such that it is compatible with interpolation techniques and be usable for geomodeling. Manual interpretation of multivariate drill-core data is a challenging, time-consuming and subjective task, and automated or semi-automated approaches are needed. However, naive machine-learning techniques that ignore the distinct spatial structure and multi-scale nature of geological systems tend to produce geologically unreasonable results. Automated geological logging and multi-scale hierarchical domaining of drill-cores has been previously addressed in several studies by means of scalograms from a wavelet transform and tessellation, albeit exploiting only univariate information. The methodology involves the extraction of the local first principal component at a neighborhood of each observation, and the segmentation of the resulting series of scores with a continuous wavelet transform for boundary detection. In this way, the correlation pattern between the variables is incorporated into the segmentation. The scalogram accurately locates the geological boundaries at depth and yields hierarchical geological domains with mineralogical composition characteristics. The performance of this approach is demonstrated on a synthetic as well as a real multivariate dataset. The real dataset consists of mineral abundances derived from drill-core hyperspectral imaging data acquired in Elvira, a shale-hosted volcanogenic massive sulfide deposit located in the Iberian Pyrite Belt, where 7000 m of drill-core were acquired along 80 boreholes. The extracted domains are sensible from a geological point of view and spatially coherent across the boreholes in cross-sections. The results at relevant scales were qualitatively validated by comparing against the lithological log. This method is fast, is appropriate for multivariate geological data along boreholes, and provides a choice of scales for hierarchical geological domains along boreholes with mineralogical composition characteristics that can be modeled in 3D. Our approach provides an automatic way to transform hyperspectral image-derived mineral maps into vertically coherent geological units that are appropriate inputs for 3D geological modeling workflows. Moreover, the method improves the boundary detection and geological domaining by making use of multivariate information.\n",
            "----------------------------------------\n",
            "Title: Approach to Detection of Anomalies of Process Signals Using Classification and Wavelet Transforms\n",
            "Abstract: The present-day IT infrastructure development level of industrial enterprises makes it possible to collect and store process information, thereby opening the possibilities to use intelligent data analysis systems. This paper overviews the problem of detecting the anomalies in process signals to improve safety and economic efficiency of the industrial enterprises. The combination of the machine learning and wavelet transform methods are proposed to detect anomalies. We have overviewed the nature of process signals to be taken into consideration as well as the advantages of wavelet analysis against the known methods of digital signals processing.\n",
            "----------------------------------------\n",
            "Title: Using Undervolting as an on-Device Defense Against Adversarial Machine Learning Attacks\n",
            "Abstract: Deep neural network (DNN) classifiers are powerful tools that drive a broad spectrum of important applications, from image recognition to autonomous vehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks that affect virtually all state-of-the-art models. These attacks make small imperceptible modifications to inputs that are sufficient to induce the DNNs to produce the wrong classification. In this paper we propose a novel, lightweight adversarial correction and/or detection mechanism for image classifiers that relies on undervolting (running a chip at a voltage that is slightly below its safe margin). We propose using controlled undervolting of the chip running the inference process in order to introduce a limited number of compute errors. We show that these errors disrupt the adversarial input in a way that can be used either to correct the classification or detect the input as adversarial. We evaluate the proposed solution in an FPGA design and through software simulation. We evaluate 10 attacks and show average detection rates of 77% and 90% on two popular DNNs.\n",
            "----------------------------------------\n",
            "Title: Adaptive recognition of machining features in sheet metal parts based on a graph class-incremental learning strategy\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Landslide Susceptibility Mapping using Association Rule Mining Based Apriori Algorithms and Multiple Clustering Algorithms\n",
            "Abstract: Haphazard development activities on mountain slopes and inadequate attention to construction aspects have led to increasing landslides and sustaining damages to the lives and the infrastructure. According to the National Research Building Organization (NBRO) reports, within the study area, nearly 3275 sq.km of the area expanded over the Ratnapura District; and 2178 sq.km area is to be highly prone to landsliding. If the appropriate investigations were performed in time, most of the landslides could be predicted relatively. This study aims to discover the real extent and severity of the landslide processes and risk evaluation within the study area. Machine Learning Approach based on Association Rule Mining and multiple Clustering algorithms were combined and implemented for the final prediction. This study possesses a strong capability to predict landslides risk by considering causative factors slope, Landuse, Geology, Soil material, elevation, intensity, and triggering factor; rainfall. Apriori Association rule algorithm, K-mean and Expectation Maximization (EM) clustering algorithms are the highest-ranking prediction algorithms. While applying the EM clustering method showed accuracy over 84% of the results with high speed and time taken to build was 0.66 seconds. The K-means algorithm gained the highest accuracy over 92% was applied and time taken to build was 1.58 seconds, though it was more time-consuming than EM algorithm. While applying the Apriori algorithm to obtain the best results, therefore ten (10) efficient prediction rules have found to fulfil the ultimate goal of this research. Moreover, the results show that the EM and Apriori algorithms have the best degree to fit for the Landslide susceptibility mapping. Keywords— Apriori, K-mean, Expectation Maximization (EM)\n",
            "----------------------------------------\n",
            "Title: Approaches For Automated Detection And Classification Of Masses In Mammograms\n",
            "Abstract: Breast cancer is one of the most common cancer among women around the world. Several techniques are available for detection of breast cancer. Mammography is one of the most effective tools for early detection. The goal of this research is to increase the diagnostic accuracy of image processing and machine learning techniques for optimum classification between normal and abnormalities in digital mammograms. GLCM texture feature extractions are known to be the most common and powerful techniques for texture analysis. This paper presents an evaluation and comparison of the performance of two different classification methods used to classify the normal and abnormal patterns. The experimental result suggest that Artificial Neural Network is outperformed the other method.\n",
            "----------------------------------------\n",
            "Title: 3D Object Classification Using Bounding Box\n",
            "Abstract: The field of 3D shape representations and recognition is changing over years with the advancement in computer vision and use of machine learning in the same field. The 3D model classification is an important problem, with applications in automotive, robotics, CAD visions, augmented reality and many more. In this research, machine learning is an important field with which we extract useful information from the AutoCAD drawing consisting of 3D Objects. It uses Features based classification techniques to identify different components for an AutoCAD drawing. This research is useful in tackling the problems where in there is a need to comprehend the CAD drawings with 3D objects present in it.\n",
            "----------------------------------------\n",
            "Title: Path Integral Quantum Mechanics: from the basics to the latest developments\n",
            "Abstract: This work is part of a joint doctoral program in condensed matter physics and theoretical chemistry that aims at simulating the quantum dynamics of light nuclei in materials and molecular systems. The general goal of the project is to develop a mathematical and simulation framework to address quantum reaction rate calculations and quantum-driven diffusion of light nuclei, such as hydrogen. H atoms show an intrinsic quantum delocalization which can be of the order of chemical bond lengths, so that nuclear quantum effects (NQEs) can have a strong impact. Zero-point energy and tunneling effects allow the exploration of regions of space that would be classically forbidden, with relevant consequences on H diffusion. The efficient simulation of molecules and materials from first principles is a long-standing challenge in the physical sciences. Machine learned force fields promise to speed up these simulations by several orders of magnitudes whilst being as accurate as high-level quantum mechanics. In the past 3 years several different approaches were proposed to fulfill this promise built on Gaussian Process Regression and Neural Networks. In this poster we demonstrate that highly accurate molecular force fields can be built using the Atomic Cluster Expansion framework and linear least squares regression. Our model is built from body ordered symmetric polynomials which is a natural extension of the traditional molecular mechanics force fields. We show that these relatively simple models are able to achieve state of the art accuracy on the MD17 benchmark dataset of small organic molecules. Furthermore, we also train several other machine learning models like sGDML, ANI and GAP, as well as a classical force field and compare them on tasks such as normal mode prediction and extrapolation to high temperature data. Finally, we fit the potential energy surface of a large flexible organic molecule and compare how well the models reproduce the dihedral torsional energy landscape form as little as 500 reference calculation. The STFC Rutherford Appleton Laboratory houses the ISIS Neutron and Muon Sources, which produce beams of neutrons and muons that can be used to study materials at the atomic level. Muons are subatomic particles -produced by bombarding a graphite target with pulses of high-energy protons that originate in a synchrotron- which are 100% spin-polarised and have approximately 1/10 of the mass of a proton. In a μSR experiment, spin-polarized positive muons are implanted in a sample and can be used, among other things, to study hydrogen defects, the magnetic structure of the sample or the organic radicals that may result from adding the muon to an organic sample. However, the μSR technique We introduce vibrational dynamical mean-field theory (VDMFT) as a non-perturbative and systematically improvable method for the simulation of anharmonic lattice dynamics. Inspired by its origin in electronic structure theory, VDMFT is a real-space embedding approach that maps the anharmonic dynamics of an extended, periodic lattice onto an impurity problem where the spectral density is self-consistently tailored. We develop VDMFT and its cluster extension with classical and quantum impurity solvers for one-dimensional models. When compared to classical exact molecular dynamics, VDMFT produces spectral function and density of states that precisely captures the frequency shifts, phonon lifetimes, and temperature dependence induced by anharmonicity. With much fewer degrees of freedom in the impurity model than in the full supercell, the approach is expected to converge to accurate results at affordable computational costs. Understanding the underlying mechanism of proton transport in hydrogen-bonded systems is crucial to a wide variety of applications ranging from voltage-gated proton channels in biological systems to proton exchange membrane fuel cells. Imidazole and 1,2,3-triazole are two promising hydrogen-bonded organic heterocycles that conduct protons via a structural transport mechanism involving intermolecular proton hops. The theoretical study of proton transport in these systems has proved challenging so far because ab initio simulations, which model the bond breaking and forming involved in structural diffusion, impose a significant computational cost given the system sizes and timescales needed to converge diffusion properties and hydrogen bond dynamics. Here, we leverage ab initio multiple time-stepping, an algorithmic advance that can be used to speed up molecular dynamics simulations, to accumulate ab initio trajectories in excess of a nanosecond for imidazole and each tautomer of 1,2,3-triazole. By using correlation function analysis, we decompose the mechanism of proton transport into a series of first-order processes and show that the proton transport mechanism occurs over three distinct time and length scales. We demonstrate that the linearity of hydrogen bond chains formed in imidazole and 1,2,3-triazole is positively correlated with the rate of proton diffusion. We also uncover evidence of a ‘blocking’ mechanism in both tautomers of 1,2,3-triazole, where hydrogen bonds formed by the middle nitrogen atom create a trap that limits the mobility of protons across the hydrogen bond network. Our simulations thus provide insights into the origins of the experimentally observed 10-fold difference in conductivity between imidazole and 1,2,3-triazole. [1] Z. Long, A. Atsango, J. Napoli, T. Markland, M. Tuckerman, J. Phys. Chem. Lett., 11 , 6156-6163 (2020) Establishing a comprehensive and quantitative understanding of mechanical instabilities in single-molecule junctions is a prerequisite for possible applications in nanoelectronic devices. Recent experimental and theoretical studies have revealed a variety of different processes triggering mechanical instabilities, including current-induced heating and nonconservative forces, however, the underlying mechanisms remain largely elusive. In this contribution, we present a fully quantum mechanical investigation of current-induced bond rupture in molecular junctions, employing the numerically exact hierarchical quantum master equation approach [1]. Based on a generic model for molecular junctions, our systematic study identifies three dissociation mechanisms: (1) ultrafast dissociation induced by the population of anti-bonding electronic states, (2) incoherent stepwise vibrational ladder climbing, (3) coherent multilevel vibrational excitations induced by multiple electronic transitions. Considering a broad range of different regimes and processes, comprising weak to strong electronic-vibrational and molecule-lead coupling as well as vibrational relaxation, we analyze the different mechanisms in detail. Furthermore, strategies for improving the stability of molecular junctions are discussed. Hybrid lead halide perovskites are a class of materials that have unique photophysical properties due to their anharmonic lattices and predominately ionic bonding. High quantum yield, a tunable band gap, high defect tolerance and low binding energy all make perovskites ideal for photovoltaic devices. Lead halide perovskites have exceptionally low rate of electron-hole recombination rates, which is implicated in their high-power conversion efficiencies. However, since both electrons and holes are diffusive and strongly couple to an anharmonicity lattice, elucidating the nature of this phenomena is theoretically difficult and little is known about the mechanism causing low recombination of charge carriers. In this work, we aim to explain the effects of anharmonicity on recombination phenomena and study how photogenerated electron and hole bind, dissociate and recombine by using molecular dynamics simulations. Using an effective mass model of the photoexcited charge carriers, we develop and deploy a quasiparticle based path integral molecular dynamics framework to study recombination. Using an atomistic model for perovskite lattice allows us to capture all orders of anharmonicity, reducing the computational complexity associated with studying this system, which would be intractable from standard solid-state methods. Equilibrium constant of isotope fractionation of boron between its two main aqueous species namely boric acid and borate is the main proxy for reconstruction of seawater pH and atmospheric pCO 2 in ancient era. The theoretically evaluated value of 1.0194 reported by Kakihana and coworkers [1] for this equilibrium constant which has been in use for some decades has now been found to underestimate A purpose of the current study is to find an alternative approach to the computation of multi-loop Feynman diagrams. Recently, deeper properties of Feynman amplitudes emerged through the study of differential forms. Feynman integrals are rewritten through the Baikov representation, from which it emerges that they form a vector space equipped with a scalar product defined by ‘intersection numbers’ of differential forms. The integral of interest is then projected onto a basis of ‘Master Integrals’ of said vector space; the basis was proven to be finite dimensional: its dimension corresponds to the one of the homology group associated to the space of integration, (or of the cohomology group equivalently).The poster includes the following:- the form of a Feynman integral in Baikov representation along with its implications (i.e., the identification of a vector space)- the determination of the dimension of said space from a geometric point of view (along with some explanatory figures)- the topological constructions underlying (along with some explanatory figures)- How the topological constructions lead to some observations related to the identification of a preferred basis of MIs.An extended treatment on these topics will be found in the editorial ‘Co-homology of Differential Forms and Feynman Diagrams’ (authors: S.L. Cacciatori, M. Conti, P. Mastrolia, S. Trevisan), which has yet to be pub\n",
            "----------------------------------------\n",
            "Title: Machine learning-based monitoring and design of managed aquifer rechargers for sustainable groundwater management: scope and challenges.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: AUTOMATED, OUTPUT-ONLY EXTRACTION OF FULL-FIELD, VERY HIGH SPATIAL RESOLUTION DYNAMIC PARAMETERS FROM VIDEOS OF OPERATING STRUCTURES\n",
            "Abstract: Modal analysis is essential for dynamic modeling and analysis of seismic excited structures. Experimental or operational modal analysis traditionally requires physically-attached wired or wireless sensors for vibration measurement of structures. The sensor instrumentation could result in mass-loading on lightweight structures, and is costly and time-consuming for large civil structures, especially for longterm applications (e.g., structural health monitoring and seismic dynamic analysis) that require significant maintenance and labors for cabling (wired) or energy supply (wireless). In addition, these sensors are discrete point-wise, providing low spatial sensing resolution that is hardly sufficient for larger structures. Non-contact optical methods such as scanning laser vibrometers provide high-resolution sensing capacity without the mass loading effect; however, they operate sequential measurement that requires considerable acquisition time. As an alternative non-contact method, digital video cameras are relatively low-cost, agile, and provide high spatial resolution, simultaneous, measurements. Combined with vision based algorithms (e.g., image correlation or template matching, optical flow, etc.), video camera based measurements have been successfully used for experimental and operational vibration measurement and modal analysis, such as the digital image correlation (DIC) and the point-tracking techniques. However, they typically require speckle pattern or high-contrast markers instrumented on the surface of structures, which raises the instrumentation issue when the measurement area is large or inaccessible. This work explores advanced computer vision and video processing algorithms to develop a novel video measurement and vision based output-only modal analysis method that removes the need of structural surface preparation in existing vision based methods. By manipulating the motion encoded in the video measurements only using multi-scale image decomposition and unsupervised machine learning techniques, the proposed method efficiently and accurately extract modal frequencies, very high spatial (pixel) resolution mode shapes, and damping ratios of the structure. The method is validated by laboratory experiments on bench-scale structures including a building structure and a cantilever beam. Video demos of these experimental results are on http://www.lanl.gov/projects/national-security-educationcenter/engineering/research-projects/blind-modal-id.php.\n",
            "----------------------------------------\n",
            "Title: Regularized robust fuzzy least squares twin support vector machine for class imbalance learning\n",
            "Abstract: Twin support vector machines (TWSVM) have been successfully applied to the classification problems. TWSVM is computationally efficient model of support vector machines (SVM). However, in real world classification problems issues of class imbalance and noise provide great challenges. Due to this, models lead to the inaccurate classification either due to higher tendency towards the majority class or due to the presence of noise. We provide an improved version of robust fuzzy least squares twin support vector machine (RFLSTSVM) known as regularized robust fuzzy least squares twin support vector machine (RRFLSTSVM) to handle the imbalance problem. The advantage of RRFLSTSVM over RFLSTSVM is that the proposed RRFLSTSVM implements the structural risk minimization principle by the introduction of regularization term in the primal formulation of the objective functions. This modification leads to the improved classification as it embodies the marrow of statistical learning theory. The proposed RRFLSTSVM doesn’t require any extra assumption as the matrices resulting in the dual are positive definite. However, RFLSTSVM is based on the assumption that the inverse of the matrices resulting in the dual always exist as the matrices are positive semi-definite. To subsidize the effects of class imbalance and noise, the data samples are assigned weights via fuzzy membership function. The fuzzy membership function incorporates the imbalance ratio knowledge and assigns appropriate weights to the data samples. Unlike TWSVM which solves a pair of quadratic programming problem (QPP), the proposed RRFLSTSVM method solves a pair of system of linear equations and hence is computationally efficient. Experimental and statistical analysis show the efficacy of the proposed RRFLSTSVM method.\n",
            "----------------------------------------\n",
            "Title: Discovering containment: from infants to machines\n",
            "Abstract: Current artificial learning systems can recognize thousands of visual categories, or play Go at a champion\"s level, but cannot explain infants learning, in particular the ability to learn complex concepts without guidance, in a specific order. A notable example is the category of 'containers' and the notion of containment, one of the earliest spatial relations to be learned, starting already at 2.5 months, and preceding other common relations (e.g., support). Such spontaneous unsupervised learning stands in contrast with current highly successful computational models, which learn in a supervised manner, that is, by using large data sets of labeled examples. How can meaningful concepts be learned without guidance, and what determines the trajectory of infant learning, making some notions appear consistently earlier than others?\n",
            "----------------------------------------\n",
            "Title: Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex Minimax Machine Learning\n",
            "Abstract: Alternating gradient-descent-ascent (AltGDA) is an optimization algorithm that has been widely used for model training in various machine learning applications, which aims to solve a nonconvex minimax optimization problem. However, the existing studies show that it suffers from a high computation complexity in nonconvex minimax optimization. In this paper, we develop a single-loop and fast AltGDA-type algorithm that leverages proximal gradient updates and momentum acceleration to solve regularized nonconvex minimax optimization problems. By leveraging the momentum acceleration technique, we prove that the algorithm converges to a critical point in nonconvex minimax optimization and achieves a computation complexity in the order of $\\mathcal{O}\\left( {{\\kappa ^{\\frac{{11}}{6}}}{\\varepsilon ^{ - 2}}} \\right)$, where ϵ is the desired level of accuracy and κ is the problem’s condition number. Such a computation complexity improves the state-of-the-art complexities of single-loop GDA and AltGDA algorithms (see the summary of comparison in Table I). We demonstrate the effectiveness of our algorithm via an experiment on adversarial deep learning.\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning for Travel Time Prediction in the Colorado Rockies\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Vectorization Approach to Language Identification of Social Media Short Texts\n",
            "Abstract: Language identification is an important task in machine translation, information storage and retrieval et al. However, traditional approaches cannot adapt those texts in social applications, which have the following characteristics: 1) shorter length, no more than 140 characters generally. 2) colloquial and anomalous grammar texts, which are generated directly by different users of the social platform. In this paper, we propose a vectorization-based approach, which exploits weighted n-gram statistical features and improved Cascade Forest approach to conduct accurate language identification of social media short texts. In order to classify a line of text, our approach firstly represents it by a fix-length feature vector, and then leverages a supervised classifier to assign a proper language to it. We implement our approach and conduct extensive evaluations on real-world social texts. The results show that our approach achieves better accuracy, precision and recall rates when compared with the state-of-art machine learning algorithms and off-the-shelf approaches. It also proves that our approach displays competitive performance in practice.\n",
            "----------------------------------------\n",
            "Title: A Study on Smart Machine Learning (ML) Tools for Crime Detection and Prediction\n",
            "Abstract: Crime, a grave menace to society, not only disrupts the lives of individuals, whether they are victims or perpetrators but also reverberates throughout families and communities. Presently, law enforcement agencies face the daunting task of thwarting criminal activities. This study delves into various machine learning algorithms employed in the detection and prevention of crime. This research paper surveys recent literature examining the application of various Machine Learning algorithms in forecasting and mitigating future criminal activities. It investigates the computational challenges and opportunities presented by historical trends in predicting crime—the study endeavours to analyse and discuss the predominant parameters explored across multiple studies. Through a review of past literature, it becomes apparent that while numerous parameters have been utilized, the primary focus remains on crime patterns concerning time and crime hotspots. This paper conducts a comprehensive inquiry into Machine Learning techniques for uncovering and forecasting future crimes. It reveals that researchers predominantly rely on supervised ML approaches in their investigations, largely due to their superior accuracy.\n",
            "----------------------------------------\n",
            "Title: A Novel Fault Feature Selection and Diagnosis Method for Rotating Machinery With Symmetrized Dot Pattern Representation\n",
            "Abstract: Fault diagnosis methods based on machine learning have made great progress for rotating machinery. The main steps of the machine learning process involve feature extraction, selection, and classification. Feature selection improves classification accuracy and reduces diagnosis time by selecting the better features. Due to the difficulty of traditional feature selection methods to rank the feature importance of each class, the best subset of features could hardly be obtained. Therefore, this article proposes a new feature selection method to address the shortcomings of the above traditional methods, called Feature Ranking based on Optimal Class Distance Ratio (FROCDR), which can choose the optimal features between every two classes of samples to obtain feature ranking that is conducive to classification. In order to comprehensively extract the fault information in the signal, the multiscale analysis and the variational mode decomposition (VMD) method are applied to process the vibration signals under different scales and frequency bands, and the processed signals are visualized by symmetrized dot pattern (SDP). In addition, features are extracted from the obtained SDP images, and the proposed FROCDR method is used to select the best subset of features. The final diagnosis task is accomplished by a random forest (RF) classifier. Experimental cases of bearing and gear data show that the proposed method has higher diagnostic accuracy and stability.\n",
            "----------------------------------------\n",
            "Title: Season-Based Occupancy Prediction in Residential Buildings Using Machine Learning Models\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Plasma Proteomic Profiles Predict the Risk of Coronary Artery Disease in the UK Biobank Cohort\n",
            "Abstract: Coronary artery disease (CAD) is a complex, multifactorial, and serious condition influenced by genetic, environmental, and lifestyle factors. Thus, it is crucial to develop strategies to predict the risk of CAD for individuals. Plasma proteomics provides a powerful framework for identifying novel biomarkers, discovering potential therapeutic targets, and further improving risk stratification. Here, we examined the association between 2,919 plasma proteins and incident CAD in the UK Biobank cohort (n=35,778). As a result, we identified 576 proteins significantly associated with CAD and found significant alterations in key biological pathways, including signal transduction, immune regulation, and chemotaxis, before CAD onset. Subsequently, we developed machine learning models to predict CAD onset at different time intervals (5 years, 10 years, over 10 years, and entire cohort), demonstrating superior performance over models based on polygenic risk scores ({Delta}AUC = 0.052), and Pooled Cohort Equations ({Delta}AUC = 0.049). Notably, the integration of PRS with proteomic data resulted in a marked enhancement in predictive accuracy (AUC = 0.779), comparable to the full model (AUC = 0.780). Key plasma protein predictors, including MMP12, GDF15, and EDA2R, showed sustained importance across models predicting CAD onset at multiple time points. Additionally, Mendelian randomization analysis provided robust evidence for a causal relationship between six plasma proteins and CAD, including MMP12, LPA and PLA2G7, highlighting their potential as therapeutic targets. In conclusion, our study elucidates the plasma proteome associated with CAD, reveals underlying pathogenic mechanisms, and provides valuable insights for identifying high-risk individuals and advancing precision medicine.\n",
            "----------------------------------------\n",
            "Title: Artificial emotion of face robot through learning in communicative interactions with human\n",
            "Abstract: It is pointed out that human-robot interface or human interface must be newly interpreted as intelligence of communicative interaction between robot and human, and is again a key issue for development of a new species of robot that is able to serve humans. We point out a concept of \"active human interface (or media) \" to be composed of three functions and essential to such new robots. When applying such machine to use for human service, psychological familiarity of robot form is another issue to ensure the psychological acceptance. We refer again to the existence of uncanny valley in familiarity to robot appearance or form. We have been developing a life-like face robot that has been a human media for realizing such intelligence of communicative interaction and technological issues and performance of face robot's recognition function of human emotion and actuation function of facial expressions are briefly summarized to understand the state-of-the arts about the face robot Mark II. Then basic studies for characterizing face robot behavior through communicative interactions with a human partner are described by showing two test results of imitation of facial expressions and personality creation in face robot response. We point out the importance of learning method employed by face robot in communicative interactions is also key issue. We can show that the most suitable learning method for human partner is OR type supervised reinforced one. Finally we discuss the value system in relation to unsupervised learning of face robot in communicative interaction to characterize its emotion or selection criteria or bias at taking a certain response facial expression to the partner's state of mind. At the end concluding remarks and future studies are briefly pointed out.\n",
            "----------------------------------------\n",
            "Title: Dog’s Emotion Extraction from Bark Using Machine Learning: A Review\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Optimization of Online Soluble Solids Content Detection Models for Apple Whole Fruit with Different Mode Spectra Combined with Spectral Correction and Model Fusion\n",
            "Abstract: Soluble solids content (SSC) is one of the main quality indicators of apples, and it is important to improve the precision of online SSC detection of whole apple fruit. Therefore, the spectral pre-processing method of spectral-to-spectral ratio (S/S), as well as multiple characteristic wavelength member model fusion (MCMF) and characteristic wavelength and non-characteristic wavelength member model fusion (CNCMF) methods, were proposed for improving the detection performance of apple whole fruit SSC by diffuse reflection (DR), diffuse transmission (DT) and full transmission (FT) spectra. The modeling analysis showed that the S/S- partial least squares regression models for all three mode spectra had high prediction performance. After competitive adaptive reweighted sampling characteristic wavelength screening, the prediction performance of all three model spectra was improved. The particle swarm optimization–extreme learning machine models of MCMF and CNCMF had the most significant enhancement effect and could make all three mode spectra have high prediction performance. DR, DT, and FT spectra all had some prediction ability for apple whole fruit SSC, with FT spectra having the strongest prediction ability, followed by DT spectra. This study is of great significance and value for improving the accuracy of the online detection model of apple whole fruit SSC.\n",
            "----------------------------------------\n",
            "Title: Time-resolved fluorescence spectroscopy in differential diagnosis of liver cancer in vivo\n",
            "Abstract: Thiswork reports a machine-learning-based approach to interpret time-resolved fluorescence spectroscopy data acquired during optical biopsy of the liver. The approach allowed to differentiate between liver parenchyma and tumor with sensitivity and specificity above 0.91 and 0.79, respectively, providing differential diagnosis of liver cancer (primary malignant tumor, metastases, or benign) with sensitivity and specificity of at least 0.80 and 0.95.\n",
            "----------------------------------------\n",
            "Title: Complexity Versus Complex Systems: A New Approach to Scientific Discovery\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Automated Detection of Multidirectional Compensatory Balance Reactions: A Step Towards Tracking Naturally Occurring Near Falls\n",
            "Abstract: Falls are the leading cause of fatal and non-fatal injuries among seniors with serious and costly consequences. Laboratory evidence supports the view that impaired ability to execute compensatory balance reactions (CBRs) or near-falls is linked to an increased risk of falling. Therefore, as an alternative to the commonly used fall risk assessment methods examining spatial-temporal parameters of gait, this study focuses on the development of machine learning-based models to detect multidirectional CBRs using wearable inertial measurement units (IMUs). Random forest models were developed based upon the data captured by five wearable IMUs to 1) detect CBRs during normal gait, and 2) identify the type of CBR (eight different classes). A perturbation treadmill (PT) was employed to systematically elicit CBRs (i.e. PT-CBRs) during walking in different directions (e.g slip-like, trip-like, and medio-lateral) and amplitudes (e.g., low-, high-amplitude). We hypothesized that these PT-CBRs could simulate naturally-occurring CBRs (N-CBRs). Proof-of-concept testing in 9 young, healthy adults demonstrated accuracies of 96.60% and 80.64% for the PT-CBR detection and type identification models, respectively. Performance of the detection model was tested against a published dataset (IMUFD) simulating N-CBRs, including the most common types observed in older adults in long-term care facilities, which achieved sensitivity of 100%, but poor specificity. Adding normal gait data from IMUFD for training improved specificity, indicating treadmill walking alone is insufficient exemplar data. Perturbation treadmill combined with overground walking data is a suitable paradigm to collect training datasets of involuntary CBR events. These findings suggest that accurate detection of naturally-occurring CBRs is feasible, and supports further investigation of implementing a wearable sensor system to track naturally-occurring CBRs as a novel means of fall risk assessment.\n",
            "----------------------------------------\n",
            "Title: Statistical Machine Learning Methods to Handle Missing PHQ-8 Score – Assuming Missing at Random\n",
            "Abstract: Aims Missing data is a challenge that most researchers encounter. It is a concern that continues to be analyzed and addressed for solutions. Missing data occurs when there is no data stored for certain variables relating to participants. In health surveys, when participants answer in the form of “I don't know” or “I'd prefer not to answer”, these responses can, in many cases, be categorized as missing data responses from a participant in a specific category or question. The eight-item Patient Health Questionnaire (PHQ-8) is an essential tool in healthcare and clinical settings to assess an individual's mental health, specifically related to symptoms of depression. The items are scored on a scale from 0 to 3 with the total score obtained by summing the scores for each item. Higher PHQ-8 scores indicate the presence of depressive symptoms. We used empirical data from a previous study on depression symptoms in patients with coronary heart disease to study the effect of considering the answers “I do not know” and “I prefer not to answer” as missing values when estimating the percentage of depression using PHQ-8. Moreover, we studied the effect of the complete case analysis and multiple imputation on parameter estimates and confidence intervals. The outcome of this study aims to shed light on the development of missing data procedural knowledge and provide methodological support for public health decision-making when data with missing values are collected. Furthermore, this study aims to prevent the exclusion of missing data rather than to generate data. Methods A simulation study with 1000 replicates was performed. Four common statistical machine learning methods for handling missing values were included in this study. These are K-Nearest Neighbor (KNN), K-Means, Classification and Regression Trees (CART), and Random Forest (RF) imputations. Five clusters were used for KNN and K-mean. Likewise, five multiple imputations were used for the CART and RF methods. The simulation was based on publicly available data with available PHQ-8 data for 1096 subjects. In the simulation study and for each replication, multivariate missing values were generated using the missing-at-random (MAR) assumption with 10%, 20%, 30%, 40%, and 50% proportions of missingness. The percent of depression was calculated using the PHQ-8 questionnaire and a comparison was made between estimated actual depression, complete-case analysis, KNN, Kmean, RF, and CART, respectively. Results The Median age of the subjects was 69 (interquartile range: 61–67) and more males (72.9%) than females were included in the data. The estimated actual depression was 16.8, whereas the estimated percentage of depression varies between 6.9–13.5, 16.2–16.7, 16.3–16.7, 16.6–16.7 and 16.7–16.8 for the complete case, KNN, Kmean, RF and CART respectively. Conclusion The results of this simulation study show that missing PHQ-8 data are best handled by applying multiple imputations based on CART or RF. However, using K-Means or KNN leads to a good estimate of the true percentage of depression. Furthermore, the results of this simulation study show that complete-case analysis leads to biased estimates of the true percentage of depression. Nevertheless, further investigation is needed to address the problem of missing PHQ-8 data under the assumption of missing not at random.\n",
            "----------------------------------------\n",
            "Title: SchemaLogix: Advancing Interoperability with Machine Learning in Schema Matching\n",
            "Abstract: —Schema matching, a fundamental process in data integration, traditionally employs pairwise comparisons to discern semantic correspondences among elements in disparate schemas. However, recent developments underscore the necessity of concurrent matching of interconnected schemas, termed schema alignment, to reconcile heterogeneous elements. This paper presents SchemaLogix, an innovative machine learning-based approach for schema matching. SchemaLogix addresses challenges such as data scarcity and domain-specific constraints through an inventive bootstrapping method, autonomously generating extensive datasets. Furthermore, SchemaLogix capitalizes on inherent alignment context constraints to optimize learning and improve precision across varied schema structures. Additionally, SchemaLogix incorporates user contributions to validate chosen correspondences, refining outputs based on valuable feedback. Empirical evaluations establish SchemaLogix's superiority over traditional methods, achieving an exceptional maximum S1 score of 0.90. These results offer practical insights for real-world applications, substantially advancing data integration and interoperability endeavors.\n",
            "----------------------------------------\n",
            "Title: Graph Search and its Application in Building Extraction from High Resolution Remote Sensing Imagery\n",
            "Abstract: Man-made object recognition from remotely sensed imagery is not only scientifically challenging but also of significant practical importance for spatial data acquisition and update of geographic information system databases, mapping, cartography, image interpretation, military activities and other applications, etc. In the literature, a large amount of work that has been done in the field of high resolution image understanding focuses on the development of efficient and robust algorithms to detect and extract typical man-made objects, such as buildings and roads. Most methods for building extraction can be classified into two categories: edge-driven approaches and region-driven approaches. The edgedriven approaches usually involve a procedure of bottom-up processing of image primitive features, trying to link or group the linear features corresponding to a building to obtain building boundary. In a region-driven strategy, various methods, such as artificial neural networks, support vector machines, machine learning strategies and other traditional classification schemes in pattern recognition are employed to categorize the regions derived by segmentation based on region features. The following section briefly reviews the methodologies of these two categories available in the literature. Edge-driven methods, such as perceptual grouping and contour tracing, are widely used for building extraction in the literature. Perceptual organization (Mohan and Nevatia 1989) was used to detect and describe buildings in aerial images. There, linear features are firstly extracted and grouped into parallel lines. Parallel lines with aligned endpoints trigger the formation of a U structure. Two U structures trigger the formation of a rectangle hypothesis which is further filtered. Katartzis and Sahli (2008) proposed a method based on a stochastic image interpretation model, using a novel contour-based grouping hierarchy under the principles of perceptual organization. The BABE (Buildup Area Building Extraction) system (McKeown 1990) performed perceptual organization of lines and orthogonal corners into chains and rectangles to form building hypotheses that were further verified using shadow information. Lin and Nevatia (1998) derived the geometric relationship between building margin lines and building shadows analytically according to a general illumination model.\n",
            "----------------------------------------\n",
            "Title: Battery Performance Evaluation through Decision Tree\n",
            "Abstract: This study addresses the pervasive concern surrounding battery performance degradation in electronic devices. While some attribute this decline to device aging, a significant portion of the population lacks awareness of the precise factors contributing to diminished battery efficiency. Consequently, the research investigates the factors related to battery performance, aiming to identify the determinants of reduced efficiency. Decision trees are used to meticulously analyze the intricate relationships between variables and discern the factors that respondents perceive as causative of diminished battery performance. This algorithm is chosen since, in predicting high-capacity lithium-ion battery performance, the decision tree outperforms other algorithms in machine learning in accuracy. The study elucidates diverse user preferences, with 55.38% favoring Android and 44.62% expressing a preference for iOS, indicating disparate perceptions of battery health: 61.54% consider their batteries as \"Good,\" while 38.46% acknowledge a decline. The decision tree analysis of 195 participants underscores the pronounced impact of prolonged usage on battery health, revealing that 95% maintain good battery performance. In contrast, 27.69% of Android users face reduced battery performance, emphasizing the need for targeted user education and Android manufacturers to prioritize device longevity. The ultimate objective is to give readers a comprehensive understanding of the dynamics of battery performance in the context of device aging and its contributing factors and give some input to manufacturers and service providers. \n",
            "----------------------------------------\n",
            "Title: Representation of Texts into String Vectors for Text Categorization\n",
            "Abstract: In this study, we propose a method for encoding documents into string vectors, instead of numerical vectors. A traditional approach to text categorization usually requires encoding documents into numerical vectors. The usual method of encoding documents therefore causes two main problems: huge dimensionality and sparse distribution. In this study, we modify or create machine learning-based approaches to text categorization, where string vectors are received as input vectors, instead of numerical vectors. As a result, we can improve text categorization performance by avoiding these two problems.\n",
            "----------------------------------------\n",
            "Title: Data augmentation in natural language processing: a novel text generation approach for long and short text classifiers\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Letter to the Editor From Fu et al: \"Machine Learning Reveals the Contribution of Lipoproteins to Liver Triglyceride Content and Inflammation\".\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Classification with Valid and Adaptive Coverage\n",
            "Abstract: Conformal inference, cross-validation+, and the jackknife+ are hold-out methods that can be combined with virtually any machine learning algorithm to construct prediction sets with guaranteed marginal coverage. In this paper, we develop specialized versions of these techniques for categorical and unordered response labels that, in addition to providing marginal coverage, are also fully adaptive to complex data distributions, in the sense that they perform favorably in terms of approximate conditional coverage compared to alternative methods. The heart of our contribution is a novel conformity score, which we explicitly demonstrate to be powerful and intuitive for classification problems, but whose underlying principle is potentially far more general. Experiments on synthetic and real data demonstrate the practical value of our theoretical guarantees, as well as the statistical advantages of the proposed methods over the existing alternatives.\n",
            "----------------------------------------\n",
            "Title: Knowledge discovery for time series\n",
            "Abstract: My thesis investigates the use of machine learning methods for analysis of economic and financial time series. Since structural models in economics and finance are known to have limited predictive power, I study a data driven, time series approach to knowledge discovery in these domains. The ultimate goal of building predictive models of such time series is to support decision making in areas such as business, investing, and government policy. \n",
            "Machine learning offers powerful tools for forecasting and decision making. Supervised learning methods can be used to develop forecasting models of economic series that can aid in decision support. Reinforcement learning methods can produce systems capable of making investment decisions. Hence, my thesis consists of two main investigations: a study of methods for predicting macroeconomic and financial time series, and a study of extensions to a reinforcement learning algorithm for constructing financial decision systems. \n",
            "In the forecasting project, I develop a supervised training methodology for models that predict challenging macroeconomic and financial time series. I compare the performance of linear and nonlinear networks with a diverse set of standard linear benchmark models. While some advantage is obtained from the use of nonlinear networks for certain of these time series, a key result is that linear network models trained with stochastic, nonlinear neural network learning algorithms can achieve greatly improved performance over the benchmark methods on most of the data sets. \n",
            "The second topic investigated is enhancements to the Recurrent Reinforcement Learning (RRL) algorithm. The RRL approach to trading system design has been shown to be effective at learning strategies that directly maximize financial objective functions, and also has been shown to outperform approaches based on supervised learning on artificial data sets. In my work, I investigate several significant extensions of RRL: to incorporate downside risk measures, to compare the RRL policy approach to an alternate RL value function approach, to extend the approach to portfolio management, and to conduct simulation studies on a number of artificial and real data sets, including an S&P-500 asset allocation system and a high frequency foreign exchange trader.\n",
            "----------------------------------------\n",
            "Title: Research Progress of Crop Disease Image Recognition Based on Wireless Network Communication and Deep Learning\n",
            "Abstract: The traditional digital image processing technology has its limitations. It requires manual design features, which consumes manpower and material resources, and identifies crops with a single type, and the results are bad. Therefore, to find an efficient and fast real-time disease image recognition method is very meaningful. Deep learning is a machine learning algorithm that can automatically learn representative features to achieve better results in areas of image recognition. Therefore, the purpose of this paper is to use deep learning methods to identify crop pests and diseases and to find efficient and fast real-time image recognition methods of disease. Deep learning is a newly developed discipline in recent years. Its purpose is to study how to actively obtain a variety of feature representation methods from data samples and rely on data-driven methods, a series of nonlinear transformations are applied to finally collect the original data from specific to abstract, from general to specified semantics, and from low-level to high-level characteristic forms. This paper analyzes the classical and the latest neural network structure based on the theory of deep learning. For the problem that the network based on natural image classification is not suitable for crop pest and disease identification tasks, this paper has improved the network structure that can take care of both recognition speed and recognition accuracy. We discussed the influence of the crop pest and disease feature extraction layer on recognition performance. Finally, we used the inner layer as the main structure to be the pest and disease feature extraction layer by comparing the advantages and disadvantages of the inner and global average pooling layers. We analyze various loss functions such as Softmax Loss, Center Loss, and Angular Softmax Loss for pest identification. In view of the shortcomings of difficulty in loss function training, convergence, and operation, making the distance between pests and diseases smaller and the distance between classes more greater improved the loss function and introduced techniques such as feature normalization and weight normalization. The experimental results show that the method can effectively enhance the characteristic expression ability of pests and diseases and thus improve the recognition rate of pests and diseases. Moreover, the method makes the pest identification network training simpler and can improve the pest and disease recognition rate better.\n",
            "----------------------------------------\n",
            "Title: Getting High: High Fidelity Simulation of High Granularity Calorimeters with High Speed\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: An improved artificial bee colony algorithm based on whale optimization algorithm for data clustering\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Developing a Smart PACS: CBIR System Using Deep Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Artificial intelligence in obstetrics\n",
            "Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of various maternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that various machine learning methods have been successfully employed for different kinds of data capture with regard to early diagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should also be considered accordingly.\n",
            "----------------------------------------\n",
            "Title: Phishing Scam Detection using Machine Learning\n",
            "Abstract: As a wrongdoing of utilizing specialized intends to take sensitive data of clients and users in the internet, phishing is as of now an advanced risk confronting the Internet, and misfortunes due to phishing are developing consistently. Recognition of these phishing scams is a very testing issue on the grounds that phishing is predominantly a semantics based assault, which particularly manhandles human vulnerabilities, anyway not system or framework vulnerabilities. Phishing costs. As a product discovery plot, two primary methodologies are generally utilized: blacklists/whitelists and machine learning approaches. Every phishing technique has different parameters and type of attack. Using decision tree algorithm we find out whether the attack is legitimate or a scam. We measure this by grouping them with diverse parameters and features, thereby assisting the machine learning algorithm to edify.\n",
            "----------------------------------------\n",
            "Title: Determining the probability of occurrence of diabetic cardiovascular disorder using machine learning algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Mission-Driven Inverse Design of Blended Wing Body Aircraft with Machine Learning\n",
            "Abstract: The intent of this work was to investigate the feasibility of developing machine learning models for calculating values of airplane configuration design variables when provided time-series, mission-informed performance data. Shallow artificial neural networks were developed, trained, and tested using data pertaining to the blended wing body (BWB) class of aerospace vehicles. Configuration design parameters were varied using a Latin-hypercube sampling scheme. These data were used by a parametric-based BWB configuration generator to create unique BWBs. Performance for each configuration was obtained via a performance estimation tool. Training and testing of neural networks was conducted using a K-fold cross-validation scheme. A random forest approach was used to determine the values of predicted configuration design variables when evaluating neural network accuracy across a blended wing body vehicle survey. The results demonstrated the viability of leveraging neural networks in mission-dependent, inverse design of blended wing bodies. In particular, feed-forward, shallow neural network architectures yielded significantly better predictive accuracy than cascade-forward architectures. Furthermore, for both architectures, increasing the number of neurons in the hidden layer increased the prediction accuracy of configuration design variables by at least 80%.\n",
            "----------------------------------------\n",
            "Title: HARResNext: An efficient ResNext inspired network for human activity recognition with inertial sensors\n",
            "Abstract: Human activity recognition (HAR) based on wearable sensors has developed as a new study topic in the domains of artificial intelligence and pattern recognition. HAR has a wide range of applications, including sports activity detection, smart homes, and health assistance, to name a few. Mobile device sensors such as accelerometers, gyroscopes, and magnetometers can generate time-series data for HAR. Computer Vision (CV) methods were previously utilised for HAR, which has a number of drawbacks, including mobility, ambient conditions, occlusion, higher cost, and, most importantly, privacy. Using sensor data instead of typical computer vision techniques has various advantages. Their work is believed to have overcome virtually all of the limitations of computer vision techniques. The use of Machine Learning (ML) and Deep Neural Networks (DNN) to recognise human activity from inertial sensor data is widely established in the literature. In this paper, we introduce HARResNeXT, a novel convolutional neural network inspired by ResNeXT. It classifies Human Activities based on inertial sensors data of smartphone. The presented model has been evaluated on a dataset by WISDM (Wireless Sensor Data Mining) Lab. We have achieved 97\\% Precision, Recall and F1-score. Moreover, the average accuracy achieved is 96.62\\%. Comparison with previous studies showed the presented model out-performed state-of-the-art.\n",
            "----------------------------------------\n",
            "Title: Automatic Double Machine Learning for Continuous Treatment Effects\n",
            "Abstract: In this paper, we introduce and prove asymptotic normality for a new nonparametric estimator of continuous treatment effects. Specifically, we estimate the average dose-response function —the expected value of an outcome of interest at a particular level of the treatment level. We utilize tools from both the double debiased machine learning (DML) and the automatic double machine learning (ADML) literatures to construct our estimator. Our estimator utilizes a novel debiasing method that leads to nice theoretical stability and balancing properties. In simulations our estimator performs well compared to current methods.\n",
            "----------------------------------------\n",
            "Title: Groundwater Level Prediction: A Novel Study on Machine Learning Based Approach with Regression Models for Sustainable Resource Management\n",
            "Abstract: Ground water is a natural vital resource with significant implications for sustainable water management. Accurate predictions of groundwater levels is essential for informed decision-making and resource allocation. The paper presents a novel machine learning based approach for groundwater level prediction. Groundwater level prediction is a complex task due to the interplay of various environmental factors. Traditional hydrological models often struggle to capture the underlying patterns accurately. Our paper aims to develop a data-driven model that leverages historical groundwater data, meteorological information, and geospatial features to predict groundwater levels with high accuracy. We propose a multi-step approach that involves data preprocessing, feature engineering, and model development. We utilize a regression model, optimized through grid search, to capture the nonlinear relationships within the data. Our experiments on a large-scale groundwater dataset demonstrate the effectiveness of the proposed approach. The model achieves a mean squared error of 0.025 and an R-squared value of 0.85, outperforming traditional models by a significant margin.\n",
            "----------------------------------------\n",
            "Title: MACHINE LEARNING USING SIMILARITY ANALYSIS IMPROVES RISK STRATIFICATION BEYOND SURGICAL RISK SCORES IN PATIENTS UNDERGOING TRANSCATHETER AORTIC VALVE REPLACEMENT\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Dynamic Knowledge Tracing Models for Large-Scale Adaptive Learning Environments\n",
            "Abstract: — Large-scale data about learners’ behavior are being generated at high speed on various online learning platforms. Knowledge Tracing (KT) is a family of machine learning sequence models that use these data to identify the likelihood of future learning performance. KT models hold great potential for the online education industry by enabling the development of personalized adaptive learning systems. This study provides an overview of five KT models from both a technical and an educational point of view. Each model is chosen based on the inclusion of at least one adaptive learning property. These are the recency effects of engagement with the learning resources, dynamic sequences of learning resources, inclusion of students’ differences, and learning resources dependencies. Furthermore, the study outlines for each model, the data representation, evaluation, and optimization component, together with their advantages and potential pitfalls. The aforementioned dimensions and the underlying model assumptions reveal potential strengths and weaknesses of each model with regard to a specific application. Based on the need for advanced analytical methods suited for large-scale data, we briefly review big data analytics along with KT learning algorithms’ scalability. Challenges and future research directions regarding learners’ performance prediction are outlined. The provided overview is intended to serve as a guide for researchers and system developers, linking the models to the learner’s knowledge acquisition process modeled over time.\n",
            "----------------------------------------\n",
            "Title: Prediction of Brand Loyalty on Supervised Machine Learning Algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Automatic Evaluation of Strephenopodia Based on Plantar Pressure and Machine Learning: A Pilot Study\n",
            "Abstract: \n",
            " Purpose Stroke patients often suffer from strephenopodia because of high muscle tension or muscle spasms, which seriously affect their walking ability and rehabilitation. During the treatment of strephenopodia, there are practical demands for convenient, automatic, and quantitative assessments of the angle of strephenopodia. However, existing strephenopodia detection methods, including traditional clinical gait analysis, gait video analysis and plantar pressure systems, suffer from object obstruction or require complex setups. In this paper, we proposed a novel methodology for automatically predicting the angles of strephenopodia based on a gait analysis system using machine learning methods.Methods Plantar pressure distribution data from thirty healthy participants were recorded during walking on the Zebris FDM-THM instrumented treadmill and were processed to generate 15 gait features. The right ankle angles on the coronal plane were measured by the Vicon system to provide a detailed description and explanation of strephenopodia walking. Three machine learning methods were implemented to build stochastic function mapping from gait features to strephenopodia angles.Results This study showed good reliability and precision prediction of the angle of strephenopodia [determination coefficient (R2)\\(\\ge\\)0.80]. Gaussian process regression (GPR) exhibited the best regression performance [R2 = 0.93, mean root-mean-square error (RMSE) = 0.67].Conclusion The study results showed that this strephenopodia-detection method is not only convenient to implement but also has high accuracy and outperforms previous reports. Measurements derived from the gait analysis system are proper estimators of the angle of strephenopodia and should be considered to improve diagnosis and assessment of the stroke population.\n",
            "----------------------------------------\n",
            "Title: Automated program and software defect root cause analysis using machine learning techniques\n",
            "Abstract: For the automated root cause analysis (ARCA) method and simplified RCA technique, their empirical assessment is presented in this study. A focus group meeting is a foundation for the target problem identification in the ARCA technique. This is compared to earlier RCA methodologies which rely on problem sampling for target problem discovery and high beginning costs. In this research, we suggest a naïve Bayes based machine learning method for identifying the underlying causes of newly reported software issues, which will facilitate a quicker and more effective resolution of software bugs. The ARCA technique produced a large number of high-quality corrective actions while requiring a reasonable amount of effort. The strategy is an effective way to find new opportunities for process improvement and produce fresh process improvement ideas in contrast to the organization’s corporate practices. In addition it is simple to utilize. Ultimately, we compared the methodology with other machine learning classifiers including support vector machine and decision tree.\n",
            "----------------------------------------\n",
            "Title: Vehicle involvements in hydroplaning crashes: Applying interpretable machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: LINES: Log-Probability Estimation via Invertible Neural Networks for Enhanced Sampling.\n",
            "Abstract: It is very challenging to sample a molecular process with large activation energies using molecular dynamics simulations. Current enhanced sampling methodologies, such as umbrella sampling and metadynamics, rely on the identification of appropriate reaction coordinates for a system. In this paper, we developed a method for log-probability estimation via invertible neural networks for enhanced sampling (LINES). This iterative scheme utilizes a normalizing flow machine learning model to learn the underlying free energy surface (FES) of a system as a function of molecular coordinates and then applies a gradient-based optimization method to the learned normalizing flow to identify reaction coordinates. A biasing potential is then evaluated over a tabulated grid of the reaction coordinate values, which can be applied to the next round of simulations for enhanced sampling, resulting in more efficient sampling. We tested the accuracy and efficiency of the LINES method in sampling the FES using the alanine dipeptide system. We also demonstrated the effectiveness of identification of reaction coordinates through simulation of cyclobutanol unbinding from β-cyclodextrin and the folding/unfolding of CLN025─a variant of the peptide Chignolin. The LINES method can be extended to the study of large-scale protein systems with complex nonlinear reaction pathways.\n",
            "----------------------------------------\n",
            "Title: Mental Disorder Diagnosis from EEG Signals Employing Automated Leaning Procedures Based on Radial Basis Functions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Unavailable Transit Feed Specification: Making It Available With Recurrent Neural Networks\n",
            "Abstract: Studies on public transportation in Europe suggest that European inhabitants use buses in ca. 56% of all public transport travels. One of the critical factors affecting such a percentage and more, in general, the demand for public transport services, with an increasing reluctance to use them, is their quality. End-users can perceive quality from various perspectives, including the availability of information, i.e., the access to details about the transit and the provided services. The approach proposed in this paper, using innovative methodologies resorting on data mining and machine learning techniques, aims to make available the unavailable data about public transport. In particular, by mining GPS traces, we manage to reconstruct the complete transit graph of public transport. The approach has been successfully validated on a real dataset collected from the local bus system of the city of L’Aquila (Italy). The experimental results demonstrate that the proposed approach and implemented framework are both effective and efficient, thus being ready for deployment.\n",
            "----------------------------------------\n",
            "Title: High-fidelity retrieval from instantaneous line-of-sight returns of nacelle-mounted lidar including supervised machine learning\n",
            "Abstract: Abstract. Wind turbine applications that leverage nacelle-mounted\n",
            "Doppler lidar are hampered by several sources of uncertainty in the lidar\n",
            "measurement, affecting both bias and random errors. Two problems encountered\n",
            "especially for nacelle-mounted lidar are solid interference due to\n",
            "intersection of the line of sight with solid objects behind, within, or in\n",
            "front of the measurement volume and spectral noise due primarily to\n",
            "limited photon capture. These two uncertainties, especially that due to\n",
            "solid interference, can be reduced with high-fidelity retrieval techniques\n",
            "(i.e., including both quality assurance/quality control and subsequent\n",
            "parameter estimation). Our work compares three such techniques, including\n",
            "conventional thresholding, advanced filtering, and a novel application of\n",
            "supervised machine learning with ensemble neural networks, based on their\n",
            "ability to reduce uncertainty introduced by the two observed nonideal\n",
            "spectral features while keeping data availability high. The approach\n",
            "leverages data from a field experiment involving a continuous-wave (CW)\n",
            "SpinnerLidar from the Technical University of Denmark (DTU) that provided\n",
            "scans of a wide range of flows both unwaked and waked by a field turbine.\n",
            "Independent measurements from an adjacent meteorological tower within the\n",
            "sampling volume permit experimental validation of the instantaneous velocity\n",
            "uncertainty remaining after retrieval that stems from solid interference and\n",
            "strong spectral noise, which is a validation that has not been performed\n",
            "previously. All three methods perform similarly for non-interfered returns,\n",
            "but the advanced filtering and machine learning techniques perform better\n",
            "when solid interference is present, which allows them to produce overall\n",
            "standard deviations of error between 0.2 and 0.3 m s−1, or a 1 %–22 %\n",
            "improvement versus the conventional thresholding technique, over the rotor\n",
            "height for the unwaked cases. Between the two improved techniques, the\n",
            "advanced filtering produces 3.5 % higher overall data availability, while\n",
            "the machine learning offers a faster runtime (i.e., ∼ 1 s\n",
            "to evaluate) that is therefore more commensurate with the requirements of\n",
            "real-time turbine control. The retrieval techniques are described in terms\n",
            "of application to CW lidar, though they are also relevant to pulsed lidar.\n",
            "Previous work by the authors (Brown and Herges, 2020) explored a novel\n",
            "attempt to quantify uncertainty in the output of a high-fidelity lidar\n",
            "retrieval technique using simulated lidar returns; this article provides\n",
            "true uncertainty quantification versus independent measurement and does so\n",
            "for three techniques rather than one.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Applying the DEMATEL−ANP Fuzzy Comprehensive Model to Evaluate Public Opinion Events\n",
            "Abstract: Network public opinion is a mirror reflecting people’s will, and evaluating its urgency can help to find hidden social crises. Research on public opinion in the field of machine learning usually focuses on micro-sentiment judgment, which is unable to offer support for the evaluation of public opinion events without additional data, and research from the perspective of artificial weighting has the disadvantage of the confusion of explanation. Judging the urgency of public opinion events is usually based on human perception, which is fuzzy and conforms to the attribute of fuzzy mathematics. Therefore, the index system in this paper was constructed in line with five principles, from which the weights were scientifically evaluated by integrating the DEMATEL and ANP model, and fuzzy mathematics was applied to determine the urgency level of public opinion. The result has three-fold significance. First, the index system constructed was more closely linked. Second, the integration of the DEMATEL and ANP weight calculating model took the interdependence of indicators fully into account. Third, fuzzy mathematics provided support for determining the public opinion crisis level, especially in the absence of immediate dissemination data.\n",
            "----------------------------------------\n",
            "Title: Enabling Scalable Sleep Monitoring with Mobile Sensing and Machine Learning\n",
            "Abstract: Sleep is a critical component for overall health of a human being. Despite it’s importance, a majority of the population is sleep deprived leading to several physical and mental health issues. Traditional methods of sleep monitoring are expensive and not scalable, limiting access to important health information. The advent of the Internet of Things and mobile sensing devices provides an opportunity for more accessible and scalable sleep monitoring. Community-scale sensing has the potential to enable aggregate public health monitoring and informed decision-making for individuals. However, scaling mobile health sensing technologies to the community level presents several challenges including data availability, model generalizability, robustness etc. This thesis focuses on addressing the challenges of sleep monitoring at the community level by developing non-intrusive, scalable, personalizable, and robust sleep detection techniques. The first technique, called WiSleep , a system that utilizes an unsupervised machine learning approach that detects sleep durations from WiFi activity of mobile devices. WiSleep leverages the strong correlation between a phone’s network activity and sleep periods and uses an ensemble of Bayesian models designed to handle irregular sleep patterns. The second technique, called SleepLess , is a semi-supervised machine learning approach that enables personalized sleep estimations for users without labeled data. Finally, I propose an approach combining uncertainity quantification with explainability to handle prediction inaccuracies from sleep prediction models. Overall, this research aims to provide innovative solutions to the challenges of mobile sleep monitoring and contribute to the broader field of mobile health sensing.\n",
            "----------------------------------------\n",
            "Title: Data-driven machine learning: A new approach to process and utilize biomedical data\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Estimation of tomato water status with photochemical reflectance index and machine learning: Assessment from proximal sensors and UAV imagery\n",
            "Abstract: Tracking plant water status is a critical step towards the adaptive precision irrigation management of processing tomatoes, one of the most important specialty crops in California. The photochemical reflectance index (PRI) from proximal sensors and the high-resolution unmanned aerial vehicle (UAV) imagery provide an opportunity to monitor the crop water status efficiently. Based on data from an experimental tomato field with intensive aerial and plant-based measurements, we developed random forest machine learning regression models to estimate tomato stem water potential (ψ stem), (using observations from proximal sensors and 12-band UAV imagery, respectively, along with weather data. The proximal sensor-based model estimation agreed well with the plant ψ stem with R 2 of 0.74 and mean absolute error (MAE) of 0.63 bars. The model included PRI, normalized difference vegetation index, vapor pressure deficit, and air temperature and tracked well with the seasonal dynamics of ψ stem across different plots. A separate model, built with multiple vegetation indices (VIs) from UAV imagery and weather variables, had an R 2 of 0.81 and MAE of 0.67 bars. The plant-level ψ stem maps generated from UAV imagery closely represented the water status differences of plots under different irrigation treatments and also tracked well the temporal change among flights. PRI was found to be the most important VI in both the proximal sensor- and the UAV-based models, providing critical information on tomato plant water status. This study demonstrated that machine learning models can accurately estimate the water status by integrating PRI, other VIs, and weather data, and thus facilitate data-driven irrigation management for processing tomatoes.\n",
            "----------------------------------------\n",
            "Title: Third International Workshop on Safety and Security in Multiagent Systems\n",
            "Abstract: A crucial part of safety-critical systems development is identifying how system behaviours lead to accidents. Doing this for complex systems is hard because of the need to consider the interaction between multiple simultaneous failures and normal system behaviours. Multi-agent simulation provides a way to explore the behaviour that emerges from a model of a system under normal and failure conditions. However, it is easy to generate vast amounts of data from such simulations that can be hard to comprehend and interpret. Machine learning can be applied to help understand the patterns that are implicit in this data. This paper first describes the concept of hazard analysis, and how this can be performed using multi-agent simulation. It then describes how machine learning techniques can be used to extract rules from simulation output. The approach is illustrated using a military system-of-systems case study.\n",
            "----------------------------------------\n",
            "Title: Uncovering COVID-19 conversations: Twitter insights and trends\n",
            "Abstract: In this paper, we delve into the public discourse surrounding COVID-19 on Twitter to unearth the collective sentiments, concerns, and spread of information during the pandemic. By leveraging a dataset of relevant tweets and corresponding ISO country codes, our analysis will map out the geographical and digital landscape of these conversations. The significance of this work lies in its potential to inform public health strategies, shape policymaking, and contribute to social research on crisis communication. Stakeholders ranging from health officials to the public have a vested interest in understanding the contours of this dialogue. Our objective is to craft a data-driven narrative through visualizations that reveal how the world engages with the pandemic on the digital front, providing actionable insights into global and local responses to COVID-19 using Machine Learning techniques.\n",
            "----------------------------------------\n",
            "Title: The SystemT IDE: an integrated development environment for information extraction rules\n",
            "Abstract: Information Extraction (IE)-the problem of extracting structured information from unstructured text - has become the key enabler for many enterprise applications such as semantic search, business analytics and regulatory compliance. While rule-based IE systems are widely used in practice due to their well-known \"explainability,\" developing high-quality information extraction rules is known to be a labor-intensive and time-consuming iterative process.\n",
            " Our demonstration showcases SystemT IDE, the integrated development environment for SystemT, a state-of-the-art rule-based IE system from IBMResearch that has been successfully embedded in multiple IBM enterprise products. SystemT IDE facilitates the development, test and analysis of high-quality IE rules by means of sophisticated techniques, ranging from data management to machine learning. We show how to build high-quality IE annotators using a suite of tools provided by SystemT IDE, including computing data provenance, learning basic features such as regular expressions and dictionaries, and automatically refining rules based on labeled examples.\n",
            "----------------------------------------\n",
            "Title: The Algorithmic Foundations of Differential Privacy\n",
            "Abstract: The problem of privacy-preserving data analysis has a long history spanning multiple disciplines. As electronic data about individuals becomes increasingly detailed, and as technology enables ever more powerful collection and curation of these data, the need increases for a robust, meaningful, and mathematically rigorous definition of privacy, together with a computationally rich class of algorithms that satisfy this definition. Differential Privacy is such a definition.After motivating and discussing the meaning of differential privacy, the preponderance of this monograph is devoted to fundamental techniques for achieving differential privacy, and application of these techniques in creative combinations, using the query-release problem as an ongoing example. A key point is that, by rethinking the computational goal, one can often obtain far better results than would be achieved by methodically replacing each step of a non-private computation with a differentially private implementation. Despite some astonishingly powerful computational results, there are still fundamental limitations — not just on what can be achieved with differential privacy but on what can be achieved with any method that protects against a complete breakdown in privacy. Virtually all the algorithms discussed herein maintain differential privacy against adversaries of arbitrary computational power. Certain algorithms are computationally intensive, others are efficient. Computational complexity for the adversary and the algorithm are both discussed.We then turn from fundamentals to applications other than queryrelease, discussing differentially private methods for mechanism design and machine learning. The vast majority of the literature on differentially private algorithms considers a single, static, database that is subject to many analyses. Differential privacy in other models, including distributed databases and computations on data streams is discussed.Finally, we note that this work is meant as a thorough introduction to the problems and techniques of differential privacy, but is not intended to be an exhaustive survey — there is by now a vast amount of work in differential privacy, and we can cover only a small portion of it.\n",
            "----------------------------------------\n",
            "Title: Guest Editorial\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Identification of Free and WHO-Compliant Handwashing Moments Using Low Cost Wrist-Worn Wearables\n",
            "Abstract: Hand washing is the simplest and most effective gesture, when correctly performed, for the prevention of many infections. For this reason, the World Health Organization (WHO) has defined a washing procedure that guarantees effective and safe cleaning. This organization recommends that States promote this activity and monitor it continuously. Based on this fact, this article presents a work oriented to study the feasibility of identifying the moments in which a person carried out a hand washing, determining its beginning and duration, as well as if these washings were compliant with the WHO guidelines. The identification of washing moments is made through the analysis, by means of Machine Learning techniques, of the data that can be collected from the inertial sensors of the smartwatch the person is wearing. This study was carried out with the participation of 15 volunteers. Data was not only collected in controlled settings but, also, more than 600 hours of sensor measurements come from free-live conditions. The results of the study showed that it is feasible to build a solid solution based on the use of low cost wearables for the identification of washing moments. The solution is very effective (with F1 over 95%) with user-dependent models. Also, with user-independent models, the identification of WHO washings is also very effective (with F1 above 85%), but more limited in the detection of free washings (F1 around 55%).\n",
            "----------------------------------------\n",
            "Title: Machine learning models-based on integration of next-generation sequencing testing and tumor cell sizes improve subtype classification of mature B-cell neoplasms\n",
            "Abstract: Background Next-generation sequencing (NGS) panels for mature B-cell neoplasms (MBNs) are widely applied clinically but have yet to be routinely used in a manner that is suitable for subtype differential diagnosis. This study retrospectively investigated newly diagnosed cases of MBNs from our laboratory to investigate mutation landscapes in Chinese patients with MBNs and to combine mutational information and machine learning (ML) into clinical applications for MBNs, especially for subtype classification. Methods Samples from the Catalogue Of Somatic Mutations In Cancer (COSMIC) database were collected for ML model construction and cases from our laboratory were used for ML model validation. Five repeats of 10-fold cross-validation Random Forest algorithm was used for ML model construction. Mutation detection was performed by NGS and tumor cell size was confirmed by cell morphology and/or flow cytometry in our laboratory. Results Totally 849 newly diagnosed MBN cases from our laboratory were retrospectively identified and included in mutational landscape analyses. Patterns of gene mutations in a variety of MBN subtypes were found, important to investigate tumorigenesis in MBNs. A long list of novel mutations was revealed, valuable to both functional studies and clinical applications. By combining gene mutation information revealed by NGS and ML, we established ML models that provide valuable information for MBN subtype classification. In total, 8895 cases of 8 subtypes of MBNs in the COSMIC database were collected and utilized for ML model construction, and the models were validated on the 849 MBN cases from our laboratory. A series of ML models was constructed in this study, and the most efficient model, with an accuracy of 0.87, was based on integration of NGS testing and tumor cell sizes. Conclusions The ML models were of great significance in the differential diagnosis of all cases and different MBN subtypes. Additionally, using NGS results to assist in subtype classification of MBNs by method of ML has positive clinical potential.\n",
            "----------------------------------------\n",
            "Title: Prediction of geothermal originated boron contamination by deep learning approach: at Western Anatolia Geothermal Systems in Turkey\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Optimal operation strategy predictive control for an integrated radiant cooling with fresh air system based on machine learning\n",
            "Abstract: Radiant cooling systems are widely valued for their great comfort and energy-saving potential. However, they still face the risk of condensation in the early stages of operation, especially in case of random occupancy and intermittent operation. This study aims to avoid unacceptable discomfort durations in randomly occupied rooms that installed integrated radiant cooling and fresh air system while consuming as little energy as possible. This paper firstly compares the effects of adopting only the setback or standby cooling strategy in a randomly occupied conference room by simulation. The simulation results demonstrate the necessity for predicting optimal operation strategy. Subsequently, optimal operation strategy predictive models were built using three machine learning algorithms on three datasets. The evaluation results of the models indicate the feasibility of using data from neighbouring cities to improve the generalisation ability of the target city model. Finally, the best one of models was used to predict optimal operation strategy and achieved good results: discomfort durations of 97.56% of the conferences were within the acceptable range. Additionally, compared to only adopting the standby cooling strategy, the radiant cooling system operating time was reduced by 8.88%, and the total energy consumption was reduced by 28.85 kWh. In this study, a model to predict optimal operation strategy is proposed. By simulating and analysing from both comfort and energy perspectives, the optimal operation strategy predictive control method effectively limits the discomfort duration and reduces energy consumption and radiant system runtime. This study provides an example of practical engineering and machine learning applications for radiant cooling systems.\n",
            "----------------------------------------\n",
            "Title: INTELLECTUAL GRAPH MODELS FOR RELATED DATA PROCESSING\n",
            "Abstract: In connection with the wide spreading of various intelligent sensors, IoT devices, smartphones, autonomous transport systems, various industrial and home automation systems, an unprecedented amount of data is generated, including those intelligently linked to each other. Linked data allows you to build complex and varied relationships between objects and subjects of the real world. Unfortunately, modern big data processing systems and machine learning models are extremely poorly suited for working with such dynamically linked data, especially in the case of real-time systems. We discuss current and future-proof approaches to working with such data using graph analysis models.\n",
            "----------------------------------------\n",
            "Title: Review On Sensor Data Acquisition With Labview\n",
            "Abstract: — In recent years many techniques has shown potential in solving the real-world problems. The objective of this paper is to put together the popular optimization techniques for understanding and utilize them for the benefit of the society. The early prediction of the disease can help the social health to be more leaning towards positive ratio. The main aim is to make the person aware about the health and the problems that he will be facing. This can lead the person to consult the doctor or physician at the correct time and acquire proper treatment or measures as required. As it is well said, precautions are better than cure, one must be cautious about the health factor and look deep into it. This project aims at spreading awareness among people by using different biomedical sensors that are available. For the easy analysis of the data that is been collected in the real time can be graphically represented by using the most popular LabVIEW software. Looking forward into the global technical world around, we can see the new technologies like artificial intelligence and machine learning emerging into the data handling. This machine learning will help us to calculate and optimize accurate results and the prediction rate would be more efficient.\n",
            "----------------------------------------\n",
            "Title: Diffuse Interstellar Bands in Gaia DR3 RVS spectra Machine-learning based new measurements\n",
            "Abstract: Diffuse interstellar bands (DIBs) are weak and broad interstellar absorption features in astronomical spectra originating from unknown molecules. To measure DIBs in spectra of late-type stars more accurately and more efficiently, we developed a Random Forest model to isolate the DIB features from the stellar components and applied this method to 780 thousand spectra collected by the Gaia Radial Velocity Spectrometer (RVS) that were published in the third data release (DR3). After subtracting the stellar components, we modeled the DIBs $\\lambda$8621 and $\\lambda$8648. After quality control, we selected 7619 reliable measurements. The rest-frame wavelength of DIB $\\lambda$8621 was updated as $\\lambda_0\\,{=}\\,8623.141\\,{\\pm}\\,0.030$ AA in vacuum, corresponding to 8620.766 AA in air, which was determined by 77 DIB measurements toward the Galactic anti-center. With the peak finding method and a coarse analysis, DIB $\\lambda$8621 was found to correlate better with the neutral hydrogen than the molecular hydrogen (represented by $^{12}$CO $J\\,{=}\\,(1{-}0)$ emission). We also obtained 179 reliable measurements of DIB $\\lambda$8648 in the RVS spectra of individual stars for the first time, further confirming this very broad DIB feature. A rough estimation of $\\lambda_0$ for DIB $\\lambda$8648 was 8646.31 AA in vacuum, corresponding to 8643.93 AA in air, assuming that the carriers of $\\lambda$8621 and $\\lambda$8648 are co-moving. We confirmed the impact of stellar residuals on the DIB measurements in Gaia DR3, which led to a distortion of the DIB profile and a shift of the center ($\\lesssim0.5$ AA), but the EW was consistent with our new measurements. With our measurements and analyses, we propose that the machine-learning-based approach can be widely applied to measure DIBs in numerous spectra from spectroscopic surveys.\n",
            "----------------------------------------\n",
            "Title: Automatic Assignment of ICD-10 Codes to Diagnostic Texts using Transformers Based Techniques\n",
            "Abstract: A fundamental task for epidemiology, statistics, and health informatics is to associate some standardized meaning to textual expressions, to enable their retrieval, aggregation and interpretation. Among the relevant expressions, those mentioning health conditions and diagnoses are of paramount importance and can be found in almost any clinical document, including death certificates. These expressions are usually coded with the International Classification of Diseases. In this paper we employ both classical Machine Learning and BERT based models to perform the automatic classification of diagnostic texts extracted from death certificates. We show the effectiveness of our proposed approach over a set of experiments, where we experiment with multiple set of features and variant of the algorithms. Our results show that BERT based models, and in particular the ones pre-trained on the specific domain outperform classical ML algorithms, reaching Accuracy and F1-Score of respectively 0.952 and 0.943.\n",
            "----------------------------------------\n",
            "Title: Energy-Aware Scheduling for High-Performance Computing Systems: A Survey\n",
            "Abstract: High-performance computing (HPC), according to its name, is traditionally oriented toward performance, especially the execution time and scalability of the computations. However, due to the high cost and environmental issues, energy consumption has already become a very important factor that needs to be considered. The paper presents a survey of energy-aware scheduling methods used in a modern HPC environment, starting with the problem definition, tackling various goals set up for this challenge, including a bi-objective approach, power and energy constraints, and a pure energy solution, as well as metrics related to the subject. Then, considered types of HPC systems and related energy-saving mechanisms are described, from multicore-processors/graphical processing units (GPU) to more complex solutions, such as compute clusters supporting dynamic voltage and frequency scaling (DVFS), power capping, and other functionalities. The main section presents a collection of carefully selected algorithms, classified by the programming method, e.g., machine learning or fuzzy logic. Moreover, other surveys published on this subject are summarized and commented on, and finally, an overview of the current state-of-the-art with open problems and further research areas is presented.\n",
            "----------------------------------------\n",
            "Title: Classification of Messenger Network Traffic Using Machine Learning Methods\n",
            "Abstract: The article proposes an approach to using the machine learning method to analyze the structure of application network sessions. A number of experiments were carried out to classify messenger applications (for example, WhatsApp, Skype, Discord, Snapchat, Zoom and Zulip) in the network traffic flow. At the first stage, the distribution of byte values in the encrypted packet was checked. As a result, characteristic features were found in the data transmission of the considered applications. This made it possible to proceed to the second stage, in which machine learning methods based on frequency analysis were used to classify network traffic. The results obtained confirmed the possibility of building a classifier on a training set, which is a vector composed of network traffic. Also, work was carried out to find the optimal parameters to improve the performance of the classifier. For this, an approach was applied based on the analysis of byte values in certain places of the packets. As a result, classification reliability has been improved for all applications by more than 20%. The resulting classifiers made it possible to systematize application-level protocols in dumps of encrypted network traffic without using cryptanalysis methods and violating the confidentiality of transmitted data packets.\n",
            "----------------------------------------\n",
            "Title: Recent progress on the simulation technology of magnetic fluid\n",
            "Abstract: Magnetic fluid is a novel magnetorheological (MR) intelligent material consisting of magnetic particles, non-magnetic matrix, and additive agents. After applying the external magnetic field, magnetic particles will interact with each other due to the magnetic dipolar forces. The viscosity and yield stress of magnetic fluid could increase several orders of magnitude in milliseconds, which is called the MR effect. The controllable and reversible property makes magnetic fluid widely applied in drug targeting delivery, magnetic thermal therapy, commercial dampers, and polishing etc. In order to comprehend the mechanical behaviors of magnetic fluid, researchers developed several theoretical models for different flow conditions. However, due to the extensive calculation, theoretical models are only applicable for some special problems, such as 2-dimensional and axial symmetry. In recent years, with the development of computer performance, simulation has become an important method to investigate the MR mechanism of magnetic fluid. This paper reviews the recent progress in the theory and simulation of magnetic fluid. Firstly, theoretical models of magnetic fluid under shear mode, squeeze mode, and valve mode are introduced. Secondly, the existing simulation methods for magnetic fluid, such as molecular dynamics, particle-level dynamic simulation, and finite element method, are illustrated. The validity of the methods and their merits and drawbacks are discussed. Then, the research progress of the simulation of magnetic fluid is summarized from 3 aspects: Simulations of mechanical properties of novel magnetic fluid, simulations of complex mechanical behaviors of conventional magnetic fluid, and simulations of biomagnetic fluid. Finally, some future trends of simulation of magnetic fluid are proposed. The following 3 topics should be emphasized in the future work. First, a comprehensive theoretical model considering a variety of microscopic interactions is required. In order to prepare magnetic particles with high MR effect, excellent dispersibility, and low density, surface coating, modification, and additive agents are usually applied in experiments. Unfortunately, the influence of non-magnetic components on the MR effect is seldom considered in simulations. Second, current simulations could not simultaneously obtain the macroscopic mechanical properties and microstructures of magnetic fluid in complex flow. Finite element method and computational fluid dynamics are applicable for complex macroscopic problems but can not obtain the microstructures at the same time. Mesoscopic simulation methods can not exhibit large-scale aggregations of particles, which leads to the deviation compared with experiments. To establish multi-scale simulation methods and improve the accuracy of simulations have become an urgent requirement. Combining simulation methods with different spatial scales and reducing the time cost by using machine learning have become a possible approach. Third, multi-physics coupling simulation methods should be established. The magnetic field controlled electrical properties of magnetic fluid have attracted researchers interest in recent years. Magnetic fluid with this novel controllable property could be widely applied in battery and sensors. Investigations on other physical properties of magnetic fluid by using mechanical, electrical, and magnetic model together will be a future trend. These achievements will all contribute to the development of high-performance magnetic fluids and further enlarge the range of applications of magnetic fluid.\n",
            "----------------------------------------\n",
            "Title: Model evidence from nonequilibrium simulations\n",
            "Abstract: The marginal likelihood, or model evidence, is a key quantity in Bayesian parameter estimation and model comparison. For many probabilistic models, computation of the marginal likelihood is challenging, because it involves a sum or integral over an enormous parameter space. Markov chain Monte Carlo (MCMC) is a powerful approach to compute marginal likelihoods. Various MCMC algorithms and evidence estimators have been proposed in the literature. Here we discuss the use of nonequilibrium techniques for estimating the marginal likelihood. Nonequilibrium estimators build on recent developments in statistical physics and are known as annealed importance sampling (AIS) and reverse AIS in probabilistic machine learning. We introduce estimators for the model evidence that combine forward and backward simulations and show for various challenging models that the evidence estimators outperform forward and reverse AIS.\n",
            "----------------------------------------\n",
            "Title: Active Robot Learning for Building Up High-Order Beliefs\n",
            "Abstract: High-order beliefs of service robots regard the robots' thought about their users' intention and preference. The existing approaches to the development of such beliefs through machine learning rely on particular social cues or specifically defined award functions. Their applications can, therefore, be limited. This paper presents an active robot learning approach to facilitate the robots to develop the beliefs by actively collecting/discovering evidence they need. The emphasis is on active learning. Hence social cues and award functions are not necessary. Simulations show that the presented approach successfully enabled a robot to discover evidences it needs.\n",
            "----------------------------------------\n",
            "Title: Detecting chronic kidney disease by using a voting classifier\n",
            "Abstract: \n",
            " \n",
            " \n",
            "Chronic Kidney Disease (CKD) is a global health problem with high morbidity and mortality rate, and it induces other diseases. Since there are no obvious symptoms during the early stage of CKD, patients often fail to notice the disease. Early detection of CKD enables patients to receive timely treatment to ameliorate the progression of this disease. Machine learning models can effectively aid clinicians achieve this goal due to their fast and accurate recognition performance. In this, we proposed a machine learning methodology for diagnosing CKD. The CKD data set was obtained from the University of California Irvine (UCI) machine learning repository, which has a large number of missing values. In general we have six machine learning algorithms like logistic regression, random forest, support vector machine, k-nearest neighbour, naive Bayes, classifier and feed forward neural network to establish models. In existing system random forest achieved the performance with 99.75% diagnosis accuracy. In proposed system, By analysing the misjudgments generated by the above model, we proposed an integrated model that combines logistic regression and random forest by using perceptron which could achieve an efficient accuracy of 99.83% after ten times of simulation. Hence, we speculated that this methodology could be applicable to more complicated clinical data for disease diagnosis. \n",
            " \n",
            " \n",
            "\n",
            "----------------------------------------\n",
            "Title: A Survey of Learning Style Detection Method using Eye-Tracking and Machine Learning in Multimedia Learning\n",
            "Abstract: Current utilization of multimedia learning environment focuses on student-centered approach. This approach is based on a theory stating that learning styles affect individuals in information processing. Based on prior works, there are three main approaches to distinguish learning styles: conventional approach—such as interview and self-reporting, artificial-intelligence-based approach, and sensor-based approach. Unfortunately, there is no comparative analysis that addresses strengths and limitations of these approaches. Thus, there is no information on how and when to use these approaches appropriately. To address this limitation, we present a brief literature review of several studies in distinguishing learning styles, including their strengths and limitations. We also present insights on potential methods of detecting learning styles in multimedia learning based on eye movement data and machine learning algorithms. Our paper is useful as a guideline for developing intelligent e-learning systems based on eye tracking and machine learning.\n",
            "----------------------------------------\n",
            "Title: Automated Socket Anomaly Detection through Deep Learning\n",
            "Abstract: The paper will demonstrate the application of Deep Learning (DL) for the detection of defective tester sockets. The proposed methodology relies on images like those used for manual or rule-based inspection, commonly collected using Automated Optical Inspection (AOI) equipment. This work represents a practical example of the use of Machine Learning for achieving improved inspection-quality outcomes at a lower cost. The experimental evaluation of the proposed methodology was performed on production set of collected socket images.\n",
            "----------------------------------------\n",
            "Title: Improve the Excavation Speed of the Tunnel Based on Genetic Algorithm— Radial Basis Function Network Algorithm\n",
            "Abstract: The acceleration of the urban process poses new challenges to transport, the construction of three dimensional traffic has become an important way to solve the congestion problem. The subway is an important factor in the appeal of a big city, however, the rapid and efficient mining of digging tunnels becomes the key to cost savings. The purpose of this paper is to optimize the use of excavation machines and maximize the potential of the development of shield machines, thus achieving savings in maintenance time and cost. For the impact of many factors and The existence of non-linear problems between the variables, we propose a radial basis function network with self-learning ability, which can fit the target and the target variable; In view of the problem that the training speed of RBF network learning method is slow, we introduce the genetic algorithm, and we propose a floating-point coding genetic algorithm based on the adaptive mechanism as a learning algorithm for RBF network learning. The final experimental results show that the accuracy of the new algorithm reaches 95.43%, while learning time significantly shortened by about 37%. All those proves that our algorithm is effective for predicting wear amount, which can improve the efficiency of the machine and save a lot of cost, it is valuable to promote.\n",
            "----------------------------------------\n",
            "Title: An Explainable Artificial Intelligence Model for the Classification of Breast Cancer\n",
            "Abstract: Breast cancer is the most common cancer among women and globally affects both genders. The disease arises due to abnormal growth of tissue formed of malignant cells. Early detection of breast cancer is crucial for enhancing the survival rate. Therefore, artificial intelligence has revolutionized healthcare and can serve as a promising tool for early diagnosis. The present study aims to develop a machine-learning model to classify breast cancer and to provide explanations for the model results. This could improve the understanding of the diagnosis and treatment of breast cancer by identifying the most important features of breast cancer tumors and the way they affect the classification task. The best-performing machine-learning model has achieved an accuracy of 97.7% using k-nearest neighbors and a precision of 98.2% based on the Wisconsin breast cancer dataset and an accuracy of 98.6% using the artificial neural network with 94.4% precision based on the Wisconsin diagnostic breast cancer dataset. Hence, this asserts the importance and effectiveness of the proposed approach. The present research explains the model behavior using model-agnostic methods, demonstrating that the bare nuclei feature in the Wisconsin breast cancer dataset and the area’s worst feature Wisconsin diagnostic breast cancer dataset are the most important factors in determining breast cancer malignancy. The work provides extensive insights into the particular characteristics of the diagnosis of breast cancer and suggests possible directions for expected investigation in the future into the fundamental biological mechanisms that underlie the disease’s onset. The findings underline the potential of machine learning to enhance breast cancer diagnosis and therapy planning while emphasizing the importance of interpretability and transparency in artificial intelligence-based healthcare systems.\n",
            "----------------------------------------\n",
            "Title: (Machine) learning from the COVID-19 lockdown about electricity market performance with a large share of renewables\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Data science techniques to gain novel insights into quality of care: a scoping review of long-term care for older adults\n",
            "Abstract: Background: The increase in powerful computers and technological devices as well as new forms of data analysis such as machine learning have resulted in the widespread availability of data science in healthcare. However, its role in organizations providing long-term care (LTC) for older people LTC for older adults has yet to be systematically synthesized. This analysis provides a state-of-the-art overview of 1) data science techniques that are used with data accumulated in LTC and for what specific purposes and, 2) the results of these techniques in researching the study objectives at hand.\n",
            "Methods: A scoping review based on guidelines of the Joanna Briggs Institute. PubMed and Cumulative Index to Nursing and Allied Health Literature (CINAHL) were searched using keywords related to data science techniques and LTC. The screening and selection process was carried out by two authors and was not limited by any research design or publication date. A narrative synthesis was conducted based on the two aims.\n",
            "Results: The search strategy yielded 1,488 studies: 27 studies were included of which the majority were conducted in the US and in a nursing home setting. Text-mining/natural language processing (NLP) and support vector machines (SVMs) were the most deployed methods; accuracy was the most used metric. These techniques were primarily utilized for researching specific adverse outcomes including the identification of risk factors for falls and the prediction of frailty. All studies concluded that these techniques are valuable for their specific purposes.\n",
            "Discussion: This review reveals the limited use of data science techniques on data accumulated in or by LTC facilities. The low number of included articles in this review indicate the need for strategies aimed at the effective utilization of data with data science techniques and evidence of their practical benefits. There is a need for a wider adoption of these techniques in order to exploit data to their full potential and, consequently, improve the quality of care in LTC by making data-informed decisions.\n",
            "----------------------------------------\n",
            "Title: Predicting multiple sclerosis severity with multimodal deep neural networks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Use of a Wearable Ambulatory Monitor in the Classification of Movement States in Parkinson ' s Disease\n",
            "Abstract: For Parkinson's patients to function at their best, their medications need to be optimally adjusted to the diurnal variation of symptoms. For this to occur, it is important for the managing clinician to have an accurate picture of how the patient's bradykinesia / hypokinesia and dyskinesia fluctuate throughout the normal daily activities. This thesis proposes the use of wearable accelerometers coupled with machine learning and statistical techniques in order to classify the movement states of Parkinson's patients and to provide a timeline of how the patients fluctuate throughout the day. A pilot study was performed using 2 patients with the goal of assessing the ability to classify dyskinesia and bradykinesia / hypokinesia based on accelerometric data. The patients were observed and videotaped. Clinical observations of bradykinesia / hypokinesia and dyskinesia were noted every minute. Neural networks were able to classify better than classification trees with an average c-index (equivalent to the area under the ROC curve) of 0.905 for bradykinesia / hypokinesia and 0.926 for dyskinesia. A separate group of 5 patients were observed with the additional goal of building models that can classify the movement of a patient without requiring clinically annotated training data for the same patient. An enhanced protocol was used in the final study. Dichotomized linear regression was found to classify well with an average c-index of 0.8219 for body bradykinesia / hypokinesia and 0.8799 using as the gold-standard the patient's diary. Dyskinesia was classified at a c-index of 0.7522. Neural networks did not perform as well, possibly because of restrictions placed on adjusting parameters. The two most clinically important problems: predicting when the patient feels he/she is \"off' or when he/she has \"troublesome dyskinesia\" were discriminated with c-indices of 0.96 and 1.0 respectively. The good result of the models despite the small number of patients is promising. Further studies with larger number of patients are therefore justified.\n",
            "----------------------------------------\n",
            "Title: Machine learning web application for predicting functional outcomes in patients with traumatic spinal cord injury following inpatient rehabilitation.\n",
            "Abstract: Accurately predicting functional outcomes in patients with spinal cord injury (SCI) helps clinicians set realistic functional recovery goals and improve the home environment after discharge. The present study aimed to develop and validate machine learning (ML) models to predict functional outcomes in patients with SCI and deploy the models within a web application. The study included data from the Japan Association of Rehabilitation Database from January 1, 1991 to December 31, 2015. Patients with SCI who were admitted to an SCI center or were transferred to a participating postacute rehabilitation hospital after receiving acute treatment were enrolled in this database. The primary outcome was functional ambulation at discharge from the rehabilitation hospital. The secondary outcome was the total motor Functional Independence Measure (FIM) score at discharge. We used binary classification models to predict whether functional ambulation was achieved, as well as regression models to predict total motor FIM scores at discharge. In the training dataset (70% random sample), using demographic characteristics and neurological and functional status as predictors, we built prediction performance matrices of multiple ML models and selected the best one for each outcome. We validated each model's predictive performance in the test dataset (the remaining 30%). Among the 4181 patients, 3827 were included in the prediction model for the total motor FIM score. The mean (SD) age was 50.4 (18.7) years, and 3211 (83.9%) patients were male. There were 3122 patients included in the prediction model for functional ambulation. The CatBoost Classifier and regressor models showed the best performances in the training dataset. On the test dataset, the CatBoost Classifier had an area under the receiver operating characteristic curve of 0.8452 and an accuracy of 0.7663 for predicting functional ambulation. Likewise, the CatBoost Regressor performed well, with an R2 of 0.7746, a mean absolute error of 9.4895, and a root mean square error of 13.5312 for predicting the total motor FIM score. The final models were deployed in a web application to provide functional predictions. The application can be found at http://www.ortho.m.chiba-u.jp/general/4560. In conclusion, our prediction models developed using ML successfully predicted functional outcomes in patients with SCI and were deployed in an open-access web application.\n",
            "----------------------------------------\n",
            "Title: Prediction of hyperaldosteronism subtypes when adrenal vein sampling is unilaterally successful.\n",
            "Abstract: Objective - Adrenal venous sampling (AVS) is the gold standard to discriminate patients with unilateral primary aldosteronism (UPA) from bilateral disease (BPA). AVS is technically-demanding and in cases of unsuccessful cannulation of adrenal veins, the results may not be interpreted. The aim of our study was to develop diagnostic models to distinguish UPA from BPA, in cases of unilateral successful AVS and the presence of contralateral suppression of aldosterone secretion. Design - Retrospective evaluation of 158 patients referred to a tertiary hypertension unit who underwent AVS. We randomly assigned 110 patients to a training cohort and 48 patients to a validation cohort to develop and test the diagnostic models. Methods - Supervised machine learning algorithms and regression models were used to develop and validate two prediction models and a 19-point score system to stratify patients according to subtype diagnosis. Results - Aldosterone levels at screening and after confirmatory testing, lowest potassium, ipsilateral and contralateral imaging findings at CT scanning, and contralateral ratio at AVS, were associated with a diagnosis of UPA and were included in the diagnostic models. Machine learning algorithms correctly classified the majority of patients both at training and validation (accuracy 82.9-95.7%). The score system displayed a sensitivity/specificity of 95.2/96.9%, with an AUC of 0.971. A flow-chart integrating our score correctly managed all patients except 3 (98.1% accuracy), avoiding the potential repetition of 77.2% of AVS. Conclusions - Our score could be integrated in clinical practice and guide decision-making in patients with unilateral successful AVS and contralateral suppression.\n",
            "----------------------------------------\n",
            "Title: A Unified Convergence Analysis of the Multiplicative Update Algorithm for Regularized Nonnegative Matrix Factorization\n",
            "Abstract: The multiplicative update (MU) algorithm has been extensively used to estimate the basis and coefficient matrices in nonnegative matrix factorization (NMF) problems under a wide range of divergences and regularizers. However, theoretical convergence guarantees have only been derived for a few special divergences without regularization. In this work, we provide a conceptually simple, self-contained, and unified proof for the convergence of the MU algorithm applied on NMF with a wide range of divergences and regularizers. Our main result shows the sequence of iterates (i.e., pairs of basis and coefficient matrices) produced by the MU algorithm converges to the set of stationary points of the nonconvex NMF optimization problem. Our proof strategy has the potential to open up new avenues for analyzing similar problems in machine learning and signal processing.\n",
            "----------------------------------------\n",
            "Title: Improving the Performance of Autonomous Vehicles through Data Engineering, Machine Learning, AI, and Integrated Hardware-Software Solutions\n",
            "Abstract: The advancement of autonomous vehicles (AVs) heavily relies on their ability to process high volumes of sensor data and make real-time decisions. This paper explores how the integration of data engineering, machine learning (ML), artificial intelligence (AI), and a cohesive hardware-software approach can further enhance the performance and safety of AVs. We propose a comprehensive framework that leverages advanced data engineering techniques for efficient data management, employs state-of-the-art ML models for accurate perception and prediction, and utilizes AI- driven strategies for decision-making and control. The proposed solutions are designed to be effective in areas with limited internet connectivity and can operate on low- powered hardware, even with outdated software.\n",
            "----------------------------------------\n",
            "Title: Multi-agent Reinforcement Learning-Based UAV Swarm Confrontation: Integrating QMIX Algorithm with Artificial Potential Field Method\n",
            "Abstract: As an important area of machine learning, re-inforcement learning has specific applicability in multi-agent systems (including UAV swarms). In this article, we use re-inforcement learning algorithm (i.e., the QMIX algorithm) to resolve the problem of UAV swarm confrontation, considering the condition of asymmetric confrontation under which the adversary's combat power is much stronger than our own. First, after constructing the system model, we develop the QMIX algorithm by designing the state space, action space, and reward function. Second, we propose a confrontation strategy that integrates decisions made by the QMIX algorithm and the artificial potential field method for UAV swarm confrontation. Finally, the experimental results show that our proposed confrontation strategy has a 72% higher win rate compared to the QMIX algorithm under asymmetric confrontation conditions.\n",
            "----------------------------------------\n",
            "Title: Generalizability in Causal Inference: Theory and Algorithms\n",
            "Abstract: Author(s): Bareinboim, Elias | Advisor(s): Pearl, Judea | Abstract: In the empirical sciences, experiments are invariably conducted with the intent of being used elsewhere (e.g., outside the laboratory), where conditions are likely to be different. This practice is based on the premise that, owing to certain commonalities between the source and target environments, causal claims will be valid even where experiments have never been performed. Yet, despite the extensive amount of empirical work relying on this premise, practically no formal treatments have been attempted to reveal the conditions under which environments can differ and still allow, in some formal sense, generalizations to be valid. This work develops a theoretical framework for understanding, representing, and algorithmizing the generalization problem described above and brings other types of generalization problems, of both causal and statistical character, under the same theoretical umbrella. The generalization problems addressed in this thesis are as follows:Problem 1. Transportability (generalizing experimental findings across settings, populations, or domains). How to reuse causal information acquired by experiments in one setting to answer causal queries in another, possibly different setting where only passive observations can be collected? This question embraces several sub-problems treated informally in the literature under rubrics such as ``external validity,\" ``meta-analysis,'' ``quasi-experiments,'' and ``heterogeneity.''Problem 2. Selection Bias (generalizing statistical findings across sampling conditions (preferential exclusion of units from the sample)). How can knowledge from a sampled subpopulation be generalized to the entire population when the sampling process is not random, but determined by variables in the analysis?Problem 3. Experimental identifiability (generalizing experimental findings across experimental conditions in the same population). How can accessible experiments be used as surrogates for other experiments that are too difficult, expensive, or unethical to be conducted in practice?Building on the modern theory of causation, we provide algebraic, graphical, and algorithmic conditions to support the inductive step required in the corresponding task in each of these problems. This characterization delineates the formal boundary between estimable and non-estimable effects, and identifies which pieces of scientific knowledge need to be collected in each study to construct a bias-free estimate of the target query. The theory provided in this work is general, in the sense that it takes as input any arbitrary set of generalizability assumptions and decides whether this specific instance admits solution. The problems discussed in this thesis have applications in several empirical sciences such as bioinformatics, medicine, economics, social sciences as well as in data-driven fields such as machine learning, artificial intelligence and statistics.\n",
            "----------------------------------------\n",
            "Title: Information systems for accounting and data analysis of housing and communal services of apartment buildings\n",
            "Abstract: The article discusses the development of information systems of housing and communal services of the Russian Federation from the point of view of resource consumption data accounting and analysis. The object of the study is \"smart\" apartment buildings. The subject of the research is information platforms, information systems and individual software developments for monitoring resource consumption in apartment buildings. It is noted that the digitalization of housing and communal services is just beginning and mainly refers to new construction. There is a potential for using digital services to manage a \"smart\" apartment building, including for the organization of telemetry. Three levels of development of digital services for resource management are identified. The list of the main digital platforms supporting the telemetry function in apartment buildings is presented. The possibilities of integration of various automated information systems are discussed. It is noted that the analytical processing of housing and communal services information is focused on the traditional tasks of management companies, such as the formation of statistics and reporting on resource consumption. It is proposed to pay attention to machine learning methods and intelligent big data analysis technologies.\n",
            "----------------------------------------\n",
            "Title: A Framework for Modeling, Optimizing, and Implementing DNNs on FPGA Using HLS\n",
            "Abstract: Deep Neural Networks (DNNs) are gaining importance for implementing large inference engines. A designer must consider numerous design choices, data-flow types, processing elements, memory hierarchy, and data-precision for a DNN implementation. A collaborative algorithm/model/hardware tool is needed to enable a reconfigurable, fast, and efficient DNN hardware accelerator. We propose an accelerator framework that automatically generates an optimized FPGA-based model given DNNs from standard machine learning frameworks without humans in the loop. For faster, accurate, and efficient hardware implementation, the framework employs a coarse-grained software-model to estimate the performance and hardware utilization using mathematical relations. The results are a High-Level-Synthesis (HLS) code with a set of optimization pragmas for fine-tuning to optimizes the hardware generated from the previous phase. Various hardware-accelerator architecture can be selected based on user preferences such as performance and FPGA chip, and the neural network size. The hardware implementation of various DNN models is shown to prove the proposed framework's flexibility and performance.\n",
            "----------------------------------------\n",
            "Title: Intrusion Detection System\n",
            "Abstract: Our project introduces an Integrated Intrusion Detection System (IDS) designed to bolster network and system security through a multi-faceted approach. This comprehensive IDS seamlessly combined Machine Learning, Anomaly Detection, File Scanning, and DDoS Prevention mechanisms to offer robust defense against diverse cyber threats. At the heart of the system lies the Machine Learning component, which continuously adapts to the evolving threat landscape. By analyzing network traffic and system behavior, it identifies both known and emerging threats in real-time, reducing reliance on traditional signature-based detection methods and allowing organizations to proactively stay ahead of cybercriminals. Anomaly Detection constantly monitors network and system activity, comparing it against established baselines. Any deviations from these baselines trigger alerts, facilitating swift responses to unusual activities that may indicate security breaches. File Scanning is another vital component ensuring data integrity and preventing malware infiltration or data exfiltration. It conducts thorough file analysis, checking for suspicious code, behavior, or unauthorized access, and offers continuous monitoring to detect anomalies in real-time. Additionally, our IDS includes Distributed Denial of Service (DDoS) Prevention mechanisms. By detecting and mitigating DDoS attacks, the system ensures the continuous availability of network resources and services even under intense traffic loads. This integrated approach to intrusion detection and prevention leverages Machine Learning, Honeypots, Anomaly Detection, File Scanning, and DDoS Prevention, empowering organizations to safeguard critical assets, maintain data integrity, and ensure network security in today's dynamic and perilous digital landscape. Our IDS solution serves as a valuable addition to the cybersecurity toolkit for organizations seeking comprehensive security against a wide range of threats.\n",
            "----------------------------------------\n",
            "Title: The EFFECT benchmark suite: measuring cancer sensitivity prediction performance - without the bias\n",
            "Abstract: Creating computational biology models applicable to industry is much more difficult than it appears. There is a major gap between a model that looks good on paper and a model that performs well in the drug discovery process. We are trying to shrink this gap by introducing the Evaluation Framework For predicting Efficiency of Cancer Treatment (EFFECT) benchmark suite based on the DepMap and GDSC data sets to facilitate the creation of well-applicable machine learning models capable of predicting gene essentiality and/or drug sensitivity on in vitro cancer cell lines. We show that standard evaluation metrics like Pearson correlation are misleading due to inherent biases in the data. Thus, to assess the performance of models properly, we propose the use of cell line/perturbation exclusive data splits, perturbation-wise evaluation, and the application of our Bias Detector framework, which can identify model predictions not explicable by data bias alone. Testing the EFFECT suite on a few popular machine learning (ML) models showed that while library-standard non-linear models have measurable performance in splits representing precision medicine and target identification tasks, the actual corrected correlations are rather low, showing that even simple knock-out (KO)/drug sensitivity prediction is a yet unsolved task. For this reason, we aim our proposed framework to be a unified test and evaluation pipeline for ML models predicting cancer sensitivity data, facilitating unbiased benchmarking to support teams to improve on the state of the art.\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Based Classification and Evaluation of Regional Ethnic Traditional Sports Tourism Resources\n",
            "Abstract: Traditional sports in ethnic minority regions are a valuable cultural heritage. Regional ethnic traditional sports are not only a sports business but also a tourism resource. The construction of a reasonable regional sports tourism resource classification model is fundamental to the development of sports tourism resources. However, the existing sports tourism resources classification is mostly constructed manually based on the national standard tourism resources classification system. The efficiency and accuracy of the traditional manual classification are poor and cannot reflect the characteristics of regional ethnic traditional sports tourism. In order to solve the above problems, a machine learning-based classification method for regional ethnic traditional sports tourism resources is proposed. Firstly, the relevant concepts and characteristics of traditional sports tourism resources are introduced. Then, taking the development of traditional sports of ethnic minorities in Yunnan Province as the research object, SWOT analysis, literature, interview, questionnaire, and mathematical statistics are used to investigate and analyse the overall status of the development of regional ethnic traditional sports. Secondly, a classification evaluation method based on an optimised back-propagation (BP) neural network is proposed. Finally, the optimised BP neural network model is applied to the classification of traditional sports tourism resources. The experimental results show that the optimised BP model performs well in the classification of traditional sports tourism resources, verifying its effectiveness.\n",
            "----------------------------------------\n",
            "Title: EMOTION RECOGNITION ON SPEECH PROCESSING USING MACHINE LEARNING\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Rule-Extraction Methods From Feedforward Neural Networks: A Systematic Literature Review\n",
            "Abstract: Motivated by the interpretability question in ML models as a crucial element for the successful deployment of AI systems, this paper focuses on rule extraction as a means for neural networks interpretability. Through a systematic literature review, different approaches for extracting rules from feedforward neural networks, an important block in deep learning models, are identified and explored. The findings reveal a range of methods developed for over two decades, mostly suitable for shallow neural networks, with recent developments to meet deep learning models' challenges. Rules offer a transparent and intuitive means of explaining neural networks, making this study a comprehensive introduction for researchers interested in the field. While the study specifically addresses feedforward networks with supervised learning and crisp rules, future work can extend to other network types, machine learning methods, and fuzzy rule extraction.\n",
            "----------------------------------------\n",
            "Title: Detection of Network Security Traffic Anomalies Based on Machine Learning KNN Method\n",
            "Abstract: This paper discusses the application and advantages of machine learning in anomaly detection of network security traffic. By summarizing the existing methods and techniques of network anomaly detection, this paper focuses on the progress of clustering, classification, statistics, and information theory in research. In particular, innovations in data preprocessing, feature selection, and algorithm design, such as experimental validation based on an improved KNN algorithm, demonstrate the potential of machine learning in improving detection accuracy and efficiency. In the future, as the amount of data increases and algorithms are further optimized, these technologies are expected to drive further development in cybersecurity and address the challenges of increasingly complex cyber threats.\n",
            "----------------------------------------\n",
            "Title: Research on the price analysis and prediction method of agricultural products based on logistics information\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine and deep learning single-cell segmentation and quantification of multi-dimensional tissue images\n",
            "Abstract: Increasingly, highly multiplexed in situ tissue imaging methods are used to profile protein expression at the single-cell level. However, a critical limitation is a lack of robust cell segmentation tools applicable for sections of tissues with a complex architecture and multiple cell types. Using human colorectal adenomas, we present a pipeline for cell segmentation and quantification that utilizes machine learning-based pixel classification to define cellular compartments, a novel method for extending incomplete cell membranes, quantification of antibody staining, and a deep learning-based cell shape descriptor. We envision that this method can be broadly applied to different imaging platforms and tissue types.\n",
            "----------------------------------------\n",
            "Title: Reducing Richtmyer–Meshkov instability jet velocity via inverse design\n",
            "Abstract: In this work, we detail a novel application of inverse design and advanced manufacturing to rapidly develop and experimentally validate modifications to a shaped charge jet analog. The shaped charge jet analog comprises a copper liner, a high explosive (HE), and a silicone buffer. We apply a genetic algorithm to determine an optimal buffer design that can be placed between the liner and the HE that results in the largest possible change in jet velocity. The use of a genetic algorithm allows for discoveries of unintuitive, complex, yet optimal buffer designs. Experiments using the optimal design verified the effectiveness of the buffer and validated the machine learning approach to hydrodynamic design optimization.\n",
            "----------------------------------------\n",
            "Title: Regularized reconstruction of absorbing and phase objects from a single in-line hologram , application to fluid mechanics and microbiology\n",
            "Abstract: Reconstruction of phase objects is a central problem in digital holography, whose various applications include microscopy, biomedical imaging, and fluid mechanics. Starting from a single in-line hologram, there is no direct way to recover the phase of the diffracted wave in the hologram plane. The reconstruction of absorbing and phase objects therefore requires the inversion of the non-linear hologram formation model. We propose a regularized reconstruction method that includes several physically-grounded constraints such as bounds on transmittance values, maximum/minimum phase, spatial smoothness or the absence of any object in parts of the field of view. To solve the non-convex and non-smooth optimization problem induced by our modeling, a variable splitting strategy is applied and the closed-form solution of the sub-problem (the so-called proximal operator) is derived. The resulting algorithm is efficient and is shown to lead to quantitative phase estimation on reconstructions of accurate simulations of in-line holograms based on the Mie theory. As our approach is adaptable to several in-line digital holography configurations, we present and discuss the promising results of reconstructions from experimental in-line holograms obtained in two different applications: the tracking of an evaporating droplet (size ∼ 100μm) and the microscopic imaging of bacteria (size ∼ 1μm). © 2018 Optical Society of America under the terms of the OSA Open Access Publishing Agreement OCIS codes: (090.1995) Digital holography; (100.3010) Image reconstruction techniques; (100.3190) Inverse problems; (100.5070) Phase retrieval. References and links 1. D. Gabor, “A new microscopic principle,” Nature 161, 777–778 (1948). 2. M. Liebling, T. Blu, and M. Unser, “Complex-wave retrieval from a single off-axis hologram,” J. Opt. Soc. Am. A 21, 367–377 (2004). 3. I. Yamaguchi, J.-i. Kato, S. Ohta, and J. Mizuno, “Image formation in phase-shifting digital holography and applications to microscopy,” Appl. Opt. 40, 6177–6186 (2001). 4. M. Jericho, H. Kreuzer, M. Kanka, and R. Riesenberg, “Quantitative phase and refractive index measurements with point-source digital in-line holographic microscopy,” Appl. Opt. 51, 1503–1515 (2012). 5. R. W. Gerchberg and W. O. Saxton, “A practical algorithm for the determination of the phase from image and diffraction plane pictures,” Optik 35, 237 (1972). 6. J. R. Fienup, “Phase retrieval algorithms: a comparison,” Appl. Opt. 21, 2758–2769 (1982). 7. R. Horisaki, Y. Ogura, M. Aino, and J. Tanida, “Single-shot phase imaging with a coded aperture,” Opt. Lett. 39, 6466–6469 (2014). 8. Z. Wang, Q. Dai, D. Ryu, K. He, R. Horstmeyer, A. Katsaggelos, and O.S. Cossairt, “Dictionary-based phase retrieval for space-time super resolution using lens-free on-chip holographic video,” in Imaging and Applied Optics 2017 (3D, AIO, COSI, IS, MATH, pcAOP), OSA Technical Digest (online) (Optical Society of America, 2017), paper CTu2B.3. 9. Y. Rivenson, Y. Wu, H. Wang, Y. Zhang, A. Feizi, and A. Ozcan, “Sparsity-based multi-height phase recovery in holographic microscopy,” Sci. Rep. 6, 37862 (2016). 10. D. Ryu, Z. Wang, K. He, G. Zheng, R. Horstmeyer, and O. Cossairt, “Subsampled phase retrieval for temporal resolution enhancement in lensless on-chip holographic video,” Biomed. Opt. Express 8, 1981–1995 (2017). 11. F. Eilenberger, S. Minardi, D. Pliakis, and T. Pertsch, “Digital holography from shadowgraphic phase estimates,” Opt. Lett. 37, 509–511 (2012). 12. Y. Rivenson, Y. Zhang, H. Günaydin, D. Teng, and A. Ozcan, “Phase recovery and holographic image reconstruction using deep learning in neural networks,” arXiv preprint arXiv:1705.04286 (2018). 13. A. Sinha, J. Lee, S. Li, and G. Barbastathis, “Lensless computational imaging through deep learning,” Optica 4, 1117-1125 (2017). 14. S. Sotthivirat and J. A. Fessler, “Penalized-likelihood image reconstruction for digital holography,” J. Opt. Soc. Am. A 21, 737–750 (2004). 15. L. Denis, D. Lorenz, É. Thiébaut, C. Fournier, and D. Trede, “Inline hologram reconstruction with sparsity constraints,” Opt. Lett. 34, 3475–3477 (2009). 16. A. Bourquard, N. Pavillon, E. Bostan, C. Depeursinge, and M. Unser, “A practical inverse-problem approach to digital holographic reconstruction,” Opt. Express 21, 3417–3433 (2013). 17. F. Soulez, É. Thiébaut, A. Schutz, A. Ferrari, F. Courbin, and M. Unser, “Proximity operators for phase retrieval,” Appl. Opt. 55, 7412–7421 (2016). 18. C. Schretter, D. Blinder, S. Bettens, H. Ottevaere, and P. Schelkens, “Regularized non-convex image reconstruction in digital holographic microscopy,” Opt. Express 25, 16491–16508 (2017). 19. J. Song, C. L. Swisher, H. Im, S. Jeong, D. Pathania, Y. Iwamoto, M. Pivovarov, R. Weissleder, and H. Lee, “Sparsity-based pixel super resolution for lens-free digital in-line holography,” Sci. Rep. 6, 24681 (2016). 20. S. Bettens, H. Yan, D. Blinder, H. Ottevaere, C. Schretter, and P. Schelkens, “Studies on the sparsifying operator in compressive digital holography,” Opt. Express 25, 18656–18676 (2017). 21. A. Berdeu, F. Momey, B. Laperrousaz, T. Bordy, X. Gidrol, J.-M. Dinten, N. Picollet-D’hahan, and C. Allier, “Comparative study of fully three-dimensional reconstruction algorithms for lens-free microscopy,” Appl. Opt. 56, 3939–3951 (2017). 22. N. Parikh and S. Boyd, Proximal Algorithms, Foundations and Trends® in Optimization 1, 127–239 (2014). 23. P. L. Combettes and J.-C. Pesquet, “Proximal Splitting Methods in Signal Processing,” in Fixed-Point Algorithms for Inverse Problems in Science and Engineering (Springer, 2011), pp. 185–212. 24. W. Hare and C. Sagastizábal, “Computing proximal points of nonconvex functions,” Math. Program. 116, 221–258 (2009). 25. R. Mourya, L. Denis, J.-M. Becker, and É. Thiebaut, “Augmented lagrangian without alternating directions: Practical algorithms for inverse problems in imaging,” in Proc. of 2015 IEEE International Conference on Image Processing (ICIP) (IEEE, 2015), pp. 1205–1209. 26. J. W. Goodman, Introduction to Fourier Optics (Roberts and Company Publishers, 2005). 27. F. Soulez, L. Denis, C. Fournier, É. Thiébaut, and C. Goepfert, “Inverse-problem approach for particle digital holography: accurate location based on local optimization,” J. Opt. Soc. Am. A 24, 1164–1171 (2007). 28. F. Soulez, L. Denis, É. Thiébaut, C. Fournier, and C. Goepfert, “Inverse problem approach in particle digital holography: out-of-field particle detection made possible,” J. Opt. Soc. Am. A 24, 3708–3716 (2007). 29. C. Fournier, L. Denis, M. Seifi, and T. Fournel, “Digital hologram processing in on-axis holography,” MultiDimensional Imaging 0, 51–73 (2014). 30. C. Fournier, F. Jolivet, L. Denis, N. Verrier, É. Thiebaut, C. Allier, and T. Fournel, “Pixel super-resolution in digital holography by regularized reconstruction,” Appl. Opt. 56, 69–77 (2017). 31. S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, “Distributed optimization and statistical learning via the alternating direction method of multipliers,” Foundations and Trends® in Machine Learning 3, 1–122 (2011). 32. J. Nocedal, “Updating quasi-Newton matrices with limited storage,” Math. Comput. 35, 773–782 (1980). 33. É. Thiébaut, “Optimization issues in blind deconvolution algorithms,” Proc. SPIE 4847, pp. 174–183 (2002). 34. D. Chareyron, J.-L. Marié, C. Fournier, J. Gire, N. Grosjean, L. Denis, M. Lance, and L. Méès “Testing an in-line digital holography ‘inverse method’ for the Lagrangian tracking of evaporating droplets in homogeneous nearly isotropic turbulence,” New J. Phys. 14, 043039 (2012). 35. L. Méès, N. Grosjean, D. Chareyron, J.-L. Marié, M. Seifi, and C. Fournier, “Evaporating droplet hologram simulation for digital in-line holography setup with divergent beam,” J. Opt. Soc. Am. A 30, 2021–2028 (2013). 36. J.-L. Marié, T. Tronchin, N. Grosjean, L. Méès, O. C. Öztürk, C. Fournier, B. Barbier, and M. Lance, “Digital holographic measurement of the lagrangian evaporation rate of droplets dispersing in a homogeneous isotropic turbulence,” Exp. Fluids 58, 11 (2017). 37. C. F. Bohren and D. R. Huffman, Absorption and Scattering of Light by Small Particles (Wiley, 1983). 38. G. Gouesbet and G. Gréhan, Generalized Lorenz-Mie Theories (Springer, 2017). 39. L. Kai and P. Massoli, “Scattering of electromagnetic-plane waves by radially inhomogeneous spheres: a finely stratified sphere model,” Appl. Opt. 33, 501–511 (1994). 40. F. Onofri, G. Gréhan, and G. Gouesbet, “Electromagnetic scattering from a multilayered sphere located in an arbitrary beam,” Appl. Opt. 34, 7113–7124 (1995). 41. G. Toker and J. Stricker, “Holographic study of suspended vaporizing volatile liquid droplets in still air,” Int. J. Heat Mass Tran. 39, 3475–3482 (1996). . 42. Y. Endo, T. Shimobaba, T. Kakue, and T. Ito, “GPU-accelerated compressive holography,” Opt. Express 24, 8437–8445 (2016).\n",
            "----------------------------------------\n",
            "Title: Automatic classification of front and back pronounciation variants of /r/ in the Götaland dialects of Swedish\n",
            "Abstract: In the Götaland region of Sweden, there are two major pronunciation variants of the /r/ phoneme: the 'front' and the 'back' variants. We present a classification experiment where we try to classify which of the two variants an unknown speech sound is by using machine learning methods and acoustic features. Specifically, the methods we use are Classification and Regression Trees, Logistic Model Trees, Multilayer Perceptrons and K­Nearest Neighbour and the features are Formants and Harmonicity (which is a measure of the balance between periodic and aperiodic energy) in bark­filtered speech. The results show that the single best feature is 'trimmed mean' F2, that Formants+Harmonicity performs better than Formants alone and that the best overall correct classification score is about 89%, which is much better than a baseline method based on choosing the majority class, which gives 52%.\n",
            "----------------------------------------\n",
            "Title: Scientific Deep Machine Learning Concepts for the Prediction of Concentration Profiles and Chemical Reaction Kinetics: Consideration of Reaction Conditions.\n",
            "Abstract: Emerging concepts from scientific deep machine learning such as physics-informed neural networks (PINNs) enable a data-driven approach for the study of complex kinetic problems. We present an extended framework that combines the advantages of PINNs with the detailed consideration of experimental parameter variations for the simulation and prediction of chemical reaction kinetics. The approach is based on truncated Taylor series expansions for the underlying fundamental equations, whereby the external variations can be interpreted as perturbations of the kinetic parameters. Accordingly, our method allows for an efficient consideration of experimental parameter settings and their influence on the concentration profiles and reaction kinetics. A particular advantage of our approach, in addition to the consideration of univariate and multivariate parameter variations, is the robust model-based exploration of the parameter space to determine optimal reaction conditions in combination with advanced reaction insights. The benefits of this concept are demonstrated for higher-order chemical reactions including catalytic and oscillatory systems in combination with small amounts of training data. All predicted values show a high level of accuracy, demonstrating the broad applicability and flexibility of our approach.\n",
            "----------------------------------------\n",
            "Title: Correlation Enhanced Machine Learning Approach based Wave Height Prediction\n",
            "Abstract: The prediction of wave height is one of the major problems of coastal engineering and coastal structures. In recent years, advances in the prediction of significant wave height have been considerably developed using flexible calculation techniques. In addition to the traditional prediction of significant wave height, soft computing has explored a new way of predicting significant wave heights. This research was conducted in the direction of forecasting a significant wave height using machine learning approaches. In this paper, a problem of significant wave height prediction problem has been tackled by using wave parameters such as wave spectral density. This prediction of significant wave height helps in wave energy converters as well as in ship navigation system. This research will optimize wave parameters for a fast and efficient wave height prediction. For this Pearson’s, Kendall’s and Spearman’s Correlation Coefficients and Particle Swarm Optimization feature reduction techniques are used. So reduced features are taken into consideration for prediction of wave height using neural network. In this work, performance evaluation metrics such as MSE and RMSE values are decreased and gives better performance of classification that is compared with existing research’s implemented methodology. From the experimental results, it is observed that proposed algorithm gives the better prediction as compared to PSO feature reduction technique. So, it is also concluded that Co-relation enhanced neural network is better as compared to PSO based neural network with increased number of features.\n",
            "----------------------------------------\n",
            "Title: A machine learning analysis of patient and imaging factors associated with achieving clinically substantial outcome improvements following total shoulder arthroplasty: Implications for selecting anatomic or reverse prostheses.\n",
            "Abstract: Background\n",
            "Indications for reverse total shoulder arthroplasty(rTSA) continue to expand making it challenging to predict whether patients will benefit more from anatomic TSA(aTSA) or rTSA. The purpose of this study was to determine which factors differ between aTSA and rTSA patients that achieve meaningful outcomes and may influence surgical indication.\n",
            "\n",
            "\n",
            "Methods\n",
            "Random Forest dimensionality reduction was applied to reduce 23 features into a model optimizing substantial clinical benefit (SCB) prediction of the American Shoulder and Elbow Surgeon score using 1117 consecutive patients with 2-year follow up. Features were compared between aTSA patients stratified by SCB achievement and subsequently with rTSA SCB achievers.\n",
            "\n",
            "\n",
            "Results\n",
            "Eight combined features optimized prediction (accuracy = 87.1%, kappa = 0.73): (1) age, (2) body mass index (BMI), (3) sex, (4) history of rheumatic disease, (5) humeral head subluxation (HH) on computed tomography (CT), (6) HH-acromion distance on X-ray, (7) glenoid retroversion on CT, and (8) Walch classification on CT. A higher proportion of males (65.6% vs. 54.9%, p = 0.022), Walch B-C glenoid morphologies (49.5% vs. 37.9%, p < 0.001), and greater BMI (30.1 vs. 26.5 kg/m2, p = 0.038) were observed in aTSA nonachievers compared with aTSA achievers, while aTSA nonachievers were statistically similar to rTSA achievers.\n",
            "\n",
            "\n",
            "Discussion\n",
            "Patients with glenohumeral osteoarthritis and intact rotator cuffs that have a BMI > 30 kg/m2 and exhibit Walch B-C glenoids may be less likely to achieve the SCB following aTSA and should be considered for rTSA.\n",
            "----------------------------------------\n",
            "Title: Research on Machine Learning Methods That Promote Public Participation in Urban Design\n",
            "Abstract: : Public participation promotes innovative ways to increase the efficiency of urban design and planning (Amado et al., 2010) but it also presents many challenges to be effective. This paper introduces the current situation of public participation and how current machine learning (ML) tools can support it. Then we propose new methods based on machine learning to improve the communication between urban designers and participants. Finally, we discuss potential effects of this new method on public participation\n",
            "----------------------------------------\n",
            "Title: Thai culture image classification with transfer learning\n",
            "Abstract: Classifying images of Thai culture is important for a variety of applications, such as tourism, education, and cultural preservation. However, building a Machine learning model from scratch to classify Thai cultural images can be challenging due to the limited availability of annotated data. In this study, we investigate the use of transfer learning for the task of image classification on a dataset of Thai cultural images. We utilize three popular convolutional neural network models, namely MobileNet, EfficientNet, and residual network (ResNet) as baseline pre-trained models. Their performances were evaluated when they were trained from random initialization, used as a feature extractor, and fully fine-tuned. The results showed that all three models performed better in terms of accuracy and training time when they were used as a feature extractor, with EfficientNet achieving the highest accuracy of 95.87% while maintaining the training time of 24 ms/iteration. To better understand the reasoning behind the predictions made by the models, we deployed the gradient-weighted class activation mapping (Grad-CAM) visualization technique to generate heatmaps that the models attend to when making predictions. Both our quantitative and qualitative experiments demonstrated that transfer learning is an effective approach to image classification on Thai cultural images.\n",
            "----------------------------------------\n",
            "Title: Validation and updating of clinical prediction models: why and how?\n",
            "Abstract: SEE RELATED ARTICLE: Rev Argent Cardiol 2019;87:291-299. http://dx.doi.org/10.7775/rac.v87.i4.15346 Are predictions from a previously developed prediction model valid for my patients? This is a difficult question that was addressed carefully in a recent paper that focused on the validity of the GRACE score to predict in-hospital mortality. (1) Why is this high-quality study by Mangariello and Gitelman important? Prediction models are increasingly published in the medical literature. Newer methods are proposed, such as labeled machine learning, deep learning and artificial intelligence. Whatever the method of development, the key issue is whether the prediction model or algorithm provides valid predictions for physicians and their patients who rely on them as a source of information and decision making. Indeed, the authors rightly argue that many differences between settings may be present. These include differences in patient characteristics, healthcare systems, and socioeconomic environment. Moreover, treatment may change over time. All these differences may make a previously developed model not valid for the particular setting where the model is applied, for example the Dr. Juan A. Fernández Hospital in Buenos Aires. Therefore, a model may need updating for a specific setting. (2)\n",
            "----------------------------------------\n",
            "Title: AN INTEGRATED MACHINE LEARNING-PROBABILISTIC APPROACH TO PREDICT BEACH VOLUME CHANGE\n",
            "Abstract: In the DataBeach study a machine learning model was developed with the aim to improve the efficiency and sustainability of design of soft coastal defense projects. A morphological model based on machine learning was trained and tested to predict beach volume changes with significantly reduced computational time compared to traditional process-based models. The machine learning model was then applied, combined with a ‘penalty function’ for inclusion of morphological feedback, to predict beach volume changes for the study area of approximately 2 km alongshore and on a 10-year project timescale. In order to run many different scenarios for the 10-year prediction, a probabilistic methodology was developed to take into account the uncertainties in this time period. The machine learning-based model provides great benefits for probabilistic simulations, due to the lower computational time, compared to process-based numerical models such as XBeach, and a flexible way in which it can incorporate measurement data. The performance of the tested machine learning models was comparable to that of the short term volume predictions of XBeach. Comparison of 10-year predicted volume changes using the machine learning model and measured beach topography (LiDAR) showed good agreement between measured and predicted volume changes for the dry beach area (when accounting for nourishments), but overestimation in the beach volume change predictions for the intertidal beach. These differences are partially attributed to the poor performance on XBeach for long term, normal wave conditions, which are an important factor in the intertidal area.\n",
            "----------------------------------------\n",
            "Title: Tumour radiomics as imaging biomarker of tumour response to chemo-radiotherapy in patients with adenocarcinoma of rectum.\n",
            "Abstract: 243 Background: We aimed to study whether texture (Radiomic) features obtained from T2W MRI of patients with rectal cancer can be used as a surrogate imaging biomarker to predict response to NACTRT. We explored various machine learning tools to develop the best model to predict response to NACTRT. Methods: One hundred patients with stage II/III who underwent MRI before and after NACTRT and surgical treatment were enrolled. Patients were classified into complete response (pCR, n = 21) and partial and nonresponse (pPR + pNR, n = 53) on the basis of histopathological report (74 patients who underwent surgery) and clinico-radiological response (26 patients who did not undergo surgery). Tumor volumes (Region of interest) were manually selected in each tumour segment. There were sixty four first-order and higher-order radiomic features. Recursive feature elimination method was used for feature selection and 5 prediction models were tested using 10-fold cross validation for predicting tumour response to NACTRT. Results: Using prediction model assessment matrix (RFC, SVC, GBC, NBC, ABC), the best results for prediction response were obtained using the random forest model with AUC of 0.79 ± 0.15 (Mean ± Standard deviation) accuracy of 0.72 ±0.12, precision of 0.77 ± 0.10, sensitivity of 0.87 ± 0.07, f1 score- 0.81 ±0.07. By using random forest model, Texrad features obtained from pre and post NACTRT MRI could accurately predict pCR. To the best of our knowledge, apart for the added values of RF model to Texrad features, is the first study to demonstrate and compare RF, SVC, GBC, NBC, Adaboost models to the same cohort of patient with 10-fold validation. Conclusions: Our study shows that RFM was most accurate and stable for predicting tumour response. MRI based Radiomic features can be used as surrogate image biomarker to accurately predict the treatment response to NACTRT in patients with locally advanced rectal cancer. The prediction model can be used as a complementary non-invasive tool to identify patients eligible for organ preservation. [Table: see text]\n",
            "----------------------------------------\n",
            "Title: Neural harmony: revolutionizing thyroid nodule diagnosis with hybrid networks and genetic algorithms.\n",
            "Abstract: In the contemporary world, thyroid disease poses a prevalent health issue, particularly affecting women's well-being. Recognizing the significance of maternal thyroid (MT) hormones in fetal neurodevelopment during the first half of pregnancy, this study introduces the HNN-GSO model. This groundbreaking hybrid approach, utilizing the MT dataset, integrates ResNet-50 and Artificial Neural Network (ANN) within a Glow-worm Swarm Optimization (GSO) framework for optimal parameter tuning. With a comprehensive methodology involving dataset preprocessing and Genetic Algorithm (GA) for feature selection, our model leverages ResNet-50 for feature extraction and ANN for classification tasks. Implemented in Python, the HNN-GSO model outperforms existing models, including K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), ResNet, GoogleNet, and ANN, achieving an impressive accuracy rate of 98%. This success underscores the effectiveness of our approach in complex classification tasks within machine learning (ML) and pattern recognition, specifically tailored to the Thyroid Ultrasound Images (TUI) Dataset. To provide a comprehensive understanding of performance, additional statistical measures such as precision, recall, and F1 score were considered. The HNN-GSO model consistently outperformed competitors across these metrics, showcasing its superiority in MT classification. The HNN-GSO model seamlessly combines ResNet-50's feature extraction, ANN's classification robustness, and GSO's optimization for unparalleled performance. This research offers a promising framework for advancing ML methodologies, enhancing accuracy, and efficiency in classification tasks related to MT health.\n",
            "----------------------------------------\n",
            "Title: Big Data and Its Applications in Smart Real Estate and the Disaster Management Life Cycle: A Systematic Analysis\n",
            "Abstract: Big data is the concept of enormous amounts of data being generated daily in different fields due to the increased use of technology and internet sources. Despite the various advancements and the hopes of better understanding, big data management and analysis remain a challenge, calling for more rigorous and detailed research, as well as the identifications of methods and ways in which big data could be tackled and put to good use. The existing research lacks in discussing and evaluating the pertinent tools and technologies to analyze big data in an efficient manner which calls for a comprehensive and holistic analysis of the published articles to summarize the concept of big data and see field-specific applications. To address this gap and keep a recent focus, research articles published in last decade, belonging to top-tier and high-impact journals, were retrieved using the search engines of Google Scholar, Scopus, and Web of Science that were narrowed down to a set of 139 relevant research articles. Different analyses were conducted on the retrieved papers including bibliometric analysis, keywords analysis, big data search trends, and authors’ names, countries, and affiliated institutes contributing the most to the field of big data. The comparative analyses show that, conceptually, big data lies at the intersection of the storage, statistics, technology, and research fields and emerged as an amalgam of these four fields with interlinked aspects such as data hosting and computing, data management, data refining, data patterns, and machine learning. The results further show that major characteristics of big data can be summarized using the seven Vs, which include variety, volume, variability, value, visualization, veracity, and velocity. Furthermore, the existing methods for big data analysis, their shortcomings, and the possible directions were also explored that could be taken for harnessing technology to ensure data analysis tools could be upgraded to be fast and efficient. The major challenges in handling big data include efficient storage, retrieval, analysis, and visualization of the large heterogeneous data, which can be tackled through authentication such as Kerberos and encrypted files, logging of attacks, secure communication through Secure Sockets Layer (SSL) and Transport Layer Security (TLS), data imputation, building learning models, dividing computations into sub-tasks, checkpoint applications for recursive tasks, and using Solid State Drives (SDD) and Phase Change Material (PCM) for storage. In terms of frameworks for big data management, two frameworks exist including Hadoop and Apache Spark, which must be used simultaneously to capture the holistic essence of the data and make the analyses meaningful, swift, and speedy. Further field-specific applications of big data in two promising and integrated fields, i.e., smart real estate and disaster management, were investigated, and a framework for field-specific applications, as well as a merger of the two areas through big data, was highlighted. The proposed frameworks show that big data can tackle the ever-present issues of customer regrets related to poor quality of information or lack of information in smart real estate to increase the customer satisfaction using an intermediate organization that can process and keep a check on the data being provided to the customers by the sellers and real estate managers. Similarly, for disaster and its risk management, data from social media, drones, multimedia, and search engines can be used to tackle natural disasters such as floods, bushfires, and earthquakes, as well as plan emergency responses. In addition, a merger framework for smart real estate and disaster risk management show that big data generated from the smart real estate in the form of occupant data, facilities management, and building integration and maintenance can be shared with the disaster risk management and emergency response teams to help prevent, prepare, respond to, or recover from the disasters.\n",
            "----------------------------------------\n",
            "Title: Relationship Induced Multi-Template Learning for Diagnosis of Alzheimer’s Disease and Mild Cognitive Impairment\n",
            "Abstract: As shown in the literature, methods based on multiple templates usually achieve better performance, compared with those using only a single template for processing medical images. However, most existing multi-template based methods simply average or concatenate multiple sets of features extracted from different templates, which potentially ignores important structural information contained in the multi-template data. Accordingly, in this paper, we propose a novel relationship induced multi-template learning method for automatic diagnosis of Alzheimer's disease (AD) and its prodromal stage, i.e., mild cognitive impairment (MCI), by explicitly modeling structural information in the multi-template data. Specifically, we first nonlinearly register each brain's magnetic resonance (MR) image separately onto multiple pre-selected templates, and then extract multiple sets of features for this MR image. Next, we develop a novel feature selection algorithm by introducing two regularization terms to model the relationships among templates and among individual subjects. Using these selected features corresponding to multiple templates, we then construct multiple support vector machine (SVM) classifiers. Finally, an ensemble classification is used to combine outputs of all SVM classifiers, for achieving the final result. We evaluate our proposed method on 459 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, including 97 AD patients, 128 normal controls (NC), 117 progressive MCI (pMCI) patients, and 117 stable MCI (sMCI) patients. The experimental results demonstrate promising classification performance, compared with several state-of-the-art methods for multi-template based AD/MCI classification.\n",
            "----------------------------------------\n",
            "Title: 5G and Beyond: On the Significance of Wireless Channel Estimation\n",
            "Abstract: Wireless channel is one of the most important components of any wireless communication system. Accurate wireless channel knowledge at the transmitter ensures that correct amount of data is being transmitted to the intended users/devices in the system. This wireless channel knowledge, known as Channel State Information (CSI), is acquired at the transmitter through the feedback sent by the users/devices. The transmitter, then, uses this CSI to adjust the transmission, both in terms of data rate and direction, to the intended users/devices. In this paper, we investigated why accurate Wireless Channel Estimation (WCE) is even more critical for contemporary wireless technologies such as 5G and beyond? We first modelled the wireless channel between a transmitter and multiple receivers having multiple antennas using independent and identically distributed Gaussian random processes and calculated channel strengths and angle of transmission using ground as our azimuth reference. We then used a Simple Random Estimation (SRE) technique at the transmitter to estimate the same wireless channel. Our numerical results show that a small perturbation in WCE leads to significant deviations in channel strengths and directions. These estimation errors at the transmitter result in data loss as well as poor Quality of Service (QoS) to the users/devices. This study leads us to develop innovative wireless channel estimation techniques using Machine Learning (ML) at the transmitter that will reduce the amount of CSI feedback and improves the over all transmission in terms of both channel strengths and direction of transmission in our future work. Comment: given the purpose of this paper is to discuss channel estimation but in this paper we are not using specific baseline channel estimation techniques. Our main purpose is to show the channel error using SRE and future need to minimise this channel error.\n",
            "----------------------------------------\n",
            "Title: Visual concepts for news story tracking: analyzing and exploiting the NIST TRESVID video annotation experiment\n",
            "Abstract: In the summer of 2003, using an interactive intelligent tool, over 100 researchers in video understanding annotated from the NIST TRECVID database over 62 hours of news video spanning six months of 1998. These 47K shots with 43 3 K labels from over 1000 visual concept categories comprise the largest publicly available ground truth for this domain. Our analysis of this data, combining the tools of statistical natural language processing, machine learning, and computer vision, finds significant novel statistical patterns that can be exploited for the accurate tracking of the episodes of a given news story over time, by using semantic labels that are solely visual. We find that the ground \"truth\" is very muddy, but by using the feature selection tool of information gain, we extract 14 reliable visual concepts with mid-frequency use; all but one are visual concepts that refer to settings, rather than actors, objects, or events. We discover that the probability of another episode of a named story to recur after a gap of d days is proportional to 1/(d + 1). We define a novel similarity measure incorporating both semantic and temporal properties between episodes i and j as: Dice(i, j)/(1 + gap(i, j)). We exploit a low-level computer vision technique, normalized cut (Laplacian eigenmaps), for clustering these episodes into stories, and in the process document a weakness of this popular technique. We use these empirical results to make specific recommendations on how better visual semantic ontologies for news stories, and how better video annotation tools, should be designed.\n",
            "----------------------------------------\n",
            "Title: A novel fusion feature imageization with improved extreme learning machine for network anomaly detection\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Extreme Gradient Boosting for Surface Electromyography Classification on Time-Domain Features\n",
            "Abstract: Surface electromyography (sEMG) signals play an essential role in disease diagnosis and rehabilitation. This study applied a powerful machine learning algorithm called extreme gradient boosting (XGBoost) to classify sEMG signals acquired from muscles around the knee for distinguishing patients with knee osteoarthritis (KOA) from healthy subjects. First, to improve data quality, we preprocessed the data via interpolation and normalization. Next, to ensure the description integrity of model input, we extracted nine time-domain features based on the statistical characteristics of sEMG signals over time. Finally, we classified the samples using XGBoost and cross-validation (CV) and compared the results to those produced by the support vector machine (SVM) and the deep neural network (DNN). Experimental results illustrate that the presented method effectively improves classification performance. Moreover, compared with the SVM and the DNN, XGBoost has higher accuracy and better classification performance, which indicates its advantages in the classification of patients with KOA based on sEMG signals.\n",
            "----------------------------------------\n",
            "Title: Landscape of sialylation patterns identify biomarkers for diagnosis and prediction of response to anti-TNF therapy in crohn’s disease\n",
            "Abstract: Crohn’s disease (CD), a subtype of inflammatory bowel disease (IBD), causes chronic gastrointestinal tract inflammation. Thirty percent of patients do not respond to anti-tumor necrosis factor (TNF) therapy. Sialylation is involved in the pathogenesis of IBD. We aimed to identify potential biomarkers for diagnosing CD and predicting anti-TNF medication outcomes in CD. Three potential biomarkers (SERPINB2, TFPI2, and SLC9B2) were screened using bioinformatics analysis and machine learning based on sialylation-related genes. Moreover, the combined model of SERPINB2, TFPI2, and SLC9B2 showed excellent diagnostic value in both the training and validation cohorts. Importantly, a Sial-score was constructed based on the expression of SERPINB2, TFPI2, and SLC9B2. The Sial-low group showed a lower level of immune infiltration than the Sial-high group. Anti-TNF therapy was effective for 94.4% of patients in the Sial-low group but only 15.8% in the Sial-high group. The Sial-score had an outstanding ability to predict and distinguish between responders and non-responders. Our comprehensive analysis indicates that SERPINB2, TFPI2, and SLC9B2 play essential roles in pathogenesis and anti-TNF therapy resistance in CD. Furthermore, it may provide novel concepts for customizing treatment for individual patients with CD.\n",
            "----------------------------------------\n",
            "Title: Staging of Primary Lymphedema Based on Radiomics Features from Subcutaneous Tissues in Lower Extremity MRI\n",
            "Abstract: Motivation: Traditional imaging-based staging methods for PLEL rely on subjective assessments by medical professionals and often struggle to capture the micro-level changes associated with lymphedema, which limits the accuracy and granularity of staging. Goal(s): To explore the value of radiomicss features based on different components extracted from MRI for assessing the staging of PLEL. Approach: We proposed a machine learning model to integrate multi-region radiomics for automated PLEL staging and employed deep learning for automated subcutaneous tissue segmentation in the lower extremity MRI. Results: The Dice coefficient for subcutaneous tissue segmentation scored 0.92, and the AUC for lymphedema staging was 0.821. Impact: The machine learning model based on radiomics in this study shows promising potential and value in lymphedema staging, which is expected to reduce subjective variability and potentially eliminate the need for clinical assays, thus enhancing its clinical applicability.\n",
            "----------------------------------------\n",
            "Title: Detecting Cross-Site Scripting Attack using Machine Learning Algorithms\n",
            "Abstract: Cross-Site scripting attacks can have a significant impact on a user’s computer due to their ability to infect it with malware. This is because the code is embedded in a vulnerable program, allowing attackers to gain access through session cookies and carry out any action that is allowed by the user’s account. This can range from credential theft to session hijacking, as well as a variety of other security vulnerabilities. Therefore the detecting and preventing the XSS attacks are critical to assure the safeguard of web-based applications. This research work concentrates on the automation of Cross-Site scripting attack detection by employing machine learning algorithms like Naive Bayes, K-Nearest Neighbors, Decision Trees, Random Forest, and Support Vector Machines. XSS attacks frequently exhibit patterns and characteristics that can be learnt from historical data. These patterns are well recognized by supervised machine learning algorithms, which can also generalize from training data to detect similar harmful patterns in real-time web traffic. XSSDataSet1, a large dataset of both genuine and malicious On-the-Web (OTW) requests and attack methods is utilized for training and testing the Machine learning models. While extracting the data, the request’s payload, request parameters, and contextual information are taken into account. The evaluation of each algorithm includes an analysis of various performance metrics such as accuracy, precision, recall, and the F1 Score. An accuracy level of 99.91% has been attained with decision tree algorithm. The results of the extensive analysis showed that decision tree classifier, random forest, support vector machine, and K-Nearest Neighbors are more efficient than Naive Bayes in detecting the XSS attack.\n",
            "----------------------------------------\n",
            "Title: Machine learning algorithms and robustness\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: High-Throughput Screening of Sulfur-Resistant Catalysts for Steam Methane Reforming Using Machine Learning and Microkinetic Modeling\n",
            "Abstract: The catalytic activity of bimetallic catalysts for the steam methane reforming (SMR) reaction was extensively studied previously. However, the performance of these materials in the presence of sulfur-containing species is yet to be investigated. In this study, we propose a novel process aided by machine learning (ML) and microkinetic modeling for the rapid screening of sulfur-resistant bimetallic catalysts. First, various ML models were developed to predict atomic adsorption energies (C, H, O, and S) on bimetallic surfaces. Easily accessible physical and chemical properties of the metals and adsorbates were used as input features. The Ensemble learning, artificial neural network, and support vector regression models achieved the best performance with R2 values of 0.74, 0.71, and 0.70, respectively. A microkinetic model was then built based on the elementary steps of the SMR reaction. Finally, the microkinetic model, together with the atomic adsorption energies predicted by the Ensemble model, were used to screen over 500 bimetallic materials. Four Ge-based alloys (Ge3Cu1, Ge3Ni1, Ge3Co1, and Ge3Fe1) and the Ni3Cu1 alloy were identified as promising and cost-effective sulfur-resistant catalysts.\n",
            "----------------------------------------\n",
            "Title: Groundwater Level Forecasting Using Machine Learning: A Case Study of the Baekje Weir in Four Major Rivers Project, South Korea\n",
            "Abstract: Understanding the impact of human‐made structures on groundwater levels is essential, with structures like dams or weirs presenting unique challenges and opportunities for study. The Baekje weir in South Korea presents an interesting case as the weir has undergone full gate opening, which is generally not the case for weirs and reservoirs, providing valuable opportunity for simulating weir removal conditions. The main objectives are investigation of groundwater level fluctuations under various weir operations, distances from the weir, and seasonal variations. The study utilizes observed data that simulates conditions with and without the weir, including scenarios of full gate opening. Multiple machine learning algorithms—Random Forest (RF), Artificial Neural Network, Support Vector Regression (SVR), Gradient Boosting, and Extreme Gradient Boosting (XGBoost)—are used to develop accurate groundwater level prediction models. The models' performance is assessed using coefficient of determination, Root mean square error (RMSE), Mean Absolute Error (MAE) indices, and visualized through Taylor diagrams. Results indicate that XGBoost outperforms other models in all three groups during both training and testing phases. Specifically, XGBoost surpasses RF by 2.09% (R2), 5.66% (RMSE), and 10.1% (MAE) in training, and outperforms SVR by 11.2% (R2), 42.0% (RMSE), and 129.2% (MAE) in testing. Additionally, the study generates groundwater level maps, providing a practical tool for managing groundwater systems and informing decision‐making in weir operations. This study not only sheds light on the dynamic relationship between weir operations and groundwater levels but also provides actionable insights for effective water management in similar hydrological settings.\n",
            "----------------------------------------\n",
            "Title: An Empirical Analysis of Evolved Radial Basis Function Networks and Support Vector Machines with Mixture of Kernels\n",
            "Abstract: Classification is one of the most fundamental and formidable tasks in many domains including biomedical. In biomedical domain, the distributions of data in most of the datasets into predefined number of classes is significantly different (i.e., the classes are distributed unevenly). Many mathematical, statistical, and machine learning approaches have been developed for classification of biomedical datasets with a varying degree of success. This paper attempts to analyze the empirical performance of two forefront machine learning algorithms particularly designed for classification problem by adding some novelty to address the problem of imbalanced dataset. The evolved radial basis function network with novel kernel and support vector machine with mixture of kernels are suitably designed for the purpose of classification of imbalanced dataset. The experimental outcome shows that both algorithms are promising compared to simple radial basis function neural networks and support vector machine, respectively. However, on an average, support vector machine with mixture kernels is better than evolved radial basis function neural networks.\n",
            "----------------------------------------\n",
            "Title: Evaluation of Cuff-less Blood Pressure Monitoring Models over Multiple Data Sets\n",
            "Abstract: Blood pressure (BP) monitoring via cuffless devices has gained significant attention in the last few years. Despite a plethora of works having been produced in this field based on traditional machine learning (ML) or deep learning (DL) models, very limited research has been carried out in terms of the external validation and reproducibility of said models to ensure that they are of clinical use. To the best of the authors’ knowledge, this is the first study to evaluate several of the currently most well cited ML/DL-based models for cuffless BP monitoring over multiple independent data sets. The results of this investigation in reproducibility are reported with particular recommendations provided regarding standardized data collection protocols, models and signals, data recording length, and open access data as potential steps to overcoming the challenge of reproducibility in ML/DL models in this field and the health domain in general.\n",
            "----------------------------------------\n",
            "Title: In-Bed Pose Estimation: Deep Learning With Shallow Dataset\n",
            "Abstract: This paper presents a robust human posture and body parts detection method under a specific application scenario known as in-bed pose estimation. Although the human pose estimation for various computer vision (CV) applications has been studied extensively in the last few decades, the in-bed pose estimation using camera-based vision methods has been ignored by the CV community because it is assumed to be identical to the general purpose pose estimation problems. However, the in-bed pose estimation has its own specialized aspects and comes with specific challenges, including the notable differences in lighting conditions throughout the day and having pose distribution different from the common human surveillance viewpoint. In this paper, we demonstrate that these challenges significantly reduce the effectiveness of the existing general purpose pose estimation models. In order to address the lighting variation challenge, the infrared selective (IRS) image acquisition technique is proposed to provide uniform quality data under various lighting conditions. In addition, to deal with the unconventional pose perspective, a 2- end histogram of oriented gradient (HOG) rectification method is presented. The deep learning framework proves to be the most effective model in human pose estimation; however, the lack of large public dataset for in-bed poses prevents us from using a large network from scratch. In this paper, we explored the idea of employing a pre-trained convolutional neural network (CNN) model trained on large public datasets of general human poses and fine-tuning the model using our own shallow (limited in size and different in perspective and color) in-bed IRS dataset. We developed an IRS imaging system and collected IRS image data from several realistic life-size mannequins in a simulated hospital room environment. A pre-trained CNN called convolutional pose machine (CPM) was fine-tuned for in-bed pose estimation by re-training its specific intermediate layers. Using the HOG rectification method, the pose estimation performance of CPM improved significantly by 26.4% in the probability of correct key-point (PCK) criteria at PCK0.1 compared to the model without such rectification. Even testing with only well aligned in-bed pose images, our fine-tuned model still surpassed the traditionally tuned CNN by another 16.6% increase in pose estimation accuracy.\n",
            "----------------------------------------\n",
            "Title: A Comprehensive Analysis of MRI Based Brain Tumor Segmentation Using Conventional and Deep Learning Methods\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Scaling up support vector machines\n",
            "Abstract: Kernel methods, such as support vector machines (SVMs), have been successfully used in various aspects of machine learning problems, such as classification, regression, and ranking. Many of them are formulated as quadratic programming (QP) problems, which take O(m3) time and O(m2) space complexities, where m is the training set size. It is thus computationally infeasible on massive data sets. By observing that practical SVM implementations only approximate the optimal solution by an iterative strategy, I scale up kernel methods by exploiting such \"approximateness\" in this thesis. \n",
            "First, I show that SVM classification problems can be equivalently formulated as minimum enclosing ball (MEB) problems in computational geometry. Then, by adopting an efficient approximate MEB algorithm, I obtain provably approximately optimal solutions with the idea of core-sets. My proposed Core Vector Machine (CVM) algorithm can be used with nonlinear kernels and has a time complexity that is linear in m and a space complexity that is independent of m for a fixed approximation factor (1 + e) 2. Experiments on large real-world data sets demonstrate that the CVM is as accurate as existing SVM implementations but is much faster and can handle much larger data sets than existing scale-up methods. \n",
            "By generalizing the underlying MEB problem as the center-constrained minimum enclosing ball (CCMEB) problem, I extend the CVM algorithm to the regression and ranking setting. Moreover, the condition on the kernel function is relaxed. Thus, the enhanced CVM algorithm can be used with any linear/nonlinear kernels. \n",
            "Finally, I introduce the enclosing ball (MEB) problem where the ball's radius is fixed and thus does not have to be minimized. I develop efficient (1 + e)- approximation algorithms that are simple to implement and do not require any sophisticated numerical solver. For the Gaussian kernel in particular, a suitable choice of this (fixed) radius is easy to determine, and the center obtained from the (1+e)-approximation of this EB problem is close to the center of the corresponding MEB. Experimental results show that the proposed algorithm has accuracies comparable to the other large-scale SVM implementations, but can handle very large data sets and is even faster than the CVM in general.\n",
            "----------------------------------------\n",
            "Title: A comparison of regression algorithms for wind speed forecasting at Alexander Bay\n",
            "Abstract: With the drive to reduce carbon emissions, the use of renewable energy such as wind power, solar power, hydropower and biofuel has become more prevalent globally. In the case of wind farms, the power generated by wind turbines is highly correlated to wind speed and direction. As a consequence, considerable research is currently being performed to accurately predict wind speed and direction ahead of time. In this paper the wind speed of South African data from the Wind Atlas of South Africa is used to forecast 1 to 24 hours ahead, in hourly intervals. Predictions are performed on a wind speed time series with three machine learning regression algorithms, namely support vector regression, ordinary least squares and Bayesian ridge regression. The resulting prediction errors from each method are compared to persistence forecast which serves as a performance benchmark. The results show a vast improvement on the persistence forecast and a slight improvement of the support vector regression over the ordinary least squares and Bayesian ridge regression. We also show that there is an additional improvement in prediction error when more features are added.\n",
            "----------------------------------------\n",
            "Title: Non-Interactive Decision Trees and Applications with Multi-Bit TFHE\n",
            "Abstract: Machine learning classification algorithms, such as decision trees and random forests, are commonly used in many applications. Clients who want to classify their data send them to a server that performs their inference using a trained model. The client must trust the server and provide the data in plaintext. Moreover, if the classification is done at a third-party cloud service, the model owner also needs to trust the cloud service. In this paper, we propose a protocol for privately evaluating decision trees. The protocol uses a novel private comparison function based on fully homomorphic encryption over the torus (TFHE) scheme and a programmable bootstrapping technique. Our comparison function for 32-bit and 64-bit integers is 26% faster than the naive TFHE implementation. The protocol is designed to be non-interactive and is less complex than the existing interactive protocols. Our experiment results show that our technique scales linearly with the depth of the decision tree and efficiently evaluates large decision trees on real datasets. Compared with the state of the art, ours is the only non-interactive protocol to evaluate a decision tree with high precision on encrypted parameters. The final download bandwidth is also 50% lower than the state of the art.\n",
            "----------------------------------------\n",
            "Title: Enabling new frontiers of nanophotonics with metamaterials, photonic crystals, and plasmonics\n",
            "Abstract: Nanophotonics is a cutting-edge interdisciplinary ﬁeld that merges state-of-the-art nanotechnology with the traditional ﬁeld of optics. Light–matter interactions at the nanoscale differ greatly from the behaviors we see at the macroscale in our daily lives, and the ﬁeld of nanophotonics aims to develop new ways to generate, manipulate, and detect light by uncovering new physics and pioneering innovative engineering solutions. Recent advancements in nanofabrication, machine learning, and the understanding of fundamental physics have pushed the boundaries of nanophotonics with applications in communications, sensing, imaging, and beyond.\n",
            "----------------------------------------\n",
            "Title: Machine learning models for hydrogen bond donor and acceptor strengths using large and diverse training data generated by first-principles interaction free energies\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Beliefs affecting concussion reporting among military cadets: advanced observations through machine learning\n",
            "Abstract: ABSTRACT Background: Untreated concussions are an important health concern. The number of concussions sustained each year is difficult to pinpoint due to diverse reporting routes and many people not reporting. A growing body of literature investigates the motivations for concussion under-reporting, proposing ties with knowledge of concussion outcomes and concussion culture. The present work employs machine learning to identify trends in knowledge and willingness to self-report concussions. Methods: 2,204 cadets completed a survey addressing athletic and pilot status, concussion symptoms and outcome beliefs, ethical beliefs, demographics, and reporting willingness. Results: Clustering and non-negative matrix analysis identified connections to self-report willingness within: knowledge of symptoms, ethical beliefs, reporting requirements, and belief of long-term concussion outcomes. Support vector machine classification of cadet reporting likelihood reveals symptom and outcome knowledge may be inversely related to reporting among those rating ethics considerations as low, while heightened ethics may predict higher reporting likeliness overall. Conclusions: Machine-learning analysis bolsters prior theories on the importance of concussion culture in reporting and indicate more symptom knowledge may decrease willingness to report. Uniquely, our analysis indicated importance of ethical behavior may be associated with general concussion reporting willingness, inviting further consideration from healthcare practitioners seeking increased reporting.\n",
            "----------------------------------------\n",
            "Title: Mechanical behaviors and internal pressure bearing capacity of nuclear containment using UHPC and ECC: From numerical simulation, machine learning prediction to fragility analysis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Clustering Methods for the Characterization of Synchrotron Radiation X-Ray Fluorescence Images of Human Carotid Atherosclerotic Plaque\n",
            "Abstract: \n",
            "This study employs computational algorithms to automatically identify and classify features in X‐Ray fluorescence (XRF) microscopy images. Principal component analysis (PCA) and unsupervised machine learning algorithms, such as Gaussian mixture (GM) clustering, are implemented to label features on a collection of XRF maps of human atherosclerotic plaque samples. The investigation involves the hard X‐Ray nanoprobe (NanoMAX) at MAX IV synchrotron radiation facility, utilizing scanning transmission X‐Ray microscopy (STXM) and XRF techniques. The analysis covers regions of interest scanned by the beam with a step size of 200 nm, yielding XRF maps of elements like calcium, iron, and zinc. These maps reveal intricate structures unsuitable for manual labeling. However, they can be accurately classified in an automated fashion using GM. Prior to clustering, PCA is used to deal with repeated patterns and background areas. The resulting clusters are associated with different types of features, which can be identified as specific tissues confirmed by histology. Regions of high concentrations of phosphorus, sulfur, calcium, and iron are found in the samples. These regions are also observed in the STXM results as spots of low transmission that typically are associated with calcium deposits only.\n",
            "----------------------------------------\n",
            "Title: Applying Hidden Markov Models to Voting Advice Applications\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine learning-based text to speech conversion for native languages\n",
            "Abstract: Marathi is one of India's most ancient languages. This research project (TTS) focuses at the growth of the Marathi Text-to-Speech system. Marathi text produced in either Devanagari or Ekalipi script is used as input for Marathi TTS. The Text to Speech system's purpose is to convert any given text into speech. In order to mimic human speakers, speech synthesis involves creating technology that can produce human-like speech from any text input. Two key elements of a text-to-speech system are text processing and speech production. It is crucial that the text processing component provides an adequate sequence of phonemic units in order to construct a speech synthesis system that produces natural-sounding speech. The Hidden Markov Model is used with the statistical parameters for speech synthesis. This research is conducted to improve the pronunciation accuracy. The primary goal of this research is to improve and fine-tune the TTS system's pronunciation accuracy for native Indian languages like Marathi and make it seem more natural than current TTS systems (like how humans speak). The WASRAW (\"Write as Spoken, Read as Written\") technique is what the TTS system uses to speak written text. The objective is to create a language-independent solution as opposed to current solutions, particularly with regard to pronunciation. Unique script i.e., Ekalipi script has been used along with Devanagari script for Marathi language. The proposed model has been tested for 35 Marathi speakers for Devanagari script and achieved MOS of 4.38 for speech intelligibility, MOS of 4.45 for pronunciation accuracy and MOS of 4.44 for naturalness. Also, for Ekalipi script it has been tested for around 10 users who are familiar with the script. The dictionary-based approach has been followed in order to speak Ekalipi words. It has achieved good results for simple words written in Ekalipi. Even though the system is able to synthesize Ekalipi words correctly, there is still a need for a generalized model. As a future work, rules can be defined and the generalized model can be implemented for Ekalipi script and can be tested with the more no users and more no of languages can be added.\n",
            "----------------------------------------\n",
            "Title: EPILEPTIC SEIZURE DETECTION FROM EEG SIGNALS WITH RECURRENT NEURAL NETWORKS BASED CLASSIFICATION MODEL\n",
            "Abstract: Epileptic seizures are a neurological disorder that occurs as a result of sudden and uncontrolled electrical activities of the non-contagious brain. This condition may cause the person to lose normal activities temporarily. Epileptic seizures are a severe disease that affects approximately 60 million people in the world, usually manifested by symptoms such as loss of consciousness, muscle twitching, sudden sensory changes, or behavioural changes [1]. Genetics, brain injury, hormonal fluctuations, infections, or metabolic problems are some of the possible causes of epileptic seizures. Although the severity and duration of the seizure varies from person to person, it is usually very short and rarely reaches a point where it endangers human life. However, such seizures need to be recognized as soon as possible in order to improve the quality of life of individuals and reduce the frequency of seizures. Epileptic seizures are a manageable disease with early diagnosis and appropriate treatment. Recognizing epileptic seizures begins with understanding a person's symptoms and triggering factors. These symptoms may include loss of consciousness, muscle twitches, sudden sensory changes, and behavioural changes. The symptoms of seizures, past medical history, and neurological examinations are essential in the diagnosis process. From past to present, many methods have been developed for the early diagnosis and detection of epileptic seizures [2]. One of these is analyzing the brain's neural activities using electroencephalography (EEG), which helps experts make a diagnosis. Although EEG signals are used as a powerful tool in epileptic seizure recognition, distinguishing the signals within them is both costly and requires highly expert experience. Therefore, this study proposed an automatic classification model for pre-processed EEG signals using Dual-Tree Complex Wavelet Transform (DT-CWT) based on deep learning-based Recurrent Neural Networks (RNN) architecture to assist experts. Compared to classical machine learning methods, deep learning-based models require less manual feature engineering because they perform data automatically thanks to deep networks instead of manually selecting and transforming the data features. These advantages make the model more general and flexible. The proposed model aims to classify EEG signals and detect epileptic seizures effectively and quickly in the early stages.\n",
            "----------------------------------------\n",
            "Title: Credit Scoring Using Ensemble Machine Learning\n",
            "Abstract: In this study, we applied ensemble machine learning to evaluate credit scoring. With decision tree as the baseline algorithm, two popular ensemble learning methods, bagging and boosting, were evaluated across different experiment conditions: using all 14 features, using selected 6 features on Australian credit data form UCI data set. Results showed that in experiments with all features improved performance was achieved by ensemble learning. The best result was obtained in adaboost CART with 14 features, in which the overall correct rate increases from 83.25% to 85.86%.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Models Approach for the Quantitative Classification of Ferricyanide Compound Using Electrochemical Detection with CPE-Fe3O4NPs\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Blockchain and ML-Based Framework for Fast and Cost-Effective Health Insurance Industry Operations\n",
            "Abstract: Health insurance is crucial for each person, bearing in mind the increasing medical costs. COVID-19 has been an eye-opener as to how important it is to have health insurance. Medical emergencies can have a severe emotional and financial impact. Thus, a health insurance policy can help mitigate financial risks in unpredictable circumstances. However, the current insurance system is very expensive, as thousands of people pay the premiums, and very few take the claims. Furthermore, the claim settlement process is excruciatingly long and tiresome. In this article, we focus on establishing a rapid and cost-effective framework for the health insurance market, based on machine learning and blockchain technology. By developing a smart contract, blockchain may eliminate any third-party organizations and make the complete process safer, easier, and more efficient. The contract pays the claim based on the claimant’s documentation. We optimized the premiums using a regression model based on the net amount claimed during the current policy tenure and various other criteria. For anticipating risk, a random forest classifier is used, which aids in the risk-rated premium rebate computation for policyholders for their next term of insurance.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Algorithms for Forest Stand Delineation Using Yearly Sentinel 2MSI Time Series\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Reprogramming Pretrained Language Models for Protein Sequence Representation Learning\n",
            "Abstract: Machine Learning-guided solutions for protein learning tasks have made significant headway in recent years. However, success in scientific discovery tasks is limited by the accessibility of well-defined and labeled in-domain data. To tackle the low-data constraint, recent adaptions of deep learning models pretrained on millions of protein sequences have shown promise; however, the construction of such domain-specific large-scale model is computationally expensive. Here, we propose Representation Learning via Dictionary Learning (R2DL), an end-to-end representation learning framework in which we reprogram deep models for alternate-domain tasks that can perform well on protein property prediction with significantly fewer training samples. R2DL reprograms a pretrained English language model to learn the embeddings of protein sequences, by learning a sparse linear mapping between English and protein sequence vocabulary embeddings. Our model can attain better accuracy and significantly improve the data efficiency by up to $10^5$ times over the baselines set by pretrained and standard supervised methods. To this end, we reprogram an off-the-shelf pre-trained English language transformer and benchmark it on a set of protein physicochemical prediction tasks (secondary structure, stability, homology, stability) as well as on a biomedically relevant set of protein function prediction tasks (antimicrobial, toxicity, antibody affinity).\n",
            "----------------------------------------\n",
            "Title: Paediatric Medicinal Formulation Development: Utilising Human Taste Panels and Incorporating Their Data into Machine Learning Training\n",
            "Abstract: This review paper explores the role of human taste panels and artificial neural networks (ANNs) in taste-masking paediatric drug formulations. Given the ethical, practical, and regulatory challenges of employing children, young adults (18–40) can serve as suitable substitutes due to the similarity in their taste sensitivity. Taste panellists need not be experts in sensory evaluation so long as a reference product is used during evaluation; however, they should be screened for bitterness taste detection thresholds. For a more robust evaluation during the developmental phase, considerations of a scoring system and the calculation of an acceptance value may be beneficial in determining the likelihood of recommending a formulation for further development. On the technological front, artificial neural networks (ANNs) can be exploited in taste-masking optimisation of medicinal formulations as they can model complex relationships between variables and enable predictions not possible previously to optimise product profiles. Machine learning classifiers may therefore tackle the challenge of predicting the bitterness intensity of paediatric formulations. While advancements have been made, further work is needed to identify effective taste-masking techniques for specific drug molecules. Continuous refinement of machine learning algorithms, using human panellist acceptability scores, can aid in enhancing paediatric formulation development and overcoming taste-masking challenges.\n",
            "----------------------------------------\n",
            "Title: Membrane protein contact and structure prediction using co-evolution in conjunction with machine learning\n",
            "Abstract: De novo membrane protein structure prediction is limited to small proteins due to the conformational search space quickly expanding with length. Long-range contacts (24+ amino acid separation)–residue positions distant in sequence, but in close proximity in the structure, are arguably the most effective way to restrict this conformational space. Inverse methods for co-evolutionary analysis predict a global set of position-pair couplings that best explain the observed amino acid co-occurrences, thus distinguishing between evolutionarily explained co-variances and these arising from spurious transitive effects. Here, we show that applying machine learning approaches and custom descriptors improves evolutionary contact prediction accuracy, resulting in improvement of average precision by 6 percentage points for the top 1L non-local contacts. Further, we demonstrate that predicted contacts improve protein folding with BCL::Fold. The mean RMSD100 metric for the top 10 models folded was reduced by an average of 2 Å for a benchmark of 25 membrane proteins.\n",
            "----------------------------------------\n",
            "Title: Construction of Autophagy-Related Gene Classifier for Early Diagnosis, Prognosis and Predicting Immune Microenvironment Features in Sepsis by Machine Learning Algorithms\n",
            "Abstract: Background The immune system plays a fundamental role in the pathophysiology of sepsis, and autophagy and autophagy-related molecules are crucial in innate and adaptive immune responses; however, the potential roles of autophagy-related genes (ARGs) in sepsis are not comprehensively understood. Methods A systematic search was conducted in ArrayExpress and Gene Expression Omnibus (GEO) cohorts from July 2005 to May 2022. Machine learning approaches, including modified Lasso penalized regression, support vector machine, and artificial neural network, were applied to identify hub ARGs, thereby developing a prediction model termed ARG classifier. Diagnostic and prognostic performance of the model was comprehensively analyzed using multi-transcriptome data. Subsequently, we systematically correlated the ARG classifier/hub ARGs with immunological characteristics of multiple aspects, including immune cell infiltration, immune and molecular pathways, cytokine levels, and immune-related genes. Further, we collected clinical specimens to preliminarily investigate ARG expression levels and to assess the diagnostic performance of ARG classifier. Results A total of ten GEO and three ArrayExpress datasets were included in this study. Based on machine learning algorithms, eight key ARGs (ATG4C, BAX, BIRC5, ERBB2, FKBP1B, HIF1A, NCKAP1, and NFKB1) were integrated to establish ARG classifier. The model exhibited excellent diagnostic values (AUC > 0.85) in multiple datasets and multiple points in time and superiorly distinguished sepsis from other critical illnesses. ARG classifier showed significant correlations with clinical characteristics or endotypes and performed better in predicting mortality (AUC = 0.70) than other clinical characteristics. Additionally, the identified hub ARGs were significantly associated with immune cell infiltration (B, T, NK, dendritic, T regulatory, and myeloid-derived suppressor cells), immune and molecular pathways (inflammation-promoting pathways, HLA, cytolytic activity, apoptosis, type-II IFN response, complement and coagulation cascades), levels of several cytokines (PDGFRB, IL-10, IFNG, and TNF), which indicated that ARG classifier/hub ARGs adequately reflected the immune microenvironment during sepsis. Finally, using clinical specimens, the expression levels of key ARGs in patients with sepsis were found to differ significantly from those of control patients, and ARG classifier exhibited superior diagnostic performance, compared to procalcitonin and C-reactive protein. Conclusion Collectively, a diagnostic and prognostic model (ARG classifier) based on eight ARGs was developed which may assist clinicians in diagnosis of sepsis and recognizing patient at high risk to guide personalized treatment. Additionally, the ARG classifier effectively reflected the immune microenvironment diversity of sepsis and may facilitate personalized counseling for specific therapy.\n",
            "----------------------------------------\n",
            "Title: Conspiracy beliefs and COVID-19 guideline adherence in adolescent psychiatric outpatients: the predictive role of adverse childhood experiences\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: On full regression decision trees\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Assessment of Cyber-Physical Intrusion Detection and Classification for Industrial Control Systems\n",
            "Abstract: The increasing interaction of industrial control systems (ICSs) with public networks and digital devices introduces new cyber threats to power systems and other critical infrastructure. Recent cyber-physical attacks such as Stuxnet and Irongate revealed unexpected ICS vulnerabilities and a need for improved security measures. Intrusion detection systems constitute a key security technology, which typically monitors cyber network data for detecting malicious activities. However, a central characteristic of modern ICSs is the increasing interdependency of physical and cyber network processes. Thus, the integration of network and physical process data is seen as a promising approach to improve predictability in real-time intrusion detection for ICSs by accounting for physical constraints and underlying process patterns. This work systematically assesses machine learning-based cyber-physical intrusion detection and multi-class classification through a comparison to its purely network data-based counterpart and evaluation of misclassifications and detection delay. Multiple supervised detection and classification pipelines are applied on a recent cyber-physical dataset, which describes various cyber attacks and physical faults on a generic ICS. A key finding is that the integration of physical process data improves detection and classification of all considered attack types. In addition, it enables simultaneous processing of attacks and faults, paving the way for holistic cross-domain root cause identification.\n",
            "----------------------------------------\n",
            "Title: Context aware Secure Collaborative Business Intelligence\n",
            "Abstract: To enable efficient decision making, professionals need to collaborate with individuals with data being a collected from various sources like distributed clouds for storage, very large databases and social media with authentication and validation is needed for access to relevant roles. Further application of machine learning to deal with unlawful actions. This paper proposes a Context Aware Secure Collaborative Business Intelligence Framework (CASCBF) to address the same. CASCBF is divided into three layers. Multiple sources of data provide different levels of abstraction and granularity of access control to different roles. To control different types of assemblage of data resources from distributed sources and provide right access to users to the edge of the network is a core challenge.\n",
            "----------------------------------------\n",
            "Title: Integration of Cancer Genomics Data for Tree‐based Dimensionality Reduction and Cancer Outcome Prediction\n",
            "Abstract: Accurate outcome prediction is crucial for precision medicine and personalized treatment of cancer. Researchers have found that multi‐dimensional cancer omics studies outperform each data type (mRNA, microRNA, methylation or somatic copy number alteration) study in human disease research. Existing methods leveraging multiple level of molecular data often suffer from various limitations, e. g., heterogeneity, poor robustness or loss of generality. To overcome these limitations, we presented the tree‐based dimensionality reduction approach for the identification of smooth tree graph and developed accurate predictive model for clinical outcome prediction. We demonstrated that 1) Discriminative Dimensionality Reduction via learning a Tree (DDRTree) achieved reduced dimension space tree with statistical significance; 2) Tree based support vector machine (SVM) classifier improved prediction performance of cancer recurrence as compared to t‐test based SVM classifier; 3) Tree based SVM classifier was robust with regard to the different number of multi‐markers; 4) Combining multiple omics data improved prediction performance of cancer recurrence as compared to a single‐omics data; and 5) Tree based SVM classifier achieved similar or better prediction performance when compared to the features from state‐of‐the‐art feature selection methods. Our results demonstrated great potential of the tree‐based dimensionality reduction approach based clinical outcome prediction.\n",
            "----------------------------------------\n",
            "Title: Greedy and Linear Ensembles of Machine Learning Methods Outperform Single Approaches for QSPR Regression Problems\n",
            "Abstract: The application of Machine Learning to cheminformatics is a large and active field of research, but there exist few papers which discuss whether ensembles of different Machine Learning methods can improve upon the performance of their component methodologies. Here we investigated a variety of methods, including kernel‐based, tree, linear, neural networks, and both greedy and linear ensemble methods. These were all tested against a standardised methodology for regression with data relevant to the pharmaceutical development process. This investigation focused on QSPR problems within drug‐like chemical space. We aimed to investigate which methods perform best, and how the ‘wisdom of crowds’ principle can be applied to ensemble predictors. It was found that no single method performs best for all problems, but that a dynamic, well‐structured ensemble predictor would perform very well across the board, usually providing an improvement in performance over the best single method. Its use of weighting factors allows the greedy ensemble to acquire a bigger contribution from the better performing models, and this helps the greedy ensemble generally to outperform the simpler linear ensemble. Choice of data preprocessing methodology was found to be crucial to performance of each method too.\n",
            "----------------------------------------\n",
            "Title: MedalCare-XL: 16,900 healthy and pathological synthetic 12 lead ECGs from electrophysiological simulations\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Jet charge and machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Fully automatic carotid arterial stiffness assessment from ultrasound videos based on machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Novel Approach for Product Recommendation Using Smartphone Sensor Data\n",
            "Abstract: Human Activity-based studies have become an omnipresent research topic in Machine Learning. Considering the countless impacts of human activity on persons' everyday life, we have analyzed the correlation between human activity and their product preferences in our study and proposed that daily human activity could be a metric for product recommendation models. To address this previously unaccounted phenomenon, a new approach is presented in our study that gives real-time recommendations to users by observing their activeness in daily life. However, product recommendation systems mostly believe in ratings, and the purchase behavior of users instead of investigating the precious insights of users' daily activities. But we examined smartphones' GPS sensor data using machine learning algorithms to urge insights from users' daily activeness and proposed a model for predicting the product of interest of the purchasers, based on the activeness of their daily life. Moreover, based on our model, we have introduced a prototype of a real-time recommendation system, especially for the retail shops that rely on users' implicit data from smartphone sensors to form product recommendations. For conducting our study, we developed an android application that—collects embedded smartphone sensor data and can detect objects to provide product recommendations and product details. Experiment shows, that our proffered daily activeness-based recommendation system using smartphone sensor data, performs with a precision of 66%, but it is also a promising performance because it does not use customers' explicit feedback.\n",
            "----------------------------------------\n",
            "Title: Music Recommend System Using Facial Emotion Recognition\n",
            "Abstract: : This paper introduces the implementation of recommending music recommending based on the user emotion recognition. Automatic Emotion Recognition is one of important feature extraction system in advanced deep learning where it can extract the features of face based on Haar Cascades and Convolution Neural Networks (CNN).For extraction of features from face a proper training model model is required for better prediction. In this paper, an automatic face recognition system via deep learning methodologies with music automatic recommendation system to play a music as per the emotion predicted by the machine like (Happy, Angry, Surprise, Sad etc). As per the emotion music will be recommended.Facial expressions are captured by a web camera in our device. Here we use CNN algorithm for the recognition of the feature from the captured image. Thus, the proposed system is based on the emotion detection the music will be recommended to the customer .\n",
            "----------------------------------------\n",
            "Title: Automatic robust estimation for exponential smoothing: Perspectives from statistics and machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: P24 Interpretable Machine Learning Prediction of Treatment Switching Among Patients with Multiple Sclerosis: An Electronic Medical Records Analysis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Research on detection method of moldy tobacco leaf raw materials based on hyperspectral and machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Application of Machine Learning Algorithm Based on Neural Network Technology\n",
            "Abstract: Neural networks have strong characteristics for processing data and information. At the same time, the current computer technology is also very advanced, and many kinds of very powerful information technologies have been developed under the promotion and promotion of modern science and technology. Therefore, relevant personnel will carry out advanced technology and neural network structure methods. Fusion, and then an artificial neural network was established on this basis. In a broad sense, machine learning refers to how to enable a machine to acquire relevant knowledge through autonomous learning, and the purpose is to enable the machine to have relevant skills similar to what people need to acquire knowledge. The research in this article aims to explore the machine learning algorithms based on neural network technology, and through literature research methods, case analysis methods, etc., to have an in-depth understanding of machine learning algorithms in neural network technology, and then through the analysis of machine learning algorithms in neural network technology The learning advantage and its influencing factors are designed based on the machine learning algorithm in the neural network and experimented. Experimental results show that LSTM performs well in replication tasks, and the performance of LSTM even far exceeds that of NTM, but the performance of LSTM in addition and multiplication tasks is much lower than that of NTM. Although the accuracy of NTM on the test set is higher than that of LSTM and RNN, the performance of the model is still relatively poor.\n",
            "----------------------------------------\n",
            "Title: Intelligent Citizenship Identity Through Family Pedigree Using Graph-Signature Based Random-Forest Model\n",
            "Abstract: There has been a global upsurge of interest in the topic of citizenship identity over the past decades, specifically in the world dominated by profound insecurity, inequalities, proliferation of identities, and rise of identity politics,engendered by capitalism. However finding effective solution to these problems has been rendered difficult. To alleviate these problems, this paper presents an analytical Machine learning model that suitably combined the graph signature with random forest techniques. This study presents the design and realization of a novel Intelligent Citizenship Identity through family pedigree using Graph Signature based random forest (GSB-RF) model. The study also showcases the development of a novel graph signature technique referred to as Canonical Code Signature(CCS) method. The CCS method is used at the pre-processing stage of the identification process to build signature for any given tuple. Performance comparisim between the present system and the baseline techniques which includes: the K-Nearest Neighbour and the traditional Random Forest shows that the present system outperformed the baseline method studied. The proposed system shows capability to perform continuous re-identification of Citizens based on their family pedigree with ability to select best sample with low computational complexity, high identification accuracy and speed. Our experimental result shows that the precision rate and identification quality of our system in most cases are equal to or greater than 70%. Therefore, the proposed Citizenship Identification machine is capable of providing usable, consistent, efficient, faster and accurate identification, to the users, security agents, government agents and institutions on-line, real-time and at any-time.Keywords- Canonical code,Citizenship Identity, Family pedigree,Graph-Signature,Machine learning, Random-forest\n",
            "----------------------------------------\n",
            "Title: Machine Learning in the Hands of a Malicious Adversary: A Near Future If Not Reality\n",
            " 1\n",
            "Abstract: Machine learning and artificial intelligence are being adopted to varying applications for automation and flexibility. Cyber security to be no different, researchers and engineers have been investigating the use of data‐driven technologies to harden the security of cyberinfrastructure and the possibility of attackers exploiting vulnerabilities in such technology (e.g. adversarial machine learning). However, not much work has investigated how attackers might try to take advantage of machine learning and AI technology against us. This chapter discusses the potential advances in targeted attacks through the utilization of machine learning techniques. In this chapter, we introduce a new concept of AI‐driven malware which advances already sophisticated cyber threats (i.e. advanced targeted attacks) that are on the rise. Furthermore, we demonstrate our prototype AI‐driven malware, built on top of a set of statistical learning technologies, on two distinct cyber‐physical systems (i.e. the Raven‐II surgical robot and a building automation system). Our experimental results demonstrate that with the support of AI technology, malware can mimic human attackers in deriving attack payloads that are custom to the target system and in determining the most opportune time to trigger the attack payload so to maximize the chance of success in realizing the malicious intent. No public records report a real threat driven by machine learning models. However, such advanced malware might already exist and simply remain undetected. We hope this chapter motivates further research on advanced offensive technologies, not to favor the adversaries, but to know them and be prepared.\n",
            "----------------------------------------\n",
            "Title: Incapable of identifying suspicious records in CTG data using ANN based machine learning techniques\n",
            "Abstract: Cardiotocography (CTG) is a simultaneous recording of fetal heart rate (FHR) and uterine contractions (UC). It is one of the most common diagnostic techniques to evaluate maternal and fetal well-being during pregnancy and before delivery. By observing the Cardiotocography trace patterns doctors can understand the state of the fetus. We implement a model based CTG data classification system using a supervised artificial neural network (ANN) and support vector machine (SVM) which can classify the CTG data based on its training data. The performance neural network based classification model has been compared with the most commonly used unsupervised clustering methods Fuzzy C-mean and k-mean clustering and supervised clustering method SVM classification. According to the arrived results, the performance of the supervised machine learning based classification (ANN) approach provided significant performance than other compared unsupervised clustering methods and supervised SVM classification method. We used Precision, Recall, F-Measure and Rand Index as the metric to evaluate the performance. Even though the traditional clustering methods can identify the Normal CTG patterns, they were incapable of finding Suspicious and Pathologic patterns and the SVM based classifier provided good performance, it was absolutely incapable of identifying a single suspicious record. It was found that, the ANN based classifier was capable of identifying Normal, Suspicious and Pathologic condition, from the nature of CTG data with very good accuracy. The important finding in this paper is Even though SVM is a well proven technique for classification, it was incapable of identifying Suspicious Records in Cardiotocogram Data - but ANN did considerably good classification of Suspicious Records.\n",
            "----------------------------------------\n",
            "Title: Anomaly detection in electronic invoice systems based on machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Progress continues in prediction of the response to treatment of RA\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Application of quantum computing to a linear non-Gaussian acyclic model for novel medical knowledge discovery\n",
            "Abstract: Recently, the utilization of real-world medical data collected from clinical sites has been attracting attention. Especially as the number of variables in real-world medical data increases, causal discovery becomes more and more effective. On the other hand, it is necessary to develop new causal discovery algorithms suitable for small data sets for situations where sample sizes are insufficient to detect reasonable causal relationships, such as rare diseases and emerging infectious diseases. This study aims to develop a new causal discovery algorithm suitable for a small number of real-world medical data using quantum computing, one of the emerging information technologies attracting attention for its application in machine learning. In this study, a new algorithm that applies the quantum kernel to a linear non-Gaussian acyclic model, one of the causal discovery algorithms, is developed. Experiments on several artificial data sets showed that the new algorithm proposed in this study was more accurate than existing methods with the Gaussian kernel under various conditions in the low-data regime. When the new algorithm was applied to real-world medical data, a case was confirmed in which the causal structure could be correctly estimated even when the amount of data was small, which was not possible with existing methods. Furthermore, the possibility of implementing the new algorithm on real quantum hardware was discussed. This study suggests that the new proposed algorithm using quantum computing might be a good choice among the causal discovery algorithms in the low-data regime for novel medical knowledge discovery.\n",
            "----------------------------------------\n",
            "Title: Environmental chemistry 2019: Effect of acoustic environmental pollution (Aep) on students health implication and learning outcomes in science-Neji\n",
            "Abstract: The study investigated the effect of acoustic pollution (AEP) on students’ health and learning outcomes in the Department of Science Education, University of Calabar, Nigeria. Acoustic pollution is the propagation of noise or sound with harmful effect on the activities on students or human being living in an environment. The sources of acoustic environmental pollution worldwide are vehicles, machines and animals. The design adopted for this study is ex-post factor research design. A total of two hundred under-graduates students in the department of Science Education, University of calabar form the sample of the study. The reliability of the instrument was ascertained using KudarRichardson’s formular 21 which yielded a reliability coefficient of 0.87 which is high enough to be accepted for the research. Data obtained was analyzed using independent t-test statistics. Findings revealed that there is a negative effect of acoustic (sound) pollution on students’ academic performance in the university of calabar. Based on the finding, it is therefore recommended that appropriate control measures should be put in place to checkmate the activities of acoustic pollutants which are capable of affecting students’ learning outcomes.\n",
            "----------------------------------------\n",
            "Title: An opposition-based social spider optimization for feature selection\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Evaluating the impact of generative adversarial models on the performance of anomaly intrusion detection\n",
            "Abstract: With the increasing rate and types of cyber attacks against information systems and communication infrastructures, many tools are needed to detect and mitigate against such attacks, for example, Intrusion Detection Systems (IDSs). Unfortunately, traditional Signature‐based IDSs (SIDSs) perform poorly against previously unseen adversarial attacks. Anomaly‐based IDSs (AIDSs) use Machine Learning (ML) and Deep Learning (DL) approaches to overcome these limitations. However, AIDS performance can be poor when trained on imbalanced datasets. To address the challenge of AIDS performance caused by these unbalanced training datasets, generative adversarial models are proposed to obtain adversarial attacks from one side and analyse their quality from another. According to extensive usage and reliability criteria for generative adversarial models in different disciplines, Generative Adversarial Networks (GANs), Bidirectional GAN (BiGAN), and Wasserstein GAN (WGAN) are employed to serve AIDS. The authors have extensively assessed their abilities and robustness to deliver high‐quality attacks for AIDS. AIDSs are constructed, trained, and tuned based on these models to measure their impacts. The authors have employed two datasets: NSL‐KDD and CICIDS‐2017 for generalisation purposes, where ML and DL approaches are utilised to implement AIDSs. Their results show that the WGAN model outperformed GANs and BiGAN models in binary and multiclass classifications for both datasets.\n",
            "----------------------------------------\n",
            "Title: Air Quality Prediction using Machine Learning\n",
            "Abstract: - The main basis of human survival is Air. The Air Quality Index is the value that qualitatively describes the condition of air quality. The greater the Air Quality Index, the more threatening risk to human health and environment. In Sri Lanka, poor air quality is a huge concern, especially in cities like Colombo and Kandy. Accurate Air Quality prediction will minimize health issues that can occur due to air pollution. This research has attempted to identify the best-suited machine learning algorithm-based approach to predict accurate air quality based on PM2.5 concentration in Colombo. In order to identify the most influenced air pollution concentrations for the air quality prediction purpose, correlation analysis was conducted. In this research, PM2.5 was predicted in Colombo city using 4 related air pollution concentrations including SO2 concentration, NO2 concentration, PM2.5 concentration & PM10 concentration. In order to get higher prediction accuracy, the gathered dataset was pre-processed by prediction beforehand. The prediction model trained and tested using machine learning algorithms such as KNN, Multiple Linear Regression, Support Vector Machines, and Random Forest. Multiple Regression was identified as the most suited prediction model which was able to gain 94% higher accuracy.\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Enabled Intelligent Fiber-Optic Communications: Major Obstacles and the Way Forward\n",
            "Abstract: Machine learning (ML) has achieved phenomenal success in revolutionizing a number of science and engineering disciplines over the last decade. Naturally, it is also being reckoned as a powerful technology to transform future fiber-optic communication systems. Over the past few years, we have seen extensive research efforts by both academia and industry to assimilate and gain from ML paradigm in several aspects of optical communications and networking. However, despite years of rigorous research, ML has not yet gained broad acceptance in commercial fiber-optic networks. In this article, we identify major common factors which are currently hindering widespread adoption of ML in practical optical networks. As ML-based methods are inherently data driven, we particularly highlight critical data-related issues as well as intrinsic limitations of the ML algorithms. Taking two important use-cases, i.e., quality-of-transmission estimation, and proactive fault detection and management as examples, we elucidate how these limiting factors shrink the deployment prospects of ML-based solutions. We also briefly discuss main challenges faced by ML-assisted methods in seven other key areas of fiber-optic communications. Finally, we suggest some useful strategies that can help alleviate existing obstacles, thus paving the way for vast deployment of ML -powered tools in real optical network infrastructures.\n",
            "----------------------------------------\n",
            "Title: Multimodal Building of Monolingual Dictionaries for Machine Translation by Non-Expert Users\n",
            "Abstract: This paper explores a new approach to help non-expert users with no background in linguistics to add new words to a monolingual dictionary in a rule-based machine translation system. Our method aims at obtaining the correct paradigm which explains not only the particular surface form introduced by the user, but also the rest of inﬂected forms of the word. An initial set of potential paradigms is automatically obtained and then interactively reﬁned by the user with a novel graphical interface through active machine learning. We show the promising results of experiments performed with a Spanish monolingual dictionary.\n",
            "----------------------------------------\n",
            "Title: Real-Time Data Transformation in Connected Vehicles: A Systematic Analysis of Architectures, Methods, and Applications\n",
            "Abstract: The emerging landscape of connected vehicles has introduced unprecedented challenges in processing and utilizing vast streams of real-time data. This article presents a comprehensive framework for real-time data transformation in connected vehicle environments, addressing the critical aspects of data processing architectures, analytical methodologies, and practical implementations. The article examines the integration of edge computing, cloud-based solutions, and hybrid architectures to optimize data transformation workflows while minimizing latency and bandwidth constraints. The article analyzes various data types generated by connected vehicles, including telemetry, diagnostics, and user-generated content, and explores their transformation requirements for enabling advanced functionalities such as predictive maintenance, traffic optimization, and enhanced driver assistance systems. Through multiple industry case studies, the article demonstrates the practical application of proposed frameworks and their impact on operational efficiency, safety metrics, and overall vehicle performance. Our findings highlight the significance of balanced architectural choices, the role of machine learning in data transformation processes, and the importance of addressing security and scalability challenges. This article contributes to the growing body of knowledge in connected vehicle technologies while providing practical insights for automotive industry practitioners implementing real-time data transformation solutions.\n",
            "----------------------------------------\n",
            "Title: A Robust State of Charge Estimator Based on the Fourier Neural Operator for xEV Batteries\n",
            "Abstract: \n",
            " This paper proposes a new state of charge estimation method inspired by the Fourier neural operator, which is capable of learning entire nonlinear dynamics of any partial differential equations. The complicated nonlinear dynamics of battery parameters is well captured by a flexible, efficient, and expressive structure of the Fourier neural operators. Extensive numerical experiments and tests with publicly available data as well as with our own data are conducted to demonstrate the noise-tolerance, time window independence, temperature generalization, and transfer learning features of the proposed method. Our proposed method performs better than the other methods considered previously its performances is competitive with any state-of-the-art machine learning-based methods.\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Based Classification of Human Behaviors and Falls in Restroom via Dual Doppler Radar Measurements\n",
            "Abstract: This study presents a radar-based remote measurement system for classification of human behaviors and falls in restrooms without privacy invasion. Our system uses a dual Doppler radar mounted onto a restroom ceiling and wall. Machine learning methods, including the convolutional neural network (CNN), long short-term memory, support vector machine, and random forest methods, are applied to the Doppler radar data to verify the model’s efficiency and features. Experimental results from 21 participants demonstrated the accurate classification of eight realistic behaviors, including falling. Using the Doppler spectrograms (time–velocity distribution) as the inputs, CNN showed the best results with an overall classification accuracy of 95.6% and 100% fall classification accuracy. We confirmed that these accuracies were better than those achieved by conventional restroom monitoring techniques using thermal sensors and radars. Furthermore, the comparison results of various machine learning methods and cases using each radar’s data show that the higher-order derivative parameters of acceleration and jerk, and the motion information in the horizontal direction are the efficient features for behavior classification in a restroom. These findings indicate that daily restroom monitoring using the proposed radar system accurately recognizes human behaviors and allows early detection of fall accidents.\n",
            "----------------------------------------\n",
            "Title: Boosting H→bb¯$$ H\\to b\\overline{b} $$ with machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Analysis of Network Intrusion Detection via Explainable Artificial Intelligence: Applications with SHAP and LIME\n",
            "Abstract: The rise of complex cyber threats in recent years has prompted the creation of Network Intrusion Detection Systems (NIDS). Nevertheless, the traditional NIDS has issues in capturing sophisticated attacks because cyber-attacks are so dynamic. In this study, it is investigated the utility of using Explainable Artificial Intelligence (XAI) methods in the context of Machine Learning models for improved transparency and effectiveness in NIDS. The performance was benchmarked for models like XGBoost, Random Forest, Support Vector Machine using SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME). The CICIDS2017 dataset, which includes various types of attacks such as DoS/DDoS, Port Scanning, and Brute Force, was balanced and subjected to comprehensive preprocessing and feature engineering steps. Results confirm that with 100% across the board accuracy, precision, recall and F1 scores for all classes stacking model shows superior performance. XAI methods provide crucial insights into the model’s decision-making process, highlighting features such as Destination Port and Packet Length as key factors. This transparency is critical for cyber security professionals to understand better about threats and how to deal with them. The results demonstrate the feasibility of NIDS achieving both high accuracy and explainability, imparting more trustworthy networking information systems.\n",
            "----------------------------------------\n",
            "Title: Rapid identification of breast cancer subtypes using micro-FTIR and machine learning methods.\n",
            "Abstract: Breast cancer (BC) molecular subtypes diagnosis involves improving clinical uptake by Fourier transform infrared (FTIR) spectroscopic imaging, which is a non-destructive and powerful technique, enabling label free extraction of biochemical information towards prognostic stratification and evaluation of cell functionality. However, methods of measurements of samples demand a long time to achieve high quality images, making its clinical use impractical because of the data acquisition speed, poor signal to noise ratio, and deficiency of optimized computational framework procedures. To address those challenges, machine learning (ML) tools can facilitate obtaining an accurate classification of BC subtypes with high actionability and accuracy. Here, we propose a ML-algorithm-based method to distinguish computationally BC cell lines. The method is developed by coupling the K-neighbors classifier (KNN) with neighborhood components analysis (NCA), and hence, the NCA-KNN method enables to identify BC subtypes without increasing model size as well as adding additional computational parameters. By incorporating FTIR imaging data, we show that classification accuracy, specificity, and sensitivity improve, respectively, 97.5%, 96.3%, and 98.2%, even at very low co-added scans and short acquisition times. Moreover, a clear distinctive accuracy (up to 9 %) difference of our proposed method (NCA-KNN) was obtained in comparison with the second best supervised support vector machine model. Our results suggest a key diagnostic NCA-KNN method for BC subtypes classification that may translate to advancement of its consolidation in subtype-associated therapeutics.\n",
            "----------------------------------------\n",
            "Title: Machine Learning in Context of IoT/Edge Devices and LoLiPoP-IoT Project*\n",
            "Abstract: Machine learning models are traditionally deployed in the cloud or on centralized servers to leverage their computing resources. However, such a deployment may reduce privacy, introduce extra latency, consume more power, etc., and subsequently negatively impact properties of an application that typically runs on a battery-operated device used to communicate via a wireless network. To minimize the negative impact, it is necessary to deploy a model directly to such a device to minimize data transfer energy and run the model closer to the data source and, application and its environment. However, this kind of deployment is a challenging task due to the very limited resources available in such devices and applications. Many people and companies have tackled this challenging problem and proposed different ways and means to solve it. Having defined the problem and our area of interest, the paper provides an overview of representative applications, methods and means, including libraries, frameworks, datasets, devices etc. It then presents a typical deployment process workflow in the context of resource-constrained devices. Finally, it sums representative results for popular resource-constrained devices (e.g., Arduino, ARM Cortex-M, ESP32, nRF5x, Nvidia Jetson, Raspberry Pi) to demonstrate how various phenomena (e.g., model type, setting, quantization) affect model performance (e.g., accuracy, loss), metrics (e.g., ROC AUC, F1 scores) and device performance (e.g., feature and inference processing time, memory usage).\n",
            "----------------------------------------\n",
            "Title: Clustering plasma concentration-time curves: applications of unsupervised learning in pharmacogenomics.\n",
            "Abstract: Pharmaceutical researchers are continually searching for techniques to improve both drug development processes and patient outcomes. An area of recent interest is the potential for machine learning (ML) applications within pharmacology. One such application not yet given close study is the unsupervised clustering of plasma concentration-time curves, hereafter, pharmacokinetic (PK) curves. In this paper, we present our findings on how to cluster PK curves by their similarity. Specifically, we find clustering to be effective at identifying similar-shaped PK curves and informative for understanding patterns within each cluster of PK curves. Because PK curves are time series data objects, our approach utilizes the extensive body of research related to the clustering of time series data as a starting point. As such, we examine many dissimilarity measures between time series data objects to find those most suitable for PK curves. We identify Euclidean distance as generally most appropriate for clustering PK curves, and we further show that dynamic time warping, Fréchet, and structure-based measures of dissimilarity like correlation may produce unexpected results. As an illustration, we apply these methods in a case study with 250 PK curves used in a previous pharmacogenomic study. Our case study finds that an unsupervised ML clustering with Euclidean distance, without any subject genetic information, is able to independently validate the same conclusions as the reference pharmacogenomic results. To our knowledge, this is the first such demonstration. Further, the case study demonstrates how the clustering of PK curves may generate insights that could be difficult to perceive solely with population level summary statistics of PK metrics.\n",
            "----------------------------------------\n",
            "Title: Find who is doing social good: using machine learning to predict corporate social responsibility performance\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Detecting Irregular Patterns in IoT Streaming Data for Fall Detection\n",
            "Abstract: Detecting patterns in real time streaming data has been an interesting and challenging data analytics problem. With the proliferation of a variety of sensor devices, real-time analytics of data from the Internet of Things (IoT) to learn regular and irregular patterns has become an important machine learning problem to enable predictive analytics for automated notification and decision support. In this work, we address the problem of learning an irregular human activity pattern, fall, from streaming IoT data from wearable sensors. We present a deep neural network model for detecting fall based on accelerometer data giving 98.75 percent accuracy using an online physical activity monitoring dataset called “MobiAct”, which was published by Vavoulas et al. The initial model was developed using IBM Watson studio and then later transferred and deployed on IBM Cloud with the streaming analytics service supported by IBM Streams for monitoring real-time IoT data. We also present the systems architecture of the real-time fall detection framework that we intend to use with Mbientlab's wearable health monitoring sensors for real time patient monitoring at retirement homes or rehabilitation clinics.\n",
            "----------------------------------------\n",
            "Title: Machine learning algorithm for predict the in-hospital mortality in critically ill patients with congestive heart failure combined with chronic kidney disease\n",
            "Abstract: Abstract Background The objective of this study was to develop and validate a machine learning (ML) model for predict in-hospital mortality among critically ill patients with congestive heart failure (CHF) combined with chronic kidney disease (CKD). Methods After employing least absolute shrinkage and selection operator regression for feature selection, six distinct methodologies were employed in the construction of the model. The selection of the optimal model was based on the area under the curve (AUC). Furthermore, the interpretation of the chosen model was facilitated through the utilization of SHapley Additive exPlanation (SHAP) values and the Local Interpretable Model-Agnostic Explanations (LIME) algorithm. Results This study collected data and enrolled 5041 patients on CHF combined with CKD from 2008 to 2019, utilizing the Medical Information Mart for Intensive Care Unit. After selection, 22 of the 47 variables collected post-intensive care unit admission were identified as mortality-associated and subsequently utilized in the development of ML models. Among the six models generated, the eXtreme Gradient Boosting (XGBoost) model demonstrated the highest AUC at 0.837. Notably, the SHAP values highlighted the sequential organ failure assessment score, age, simplified acute physiology score II, and urine output as the four most influential variables in the XGBoost model. In addition, the LIME algorithm explains the individualized predictions. Conclusions In conclusion, our study accomplished the successful development and validation of ML models for predicting in-hospital mortality in critically ill patients with CHF combined with CKD. Notably, the XGBoost model emerged as the most efficacious among all the ML models employed.\n",
            "----------------------------------------\n",
            "Title: Face Recognition through Machine Learning of Periocular region\n",
            "Abstract: - Facial acknowledgment is a biometric software that is able to check an individual from an advanced picture or video outline by contrasting and investigating designs dependent on the individual's facial forms. Structuring the face acknowledgment frameworks that are invariant to aging is difficult as biometric frameworks endures severely because of subjects aging. None of the current strategies are keeping pace with human capacity in perceiving the comparability crosswise over two appearances .In this paper age invariant highlights are determined utilizing Local binary patterns and Gaussian naive Bayes is utilized a classifier for generating matching score. The experimentation is done on the FGNET database and the experimentation results show an acknowledgment precision of 96% with naive Bayes.\n",
            "----------------------------------------\n",
            "Title: Detektion von Blattlausbefall in Salatkulturen durch Messungen der spektralen Reflektanz\n",
            "Abstract: Tobias Wilhelm Tholen a , Laura Verena Junker a , Uwe Rascher a , Hannah Jaenicke b , Onno Muller a a Forschungszentrum Julich GmbH, Institut fur Bio- und Geowissenschaften, Pflanzenwissenschaften (IBG-2), 52428 Julich b Kompetenzzentrum Gartenbau (KOGA), Campus Klein-Altendorf 2, 53359 Rheinbach T.Tholen@fz-juelich.de L.Junker@fz-juelich.de U.Rascher@fz-juelich.de H.Jaenicke@uni-bonn.de O.Muller@fz-juelich.de Blattlause gelten als Hauptschadlinge in Salatkulturen. Bei der Salatproduktion muss besonderes auf die Vermeidung von Blattlausbefall geachtet werden, um den hohen Qualitatsanforderungen des Marktes gerecht zu werden. Aus diesem Grund applizieren Landwirte Insektizide, um ihre Kultur, insbesondere verzehrfertige Ware befallsfrei zu halten. Da Blattlause zeitlich und raumlich stark variabel auftreten und zusatzlich die Starke des Befalls von Pflanze zu Pflanze variiert, werden bei jeder Applikation auch nicht befallene Salatpflanzen behandelt. Vor diesem Hintergrund liegt es Nahe eine Methode zu entwickeln, die befallene von gesunden Salaten unterscheiden kann, um dadurch eine selektive Applikation von Pflanzenschutzmitteln zu ermoglichen. Fur Nutzpflanzen wie Weizen und Sojabohnen konnte bereits gezeigt werden, dass sich die spektrale Reflektanz blattlausbefallener Pflanzen gegenuber gesunden Pflanzen verandert. Um diese These fur Salatpflanzen zu uberprufen, haben wir in diesem Sommer die spektrale Reflektanz von befallenen und gesunden Salatpflanzen in einem Freilandversuch unter Praxisbedingungen und einem Gewachshausversuch inklusive hochauflosender hyperspektral bildgebender Verfahren unter Laborbedingungen gemessen. Im ersten Freilandversuch unter Praxisbedingungen wurden die Mini-Romana Salatsorten ( L.sativa) Thimble und Xiumara untersucht. Die Pflanzen wurden einmal wochentlich uber einen Zeitraum von 3-4 Wochen gemessen. In der Regel trat bei diesem Freilandversuch ein Mischbefall verschiedener Blattlausarten auf, wobei die Arten Nassonovia ribisnigri, Myzus persicae und Macrosiphum euphorbiae am haufigsten auftraten. Beim Laborversuch mit bildgebendem Verfahren wurden die Kopfsalatsorten ( L.sativa) Briweri und Analena untersucht. Anschliesend wurde die spektrale Reflektanz der Pflanzen uber einen Zeitraum von 3-4 Wochen zweimal wochentlich erfasst. Der bildgebende Laborversuch wurde mit der Blattlausart Nassonovia ribisnigri und einem Mischbefall der im Feldversuch vorkommenden Blattlausarten durchgefuhrt. Bei allen Versuchen wurde nach jeder Messung der Blattlausbefall quantifiziert. Aktuell werden die erhobenen Daten mit Hilfe von Machine-Learning Verfahren ausgewertet. Ziel dieser Auswertung ist die Entwicklung eines Klassifikators, der befallene von gesunden Salaten auf Grund ihrer spektralen Reflektanz unterscheiden kann.\n",
            "----------------------------------------\n",
            "Title: An efficient model-based branch-and-price algorithm for unrelated-parallel machine batching and scheduling problems\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Air Quality Index Prediction in Realtime Using SVM based model in Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Theoretical Aspects of Evolutionary Computing\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Methods for Forecasting Nonlinear Non-stationary Processes in Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: FIPSER: Improving Fairness Testing of DNN by Seed Prioritization\n",
            "Abstract: As a rapidly evolving AI technology, deep neural networks are becoming increasingly integrated into human society, yet raising concerns about fairness issues. Previous studies have proposed a metric called causal fairness to measure the fairness of machine learning models and proposed some search algorithms to mine individual discrimination instance pairs (IDIPs). Fairness issues can be alleviated by retraining models with corrected IDIPs. However, the number of samples that are used as seeds for these methods is often limited due to the pursuit of efficiency. In addition, the quantity of IDIPs generated on different seeds varies, so it makes sense to select appropriate samples as seeds, which has not been sufficiently considered in past studies. In this paper, we study the imbalance in IDIP quantities for various datasets and sensitive attributes, highlighting the need for selecting and ranking seed samples. Then, we proposed FIPSER, a feature importance and perturbation potential-based seed prioritization method. Our experimental results show that, on average, when applied to the current state-of-the-art method of IDIP mining, FIPSER can improve its effectiveness by 45% and efficiency by 11%.CCS CONCEPTS• Computing methodologies → Artificial intelligence; • Software and its engineering;\n",
            "----------------------------------------\n",
            "Title: From organs to algorithms: Redefining cancer classification in the age of artificial intelligence\n",
            "Abstract: Abstract Traditional cancer classification based on organ of origin and histology is increasingly at odds with precision oncology. Tumors in different organs can share molecular features, while those in the same organ can be heterogeneous. This disconnect impacts clinical trials, drug development, and patient care. Recent advances in artificial intelligence (AI), particularly machine learning and deep learning, offer promising avenues for reclassifying cancers through comprehensive integration of molecular, histopathological, imaging, and clinical characteristics. AI‐driven approaches have the potential to reveal novel cancer subtypes, identify new prognostic variables, and guide more precise treatment strategies for improving patient outcomes.\n",
            "----------------------------------------\n",
            "Title: Efficient Algorithms for Large-scale Generalized Eigenvector Computation and Canonical Correlation Analysis\n",
            "Abstract: This paper considers the problem of canonical-correlation analysis (CCA) (Hotelling, 1936) and, more broadly, the generalized eigenvector problem for a pair of symmetric matrices. These are two fundamental problems in data analysis and scientific computing with numerous applications in machine learning and statistics (Shi and Malik, 2000; Hardoon et al., 2004; Witten et al., 2009). \n",
            "We provide simple iterative algorithms, with improved runtimes, for solving these problems that are globally linearly convergent with moderate dependencies on the condition numbers and eigenvalue gaps of the matrices involved. \n",
            "We obtain our results by reducing CCA to the top-$k$ generalized eigenvector problem. We solve this problem through a general framework that simply requires black box access to an approximate linear system solver. Instantiating this framework with accelerated gradient descent we obtain a running time of $O(\\frac{z k \\sqrt{\\kappa}}{\\rho} \\log(1/\\epsilon) \\log \\left(k\\kappa/\\rho\\right))$ where $z$ is the total number of nonzero entries, $\\kappa$ is the condition number and $\\rho$ is the relative eigenvalue gap of the appropriate matrices. \n",
            "Our algorithm is linear in the input size and the number of components $k$ up to a $\\log(k)$ factor. This is essential for handling large-scale matrices that appear in practice. To the best of our knowledge this is the first such algorithm with global linear convergence. We hope that our results prompt further research and ultimately improve the practical running time for performing these important data analysis procedures on large data sets.\n",
            "----------------------------------------\n",
            "Title: Machine Learning for Science: Mathematics at the Interface of Data-driven and Mechanistic Modelling\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Improving Face Recognition Robustness: An Innovative Approach Using Tchebichef Hahn Moments and CNNs\n",
            "Abstract: In recent years, face recognition technology has experienced significant advancements driven by improvements in computer vision and machine learning. This paper introduces a novel approach to face recognition by leveraging Tchebichef-Hahn (TH) orthogonal moments in conjunction with Convolutional Neural Networks (CNNs) named THCNN. The proposed method aims to enhance the accuracy and robustness of face recognition systems, especially under varying noise conditions. Experimental results demonstrate that the integration of TH moments with CNNs model provides superior performance across multiple noise types, achieving the highest accuracies of 93.52%, 92.31%, and 95.41%, for salt and pepper, Gaussian, and speckle noise, respectively. This approach not only improves the recognition robustness but also demonstrates that Tchebichef Hahn moments lower orders could be more efficient in capturing relevant features.\n",
            "----------------------------------------\n",
            "Title: Privacy-hardened and hallucination-resistant synthetic data generation with logic-solvers\n",
            "Abstract: Machine-generated data is a valuable resource for training Artificial Intelligence algorithms, evaluating rare workflows, and sharing data under stricter data legislations. The challenge is to generate data that is accurate and private. Current statistical and deep learning methods struggle with large data volumes, are prone to hallucinating scenarios incompatible with reality, and seldom quantify privacy meaningfully. Here we introduce Genomator, a logic solving approach (SAT solving), which efficiently produces private and realistic representations of the original data. We demonstrate the method on genomic data, which arguably is the most complex and private information. Synthetic genomes hold great potential for balancing underrepresented populations in medical research and advancing global data exchange. We benchmark Genomator against state-of-the-art methodologies (Markov generation, Restricted Boltzmann Machine, Generative Adversarial Network and Conditional Restricted Boltzmann Machines), demonstrating an 84-93% accuracy improvement and 95-98% higher privacy. Genomator is also 1000-1600 times more efficient, making it the only tested method that scales to whole genomes. We show the universal trade-off between privacy and accuracy, and use Genomator's tuning capability to cater to all applications along the spectrum, from provable private representations of sensitive cohorts, to datasets with indistinguishable pharmacogenomic profiles. Demonstrating the production-scale generation of tuneable synthetic data can increase trust and pave the way into the clinic.\n",
            "----------------------------------------\n",
            "Title: Drawing Illustration Using Android Studio\n",
            "Abstract: This building is implemented with Android and machine learning in mind. We can doodle or sketch on our phones. Change a pixel at a nice spot. In this project, the programme has a variety of specialised brushes and brush sets to help you with your illustration, and it is fully customisable, allowing users to design their own brushes. Choose a shading utilizing various shading models, e.g., RGB, HSV, or by utilizing a shading eye dropper. Also, color pallet generator victimization machine learning makes it simple to form a color palette from any image, therefore it will come back the color palette as the second array of colors. Which follows the k- mean bunch algorithmic program? Keywords: Drawing App, canvas, Android App, colors\n",
            "----------------------------------------\n",
            "Title: Towards understanding and synthesis of contact-rich anthropomorphic motions through interactive cyber-physical human\n",
            "Abstract: This article presents perspective on the research challenge of understanding and synthesizing anthropomorphic whole-body contact motions through a platform called “interactive cyber-physical human (iCPH)” for data collection and augmentation. The iCPH platform combines humanoid robots as “physical twins” of human and “digital twins” that simulates humans and robots in cyber-space. Several critical research topics are introduced to address this challenge by leveraging the advanced model-based analysis together with data-driven learning to exploit collected data from the integrated platform of iCPH. Definition of general description is identified as the first topic as a common basis of contact motions compatible to both humans and humanoids. Then, we set continual learning of a feasible contact motion network as the second challenge by benefiting from model-based approach and machine learning bridged by the efficient analytical gradient computation developed by the author and his collaborators. The final target is to establish a high-level symbolic system allowing automatic understanding and generation of contact motions in unexperienced environments. The proposed approaches are still under investigation, and the author expects that this article triggers discussions and further collaborations from different research communities, including robotics, artificial intelligence, neuroscience, and biomechanics.\n",
            "----------------------------------------\n",
            "Title: Extraction of knowledge from Artificial Neural Networks using Symbolic Machine Learning Systems and Genetic Algorithm\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Estimation of Machining Time for CNC Manufacturing Using Neural Computing\n",
            "Abstract: An approach to solving the problem of machining time estimation in production of complex products within CNC machining systems is presented in the paper. Heuristic analysis of the process is used to define the attributes of influence to machining time. For the problem of estimating machining time the following „Neural Computing techniques“ are used: Back-Propagation Neural Network, Modular Neural Network, Radial Basis Function Neural Network, General Regression Neural Network and Self-Organizing Map Neural Network. Real data from the technological process obtained by measuring are used to design the model used in investigation. The established model is used to carry out the investigation aimed at learning and testing different algorithms of neural networks and the results are given by the RMS error. The best results in the validation phase were achieved by Modular Neural Network ( RMSE : 1.89 %) and Back-Propagation Neural Network ( RMSE : 2.03 %) while the worst results were achieved by Self-Organizing Map Neural Network ( RMSE : 10.05 %). (\n",
            "----------------------------------------\n",
            "Title: Regularization for sparsity in statistical analysis and machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Development of a Big Data analytics demonstrator\n",
            "Abstract: The continued development of the information era has established the term ‘Big Data’ and large datasets are now easily created and stored. Now humanity begins to understand the value of data, and more importantly, that valuable insights are captured within data. To uncover and convert these insights into value, various mathematical and statistical techniques are combined with powerful computing capabilities to perform analytics. This process is described by the term ‘data science’. Machine learning is part of data analytics and is based on some of the mathematical techniques available. The ability of the industrial engineer to integrate systems and incorporate new technological developments benefiting business makes it inevitable that the industrial engineering domain will also be involved in data analytics. The aim of this study was to develop a demonstrator so that the industrial engineering domain can learn from it and have first-hand knowledge in order to better understand a Big Data Analytics system. This study describes how the demonstrator as a system was developed, what practical obstacles were encountered as well as the techniques currently available to analyse large datasets for new insights. An architecture has been developed based on existing but somewhat limited literature and a hardware implementation has been done accordingly. For the purpose of this study, three computers were used: the first was configured as the master node and the other two as slave nodes. Software that coordinates and executes the analysis was identified and used to analyse various test datasets available in the public domain. The datasets are in different formats which require different machine iii Stellenbosch University https://scholar.sun.ac.za\n",
            "----------------------------------------\n",
            "Title: A Systematic Method of Stroke Prediction Model based on Big Data and Machine Learning\n",
            "Abstract: There is an enormous increase in number of diseases worldwide. The non-communicable diseases such as cardio vascular disease will leads to death. The second major reason of death in people worldwide occurs due to stroke. It affects any portion of brain due to interruption or reduction of Blood supply. The brain damage can be reduced if required actions taken earlier. So there is necessary requirement to build stroke predictive models. The combined techniques of Machine Learning (ML) and Deep Learning (DL) techniques play the vital role in Disease Prediction. There are many researches has been done for stroke prediction using various ML Algorithms. In order to improve accuracy, the proposed model will work on the hybrid ANNRF (Artificial Neural Network-Random Forest). The proposed method can be reached 94% in classification accuracy.\n",
            "----------------------------------------\n",
            "Title: AN INTELLIGENT REASONING MODEL FOR YARN MANUFACTURE\n",
            "Abstract: Although many works have been done to construct prediction models on yarn processing quality, the relation between spinning variables and yarn properties has not been established conclusively so far. Support vector machines (SVMs), based on statistical learning theory, are gaining applications in the areas of machine learning and pattern recognition because of the high accuracy and good generalization capability. This study briefly introduces the SVM regression algorithms, and presents the SVM based system architecture for predicting yarn properties. Model selection which amounts to search in hyper-parameter space is performed for study of suitable parameters with grid-research method. Experimental results have been compared with those of ANN models. The investigation indicates that in the small data sets and real-life production, SVM models are capable of remaining the stability of predictive accuracy, and more suitable for noisy and dynamic spinning process\n",
            "----------------------------------------\n",
            "Title: Simulation of Human Activity Intensity and Its Influence on Mammal Diversity in Sanjiangyuan National Park, China\n",
            "Abstract: The rapid pace of development in western China has brought about inevitable concerns for environmental conditions and their management. The Sanjiangyuan National Park strives to address concerns for sustainable water resources management and biodiversity management, especially for the protection of endangered flora and fauna. In this study, a machine learning model (MaxEnt) was used to predict the human activity intensity and its effects on species in Sanjiangyuan protected by the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES). The model used human settlements as input and datasets such as terrain factors, climate, and artificial structures as environmental factors. The results showed that human activity intensity was significantly different between the East and the West. The area with the highest human activity intensity was Yushu County in the south area, and Xinghai-Zeku County in the east. By comparing the mammal richness with human activity intensity, we found human–wildlife coexistence in Sanjiangyuan. A detailed analysis on the CITES protected species showed that many important species, such as snow leopards, red pandas, and small Indian civets, occupied areas with high human activity intensity. The national park protects 3/4 CITES species with 1/3 in the area of the Sanjiangyuan region, owing to the relatively low human activity intensity.\n",
            "----------------------------------------\n",
            "Title: Analysis and Research on Combination Feature Extraction Method of EEG Singnal\n",
            "Abstract: EEG feature extraction problem is studied in this paper. EEG analysis is the core content of the Brain-computer interface technology research. How to effectively extract the reflect people's behavior intention characteristic from EEG signals, it's a hot spot in this neighborhood research. According to the characteristics of EEG signal, the single method of feature extraction can't describe the characteristics of the signal very well. So We have own designed experiment, and put forward a combination feature extraction method, which contains calculation the maximum Lyapunov exponent and use wavelet packet transform to calculate the rhythm average energy with wavelet energy entropy, then, the extract feature vector is inputted into the binary tree support vector machine (SVM) and the extreme learning machine (ELM), respectively. From the recognition result show that, when use the combination method of feature extraction to solve the problem of feature extraction and classification about this subject acquisition EEG, it's feasible and effective. At the same time, it also provides a new thought and method.\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Powered DNS Firewall\n",
            "Abstract: With the quick development in landscape of cybersecurity, the importance of DNS firewall solutions has been recently pronounced. Such solutions work as building blocks in forming inoficial access to various domains, suggesting real-time protection and gretaly unclear communications. The conventional paradigm depends heavily on preprepared lists of known malicious domains, necessitating frequent updates to maintain relevance. However, this method shows inadequate in yet-to-be-cataloged malicious or domains identifying emerging, leading to potential vulnerabilities. Throughout this paper, a creative research endeavor is discussed to shed lights on presenting a cutting-edge DNS firewall solution that proves the power of Machine Learning (ML) techniques. The major purpose is to use the real-time detection of malicious domain requests, thereby critically enhancing cybersecurity protocols. A reasonable assembled dataset, incorporating 34 intricate features and meticulously recorded instances totaling 90,000, was critically chosen from genuine DNS logs. Similarly, it becomes more riched through the careful integration of Open-Source Intelligence (OSINT) sources. The set goal includes the empowerment of precise in addition to rapid classification of domain requests as either malicious or benign.\n",
            "----------------------------------------\n",
            "Title: A novel method for calculating ambient aerosol liquid water content based on measurements of a humidified nephelometer system\n",
            "Abstract: Abstract. Water condensed on ambient aerosol particles plays significant\n",
            "roles in atmospheric environment, atmospheric chemistry and climate. Before\n",
            "now, no instruments were available for real-time monitoring of ambient\n",
            "aerosol liquid water contents (ALWCs). In this paper, a novel method is\n",
            "proposed to calculate ambient ALWC based on measurements of a\n",
            "three-wavelength humidified nephelometer system, which measures aerosol light\n",
            "scattering coefficients and backscattering coefficients at three wavelengths\n",
            "under dry state and different relative humidity (RH) conditions, providing\n",
            "measurements of light scattering enhancement factor f (RH). The proposed ALWC calculation method includes two steps: the first\n",
            "step is the estimation of the dry state total volume concentration of ambient\n",
            "aerosol particles, Va (dry), with a machine\n",
            "learning method called random forest model based on measurements of the\n",
            "“dry” nephelometer. The estimated Va (dry) agrees\n",
            "well with the measured one. The second step is the estimation of the volume\n",
            "growth factor Vg(RH) of ambient aerosol\n",
            "particles due to water uptake, using f (RH) and the\n",
            "Angstrom exponent. The ALWC is calculated from the\n",
            "estimated Va (dry) and Vg(RH). To validate the new method, the ambient ALWC calculated\n",
            "from measurements of the humidified nephelometer system during the Gucheng\n",
            "campaign was compared with ambient ALWC calculated from ISORROPIA\n",
            "thermodynamic model using aerosol chemistry data. A good agreement was\n",
            "achieved, with a slope and intercept of 1.14 and − 8.6  µ m 3  cm −3 ( r2 =  0.92), respectively. The\n",
            "advantage of this new method is that the ambient ALWC can be obtained solely\n",
            "based on measurements of a three-wavelength humidified nephelometer system,\n",
            "facilitating the real-time monitoring of the ambient ALWC and promoting the\n",
            "study of aerosol liquid water and its role in atmospheric chemistry,\n",
            "secondary aerosol formation and climate change.\n",
            "----------------------------------------\n",
            "Title: An IGBT coupling structure with a smart service life reliability predictor using active learning\n",
            "Abstract: \n",
            " An effective approach is proposed to evaluate the service life reliability of a multi-physics coupling structure of an insulated gate bipolar transistor (IGBT) module. The node-based smoothed finite element method with stabilization terms is firstly employed to construct an electrical-thermal-mechanical (ETM) coupling structure of the IGBT module, based on which the multi-physics responses can be accurately calculated to predict the service life of the IGBT module. By using the high-quality sample data obtained through the ETM coupling model, a Monte Carlo based active learning Kriging metamodel (AK-MCS) is developed to assess the service life reliability of the IGBT module, which can greatly reduce the computational cost needed by the surrogate model construction and reliability analysis. Numerical results show that the proposed ETM coupling structure can produce high-quality sample data of the IGBT dynamics and the AK-MCS machine learning technique can accurately estimate the service life reliability of the IGBT module.\n",
            "----------------------------------------\n",
            "Title: Matrix Factorization-based Technique for Drug Repurposing Predictions\n",
            "Abstract: Classical drug design methodologies are hugely costly and time-consuming, with approximately 85% of the new proposed molecules failing in the first three phases of the FDA drug approval process. Thus, strategies to find alternative indications for already approved drugs that leverage computational methods are of crucial relevance. We previously demonstrated the efficacy of the Non-negative Matrix Tri-Factorization, a method that allows exploiting both data integration and machine learning, to infer novel indications for approved drugs. In this work, we present an innovative enhancement of the NMTF method that consists of a shortest-path evaluation of drug-protein pairs using the protein-to-protein interaction network. This approach allows inferring novel protein targets that were never considered as drug targets before, increasing the information fed to the NMTF method. Indeed, this novel advance enables the investigation of drug-centric predictions, simultaneously identifying therapeutic classes, protein targets and diseases associated with a particular drug. To test our methodology, we applied the NMTF and shortest-path enhancement methods to an outdated collection of data and compared the predictions against the most updated version, obtaining very good performance, with an Average Precision Score of 0.82. The data enhancement strategy allowed increasing the number of putative protein targets from 3,691 to 15,295, while the predictive performance of the method is slightly increased. Finally, we also validated our top-scored predictions according to the literature, finding relevant confirmation of predicted interactions between drugs and protein targets, as well as of predicted annotations between drugs and both therapeutic classes and diseases.\n",
            "----------------------------------------\n",
            "Title: Use of flipped classroom in the marketing career during the educational process on financial mathematics\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Facial Emotion Recognition – A gift for the visionless\n",
            "Abstract: — Most of the mundane activities these days are automated. There are others, which do not have a fixed pattern. For instance, recognition of emotions of an individual given the facial expressions. Using the Machine Learning concepts, a model is trained with various facial images having varied expressions, of single and multiple individuals. In the current work, face detection and emotion recognition is carried out at real time even when an individual is on the move. The findings of the paper can be useful in identifying missing individual, helping individuals in emotional distress. It can also help the visionless analyze the mood of the person with whom he is interacting. The name of the individual whose identity is verified is also verbally provided as an assistance to the impaired. Various face recognition algorithms and the relative comparison and analysis is also brought out usic plays an essential role in the well-being of many people. It can be therapeutic, motivational and can even unite people.\n",
            "----------------------------------------\n",
            "Title: Improving The Detection of Plagiarism in Scientific Articles Using Machine Learning Approaches\n",
            "Abstract: . One of the modern problems that occur in the current research and publication process is the duplication of the results of other people's research that is presented again by other parties. With the ease of the resources obtained, the more open the opportunity to bring up a problem called Plagiarism. This is attempted to be completed by the computer system with new approaches to detect and predict the existence of plagiarism in research automatically. In this article, approaches and methods for detecting plagiarism use machine learning techniques, where machine learning is empowered to become an algorithm as construction and evaluation in detecting plagiarism. Technically, this algorithm will compare and analyze the compatibility of words and sentences in documents with other document databases so that the analysis becomes an evaluation material, prediction, and determination that the document is plagiarism or not. The purpose of this study is to protect intellectual property and ideas, as well as the results to improve better performance and level of accuracy in detecting plagiarism.\n",
            "----------------------------------------\n",
            "Title: Application of Machine Learning Methods in Baikal-GVD: Background Noise Rejection and Selection of Neutrino-Induced Events\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Stellar Abundances to Predict Exoplanet Host Stars\n",
            "Abstract: Introduction: Since the initial discovery of the “planet-metallicity” relationship for giant planets, as popularized by Fischer & Valenti [1] the iron content within a star, or the [Fe/H] ratio, has been used as a proxy for the overall metallicity of the star. While it has been assumed that the abundances of other important bio-essential elements, such as C, O, Si, and Mg, have been consistent with the Fe-trends in giant planet hosting stars, these results have not been seen despite a variety of studies over the last ~10 years. Additionally, there has not been any detected correlation between stellar abundances and smaller, terrestrial planets. Despite the huge number of exoplanetary detections from the Kepler mission, the traditional radial velocity and transiting detection techniques only utilize the physical properties of the stellar system. Here we take advantage of the host’s stellar abundances in order to statistically examine any possible dependence of the occurrence of exoplanets to the chemistry of the star. We used the Hypatia Catalog [2, 3] as a large sample of non-Fe abundances for stars that do and do not have detected exoplanets. We produced a target list of possible planet-hosting stars that have a high probability of hosting a detectable exoplanet. Hypatia Catalog: The Hypatia Catalog is a database of stellar abundances which includes +65 elements and species within >6000 FGK-stars that are less than 150 pc from the Sun. Hypatia was compiled from over 200 literature sources such that the data were homogenized to the same solar scale. The median value was used during those instances where multiple literature values existed for the same element in the same star. Hypatia currently contains stellar abundances for +300 exoplanet host stars. Supervised Machine Learning: When comparing non-Fe element ratios in stars with and without planets, the standard method has looked at individual elements between the two groups. However, by employing the award-winning supervised machine learning algorithm XGBoost [4], we are able to analyze the elements as an ensemble in a way that is very similar to the Netflix movie recommendation algorithm. For example, after watching a number of movies, Netflix is able to assess that you enjoy a particular genre of movies. It then applies this information to the back catalog of movies that you haven’t watched and makes recommendations, with listed probabilitoes, that you will like the movie.\n",
            "----------------------------------------\n",
            "Title: AMELIORATION OF MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE IN MEDICAL MANAGEMENT (A CASE STUDY ON THE PANDEMIC OF COVID 19 CASES IN ASIA)\n",
            "Abstract: Machine learning is seeing increasingly utilized in medical management for different reasons: tremendous sums of information are being captured and made accessible carefully; handling of vast sums of information has gotten to be cost-effective due to the expanded computing control presently accessible at reasonable costs; and different open source systems, toolkits, and libraries are accessible that can be utilized to construct and execute ML applications. Particularly in healthcare, ML has driven to energizing modern improvements that may rethink COVID-19 treatment and vaccination within a long time to come. With modern occurrences of the brand modern coronavirus clutter, COVID-19, creating day through the day, it is common to compare the unused affliction to other flare-ups in current history. Machine learning can offer assistance to anticipate three sorts of restorative dangers - disease, seriousness, and result. Whereas it is still it is early for COVID-19 with machine learning, but early applications seem promising.  Machine learning is utilized when a computer has been instructed to recognize designs by giving it with information and a calculation to assist get it that information. This method of learning from the information is called training and the yield that we accomplish is through testing. Machine learning-based robotic surgery is changing the way surgery is performed nowadays. Machine learning in healthcare is getting to be more broadly utilized and is making a difference in patients and clinicians in numerous diverse ways. Cybersecurity and protection are major concerns and open challenges in healthcare which are yet to be addressed.\n",
            "----------------------------------------\n",
            "Title: The CLaC Discourse Parser at CoNLL-2016\n",
            "Abstract: This paper describes our submission \"CLaC\" to the CoNLL-2016 shared task on shallow discourse parsing. We used two complementary approaches for the task. A standard machine learning approach for the parsing of explicit relations, and a deep learning approach for non-explicit relations. Overall, our parser achieves an F1-score of 0.2106 on the identification of discourse relations (0.3110 for explicit relations and 0.1219 for non-explicit relations) on the blind CoNLL-2016 test set.\n",
            "----------------------------------------\n",
            "Title: Review on machine and deep learning models for the detection and prediction of Coronavirus\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Spatial localisation and sensing in two dimensions via metasurfaces\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: ANALYSIS OF THE METHODS AND SPECIFIC OF THE FIELD TRIAL DATA DIGITALIZATION AS THE BASIS OF FARMING MANAGEMENT\n",
            "Abstract: The purpose of the study. The topic of crop management, which is largely determined by modern digitalization processes, is relevant and is in the center of attention of both specialists and experts in the field of agriculture and in the field of computer technology, because the production of products of the agricultural sector plays a vital role in the world economy. Considering that traditional field data processing methods are unable to meet the ever-growing needs of agricultural producers at the new stage of agricultural development and are a serious obstacle to obtaining the necessary information, the purpose of the article is to conduct a critical review and analysis of publications on the digitization of field research databases in order to develop and adopt effective management decisions in crop production. Research methods. Research was conducted using generally accepted scientific methods: abstract-logical; analysis and synthesis; induction and deduction; expert evaluations. Research results. The conducted analysis made it possible to determine that the level of development of agricultural enterprises currently largely depends on modern digital technologies, the implementation of which involves a change in the general paradigm of production process management and allows commodity producers to act accordingly to increase production volumes. It has been proven that along with updating the material and technical component, the priority of production is the intellectualization of production and management activities based on digitization. Conclusion. In order to benefit from the ever-increasing amount of data that comes from numerous sources of digital transformation, despite the fact that the vast majority of farmers and agricultural producers are not experts in this field and are unable to fully understand the basic laws of the algorithms being created, the scientific and methodological approach to increase the effectiveness of machine learning for automatic recognition of agricultural crops, detection of diseases and weeds, forecasting of yield and quality of the crop, management of water resources and soil can be useful for agricultural enterprises of many countries of the world. Key words: machine learning, precision farming, productivity, soil conditions, water resources.\n",
            "----------------------------------------\n",
            "Title: Fraud Detection in Banking: A Machine Learning Approach using Credit Card Transaction Data\n",
            "Abstract: Financial fraud poses a significant threat to the banking industry, with fraudsters continually evolving their tactics to exploit vulnerabilities. This paper investigates the efficacy of various machine learning algorithms for fraud detection using the Credit Card Fraud dataset from Kaggle. The paper explores Decision Tree, K-Nearest Neighbors (KNN), Logistic Regression, Support Vector Machine (SVM), Random Forest, and XGBoost algorithms. The study analyzes the performance of these models and discusses their real-time implementation in banking systems. Furthermore, we outline potential future directions to enhance fraud detection capabilities.\n",
            "----------------------------------------\n",
            "Title: Speaking with machines: interacting with bots for language teaching and\n",
            " learning\n",
            "Abstract: This piece explores technologies for freer communication with machines, i.e. bots (chatbots or conversational agents), rather than the concept of speaking to machines, such as Intelligent Assistants (IA) like Alexa. Bots are computer programmes which simulate natural intelligent communication using text or speech technologies. The first chatbot claimed to pass the Turing Test (a test to identify whether a computer is intelligent), ELIZA, was created by Joseph Weizenbaum in 1966 to imitate a psychotherapist. More recently, interest in chatbots appears to have shifted from whether they can be perceived as human to their ability to imitate natural conversations to achieve specific purposes and provide efficient customer services.\n",
            "----------------------------------------\n",
            "Title: A Survey on the Use of Data Points in IDS Research\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Polysaccharides and Composite Adsorbents in the Spotlight for Effective Agrochemical Residue Removal from Water\n",
            "Abstract: Agrochemical residues, including pesticides and herbicides, pose significant environmental and health risks when present in water sources. Conventional water treatment methods often fall short in effectively removing these persistent pollutants, necessitating innovative solutions. This review explores the use of polysaccharides and composite adsorbents as sustainable alternatives for agrochemical residue removal from water. Biopolymers such as chitosan, alginate, and cellulose are highlighted for their biodegradability, biocompatibility, and ability to be functionalized for enhanced adsorption performance. Recent advances in the development of composite materials incorporating nanomaterials, such as graphene, oxide, and metal oxides, have shown significant promise in enhancing the efficiency and selectivity of agrochemical adsorption. The review also addresses the fundamental mechanism of adsorption, such as electrostatic interactions, hydrogen bonding, and hydrophobic forces, that contribute to the effectiveness of these materials. Challenges associated with scalability, regeneration, and real-world applications are discussed, as well as future opportunities for integrating emerging technologies like 3D printing and machine learning into adsorbent design. Overall, polysaccharides and composites offer a promising pathway toward achieving efficient and sustainable agrochemical residue removal, with ongoing research needed to overcome current limitations and optimize their practical application in water treatment.\n",
            "----------------------------------------\n",
            "Title: An investigation on annular cartilage samples for post-mortem interval estimation using Fourier transform infrared spectroscopy\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A novel technique based on the improved firefly algorithm coupled with extreme learning machine (ELM-IFF) for predicting the thermal conductivity of soil\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: DiffPhysiNet: A Bearing Diagnostic Framework Based on Physics-Driven Diffusion Network for Unseen Working Conditions\n",
            "Abstract: Fault diagnosis is essential to ensure bearing safety in industrial applications. Many existing diagnostic methods require large scales of data from a full range of working conditions. However, the structure and working conditions differences between machines lead to significant variation in data distribution, making it difficult to diagnostic with unseen samples. To handle this situation, an unknown condition diagnosis Framework (UCDF) based on physics-driven diffusion network (DiffPhysiNet) is proposed, effectively integrating the generation capability of the diffusion model and learning from the working conditional encoding (WCE). Specifically, signals under limited working conditions are gradually convert to noise through a forward noising process. Then, DiffPhysiNet reconstructs signals from the noise by a reverse denoising process. In addition, a physics-driven UNet (Physi-UNet) structure is designed to extract WCE for noise level prediction during the reverse process. Moreover, an Unsupervised Clustering Filter (UCFilter) is constructed to select signals with high quality after generation. Signals under unknown working condition can be generated with certain WCE. Ultimately, extensive experiments on two bearing datasets (SDUST and PU) validate the effectiveness of our method compared with the state-of-the-art baselines and the ablution test confirms the significant role of Physi-UNet and UCFilter.\n",
            "----------------------------------------\n",
            "Title: Estimating Flyrock Distance Induced Due to Mine Blasting by Extreme Learning Machine Coupled with an Equilibrium Optimizer\n",
            "Abstract: Blasting is essential for breaking hard rock in opencast mines and tunneling projects. It creates an adverse impact on flyrock. Thus, it is essential to forecast flyrock to minimize the environmental effects. The objective of this study is to forecast/estimate the amount of flyrock produced during blasting by applying three creative composite intelligent models: equilibrium optimizer-coupled extreme learning machine (EO-ELM), particle swarm optimization-based extreme learning machine (PSO-ELM), and particle swarm optimization-artificial neural network (PSO-ANN). To obtain a successful conclusion, we considered 114 blasting data parameters consisting of eight inputs (hole diameter, burden, stemming length, rock density, charge-per-meter, powder factor (PF), blastability index (BI), and weathering index), and one output parameter (flyrock distance). We then compared the results of different models using seven different performance indices. Every predictive model accomplished the results comparable with the measured values of flyrock. To show the effectiveness of the developed EO-ELM, the result from each model run 10-times is compared. The average result shows that the EO-ELM model in testing (R2 = 0.97, RMSE = 32.14, MAE = 19.78, MAPE = 20.37, NSE = 0.93, VAF = 93.97, A20 = 0.57) achieved a better performance as compared to the PSO-ANN model (R2 = 0.87, RMSE = 64.44, MAE = 36.02, MAPE = 29.96, NSE = 0.72, VAF = 74.72, A20 = 0.33) and PSO-ELM model (R2 = 0.88, RMSE = 48.55, MAE = 26.97, MAPE = 26.71, NSE = 0.84, VAF = 84.84, A20 = 0.51). Further, a non-parametric test is performed to assess the performance of these three models developed. It shows that the EO-ELM performed better in the prediction of flyrock compared to PSO-ELM and PSO-ANN. We did sensitivity analysis by introducing a new parameter, WI. Input parameters, PF and BI, showed the highest sensitivity with 0.98 each.\n",
            "----------------------------------------\n",
            "Title: Maintaining proper health records improves machine learning predictions for novel 2019-nCoV\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: P10.13.A DEMOCRATIZING QUALITY: A STRATEGY TO MAKE LEVEL OF EVIDENCE ASSESSMENTS QUICK, EASY, AND ACCESSIBLE TO ALL\n",
            "Abstract: \n",
            " \n",
            " \n",
            " Advances in clinical care depend decisively on evidence from high-quality clinical trials. EANO and other international societies have established systematic and transparent methodologies for assessing the quality of clinical trials, but the process is time-consuming and challenging to master. Using advanced computational strategies, we have developed three novel models—an Excel-based calculator, a machine learning (ML) model, and a permutation-based decision tree—designed to facilitate this assessment and make it easily accessible to clinicians and researchers.\n",
            " \n",
            " \n",
            " \n",
            " A PRISMA-compliant literature review was conducted to identify all therapeutic human trials involving adult neuro-oncology patients published in the last 12 months in high-impact journals. Articles fulfilling pre-specified inclusion and exclusion criteria were selected and a level of evidence was assigned independently by two investigators, with differences resolved by consensus. Simultaneously, an advanced ML model was created, employing a Support Vector Machine (SVM) algorithm renowned for its efficacy in classification tasks. The SVM model was configured with a 0.2 train-test split to validate its predictive accuracy and recursive feature elimination to evaluate the significance of input features, confirming their equal importance. Additionally, a permutation-based decision tree was developed, where a collaborative team analyzed all possible permutations of questionnaire responses to assign explicit quality ratings through a data-driven decision framework. Finally, an Excel-based tool was developed to calculate the level of evidence. The results of all four assessment strategies were statistically compared.\n",
            " \n",
            " \n",
            " \n",
            " The ML model was developed and trained on a dataset of 225 categorized research papers and achieved a classification accuracy of 97%. The permutation-based decision tree tool was designed to map all possible questionnaire response permutations to specific trial quality levels, with 11,521 independently graded permutation response pathways. The Excel-based tool was programmed to use a phrase-matching algorithm to identify an evidence level based on a user’s provided answers. The permutation and Excel-based strategies provided excellent classification accuracy but were inferior to the ML model. As we will demonstrate, all three models were easy to use and provided rapid and reliable levels of evidence assessments.\n",
            " \n",
            " \n",
            " \n",
            " By providing open access to these tools to clinicians and researchers and making the level of evidence assessments efficient, consistent, and transparent, we hope to democratize the ability to evaluate published trials, thereby improving the quality of clinical care. We also hope that clinical researchers will utilize these tools to enhance the quality of their clinical trials at the design stage.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Research and Design of a Key Technology for Accelerating Convolution Computation for FPGA-Based CNN\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Investigation and Evaluation of a Zero Input Tracking Analyzer (ZITA)\n",
            "Abstract: Abstract : This study was designed to evaluate a psychomotor testing instrument known as the ZITA (Zero Input Tracking Analyzer). This instrument was being considered as a prediction device in the selection of applicants for the U. S. Navy aircrew training program. Analysis of the data obtained from six subjects (all U. S. Navy pilots) over 26 hours of testing, showed the machine capable of consistent results in distinguishing between subjects with respect to this particular psychomotor task. A major disadvantage of the ZITA that became apparent was the amount of time (approximately 2 hours) required before learning curves were leveled out and the rate at which different individuals develop their learning curve.\n",
            "----------------------------------------\n",
            "Title: The field terrain recognition based on extreme learning machine using wavelet features\n",
            "Abstract: Feature extraction and classification algorithm is important to determine the accuracy of classification. The terrain recognition of a legged robot has higher requirements on real-time classification. Considering the traditional training methods is difficult to meet the requirements, this paper applies the extreme learning machine using wavelet features to terrain recognition. The experimental results show that recognition rate of the extreme learning algorithm is 96.78%, which is 30.89% and 20.45% higher than BP and SVM algorithm respectively. Hence, the proposed method in this paper has obvious advantages over traditional algorithm in parameter selection and learning speed.\n",
            "----------------------------------------\n",
            "Title: Sentinel 3 OLCI and Machine Learning for Cyanobacteria Bloom Detection Over Small Inland Water Target\n",
            "Abstract: High nutrient input agricultural practices and nutrient enrichment have been identified as the main factors driving cyanobacterial harmful algal blooms (cyanoHABs) formation in Uruguay. Current agricultural practices are already inflicting significant harm on aquatic ecosystems and human well-being, with future forecasts indicating a worsening of these trends. Thus, real-time detection of cyanoHABs in inland freshwater ecosystems is imperative for mitigating potential threats. Conventional cyanobacteria detection models often entail intricate procedures, necessitating the integration of biophysical, chemical, or on-site DNA sequencing measurements. Leveraging satellite imagery offers a cost-effective means to pinpoint cyanoHAB occurrences across extensive spatial and temporal scales. Within the European Space Agency's (ESA) satellite fleet, the Sentinel 3 satellites equipped with the Ocean and Land Color Instrument (OLCI) present a notable resource. In this study, we employed the cyanoHAB detection algorithm, Maximum peak-height (MPH), on OLCI data from the Laguna del Sauce lagoon to establish a baseline detection accuracy of 85%. The success of MPH's tree-like algorithm encouraged us to use machine learning classification algorithms based on decision trees to improve detection accuracy. The XGBoost classification model outperformed the other models by achieving an accuracy of 92%.\n",
            "----------------------------------------\n",
            "Title: Data mining Classification Techniques for Intrusion Detection System\n",
            "Abstract: In today’s contemporary era detection of network attacks has become the need of the hour due to increasing network traffic over the network. Data mining technique plays a vital role in searching network attacks and anomalies. These techniques help in selecting and refining useful and relevant information from large data sets. Data mining technique helps in classify relevant data for Intrusion Detection System. Intrusion Detection system generates alarms for the network traffic about the foreign invasions in the system. In the following paper we have used data mining classification techniques for intrusion detection in order to build a safe network. Random tree, Naive Bayes, J48 and Random forest machine learning classifier are used for classification. Comparison based on parameters like data accuracy, finding useful patterns, extracts useful information between the techniques.\n",
            "----------------------------------------\n",
            "Title: Prediction of North Atlantic Oscillation Index with Convolutional LSTM Based on Ensemble Empirical Mode Decomposition\n",
            "Abstract: The North Atlantic Oscillation (NAO) is the most significant mode of the atmosphere in the North Atlantic, and it plays an important role in regulating the local weather and climate and even those of the entire Northern Hemisphere. Therefore, it is vital to predict NAO events. Since the NAO event can be quantified by the NAO index, an effective neural network model EEMD-ConvLSTM, which is based on Convolutional Long Short-Term Memory (ConvLSTM) with Ensemble Empirical Mode Decomposition (EEMD), is proposed for NAO index prediction in this paper. EEMD is applied to preprocess NAO index data, which are issued by the National Oceanic and Atmospheric Administration (NOAA), and NAO index data are decomposed into several Intrinsic Mode Functions (IMFs). After being filtered by the energy threshold, the remaining IMFs are used to reconstruct new NAO index data as the input of ConvLSTM. In order to evaluate the performance of EEMD-ConvLSTM, six methods were selected as the benchmark, which included traditional models, machine learning algorithms, and other deep neural networks. Furthermore, we forecast the NAO index with EEMD-ConvLSTM and the Rolling Forecast (RF) and compared the results with those of Global Forecast System (GFS) and the averaging of 11 Medium Range Forecast (MRF) model ensemble members (ENSM) provided by the NOAA Climate Prediction Center. The experimental results show that EEMD-ConvLSTM not only has the highest reliability from evaluation metrics, but also can better capture the variation trend of the NAO index data.\n",
            "----------------------------------------\n",
            "Title: Usability of Artificial Intelligence in Cyber Security\n",
            "Abstract: The Internet of Things is getting increasingly intelligent and sophisticated. The use of smart devices is rapidly expanding. Artificial intelligence and machine learning are being integrated into IoT applications, resulting in competitive benefits such as increased operational productivity. Large businesses have been purchasing smaller start-ups that have been working at the intersection of artificial intelligence and the Internet of Things over the past decade. In addition, leading IoT service providers are increasingly offering advanced AI features including machine-based learning analytics. We evaluated various papers relevant to the application of artificial intelligence in cyber-security in this report.\n",
            "----------------------------------------\n",
            "Title: Tumor Microenvironment, Radiology, and Artificial Intelligence: Should We Consider Tumor Periphery?\n",
            "Abstract: The tumor microenvironment (TME) consists of cellular and noncellular components which enable the tumor to interact with its surroundings and plays an important role in the tumor progression and how the immune system reacts to the malignancy. In the present study, we investigate the diagnostic potential of the TME in differentiating benign and malignant lesions using image quantification and machine learning.\n",
            "----------------------------------------\n",
            "Title: FLoX: Federated Learning with FaaS at the Edge\n",
            "Abstract: Federated learning (FL) is a technique for distributed machine learning that enables the use of siloed and distributed data. With FL, individual machine learning models are trained separately and then only model parameters (e.g., weights in a neural network) are shared and aggregated to create a global model, allowing data to remain in its original environment. While many applications can benefit from FL, existing frameworks are incomplete, cumbersome, and environment-dependent. To address these issues, we present FLoX, an FL framework built on the funcX federated serverless computing platform. FLoX decouples FL model training/inference from infrastructure management and thus enables users to easily deploy FL models on one or more remote computers with a single line of Python code. We evaluate FLoX using three benchmark datasets deployed on ten heterogeneous and distributed compute endpoints. We show that FLoX incurs minimal overhead, especially with respect to the large communication overheads between endpoints for data transfer. We show how balancing the number of samples and epochs with respect to the capacities of participating endpoints can significantly reduce training time with minimal reduction in accuracy. Finally, we show that global models consistently outperform any single model on average by 8%.\n",
            "----------------------------------------\n",
            "Title: Polygalic acid inhibits african swine fever virus polymerase activity: findings from machine learning and in vitro testing\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Bayesian optimization for materials design\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Nearest Charging Station Identification for EV Using Machine Learning Techniques\n",
            "Abstract: As the call for electric cars (EVs) continues to surge, making sure efficient access to charging infrastructure will become paramount for encouraging their large adoption. The research addresses the urgent undertaking of optimising EV charging infrastructure by means of predicting EV charging requirements and recommending the nearest charging stations based totally on the car's charging functionality. The work goal is to expand a predictive approach that anticipates EV charging requirements and guides users to the most suitable charging stations. The approach utilizes number of object mastering algorithms, which include Decision Tree Regression, K-Nearest Neighbours Regression, and Support Vector Regression, trained on real-local charging station records from Bangalore. These techniques are designed to estimate charging points at various geographic locations, empowering EV customers to make informed choices based on their instant charging requirements. The research demonstrates the software of each set of rules in exactly predicting charging points and identifying the most suitable charging stations. Beyond Bangalore, the proposed technique can be adapted to benefit other cities and regions, contributing to sustainable transportation, and expediting the transition to electric mobility.\n",
            "----------------------------------------\n",
            "Title: Tightening the Evaluation of PAC Bounds Using Formal Verification Results\n",
            "Abstract: Probably Approximately Correct (PAC) bounds are widely used to derive probabilistic guarantees for the generalisation of machine learning models. They highlight the components of the model which contribute to its generalisation capacity. However, current state-of-the-art results are loose in approximating the generalisation capacity of deployed machine learning models. Consequently, while PAC bounds are theoretically useful, their applicability for evaluating a model's generalisation property in a given operational design domain is limited. The underlying classical theory is supported by the idea that bounds can be tightened when the number of test points available to the user to evaluate the model increases. Yet, in the case of neural networks, the number of test points required to obtain bounds of interest is often impractical even for small problems. In this paper, we take the novel approach of using the formal verification of neural systems to inform the evaluation of PAC bounds. Rather than using pointwise information obtained from repeated tests, we use verification results on regions around test points. We show that conditioning existing bounds on verification results leads to a tightening proportional to the underlying probability mass of the verified region.\n",
            "----------------------------------------\n",
            "Title: RakshaNet: URL - Aware Malicious Website Classifier\n",
            "Abstract: Software revolution has resulted in a hyperbolic increase in internet browsing, making internet security a vital issue. Most naive users typically visit unknown websites, and due to their lack of awareness and software proficiency, malicious websites pose a significant threat to their data and security. This paper proposes a classification algorithm that determines whether a website is malicious or benign based on its application layer and network layer features. These features are extracted from the header and body of the HTTP/HTTPS request/response of a website, upon which the ML algorithm acts to determine whether the website is malicious. The client-server data can be intercepted using a proxy service, such as the Squid proxy, and the ML classifier runs as part of the Internet Content Adaptation Protocol (ICAP). If a website is determined as potentially malicious, the user shall be notified immediately and redirected back to the previous benign webpage. The URL parameters extracted include the Server name, DNS query time, TCP details, etc., which are chosen after extensive study of the contribution of these features (importance) to the classification. The study is performed on the decision tree and random forest supervised machine learning algorithms, and it is observed that the random forest algorithm is the most suitable ML classification methodology, achieving a test accuracy of 92%. The classification performance is visualized with the help of the confusion matrix and receiver operating characteristics curve (ROC), with an area under the curve (AUC) of 84%. Thus, this paper proposes an end-to-end software that utilises the random forest algorithm for the classification of websites as malicious or benign, and preempt users from accessing harmful websites.\n",
            "----------------------------------------\n",
            "Title: Efficient and Accurate Simulations of Vibrational and Electronic Spectra with Symmetry-Preserving Neural Network Models for Tensorial Properties.\n",
            "Abstract: Machine learning has revolutionized the high-dimensional representations for molecular properties such as potential energy. However, there are scarce machine learning models targeting tensorial properties, which are rotationally covariant. Here, we propose tensorial neural network (NN) models to learn both tensorial response and transition properties in which atomic coordinate vectors are multiplied with scalar NN outputs or their derivatives to preserve the rotationally covariant symmetry. This strategy keeps structural descriptors symmetry invariant so that the resulting tensorial NN models are as efficient as their scalar counterparts. We validate the performance and universality of this approach by learning response properties of water oligomers and liquid water and transition dipole moment of a model structural unit of proteins. Machine-learned tensorial models have enabled efficient simulations of vibrational spectra of liquid water and ultraviolet spectra of realistic proteins, promising feasible and accurate spectroscopic simulations for biomolecules and materials.\n",
            "----------------------------------------\n",
            "Title: Kernel-based data transformation model for nonlinear classification of symbolic data\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Guarantees for Self-Play in Multiplayer Games via Polymatrix Decomposability\n",
            "Abstract: Self-play is a technique for machine learning in multi-agent systems where a learning algorithm learns by interacting with copies of itself. Self-play is useful for generating large quantities of data for learning, but has the drawback that the agents the learner will face post-training may have dramatically different behavior than the learner came to expect by interacting with itself. For the special case of two-player constant-sum games, self-play that reaches Nash equilibrium is guaranteed to produce strategies that perform well against any post-training opponent; however, no such guarantee exists for multiplayer games. We show that in games that approximately decompose into a set of two-player constant-sum games (called constant-sum polymatrix games) where global $\\epsilon$-Nash equilibria are boundedly far from Nash equilibria in each subgame (called subgame stability), any no-external-regret algorithm that learns by self-play will produce a strategy with bounded vulnerability. For the first time, our results identify a structural property of multiplayer games that enable performance guarantees for the strategies produced by a broad class of self-play algorithms. We demonstrate our findings through experiments on Leduc poker.\n",
            "----------------------------------------\n",
            "Title: Torque ripple reduction in Permanent Magnet Synchronous Machines using angle-based iterative learning control\n",
            "Abstract: Permanent Magnet Synchronous Machines (PMSM) are used in many applications, particularly in high-performance drive systems. However, one inherent problem of PMSM is its parasitic undesired torque ripple, which reduces the PMSM performances. Several kinds of parasitic torque ripples are periodic functions of the rotor position. To reduce them, a method called Iterative Learning Control (ILC) seems well suited, but is efficient for only one constant speed chosen by the designer (and all the integer multiples of this speed). To design a solution for a varying speed, an ILC variant named angle-based ILC is proposed, which no longer uses time as the reference, but the angular position. This angle-based ILC can simply be implemented and does not require a heavy computational load. Simulations of a PMSM variable speed drive system and experiments have been done to assess the performances of the proposed technique.\n",
            "----------------------------------------\n",
            "Title: Combining hypothesis-driven ECG indices with machine learning improves ventricular arrhythmic risk prediction in a low-risk population\n",
            "Abstract: \n",
            " \n",
            " \n",
            " Life-threatening ventricular arrhythmias (LTVA) are a leading cause of mortality, but early identification of high-risk individuals remains a major challenge. An ECG index, TMV (T-wave morphology variations), predicts LTVA in 51,794 individuals without known cardiovascular disease from the UK Biobank (UKB) within a 10-year follow up (cohort 1), with an area under the ROC curve (AUC) of 0.558 and a hazard ratio (HR) of 1.57. Machine learning on the ECG has shown a high accuracy in detecting patients with cardiovascular disease, but its LTVA predictive value in a low-risk population and comparisons with hypothesis-driven risk markers, like TMV, is unknown.\n",
            " \n",
            " \n",
            " \n",
            " We tested the LTVA predictive value of a score combining a multi-layer convolutional neural network (CNN) model and TMV in individuals without known cardiovascular disease.\n",
            " \n",
            " \n",
            " \n",
            " Using UKB we split the individuals from cohort 1 into training (90%) and internal test (10%) sets (Figure 1). In the training set, we applied 10-fold cross validation to train a multi-layer CNN with an attention layer, where the input was a 15-second ECG at rest (lead I), and the output was occurrence (or not) of LTVA within a 10-year follow-up. We used 10-second ECG data (lead I) from an independent cohort of 32,209 individuals without cardiovascular disease from UKB (cohort 2) as an external test set (median follow-up was 3.4 years), where we also calculated TMV. We next combined them into a score (weighted by their relative contribution to LTVA in a logistic regression). The AUC, and Cox regression HRs were calculated to estimate the performance of the CNN, TMV and the combined score.\n",
            " \n",
            " \n",
            " \n",
            " In cohort 1, 217 subjects had a LTVA during the follow-up period. In the internal test set, the AUC of the CNN was 0.707. In the external test set (60 LTVA events during the follow-up period), the CNN’s prediction and TMV led to AUCs of 0.610 and 0.604, respectively. Interestingly, the CNN’s prediction and TMV were not correlated (ρ = 0.005), and the combined score led to an AUC of 0.627. We set a threshold at the score value that maximised sensitivity and specificity, and survival analyses showed a HR of 3.007 (P < 0.0001) for individuals in the score+ (score > threshold) versus those in the score- (score < threshold) group, after adjusting for age and gender (Figure 2). The continuous score also predicted LTVA independently from age and gender.\n",
            " \n",
            " \n",
            " \n",
            " A CNN-based model predicts LTVA in a low-risk population independently from TMV, a strong ECG risk predictor derived from knowledge on the underlying electrophysiology. When TMV and the CNN are combined into a score, the LTVA risk stratification improves, independently from age and gender. Our findings support the combination of hypothesis-based risk markers and CNN approaches to optimise LTVA prediction in a low-risk population.Study designSurvival curves\n",
            "\n",
            "----------------------------------------\n",
            "Title: Combining Long-Term Recurrent Convolutional and Graph Convolutional Networks to Detect Phishing Sites Using URL and HTML\n",
            "Abstract: Phishing, a well-known cyber-attack practice has gained significant research attention in the cyber-security domain for the last two decades due to its dynamic attacking strategies. Although different solutions have been exercised against phishing, phishing attacks have dramatically increased in the past few years. Recent studies have shown that machine learning has become prominent in the present anti-phishing context, and the techniques like deep learning have extensively improved anti-phishing tools’ detection ability. This paper proposes PhishDet, a new way of detecting phishing websites through Long-term Recurrent Convolutional Network and Graph Convolutional Network using URL and HTML features. PhishDet is the first of its kind, which uses the powerful analysis and processing capabilities of Graph Neural Network in the anti-phishing domain and recorded 96.42% detection accuracy, with a 0.036 false-negative rate. It is effective against zero-day attacks, and the average detection time which is 1.8 seconds could also be considered realistic. The feature selection of PhishDet is automatic and occurs inside the system, as PhishDet gradually learns URLs and HTML content features to handle constantly changing phishing attacks. This has outperformed similar solutions by achieving a 99.53% f1-score with a public benchmark dataset. However, PhishDet requires periodic retraining to maintain its performance over time. If such retraining could be facilitated, PhishDet could fight against phishers for a more extended period to safeguard Internet users from this Internet threat.\n",
            "----------------------------------------\n",
            "Title: Review Paper on Facial Expression Based Music Recommendation System\n",
            "Abstract: Music plays an important role in one's life, the tone of music helps to heal the pain and it also helps to enjoy moments. We have different song lists depending upon the mood. But there are no such tools that can be used as an emotion-based music player that detects the emotion of the person and plays music according to the mood. The proposed system is Emotion Based Music Player using Python and Machine Learning.\n",
            "----------------------------------------\n",
            "Title: Assessing the Value of eBay Listing Features\n",
            "Abstract: We used machine learning to access the value of additional features sellers can use to highlight their eBay item listings. The set of features a user can add to their listing includes subtitles, extra photos, a pop up photo view of an item, a ―listing designer‖, and a bold listing of their item in search results. As eBay fixes the costs for these features, we implemented a price-prediction scheme to determine which listing features add most value to an item and identified the relative importance of specific features in price determination. Motivation\n",
            "----------------------------------------\n",
            "Title: Facial Emotion Recognition Using Conventional Machine Learning and Deep Learning Methods: Current Achievements, Analysis and Remaining Challenges\n",
            "Abstract: Facial emotion recognition (FER) is an emerging and significant research area in the pattern recognition domain. In daily life, the role of non-verbal communication is significant, and in overall communication, its involvement is around 55% to 93%. Facial emotion analysis is efficiently used in surveillance videos, expression analysis, gesture recognition, smart homes, computer games, depression treatment, patient monitoring, anxiety, detecting lies, psychoanalysis, paralinguistic communication, detecting operator fatigue and robotics. In this paper, we present a detailed review on FER. The literature is collected from different reputable research published during the current decade. This review is based on conventional machine learning (ML) and various deep learning (DL) approaches. Further, different FER datasets for evaluation metrics that are publicly available are discussed and compared with benchmark results. This paper provides a holistic review of FER using traditional ML and DL methods to highlight the future gap in this domain for new researchers. Finally, this review work is a guidebook and very helpful for young researchers in the FER area, providing a general understating and basic knowledge of the current state-of-the-art methods, and to experienced researchers looking for productive directions for future work.\n",
            "----------------------------------------\n",
            "Title: Hybrid blockchain-enabled secure microservices fabric for decentralized multi-domain avionics systems\n",
            "Abstract: Advancement in artificial intelligence (AI) and machine learning (ML), dynamic data driven application systems (DDDAS), and hierarchical cloud-fog-edge computing paradigm provide opportunities for enhancing multi-domain systems performance. As one example that represents multi-domain scenario, a “fly-by-feel” system utilizes DDDAS framework to support autonomous operations and improve maneuverability, safety and fuel efficiency. The DDDAS “fly-by-feel\" avionics system can enhance multi-domain coordination to support domain specific operations. However, conventional enabling technologies rely on a centralized manner for data aggregation, sharing and security policy enforcement, and it incurs critical issues related to bottleneck of performance, data provenance and consistency. Inspired by the containerized microservices and blockchain technology, this paper introduces BLEM, a hybrid BLockchain-Enabled secure Microservices fabric to support decentralized, secure and efficient data fusion\n",
            "----------------------------------------\n",
            "Title: Artificial Intelligence (AI) Powered Matchmaker: Finding Your Ideal Vendor Every Time\n",
            "Abstract: In today’s fast-paced business environment, the ability to quickly and accurately identify suitable vendors is crucial for maintaining competitive advantage. Traditional vendor selection processes can be time-consuming and prone to errors, leading to suboptimal partnerships. This paper explores an AI-powered approach to vendor matchmaking, leveraging machine learning algorithms and big data analytics to enhance decision-making accuracy and efficiency. The proposed method involves a comprehensive analysis of historical vendor performance data using advanced machine learning models to evaluate vendors based on multiple criteria, including performance history, cost-effectiveness, and compliance with regulatory standards. Tools such as Python for data processing, sci-kit-learn for model development, and Matplotlib for data visualization were utilized. The dataset, spanning five years and including data on over 500 vendors, was sourced from internal business records and external market intelligence. Our findings suggest that AI-powered matchmaking significantly improves the quality of vendor selection, reducing both time and cost while increasing overall satisfaction and performance. The study underscores the transformative potential of AI in streamlining business operations and fostering strategic partnerships.\n",
            "----------------------------------------\n",
            "Title: Enhancing residential demand response through dynamic pricing forecasting\n",
            "Abstract: This study rigorously investigates the impact of demand response mechanisms in daily household operations, leveraging smart devices driven by dynamic pricing. It introduces a machine learning framework tailored for real-time predictive capabilities. The main objective is to enhance user convenience, optimize appliance management, and reduce electricity expenses by analyzing market prices. The focal point lies in monitoring and utilizing essential and non-essential devices, responsive to real-time fluctuations in grid prices throughout the day. This approach involves systematic data collection for training sophisticated models, particularly using Long Short-Term Memory (LSTM) networks. The performance of the adopted machine learning model is validated and evaluated for its ability to regulate device usage in dynamic grid pricing scenarios. Eventually, this study aims to establish a responsive and energy-efficient residential ecosystem, aligning with contemporary demands for sustainable living through cost analysis.\n",
            "----------------------------------------\n",
            "Title: Automatic Detection and Classification of Rock Microstructures through Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A systematic review and meta-analysis of groundwater level forecasting with machine learning techniques: Current status and future directions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Towards the ultimate differential SMEFT analysis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine learning for tackling microbiota data and infection complications in immunocompromised patients with cancer\n",
            "Abstract: In the last two decades, overall cancer survival has improved steadily in most developed countries; however, cancer still constitutes a significant public health problem and is the second leading cause of death worldwide [1]. Infectious complications represent an important cause of morbidity and mortality in patients with cancer, particularly in those with haematological malignancies or in haematopoietic stem cell transplantation recipients [2]. A severely impaired immune function (especially neutropenia) and the disruption of natural anatomical barriers such as the skin and mucosal surfaces, as a result of the intensive cytotoxic chemotherapy and immunosuppressive drugs, facilitate the passage of colonizing bacteria and fungi from the body niches into bloodstream, which ultimately leads to severe infectious complications. Other factors that promote the bloodstream dissemination of pathogens in these patients include the need for prolonged hospitalization, intensive care admission, as well as the extensive use of invasive procedures. The administration of empirical antibiotics has been the standard of care for chemotherapy-treated cancer patients with fever and severe neutropenia since the beginning of the 1960s, when bacterial bloodstream infections emerged as a prominent cause of death in these patients. While this approach has effectively reduced the burden of infection and saved innumerable lives, the use of multiple antibiotics decreases the commensal microbial diversity and consequently results in the profound disruption of the gut microbiota, which further increases the risk of developing bloodstream infections in patients with cancer [2]. Consequently, antibiotics that destroy the gut microbiota deplete the colonization resistance against pathogens and ultimately promote the growth of pathogenic microbial species such as Clostridium difficile (C. difficile), Candida albicans, Pseudomonas aeruginosa and other intestinal pathogens [2]. In addition, the prolonged use of broad-spectrum antibiotics has resulted in the emergence and dissemination of multidrug-resistant (MDR) pathogens, including extended-spectrum beta-lactamase-producing Escherichia coli, methicillin-resistant coagulasenegative staphylococci, vancomycin-resistant enterococci and MDR Pseudomonas aeruginosa [2].\n",
            "----------------------------------------\n",
            "Title: Crops Classification Using Machine Learning And Google Earth Engine\n",
            "Abstract: The primary objective of this study was to address the critical challenge of obtaining accurate information regarding the spatial distribution and classification of crops in agricultural areas. The aim was to enhance agricultural decision-making and management, especially in regions with limited water resources, where crop productivity and sustainability are crucial for achieving food security and sustainable development. To achieve this objective, this study utilized machine-learning classification algorithms in conjunction with Landsat and Sentinel satellite imagery. The classification of different crops was based on Normalized Difference Vegetation Index (NDVI) phenology . The classification process and post-processing were conducted using the Google Earth Engine (GEE) platform , as well as utilizing Python, and scikit-learn library. Ground-truth data provided by local experts, along with the EUROMAP 2018 dataset in South Spain, were used to label the classification results . The findings of this study demonstrated a classification accuracy of 72% for certain crop types, indicating significant implications for sustainable agricultural practices and land use planning.\n",
            "----------------------------------------\n",
            "Title: Computer-Aided Detection (CADe) and Segmentation Methods for Breast Cancer Using Magnetic Resonance Imaging (MRI).\n",
            "Abstract: Breast cancer continues to be a major health concern, and early detection is vital for enhancing survival rates. Magnetic resonance imaging (MRI) is a key tool due to its substantial sensitivity for invasive breast cancers. Computer-aided detection (CADe) systems enhance the effectiveness of MRI by identifying potential lesions, aiding radiologists in focusing on areas of interest, extracting quantitative features, and integrating with computer-aided diagnosis (CADx) pipelines. This review aims to provide a comprehensive overview of the current state of CADe systems in breast MRI, focusing on the technical details of pipelines and segmentation models including classical intensity-based methods, supervised and unsupervised machine learning (ML) approaches, and the latest deep learning (DL) architectures. It highlights recent advancements from traditional algorithms to sophisticated DL models such as U-Nets, emphasizing CADe implementation of multi-parametric MRI acquisitions. Despite these advancements, CADe systems face challenges like variable false-positive and negative rates, complexity in interpreting extensive imaging data, variability in system performance, and lack of large-scale studies and multicentric models, limiting the generalizability and suitability for clinical implementation. Technical issues, including image artefacts and the need for reproducible and explainable detection algorithms, remain significant hurdles. Future directions emphasize developing more robust and generalizable algorithms, integrating explainable AI to improve transparency and trust among clinicians, developing multi-purpose AI systems, and incorporating large language models to enhance diagnostic reporting and patient management. Additionally, efforts to standardize and streamline MRI protocols aim to increase accessibility and reduce costs, optimizing the use of CADe systems in clinical practice. LEVEL OF EVIDENCE: NA TECHNICAL EFFICACY: Stage 2.\n",
            "----------------------------------------\n",
            "Title: Analysis of the Composition of Ancient Glass and Its Identification Based on the Daen-LR, ARIMA-LSTM and MLR Combined Process\n",
            "Abstract: The glass relics are precious material evidence of the early trade and cultural exchange between the East and the West. To explore the cultural differences and trade development between early China and foreign countries, it is extremely important to classify glass cultural relics. Despite their similar appearances, Chinese glass contains more lead, while foreign glass contains more potassium. In view of this, this paper proposes a joint Daen-LR, ARIMA-LSTM, and MLR machine learning algorithm (JMLA) for the analysis and identification of the chemical composition of ancient glass. We separate the sampling points of ancient glass into two systems: lead-barium glass and high-potassium glass. Firstly, an improved logistic regression model based on a double adaptive elastic network (Daen-LR) is used to select variables with both Oracle and adaptive classification characteristics. Secondly, the ARIMA-LSTM model was used to establish the correlation curve of chemical composition before and after weathering and to predict the change in chemical composition with weathering. Thirdly, combining the data processed by the above two methods, a multiple linear regression model (MLR) is used to classify unknown glass products. It was shown that the sample obtained by this processing method has a very good fit. In comparison with other similar types of models like Decision Trees (DT), Random Forests (RF), Support Vector Machines (SVM), and Random Forests based on classification and regression trees (CART-RF), the classification accuracy of JMLA is 97.9% on the train set. The accuracy rate on the test set reached 97.6%. The results of the research demonstrate that JMLA can improve the accuracy of the glass type classification problem, greatly enhance the research efficiency of archaeological staff, and gain a more reliable result.\n",
            "----------------------------------------\n",
            "Title: Towards Inherently Interpretable Machine Learning for Healthcare\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Thermomechanical Properties of Transition Metal Dichalcogenides Predicted by a Machine Learning Parameterized Force Field.\n",
            "Abstract: The mechanical and thermal properties of transition metal dichalcogenides (TMDs) are directly relevant to their applications in electronics, thermoelectric devices, and heat management systems. In this study, we use a machine learning (ML) approach to parametrize molecular dynamics (MD) force fields to predict the mechanical and thermal transport properties of a library of monolayered TMDs (MoS2, MoTe2, WSe2, WS2, and ReS2). The ML-trained force fields were then employed in equilibrium MD simulations to calculate the lattice thermal conductivities of the foregoing TMDs and to investigate how they are affected by small and large mechanical strains. Furthermore, using nonequilibrium MD, we studied thermal transport across grain boundaries. The presented approach provides a fast albeit accurate methodology to compute both mechanical and thermal properties of TMDs, especially for relatively large systems and spatially complex structures, where density functional theory computational cost is prohibitive.\n",
            "----------------------------------------\n",
            "Title: A Resource Utilization Prediction Model for Cloud Data Centers Using Evolutionary Algorithms and Machine Learning Techniques\n",
            "Abstract: Cloud computing has revolutionized the modes of computing. With huge success and diverse benefits, the paradigm faces several challenges as well. Power consumption, dynamic resource scaling, and over- and under-provisioning issues are challenges for the cloud computing paradigm. The research has been carried out in cloud computing for resource utilization prediction to overcome over- and under-provisioning issues. Over-provisioning of resources consumes more energy and leads to high costs. However, under-provisioning induces Service Level Agreement (SLA) violation and Quality of Service (QoS) degradation. Most of the existing mechanisms focus on single resource utilization prediction, such as memory, CPU, storage, network, or servers allocated to cloud applications but overlook the correlation among resources. This research focuses on multi-resource utilization prediction using Functional Link Neural Network (FLNN) with hybrid Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The proposed technique is evaluated on Google cluster traces data. Experimental results show that the proposed model yields better accuracy as compared to traditional techniques.\n",
            "----------------------------------------\n",
            "Title: Chemistry-informed machine learning: Using chemical property features to improve gas classification performance\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Transfer Learning for sEMG-based Hand Gesture Classification using Deep Learning in a Master- Slave Architecture\n",
            "Abstract: Recent advancements in diagnostic learning and development of gesture-based human machine interfaces have driven surface electromyography (sEMG) towards significant importance. Analysis of hand gestures requires an accurate assessment of sEMG signals. The proposed work presents a novel sequential master-slave architecture consisting of deep neural networks (DNNs) for classification of signs from the Indian sign language using signals recorded from multiple sEMG channels. The performance of the master-slave network is augmented by leveraging additional synthetic feature data generated by long short term memory networks. Performance of the proposed network is compared to that of a conventional DNN prior to and after the addition of synthetic data. Up to 14% improvement is observed in the conventional DNN and up to 9% improvement in master-slave network on addition of synthetic data with an average accuracy value of 93.5% asserting the suitability of the proposed approach.\n",
            "----------------------------------------\n",
            "Title: Legal Issues of Copyright Objects Processing by AI Systems in the Process of Machine Learning\n",
            "Abstract: The research paper analyses the legal aspects of copyright objects processing by AI systems, including the legality of automated analysis of text and data in digital form — TDM (text and data mining) and machine learning. The research paper examines: the grounds for qualifying such processing as copyright infringement and certain obstacles to the full protection of copyright (including Big Data, being a subject of processing by AI systems). The paper proposes the adoption of certain public law principles of copyright objects processing by artificial intelligent systems, in particular: the principle of limited purpose, according to which the processing of works should be carried out exclusively for the purposes established by the operator of the artificial intellectual system; the principle of limited storage, which involves storing personal data (in a form accessible to identify the subjects of this data) no longer than required in-order to achieve the stated processing purposes; the principle of transparent reporting — reporting on the quantity and quality of processed data sets, accessible to any person, regardless of interest.\n",
            "----------------------------------------\n",
            "Title: A Novel Context-Sensitive SVM for Classification of Remote Sensing Images\n",
            "Abstract: In this paper, a novel context-sensitive classification technique based on Support Vector Machines (CS-SVM) is proposed. This technique aims at exploiting the promising SVM method for classification of 2-D (or n-D) scenes by considering the spatial-context information of the pixel to be analyzed. In greater detail, the proposed architecture properly exploits the spatial-context information for: i) increasing the robustness of the learning procedure of SVMs to the noise present in the training set (mislabeled training samples); ii) regularizing the classification maps. The first property is achieved by introducing a context-sensitive term in the objective function to be minimized for defining the decision hyperplane in the SVM kernel space. The second property is obtained including in the classification procedure of a generic pattern the information of neighboring pixels. Experiments carried out on very high geometrical resolution images confirm the validity of the proposed technique.\n",
            "----------------------------------------\n",
            "Title: Tensor Networks for Dimensionality Reduction and Large-scale Optimization: Part 1 Low-Rank Tensor Decompositions\n",
            "Abstract: Modern applications in engineering and data science are increasinglybased on multidimensional data of exceedingly high volume, variety,and structural richness. However, standard machine learning algorithmstypically scale exponentially with data volume and complexityof cross-modal couplings - the so called curse of dimensionality -which is prohibitive to the analysis of large-scale, multi-modal andmulti-relational datasets. Given that such data are often efficientlyrepresented as multiway arrays or tensors, it is therefore timely andvaluable for the multidisciplinary machine learning and data analyticcommunities to review low-rank tensor decompositions and tensor networksas emerging tools for dimensionality reduction and large scaleoptimization problems. Our particular emphasis is on elucidating that,by virtue of the underlying low-rank approximations, tensor networkshave the ability to alleviate the curse of dimensionality in a numberof applied areas. In Part 1 of this monograph we provide innovativesolutions to low-rank tensor network decompositions and easy to interpretgraphical representations of the mathematical operations ontensor networks. Such a conceptual insight allows for seamless migrationof ideas from the flat-view matrices to tensor network operationsand vice versa, and provides a platform for further developments, practicalapplications, and non-Euclidean extensions. It also permits theintroduction of various tensor network operations without an explicitnotion of mathematical expressions, which may be beneficial for manyresearch communities that do not directly rely on multilinear algebra.Our focus is on the Tucker and tensor train TT decompositions andtheir extensions, and on demonstrating the ability of tensor networksto provide linearly or even super-linearly e.g., logarithmically scalablesolutions, as illustrated in detail in Part 2 of this monograph.\n",
            "----------------------------------------\n",
            "Title: Comparison on Image to Image Translation Algorithms\n",
            "Abstract: Image to image translation(I2I) is one of the important parts in computer vision area. It includes lots of applications in this time. GAN provides basic theory for this problem which is an advanced method of machine learning area. The structure of GAN contains two main parts: Generator and Discriminator. This new method developed the performance of I2I problem. In this paper, five papers of I2I area using GAN method have been summarized including a paper about cGAN and a paper about cycle GAN. The rest three paper is about unsupervised learning. These five papers used different method based on GAN algorithm and can be used on different problems. Finally, there are still some problems cannot be solved in this area, this paper also discuss which problem could be development in the future.\n",
            "----------------------------------------\n",
            "Title: Machine learning based canine posture estimation using inertial data\n",
            "Abstract: The aim of this study was to design a new canine posture estimation system specifically for working dogs. The system was composed of Inertial Measurement Units (IMUs) that are commercially available, and a supervised learning algorithm which was developed for different behaviours. Three IMUs, each containing a 3-axis accelerometer, gyroscope, and magnetometer, were attached to the dogs’ chest, back, and neck. To build and test the model, data were collected during a video-recorded behaviour test where the trainee assistance dogs performed static postures (standing, sitting, lying down) and dynamic activities (walking, body shake). Advanced feature extraction techniques were employed for the first time in this field, including statistical, temporal, and spectral methods. The most important features for posture prediction were chosen using Select K Best with ANOVA F-value. The individual contributions of each IMU, sensor, and feature type were analysed using Select K Best scores and Random Forest feature importance. Results showed that the back and chest IMUs were more important than the neck IMU, and the accelerometers were more important than the gyroscopes. The addition of IMUs to the chest and back of dog harnesses is recommended to improve performance. Additionally, statistical and temporal feature domains were more important than spectral feature domains. Three novel cascade arrangements of Random Forest and Isolation Forest were fitted to the dataset. The best classifier achieved an f1-macro of 0.83 and an f1-weighted of 0.90 for the prediction of the five postures, demonstrating a better performance than previous studies. These results were attributed to the data collection methodology (number of subjects and observations, multiple IMUs, use of common working dog breeds) and novel machine learning techniques (advanced feature extraction, feature selection and modelling arrangements) employed. The dataset and code used are publicly available on Mendeley Data and GitHub, respectively.\n",
            "----------------------------------------\n",
            "Title: Neural networks empowered: a machine learning-enabled, Gyro mmID for enhanced virtual reality and motion tracking applications\n",
            "Abstract: \n",
            " With the emerging developments in millimeter-wave/5G technologies, the potential for wireless Internet of things devices to achieve widespread sensing, precise localization, and high data-rate communication systems becomes increasingly viable. The surge in interest surrounding virtual reality (VR) and augmented reality (AR) technologies is attributed to the vast array of applications they enable, ranging from surgical training to motion capture and daily interactions in VR spaces. To further elevate the user experience, and real-time and accurate orientation detection of the user, the authors proposes the utilization of a frequency-modulated continuous-wave (FMCW) radar system coupled with an ultra-low-power, sticker-like millimeter-wave identification (mmID). The mmID features four backscattering elements, multiplexed in amplitude, frequency, and spatial domains. This design utilizes the training of a supervised learning classification convolutional neural network, enabling accurate real-time three-axis orientation detection of the user. The proposed orientation detection system exhibits exceptional performance, achieving a noteworthy accuracy of 90.58% over three axes at a distance of 8 m. This high accuracy underscores the precision of the orientation detection system, particularly tailored for medium-range VR/AR applications. The integration of the FMCW-based mmID system with machine learning proves to be a promising advancement, contributing to the seamless and immersive interaction within virtual and augmented environments.\n",
            "----------------------------------------\n",
            "Title: Human activity classification using simulated micro-Dopplers and time-frequency analysis in conjunction with machine learning algorithm\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine learning approach to gait deviation prediction based on isokinetic data acquired from biometric sensors.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Financial Distress Prediction Based on Multiple Feature Subsets Ensembles\n",
            "Abstract: In order to predict financial distress effectively,This paper constructs base classifiers by integrating multiple learning algorithms such as support vector machine,multi-discriminant analysis,Logistic regression,and CART with multiple feature selection methods including t test,one way ANOVA,stepwise discriminant analysis,stepwise Logistic regression and neighborhood rough sets.And then it proposes a multiple feature subsets ensembles,which select its base classifiers using an accuracy-guided forward search and post-pruning strategy.This method does not need to calculate the diversity among the base classifiers. Firstly it implements the forward search based on the principle of maximizing the system prediction accuracy,and then chooses the combing system with the highest accuracy or a satisfied one as the final result.Using Chinese listed companies' real data as our sample data and 10 fold Cross-Validation as an assessment,an empirical study is carried out.By comparing the experiment result with the individual best base classifier and within its inside components,it indicates that this method can improve the prediction accuracy significantly and provide more flexibility to financial distress prediction.\n",
            "----------------------------------------\n",
            "Title: Validating an iOS-based Rhythmic Auditory Cueing Evaluation (iRACE) for Parkinson's Disease\n",
            "Abstract: Movement disorders such as Parkinson's disease (PD) will affect a rapidly growing segment of the population as society continues to age. Rhythmic Auditory Cueing (RAC) is a well-supported evidence-based intervention for the treatment of gait impairments in PD. RAC interventions have not been widely adopted, however, due to limitations in access to personnel, technological, and financial resources. To help \"scale up\" RAC for wider distribution, we have developed an iOS-based Rhythmic Auditory Cueing Evaluation (iRACE) mobile application to deliver RAC and assess motor performance in PD patients. The touchscreen of the mobile device is used to assess motor timing during index finger tapping, and the device's built-in tri-axial accelerometer and gyroscope to assess step time and step length during walking. Novel machine learning-based gait analysis algorithms have been developed for iRACE, including heel strike detection, step length quantification, and left-versus-right foot identification. The concurrent validity of iRACE was assessed using a clinic-standard instrumented walking mat and a pair of force-sensing resistor sensors. Results from 10 PD patients reveal that iRACE has low error rates (<±1.0%) across a set of four clinically relevant outcome measures, indicating a potentially useful clinical tool.\n",
            "----------------------------------------\n",
            "Title: Towards efﬁcient Bayesian Optimization for Big Data\n",
            "Abstract: We present a new Bayesian optimization method, environmental entropy search (EnvES), suited for optimizing the hyperparameters of machine learning algorithms on large datasets. EnvES executes fast algorithm runs on subsets of the data and probabilistically extrapolates their performance to reason about performance on the entire dataset. It considers the dataset size as an additional degree of freedom to choose freely at each step of the optimization, and sets it adaptively to trade off expected information gain about the location of the best conﬁgura-tion vs. expected time spent. We empirically evaluate EnvES for optimizing the hyperparameters of a support vector machine, showing that extrapolating performance from small to large datasets can yield a considerable speedup over standard Bayesian optimization methods.\n",
            "----------------------------------------\n",
            "Title: Cervical Cancer Diagnostics Healthcare System Using Hybrid Object Detection Adversarial Networks\n",
            "Abstract: Cervical cancer is one of the common cancers among women and it causes significant mortality in many developing countries. Diagnosis of cervical lesions is done using pap smear test or visual inspection using acetic acid (staining). Digital colposcopy, an inexpensive methodology, provides painless and efficient screening results. Therefore, automating cervical cancer screening using colposcopy images will be highly useful in saving many lives. Nowadays, many automation techniques using computer vision and machine learning in cervical screening gained attention, paving the way for diagnosing cervical cancer. However, most of the methods rely entirely on the annotation of cervical spotting and segmentation. This paper aims to introduce the Faster Small-Object Detection Neural Networks (FSOD-GAN) to address the cervical screening and diagnosis of cervical cancer and the type of cancer using digital colposcopy images. The proposed approach automatically detects the cervical spot using Faster Region-Based Convolutional Neural Network (FR-CNN) and performs the hierarchical multiclass classification of three types of cervical cancer lesions. Experimentation was done with colposcopy data collected from available open sources consisting of 1,993 patients with three cervical categories, and the proposed approach shows 99% accuracy in diagnosing the stages of cervical cancer.\n",
            "----------------------------------------\n",
            "Title: Cognitive spectrum sensing algorithm based on an RBF neural network and machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Analysis of Final Ratings in Tourism Using Various Machine Learning Techniques\n",
            "Abstract: Abstract: User-generated ratings are a tremendous asset to product descriptions and significantly impact decision-making in Context-Aware Recommender Systems. Researchers exploit this information to predict user preferences, model the item's attributes, and offer intelligible recommendations. However, not all contextual ratings are significant because they may be posted by various users for various reasons and based on different routines. Further, as users care about different attributes of multiple contexts, not all user ratings equally reflect the users' opinion of the overall rating, a primary concern in recommender systems. This article predicts the overall rating using user-user and item collaborative filtering with significant contexts and the outcome tested on various machine and deep learning models using the contextual segments.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Techniques for Network-based Intrusion Detection System: A Survey Paper\n",
            "Abstract: The rapid growth of Internet technologies and further dependence on online services, increase the demand for keeping these networks and data secure. The protection of online information is becoming even more vital to the national security and economic stability. Recently, network security has become one of the most concerning subjects in the current research and industry fields. Intrusion Detection Systems (IDSs) are considered as the backbone for network and data protection. Throughout time, different IDS approaches have been implemented to attain maximum detection accuracy. Machine learning IDS is one of the promising IDS techniques that have been created to detect known as well as unknown attacks. This paper investigates various machine learning techniques used to deploy Network-based Intrusion Detection System (NIDS). This survey could provide a more robust understanding of the existing techniques and assists intrigued researchers to identify research opportunities and investigate more in this direction.\n",
            "----------------------------------------\n",
            "Title: A Novel Framework for High-category Coverage Clothing Recommendation System Based on Sentiment Analysis\n",
            "Abstract: Users are always accustomed to checking others' reviews to determine if the product meets their expectations before purchasing clothing online. Sentiment analysis (SA) technology can effectively identify emotional feedback from numerous reviews and help users and manufacturers accurately identify product defects. However, traditional SA techniques, such as sentiment lexicons and machine learning, have limitations when dealing with large-scale datasets, it is challenging to identify clothing defects or provide extensive category recommendations accurately on high-category coverage clothing. To address this issue, this study proposes a new framework for a fine-grained feature-level SA-based high-category coverage clothing recommendation system (HCCRS). We constructed a dataset containing 82,832 clothing reviews and extracted nine clothing features that users are concerned about from questionnaires and the BERT model. We designed a hybrid SA method combining BERT and SentiStrength and built a relationship model based on feature weights and sentiment scores. The experiment results show that our method outperforms traditional lexicon-based methods by 10-25% and improves by 3% compared to BERT alone. HCCRS introduces a personalized and more authentic approach, offering a fresh perspective for clothing recommendation researchers and practitioners.\n",
            "----------------------------------------\n",
            "Title: A Comprehensive Study of Blockchain for Federated Learning Toward Safe Distributed Machine Learning Systems\n",
            "Abstract: Individuals have the ability to reveal the necessary data by using federated learning (FL), which is a possible decentralized method to deep learning. FL is in the process of rewriting the industrial paradigms that are now used for mathematical modelling and analysis in order to make it possible for an expanding range of industries to construct distributed machine learning models that are secure and safeguard users' privacy. However, when put into reality, FL’s core traits have led to problems such as insufficient protection of users' privacy, high communication costs, varied system architectures, and unreliable model uploads. In contrast to the widespread notion, adding Blockchain technology offers the FL the opportunity to significantly improve both its performance and its level of security, in addition to expanding the applications for which it may be used. is what we refer to as this hybrid form that combines elements of the block chain and FL. This article provides a comprehensive look into BCFL and discusses the implications that may be drawn from this innovative research paradigm. To begin, we will provide a brief overview of the FL technology and then discuss the challenges that it now confronts. After that, a brief summary of the Blockchain ecosystem is provided. After that, the platform as well as the structural design of BCFL are emphasized. We also examine the efforts being made to enhance the performance of FL by using Blockchain technology, as well as numerous implementations of FL incentive systems that have been integrated. In this section, we will summarize the BCFL industrial application scenarios.\n",
            "----------------------------------------\n",
            "Title: MANAGEMENT OF COMPLEX OBJECTS IN CONDITIONS OF UNCERTAINTY OF INFORMATION IN THE REGIONAL AND SECTORAL ASPECT\n",
            "Abstract: Making managerial decisions in conditions of uncertain reliability, quality and analytical significance of information is almost an everyday task for any analyst tasked with determining the future decision- making corridor. In most classifications, uncertainty is divided into informational and situational. Effective decision-making in an environment with an unobvious further outcome, which in practice happens extremely rarely, cannot be carried out without the use of special methods of expert assessments, modern technologies for systematization and data processing, as well as the latest methods of machine learning, due to the extreme complexity and complexity of modern operating environments of economic entities.\n",
            "----------------------------------------\n",
            "Title: Data Normalisation using Differential Evolution and Aggregated Logistic Functions\n",
            "Abstract: Can evolutionary algorithms discover transformation functions capable of normalising arbitrary data? Many statistical and machine learning techniques that input data is normally distributed. However, in most realistic situations the data is distinctly non-normal. Therefore predictive performance may be compromised if steps are not taken to address this issue. We propose in this paper a new algorithm in which differential evolution is used to optimise the multiple parameters of a complex data transformation function. In order to optimise the transformation function, differential evolution is guided by a statistic used to measure the normality of the resulting output data. A set of soft constraints for controlling the scale and position of the output distribution are also included. On a set of fifteen datasets which includes a mixture of artificial data drawn from various different non-normal distributions; blood glucose level data from patients with diabetes; and gene expression data; our method is shown to effectively normalise the data in most cases.\n",
            "----------------------------------------\n",
            "Title: Innovations in News Media: Crisis Classification System\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Image Generation Estimation & Analysis under Gaussian And Poisson Noise Environment Using Machine Learning\n",
            "Abstract: : In this paper we are generating the image of numbers from one to five and predicting these numbers using machine learning tool. After predicting the or estimating the number we have choose second number and add the Gaussian noise in that number with two different amounts i.e. 5%, and 50 %.We have seen the effect of noise on the number image. The same experiment was repeated with the Poisson noise environment. Finally we compare between the images affected by Gaussian and Poisson noise.\n",
            "----------------------------------------\n",
            "Title: Harnessing the power of artificial intelligence: A new door for quick surgery in Pakistan.\n",
            "Abstract: Artificial intelligence (AI) has the potential to transform surgery in Pakistan, improving results, reducing complications, and increasing patient safety. Deep learning, a branch of machine learning, can assist surgeons in making wise judgments. Pubmed and Research Gate discuss the promise of AI in surgery. Incorporating AI in healthcare systems can expedite diagnosis and management while avoiding injudicious resource allocation.\n",
            "AI-based techniques in cardiology, nephrology, and neurology enable high-accuracy detection of cardiovascular disease risks, kidney disease treatment, and epileptic episode identification. Neurological devices like bispectral index monitor (BIS) and Near-infrared spectroscopy (NIRS) utilize advanced technology for reliable monitoring and objective diagnosis of neurological issues (Ahmed, 2022). AI uses electronic data and neural network methods to evaluate operating room logistics, time management, and anesthesiologist activities using electronic data and neural network methods (Khan F. H., 2019). AI algorithms are effectively detect minute differences for accurate diagnosis, with studies showing high specificity, sensitivity, and inter-operator repeatability. AI can be used to train and assess neurosurgical residents and early mid-career surgeons, improving diagnosis and 3D simulation labs (Shlobin, 2022). Surgeons play a crucial role in adopting AI-based technologies for surgical care by partnering with data scientists to capture novel clinical data and generate meaningful interpretations. They should demand transparency and interpretability in algorithms to hold AI accountable for its predictions and recommendations.AI advancements in plastic surgery practice, research, and education offer opportunities for improvement. Combining AI-enabled decision-making tools with predictive analytics and human intuition, surgeons can make real-time decisions based on 3D planning, anatomical localization, and navigation (Rasteau, 2022). While current AI tools cannot perform complex surgical procedures, advancements may enable them to perform more complex tasks in the future.\n",
            "Pakistan is a significant market for AI-based solutions, utilizing technology in various industries to address challenges and boost demand. The country has enhanced its self-security systems, including AI-powered missiles, cyber security, and effective cameras (Khan, 2022). AI allows tasks to be completed more precisely and efficiently, with machine learning and deep learning being advanced subtypes. In developing countries like Pakistan, AI tools are needed for patient-centred diagnosis and treatment assistance, especially in emergency surgery such as cardiac illnesses or life threatening bleeding caused road traffic accident. Hence insuring patient receive care timely. An appropriate budget should be allocated for AI technologies in the health sector.\n",
            "----------------------------------------\n",
            "Title: Classifying different movement of human body based on EEG data using Machine Learning Algorithms.\n",
            "Abstract: v\n",
            "----------------------------------------\n",
            "Title: Books Received Since January 1, 1994\n",
            "Abstract: Computational Learning Theory and Natural Learning Systems: Vol. 1. Constraints and Prospects, ed. by S.J. Hanson, G.A. Drastal, and R.L. Rivest. Cambridge, MA: MIT Press, 1994.565 pp. + xii. Paper, $49.95. Vol. 2. Intersections Between Theory and Experiment, ed. by S.J. Hanson, T. Petsche, M. Keams, and R.L. Rivest. Cambridge, MA: MIT Press, 1994. 449 pp. + xxiii. Paper, $49.95. The state of the learning field: computational learning theory, neural networks, and symbolic machine learning.\n",
            "----------------------------------------\n",
            "Title: Machine learning and pharmacophore‐based prediction of allosteric modulators of Nicotinic acetylcholine receptors\n",
            "Abstract: Nicotinic acetylcholine receptors are important members of the ligand‐gated ion channel family.\n",
            "----------------------------------------\n",
            "Title: Enhancing Privacy in Federated Learning: A Practical Assessment of Combined PETs in a Cross-Silo Setting\n",
            "Abstract: Federated Learning (FL) has emerged as a revolutionary machine learning setting to enable collaborative training in a privacy-preserving way. However, recent research has showcased significant privacy attacks that pose a serious threat to the proliferation of FL as a technology designed to safeguard privacy during training with sensitive data from multiple entities. The rapid evolution of Privacy Enhancing Technologies offers promising methods for securing data inputs and outputs in FL scenarios. This paper evaluates and benchmarks the practical application of two PET methods, which has been integrated within a custom-built FL platform. The work conducts a comparative analysis of several privacy techniques applied to Federated Learning scenarios, with a primary focus on computational and communication performance.\n",
            "----------------------------------------\n",
            "Title: Malware Propagation on Social Time Varying Networks: A Comparative Study of Machine Learning Frameworks\n",
            "Abstract: Significant research into the logarithmic analysis of complex networks yields solution to help minimize virus spread and propagation over networks. This task of virus propagation is been a recurring subject, and design of complex models will yield modeling solutions used in a number of events not limited to and include propagation, dataflow, network immunization, resource management, service distribution, adoption of viral marketing etc. Stochastic models are successfully used to predict the virus propagation processes and its effects on networks. The study employs SI-models for independent cascade and the dynamic models with Enron dataset (of e-mail addresses) and presents comparative result using varied machine models. Study samples 25,000 emails of Enron dataset with Entropy and Information Gain computed to address issues of blocking targeting and extent of virus spread on graphs. Study addressed the problem of the expected spread immunization and the expected epidemic spread minimization; but not the epidemic threshold (for space constraint).\n",
            "----------------------------------------\n",
            "Title: Prediction of Body Weight by Using PCA-Supported Gradient Boosting and Random Forest Algorithms in Water Buffaloes (Bubalus bubalis) Reared in South-Eastern Mexico\n",
            "Abstract: Simple Summary Accurately estimating body weight is crucial for managing water buffalo health and optimizing feeding strategies. This study explored the effectiveness of machine learning models in predicting body weight based on body measurements. Principal component analysis was employed to reduce the dimensionality of the data and identify the most relevant features. Subsequently, Gradient Boosting and Random Forest algorithms were utilized to predict body weight using the reduced data set. The Gradient Boosting algorithm demonstrated superior performance compared to the Random Forest algorithm. These findings suggest that the combination of principal component analysis and Gradient Boosting offers a reliable and effective method for estimating body weight in water buffaloes. This approach holds promise for improving animal production and health management practices. Future research could focus on enhancing the applicability and generalizability of these models to diverse water buffalo populations across various geographical regions. Abstract This study aims to use advanced machine learning techniques supported by Principal Component Analysis (PCA) to estimate body weight (BW) in buffalos raised in southeastern Mexico and compare their performance. The first stage of the current study consists of body measurements and the process of determining the most informative variables using PCA, a dimension reduction method. This process reduces the data size by eliminating the complex structure of the model and provides a faster and more effective learning process. As a second stage, two separate prediction models were developed with Gradient Boosting and Random Forest algorithms, using the principal components obtained from the data set reduced by PCA. The performances of both models were compared using R2, RMSE and MAE metrics, and showed that the Gradient Boosting model achieved a better prediction performance with a higher R2 value and lower error rates than the Random Forest model. In conclusion, PCA-supported modeling applications can provide more reliable results, and the Gradient Boosting algorithm is superior to Random Forest in this context. The current study demonstrates the potential use of machine learning approaches in estimating body weight in water buffalos, and will support sustainable animal husbandry by contributing to decision making processes in the field of animal science.\n",
            "----------------------------------------\n",
            "Title: Integrated Calibration of Simulation Models for Autonomous Space Habitat Operations\n",
            "Abstract: Space habitats for exploration beyond low earth orbit need to provide the crew with enhanced capabilities for earth-independent operations. Mission control has traditionally been the main decision maker in anomaly response procedures, but this role will be limited in deep space due to increased communication delays. Digital simulation models are used by ground control for troubleshooting tasks and are likely to be essential assets for the crew to test \"what-if\" scenarios when important faults are detected onboard. Migrating models from mission control to a space habitat is however challenging as these models are typically heterogeneous and rely on the knowledge of sub-system specialists to be operated. Efforts have been made to automate the integration of multiple simulation models, but their calibration, i.e., the assignment of model parameters that best represent the system behavior, typically remains expert-driven and focused on individual models. To alleviate this reliance on experts and facilitate integration without human intervention, we propose leveraging the interpretable representation ability of probabilistic graphical models to encode dependencies between simulation models at the time of calibration. In this mathematical abstraction, nodes represent random variables, and edges embed causal relationships as conditional probability distributions. We build a graphical model hierarchically with a first layer of nodes representing subsystem states, and a second layer for the simulation model parameters, e.g., a set of possible slopes and intercepts of a regression model. The two layers are mapped probabilistically using domain knowledge from sub-system specialists thereby enabling the migration of reasoning capabilities from mission control to a space habitat. The created network is used to infer the most likely set of simulation parameters given the believed system state which is derived from a diagnosis module. We study the proposed mechanism by implementing it in a docking scenario. In this scenario, the crew of an incoming vehicle is performing a system readiness check before docking to a space station. An algorithm detects a CO2 removal fault, and we perform calibration accordingly using a graphical model. Three types of simulation models are being integrated via calibration, namely: (i) machine learning models trained on empirical data from a testbed of the ISS Carbon Dioxide Removal Assembly, (ii) physics-based models that were designed for this same testbed and (iii) knowledge-based models derived from NASA’s flight rules on admissible CO2 concentrations in a space habitat. We explore a method to implement such a graphical model that consists of (i) selecting a subset of system states as degrees of faulty behaviors, (ii) identifying their dependencies, i.e., defining the likelihood of cascading fault symptoms across subsystems, and (iii) selecting the simulation models that are expected to provide the most insight onboard and which can be parameterized given the network of system states established in the previous two steps. Our study reveals challenges that are to be solved for implementing this graphical model-based calibration. Specifically, it identifies a need to formalize the creation of the network for the subsystem states and to assess how to leverage existing standards for simulation model interfaces.\n",
            "----------------------------------------\n",
            "Title: Predicting pain among female survivors of recent interpersonal violence: A proof-of-concept machine-learning approach\n",
            "Abstract: Interpersonal violence (IPV) is highly prevalent in the United States and is a major public health problem. The emergence and/or worsening of chronic pain are known sequelae of IPV; however, not all those who experience IPV develop chronic pain. To mitigate its development, it is critical to identify the factors that are associated with increased risk of pain after IPV. This proof-of-concept study used machine-learning strategies to predict pain severity and interference in 47 young women, ages 18 to 30, who experienced an incident of IPV (i.e., physical and/or sexual assault) within three months of their baseline assessment. Young women are more likely than men to experience IPV and to subsequently develop posttraumatic stress disorder (PTSD) and chronic pain. Women completed a comprehensive assessment of theory-driven cognitive and neurobiological predictors of pain severity and pain-related interference (e.g., pain, coping, disability, psychiatric diagnosis/symptoms, PTSD/trauma, executive function, neuroendocrine, and physiological stress response). Gradient boosting machine models were used to predict symptoms of pain severity and pain-related interference across time (Baseline, 1-,3-,6- follow-up assessments). Models showed excellent predictive performance for pain severity and adequate predictive performance for pain-related interference. This proof-of-concept study suggests that machine-learning approaches are a useful tool for identifying predictors of pain development in survivors of recent IPV. Baseline measures of pain, family life impairment, neuropsychological function, and trauma history were of greatest importance in predicting pain and pain-related interference across a 6-month follow-up period. Present findings support the use of machine-learning techniques in larger studies of post-IPV pain development and highlight theory-driven predictors that could inform the development of targeted early intervention programs. However, these results should be replicated in a larger dataset with lower levels of missing data.\n",
            "----------------------------------------\n",
            "Title: Reference evapotranspiration estimation using machine learning approaches for arid and semi-arid regions of India\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A New Approach for Classifier Model Selection and Tuning Using Logistic Regression and Genetic Algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: GNNExplainer: Generating Explanations for Graph Neural Networks\n",
            "Abstract: Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GnnExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GnnExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GnnExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GnnExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0% in explanation accuracy. GnnExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.\n",
            "----------------------------------------\n",
            "Title: Exposure to Spoken Communication During the COVID-19 Pandemic Among Children With Cochlear Implants\n",
            "Abstract: Key Points Question Did decreases in exposure to spoken communication, found in the early stages of the COVID-19 pandemic among children using cochlear implants, resolve as lockdowns became more intermittent in later pandemic stages? Findings In this cohort study, sound environments cataloged using machine learning for cochlear implants were measured by 2746 datalogs for 262 children using cochlear implants before and during 2 years of COVID-19 lockdowns in Ontario, Canada. Due to school closures during lockdowns, school-aged children experienced significantly decreased exposure to spoken language, which has not recovered to the prepandemic baseline. Meaning This study suggests that school closures due to COVID-19 lockdowns are associated with reduced exposure to spoken communications among children using cochlear implants during sensitive periods of development.\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Prediction Model for Immediate Graft Function After Deceased Donor Kidney Transplantation\n",
            "Abstract: Background. After kidney transplantation (KTx), the graft can evolve from excellent immediate graft function (IGF) to total absence of function requiring dialysis. Recipients with IGF do not seem to benefit from using machine perfusion, an expensive procedure, in the long term when compared with cold storage. This study proposes to develop a prediction model for IGF in KTx deceased donor patients using machine learning algorithms. Methods. Unsensitized recipients who received their first KTx deceased donor between January 1, 2010, and December 31, 2019, were classified according to the conduct of renal function after transplantation. Variables related to the donor, recipient, kidney preservation, and immunology were used. The patients were randomly divided into 2 groups: 70% were assigned to the training and 30% to the test group. Popular machine learning algorithms were used: eXtreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine, Gradient Boosting classifier, Logistic Regression, CatBoost classifier, AdaBoost classifier, and Random Forest classifier. Comparative performance analysis on the test dataset was performed using the results of the AUC values, sensitivity, specificity, positive predictive value, negative predictive value, and F1 score. Results. Of the 859 patients, 21.7% (n = 186) had IGF. The best predictive performance resulted from the eXtreme Gradient Boosting model (AUC, 0.78; 95% CI, 0.71–0.84; sensitivity, 0.64; specificity, 0.78). Five variables with the highest predictive value were identified. Conclusions. Our results indicated the possibility of creating a model for the prediction of IGF, enhancing the selection of patients who would benefit from an expensive treatment, as in the case of machine perfusion preservation.\n",
            "----------------------------------------\n",
            "Title: Modeling human behavior at a large scale\n",
            "Abstract: Until recently, complex phenomena—such as human behavior and disease epidemics—have been modeled primarily at an aggregate level. Detailed studies have been limited to small domains encompassing only a few subjects, as scaling the methods involved poses considerable challenges in terms of cost, human effort required, computational bottlenecks, and data sources available. With the surge of online social media and sensor networks, the abundance of interesting and publicly accessible data is beginning to increase. However, we also need the ability to reason about it efficiently. The underlying theme of this thesis is the unification and data mining of diverse, noisy, and incomplete sensory data over large numbers of individuals. We show that the mined patterns can be leveraged in predictive models of human behavior and other phenomena at a large scale. We find that raw sensory data linked with the content of users' online communication, the explicit as well as the implicit online social interactions, and interpersonal relationships are rich information sources upon which strong machine learning models can be built. Example domains where such models apply include understanding human activities, predicting people's location and social ties from their online behavior, and predicting the emergence of global epidemics from day-to-day interpersonal interactions.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Techniques Associated With Infrared Thermography to Optimize the Diagnosis of Bovine Subclinical Mastitis\n",
            "Abstract: Bovine subclinical mastitis (SCM) is the costliest disease for the dairy industry. Technologies aimed at the early diagnosis of this condition, such as infrared thermography (IRT), can be used to generate large amounts of data that provide valuable information when analyzed using learning techniques. The objective of this study was to evaluate and optimize the use of machine learning by applying the Extreme Gradient Boosting (XGBoost) algorithm in the diagnosis of bovine SCM, based on udder thermogram analysis. Over 14 months, a total of 1035 milk samples were collected from 97 dairy cows subjected to an automatic milking system. Somatic cell counts were performed by flow cytometry, and the health status of the mammary gland was determined based on a cutoff of 200,000 cells/mL of milk. The attributes analyzed collectively included air temperature, relative humidity, temperature‐humidity index, breed, body temperature, teat dirtiness score, parity, days in milk, mammary gland position, milk yield, electrical conductivity, milk fat, coldest and hottest points in the mammary gland region of interest, average mammary gland temperature, thermal amplitude, and the difference between the average temperature of the region of interest and the animal’s body temperature, as well as the microbiological evaluation of the milk. Using the XGBoost algorithm, the most relevant variables for solving the classification problem were identified and selected to construct the final model with the best fit and performance. The best area under the receiver operating characteristic curve (AUC: 0.843) and specificity (Sp: 93.3%) were obtained when using all thermographic variables. The coldest point in the region of interest was considered the most important for decision making in mastitis diagnosis. The use of XGBoost can enhance the diagnostic capability for SCM when IRT is employed. The developed optimized model can be used as a confirmatory mechanism for SCM.\n",
            "----------------------------------------\n",
            "Title: Self-Organizing Maps Fusion: An Approach to Different Size Maps\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Examining the radius valley: a machine-learning approach\n",
            "Abstract: \n",
            " The ‘radius valley’ is a relative dearth of planets between two potential populations of exoplanets, super-Earths and mini-Neptunes. This feature appears in examining the distribution of planetary radii, but has only ever been characterized on small samples. The valley could be a result of photoevaporation, which has been predicted in numerous theoretical models, or a result of other processes. Here, we investigate the relationship between planetary radius and orbital period through two-dimensional kernel density estimator and various clustering methods, using all known super-Earths (R < 4.0RE). With our larger sample, we confirm the radius valley and characterize it as a power law. Using a variety of methods, we find a range of slopes that are consistent with each other and distinctly negative. We average over these results and find the slope to be $m=-0.319^{+0.088}_{-0.116}$. We repeat our analysis on samples from previous studies. For all methods we use, the resulting line has a negative slope, which is consistent with models of photoevaporation and core-powered mass-loss but inconsistent with planets forming in a gas-poor disc\n",
            "----------------------------------------\n",
            "Title: Distributed Programming Frameworks in Cloud Platforms\n",
            "Abstract: : Cloud computing technology has enabled storage and analysis of large volumes of data or big data. With cloud computing, a new discipline in computer science known as Data Science came into existence. Data Science is an interdisciplinary field which includes statistics, machine learning, predictive analytics and deep learning. It is meant for extracting hidden patterns from big data. Since big data consumes more storage space that cannot be accommodated with traditional storage devices, cloud computing resources of Infrastructure as a Service (IaaS) is used. Therefore, big data and big data analytics cannot exist without cloud computing. Another important fact is that big data can be subjected to analytics for obtaining Business Intelligence (BI). This process needs distributed programming frameworks like Hadoop, Apache Spark, Apache Flink, Apache Storm and Apache Samza. Without thorough understanding about these frameworks that run in cloud platforms, it is difficult to use them appropriately. Therefore, this paper throws light into a comparative study of these frameworks and evaluation of Apache Flink and Apache Spark with an empirical study. TeraSort benchmark is used for experiments.\n",
            "----------------------------------------\n",
            "Title: Transductive Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Predictive Factors for High Post-void Residual Volume in Older Females After OnabotulinumA Treatment for Severe Overactive Bladder Using a Machine Learning Model\n",
            "Abstract: Introduction Intravesical onabotulinumA injection is actively used for the treatment of overactive bladder (OAB). However, it occasionally results in significant post-void residual urine (PVR) volume, which can lead to complications and can further impair the activities of daily living in older people. Therefore, this study aimed to identify the predictors of a high post-onabotulinumA injection PVR volume in older women with severe OAB. Methods An observational study was conducted on older women who had previously received intravesical onabotulinumA injections to treat OAB between 2020 and 2022. Urodynamic studies and symptom assessments were conducted, and machine learning models, including random forest and support vector machine (SVM) models, were developed using the R code generated by Chat Generative Pre-trained Transformer 4 (ChatGPT, OpenAI, San Francisco, USA). Results Among 128 patients with OAB, 23 (18.0%) had a PVR volume of > 200 mL after receiving onabotulinumA injections. The factors associated with a PVR volume of > 200 mL were investigated using univariate and multivariate analyses. Age, frailty, OAB-wet, daytime frequency, and nocturia were significant predictors. Random forest analysis highlighted daytime frequency, frailty, and voiding efficiency as important factors. An SVM model incorporating daytime frequency, frailty, and voiding efficiency improved PVR volume prediction. Logit(p) estimation yielded an area under the receiver operating characteristic curve of 0.926294. Conclusion The study found daytime frequency, frailty, and voiding inefficiency to be significant factors associated with a PVR volume of > 200 mL, in older women with severe OAB. Utilizing advanced machine learning techniques and following the guidance of ChatGPT, this research emphasizes the relevance of considering multiple intersecting factors for predicting PVR volume. The findings contribute to our understanding of onabotulinumA injection treatment for OAB and support evidence-based decision-making using readily available information.\n",
            "----------------------------------------\n",
            "Title: Synaptic Learning of Long-Term Cognitive Networks with Inputs\n",
            "Abstract: In contrast with the extense variety of machine learning algorithms, to fully automate the reasoning process, only a few can take advantage of the expert knowledge. Fuzzy Cognitive Maps (FCMs) are neural networks that can naturally integrate this kind of knowledge in the inference process. Nevertheless, FCMs have serious drawbacks difficult to overcome from the absence of an intrinsically learning algorithm or limited prediction horizon of the activation space of the neurons. Recently, some variants of the FCMs like Short-Term Cognitive Networks (STCN) and Long Term Cognitive Networks (LTCN) have been proposed to solve these problems. In this paper, we propose a new neural network model as a variant of LTCNs called Long-Term Cognitive Networks with Inputs (LTCNIs). A new kind of input neuron which is not present in the traditional FCMs approach or the derived algorithms STCNs and LTCNs is introduced, in order to model inputs like energy or mass in physical systems. The performance of the method is discussed through the modeling of a passive circuit problem. As a second contribution, a new flexible reasoning strategy, which preserves the expert knowledge through synaptic learning is presented. A synaptic learning based on a gradient descent method is implemented limited by a set of restrictions that preserves the model semantics.\n",
            "----------------------------------------\n",
            "Title: A Hybrid Model for Medical Data Using Machine Learning Approaches\n",
            "Abstract: — Clustering is the process of grouping data into clusters, where objects within each cluster have high similarity, but are dissimilar to the objects in other clusters. The K-means algorithm is used for clustering large sets of data. The accuracy of the K-Means depends upon the selection of Centroids. The execution of the standard K-Means algorithm need to reassign the data points a number of times, during every iteration of the loop. The hybrid approach that includes both K-Means algorithm and genetic algorithm yields good result in the process of clustering. In this study, we proposed an implementation of genetic algorithm which we investigate the quality of clustering technique compared with standard K-Means clustering algorithm using the Medical data set.\n",
            "----------------------------------------\n",
            "Title: Deep Learning in Medical Research\n",
            "Abstract: Deep Learning proposed by Hinton[1] is a new learning algorithm of multi-layer neural network and is a type of machine learning . Deep Learning helps researchers analyze medical data to treat disease. It also helps in diagnosis of disease in early stages like cancer, Alzheimer’s disease and so on. This paper analyzes research directions and future prospects of Deep Learning in medical field which help patients to enhance quality of life. Also ease doctors to make strong predictions on basis of datasets previewed.\n",
            "----------------------------------------\n",
            "Title: Performance Evaluation of Predictive Machine Learning Models for Diabetic Disease Using Python\n",
            "Abstract: The discovery of knowledge from medical database is always beneficial as well as challenging task for diagnosis. For example, patients having high blood glucose are required to diagnose as they fall within a group of Diabetes mellitus. Prediction of diabetes mellitus is an essential research in the domain of medical industry. With the advent of artificial intelligence and machine learning this type of prediction removes the hurdles faced in data mining used for similar task. In case of data mining, extraction of knowledge from information stored in database takes place and an understandable description of patterns is achieved. A large number of researches have been already taken place to predict diabetes using traditional machine learning algorithm such as artificial neural network, Naïve Bayes theorem, decision tree, etc. However, determination of diabetes with a certain degree of confidence is required from the accuracy or any other performance measures point of view. In this context, this research work presents machine learning models such as decision tree, support vector machine, random forest, k-nearest neighbours and Naïve-Bayes as classifier to classify whether a patient is diabetic or prone to diabetic. Performance measures of these algorithms have been carried out in terms of accuracy score. Dataset for training and testing the algorithms mentioned is retrieved from Pima Indian Database. On the basis of their comparative evaluation, most important feature with respect to identification of diabetic is extracted. A complete python code has been developed for this research work.\n",
            "----------------------------------------\n",
            "Title: IDRMutPred: predicting disease-associated germline nonsynonymous single nucleotide variants (nsSNVs) in intrinsically disordered regions\n",
            "Abstract: Abstract Motivation Despite of the lack of folded structure, intrinsically disordered regions (IDRs) of proteins play versatile roles in various biological processes, and many nonsynonymous single nucleotide variants (nsSNVs) in IDRs are associated with human diseases. The continuous accumulation of nsSNVs resulted from the wide application of NGS has driven the development of disease-association prediction methods for decades. However, their performance on nsSNVs in IDRs remains inferior, possibly due to the domination of nsSNVs from structured regions in training data. Therefore, it is highly demanding to build a disease-association predictor specifically for nsSNVs in IDRs with better performance. Results We present IDRMutPred, a machine learning-based tool specifically for predicting disease-associated germline nsSNVs in IDRs. Based on 17 selected optimal features that are extracted from sequence alignments, protein annotations, hydrophobicity indices and disorder scores, IDRMutPred was trained using three ensemble learning algorithms on the training dataset containing only IDR nsSNVs. The evaluation on the two testing datasets shows that all the three prediction models outperform 17 other popular general predictors significantly, achieving the ACC between 0.856 and 0.868 and MCC between 0.713 and 0.737. IDRMutPred will prioritize disease-associated IDR germline nsSNVs more reliably than general predictors. Availability and implementation The software is freely available at http://www.wdspdb.com/IDRMutPred. Supplementary information Supplementary data are available at Bioinformatics online.\n",
            "----------------------------------------\n",
            "Title: A Survey of Privacy Attacks in Machine Learning\n",
            "Abstract: As machine learning becomes more widely used, the need to study its implications in security and privacy becomes more urgent. Although the body of work in privacy has been steadily growing over the past few years, research on the privacy aspects of machine learning has received less focus than the security aspects. Our contribution in this research is an analysis of more than 45 papers related to privacy attacks against machine learning that have been published during the past seven years. We propose an attack taxonomy, together with a threat model that allows the categorization of different attacks based on the adversarial knowledge, and the assets under attack. An initial exploration of the causes of privacy leaks is presented, as well as a detailed analysis of the different attacks. Finally, we present an overview of the most commonly proposed defenses and a discussion of the open problems and future directions identified during our analysis.\n",
            "----------------------------------------\n",
            "Title: Machine learning-based image analysis for PM2.5 measurement\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Optimum Maintenance Strategy of a Repairable System Under Long-Term Free Preventive Maintenance Warranty with Predicted Maintenance\n",
            "Abstract: In this paper, the optimum user’s maintenance strategy of a repairable system for free preventive maintenance (PM) warranty policy is proposed. This study considers predicted maintenance due to the system failure is likely occurring and requires repair during periodic maintenance time. Periodic maintenance can be classified as one of three types — imperfect PM, perfect PM and predicted maintenance. The probability that periodic maintenance is perfect PM or predicted maintenance depends on the number of imperfect maintenance operations conducted since the previous renewal cycle. The sellers offer free perfect and imperfect PM warranty. An optimal periodic maintenance time is determined by minimizing the total cost. Some special cases, implemented with machine learning and human learning, are given to demonstrate the feasibility of the proposed strategy. A numerical example is given.\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning to Demystify Startups Funding, Post-Money Valuation, and Success\n",
            "Abstract: This chapter develops a novel approach to predict post-money valuation of startups across various regions and sectors, as well as their probabilities of success. Using startup funding data and descriptions from Crunchbase over a ten-year period, we develop two models linking information such as description, region, and venture capital funding to successful outcomes such as the achievement of an acquisition or IPO. The first model utilizes latent Dirichlet allocation, a generative statistical model in natural language processing, to organize the startups in the dataset into clusters representing various sectors in the typical economy. An optimized distributed gradient boosting regressor (XGBoost) is subsequently deployed to make use of the resultant feature set to predict post-money valuation, with Bayesian optimization used to find the optimal hyperparameters. Our model consistently achieves an accuracy of over 95% on hold-out test sets, even with some continuous features removed. The second model is a feed-forward neural network constructed using TensorFlow, with the final layer providing probabilities of success.We find that post-money valuations across regions are typically log-normally distributed, and startups in regions such as San Francisco Bay Area typically witness higher valuations across most sectors. We also find that startups operating in specific geographical regions and sectors of economy (e.g., regions and sectors with higher number of investors) typically have higher predicted probabilities of success. Our approach offers an empirical perspective to startups, policymakers, and venture funds to benchmark and predict valuation and success, clearing some opacity in the modern startup economy.\n",
            "----------------------------------------\n",
            "Title: Achieving Technological Equity and Equal Access to the Learning Tools of the 21st Century\n",
            "Abstract: Is there a problem of technology equity in our schools? Just ask the kids and teachers who use it. Even better, ask those who can't access it enough or at all. Technology's new tools are seen as empowering, productive and motivational. They make learning fun; more importantly, they let the user both access and create new realms of knowing and doing. But there simply aren't enough of these learning tools to go around, and many learners are being denied access. School decision-makers are aware of the critical need for broader technology access. Parents, too, recognize the importance and, those who can, provide it at home. Employers tell us that nearly all workers entering the job market in this next century need to have an expanded set of technical skills in communication, problem-solving and production. Productivity and profit will both be linked to workers' effective uses of new technologies. Many high school graduates can't compete for entry-level technical jobs. Once hired, they're unable to progress to more responsible, remunerative levels of their chosen professions. Inequities of class, gender, ethnicity and economic disparity correlate highly with denied or restricted access to the tools of technology. The have-nots have increasingly less. When it comes to gaining greater access, many groups and classes are simply unable. The resources are just not there. Futurists tell us that tomorrow's workers who want to stay employed, or be re-employed, will need the skill of learning new skills. Technology will be the common link among most of tomorrow's jobs. Our growth as a national power has depended largely on the expertise of our workers. If our schools fail to pass on these new skills, there may not be another opportunity. Inequity of access to today's new tools becomes tomorrow's enduring societal loss. The State of Technology Students don't have to share pencils. Most teachers even have their own overhead projectors, and certainly their own chalkboards. But when it comes to technology, there clearly isn't enough to go around. Yes, it does cost a lot more than paper and pencils: camcorders and computers are hundreds to thousands of dollars apiece. Most schools don't have the funds to address the issue of adequate access, let alone equity. In Minnesota's Saint Paul Public Schools, there are 13 students to each computer. That's not quite as attractive as our state average of about 10:1 and the national ratio of 11:1. Ratios vary considerably among the 16,000 school districts and, taken alone, don't tell us much about equity of usage, anyway. Many of our district's computers are older, less-powerful machines without high-resolution color, CD-ROMs or Internet access. We need to remind ourselves, too, that there's more to technology tools than computers. Video tools are smaller and more powerful. New camcorders are hand-held and with editing features formerly found only on more expensive equipment. We find technology permeating new areas, enriching music, art and industrial/vocational education. But, it's not just the number of tools we make available, the number of new features makes a difference, too. Newer technologies are functionally different than a decade ago. We see far more powerful tools, which let us move from thinking to doing, to modifying, to creating. Knowledge and information are made more accessible to both learners and teachers. Special needs students are also major beneficiaries of these new tools. For the first time, technology makes learning accessible to many challenged students. While a convenience for some learners, technology can be an absolute necessity for others. Instead of adapting our needs to technology, these new tools are better able to adapt to us and our unique learning needs. Equity Issues A recent search disclosed few current articles on the topic of equity and technology. However, Neuman's 1991 article[1] was helpful in clarifying who are the technology \"have-nots. …\n",
            "----------------------------------------\n",
            "Title: Positioning for conceptual development using latent semantic analysis Conference or Workshop Item\n",
            "Abstract: With increasing opportunities to learn online, the problem of positioning learners in an educational network of content offers new possibilities for the utilisation of geometry-based natural language processing techniques. In this article, the adoption of latent semantic analysis (LSA) for guiding learners in their conceptual development is investigated. We propose five new algorithmic derivations of LSA and test their validity for positioning in an experiment in order to draw back conclusions on the suitability of machine learning from previously accredited evidence. Special attention is thereby directed towards the role of distractors and the calculation of thresholds when using similarities as a proxy for assessing conceptual closeness. Results indicate that learning improves positioning. Distractors are of low value and seem to be replaceable by generic noise to improve threshold calculation. Furthermore, new ways to flexibly calculate thresholds could be identified.\n",
            "----------------------------------------\n",
            "Title: Use of machine learning to identify relevant research publications in clinical oncology.\n",
            "Abstract: 6558 Background: Finding high-quality science to support decisions for individual patients is challenging. Common approaches to assess clinical literature quality and relevance rely on bibliometrics or expert knowledge. We describe a method to automatically identify clinically relevant, high-quality scientific citations using abstract content. Methods: We used machine learning trained on text from PubMed papers cited in 3 expert resources: NCCN, NCI-PDQ, and Hemonc.org. Balanced training data included text cited in at least two sources to form an “on topic” set (i.e., relevant and high quality), and an “off-topic” set, not cited in any of the above 3 sources. The off-topic set was published in lower ranked journals, using a citation-based score. Articles were part of an Oncology Clinical Trial corpus generated using a standard PubMed query. We used a gradient boosted-tree approach with a binary logistic supervised learning classification. Briefly, 988 texts were processed to produce a term frequency-inverse document frequency (tf-idf) n-gram representation of both the training and the test set (70/30 split). Ideal parameters were determined using 1000-fold cross validation. Results: Our model classified papers in the test set with 0.93 accuracy (95% CI (0.09:0.96) p ≤ 0.0001), with sensitivity 0.95 and specificity 0.91. Some false positives contained language considered clinically relevant that may have been missed or not yet included in expert resources. False negatives revealed a potential bias towards chemotherapy-focused research over radiation therapy or surgical approaches. Conclusions: Machine learning can be used to automatically identify relevant clinical publications from biographic databases, without relying on expert curation or bibliometric methods. The use of machine learning to identify relevant publications may reduce the time clinicians spend finding pertinent evidence for a patient. This approach is generalizable to cases where a corpus of high-quality publications that can serve as a training set exists or cases where document metadata is unreliable, as is the case of “grey” literature within oncology and beyond to other diseases. Future work will extend this approach and may integrate it into oncology clinical decision-support tools.\n",
            "----------------------------------------\n",
            "Title: Learning Expressive Models of Gene Regulation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Review of Metaheuristic Optimization for Network Traffic Management in Telecommunications\n",
            "Abstract: This review aims to identify metaheuristic optimization and machine learning in the context of network management in the current era and some graphs of real network applications, such as traffic prediction, resource assignment, and network protection. Bio-inspired meta-functions, which model heuristic approaches to problem-solving in nature, have been shown to provide the best solutions to the OP problem and possess properties that make them ideal for optimizing dynamic networks. In the same vein, neural networks and reinforcement learning models have also performed significantly better in optimizing network performance by providing precise forecasts and decision-making adaptabilities. Incorporating these methodologies into folded working models has facilitated the development of solutions for the more complicated new networks such as SDNs, MANETs and IoTs. This review consolidates the most recent work in this field while identifying new advances as revolutionary technologies for refining the next-generation networks; it discusses possible paths for future research to overcome the existing drawbacks.\n",
            "----------------------------------------\n",
            "Title: Efficient Model Quality Evaluation in Federated Learning via Functional Encryption\n",
            "Abstract: Federated Learning(FL) is a distributed machine learning paradigm that exchanges data among multiple parties without directly sharing the original data. However, FL faces the inherent issue of statistical heterogeneity. Recently, some privacy preserving federated learning scheme have considered this issue. But they use homomorphic encryption, which imposes significant computational and communication overhead on the clients. To address this issue, we propose an efficient model quality evaluation scheme in FL via functional encryption. Specifically, we first use inner product functional encryption(IPFE) to efficiently and securely calculate the cosine similarity between global update and each local update on the server, then use clustering algorithm to assign weights to each client based on cosine similarity, and finally update the global model through weighted aggregation. Experimental results show that compared with other model quality evaluation scheme, our approach increases the computational efficiency by up to 25% and reduces communication cost by up to 70%.\n",
            "----------------------------------------\n",
            "Title: FedACA: An Adaptive Communication-Efficient Asynchronous Framework for Federated Learning\n",
            "Abstract: Federated Learning (FL) is a type of distributed machine learning, which avoids sharing privacy and sensitive data with a central server. Despite the advances in FL, current approaches cannot provide satisfactory performance when dealing with heterogeneity in data and unpredictability of system devices. First, straggler devices can adversely impact convergence speed of the global model training. Second, for model aggregation in traditional FL, edge devices communicate frequently with a central server using their local updates. However, this process may encounter communication bottleneck caused by substantial bandwidth usage. To address these challenges, this paper presents an adaptive, communication-efficient and asynchronous FL technique called FedACA comprising feedback loops at two levels. Our approach contains a self-adjusting local training step with active participant selection to accelerate the convergence of the global model. To reduce the communication overhead, FedACA supports an adaptive uploading policy at the edge devices, which leverages the model similarity and L2-norm differences between the current and previous local gradient. It also utilizes contrastive learning to tackle data heterogeneity by regularizing the local training if the local model has deviated from the global model and helps with the model similarity measurement in the uploading policy. Extensive experiments on a benchmark comprising three image datasets with non-independent and identically distributed (non-i.i.d) data show that FedACA adapts well to the straggler effect in asynchronous environments and also provides significant reductions in communication costs compared to other state-of-the-art FL algorithms.\n",
            "----------------------------------------\n",
            "Title: Enhancing Named Entity Recognition in Twitter Messages Using Entity Linking\n",
            "Abstract: In this paper, we describe our approach for Named Entity Recognition in Twitter, a shared task for ACL 2015 Workshop on Noisy User-generated Text (Baldwin et al., 2015). Because of the noisy, short, and colloquial nature of Twitter, the performance of Named Entity Recognition (NER) degrades significantly. To address this problem, we propose a novel method to enhance the performance of the Twitter NER task by using Entity Linking which is a method for detecting entity mentions in text and resolving them to corresponding entries in knowledge bases such as Wikipedia. Our method is based on supervised machine-learning and uses the highquality knowledge obtained from several open knowledge bases. In comparison with the other systems proposed for this shared task, our method achieved the best performance.\n",
            "----------------------------------------\n",
            "Title: Combining machine and deep transfer learning for mediastinal lymph node evaluation in patients with lung cancer\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine Learning from Noisy Information\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Proceedings of the 20th ACM international conference on Multimedia\n",
            "Abstract: We are delighted to welcome you to 20th ACM International Conference on Multimedia, ACM Multimedia 2012, which is held from October 29th to November 2nd, 2012 in Nara, Japan. Welcome to Japan's ancient capital, the cradle of Japanese culture and final destination of the Silk Road. \n",
            " \n",
            "Like the Silk Road of ancient times, multimedia today provides a medium allowing the diverse exchange of ideas across many fields including signal processing, information retrieval, machine learning, content analysis, networking, applications, human-centered systems, art and education and many more. Because of this confluence, multimedia has become one of the fastest growing and most interesting areas in Computer Science. It is again in 2012 that Nara, Japan is a final destination, this time for sharing ideas in multimedia. ACM Multimedia is the premier conference and worldwide event bringing together multimedia experts and practitioners across academia and industry. The central feature of the conference, which continues this year as in every year since its inception, is the outstanding Technical Program. This year's conference features both oral and poster presentations covering all aspects of the multimedia field chosen through a highly selective review process. Notably, this year's conference includes special Technical Program activities recognizing the 20th anniversary of ACM Multimedia. \n",
            " \n",
            "In addition to the Technical Program, this year's conference features a diverse range of activities including Panels, Demonstrations and Tutorials. Additionally, a wide array of Workshops brings focus on new topics for investigation. The conference features also special sessions on Brave New Ideas, a Grand Challenge contest and Open Source Software Competition and includes a Doctoral Symposium for mentoring graduate students. Finally, the conference provides a rich Multimedia Art Exhibition to stimulate artists and researchers alike to meet and discover the frontiers of multimedia artistic communication! \n",
            " \n",
            "The 20th Anniversary Keynote Talk and 20th Anniversary Panel This year celebrates the 20th Anniversary of ACM Multimedia, which was first initiated by the ACM SIGMM in 1993. To mark this auspicious occasion, the conference features a 20th Anniversary Keynote Talk and a 20th Anniversary Panel. These two events reflect on major milestones and achievements in multimedia as well as discuss promising ideas and directions for the future. \n",
            " \n",
            "Innovations for this Year's Conference: In attempt to continuously improve ACM Multimedia and ensure its vibrant role for the multimedia community, we have made a number of enhancements for this year's conference: \n",
            "The Technical Program Committee defined eleven Technical Areas for major focus for this year's conference, including introducing new Technical Areas for Multimedia Activity and Event Understanding and Social Media to reflect their growing interest and promise. \n",
            "Technical Short Papers are presented as plenary posters to make them more visible at this year's conference, which reflects the growing quality of short papers. \n",
            "Plenary sessions bring singular focus to conference activities in the morning sessions each day, and afternoon sessions are held in parallel to allow pursuit of more specialized interests at the conference. \n",
            "Workshops and Tutorials are held on separate days from the main conference in order to reduce conflict with the regular Technical Program. \n",
            "Since Workshops are important seeds for the next generation of multimedia, two complementary workshop registrations are provided for invited talks of each workshop to encourage participation of notable speakers. \n",
            "The Multimedia Art Exhibition features both invited and selected artists and is open for two weeks in the satellite venue close to the main conference with good public access, which allows stimulation broadly to visitors to Nara. \n",
            "nFollowing the last year's precedent, Tutorials are made free for all participants. \n",
            "Recognizing that students are the lifeblood of our next generation of multimedia thinkers, this year's Student Travel Grant is greatly expanded.\n",
            "----------------------------------------\n",
            "Title: Automatic assessment of students' software models using a simple heuristic and machine learning\n",
            "Abstract: Software models are increasingly popular. To educate the next generation of software engineers, it is important that they learn how to model software systems well, so that they can design them effectively in industry. It is also important that instructors have the tools that can help them assess students' models more effectively. In this paper, we investigate how a tool that combines a simple heuristic with machine learning techniques can be used to help assess student submissions in model-driven engineering courses. We apply our proposed technique to first identify submissions of high quality and second to predict approximate letter grades. The results are comparable to human grading and a complex rule-based technique for the former and surprisingly accurate for the latter.\n",
            "----------------------------------------\n",
            "Title: Ego-motion and Surrounding Vehicle State Estimation Using a Monocular Camera\n",
            "Abstract: Understanding ego-motion and surrounding vehicle state is essential to enable automated driving and advanced driving assistance technologies. Typical approaches to solve this problem use fusion of multiple sensors such as LiDAR, camera, and radar to recognize surrounding vehicle state, including position, velocity, and orientation. Such sensing modalities are overly complex and costly for production of personal use vehicles. In this paper, we propose a novel machine learning method to estimate ego-motion and surrounding vehicle state using a single monocular camera. Our approach is based on a combination of three deep neural networks to estimate the 3D vehicle bounding box, depth, and optical flow from a sequence of images. The main contribution of this paper is a new framework and algorithm that integrates these three networks in order to estimate the ego-motion and surrounding vehicle state. To realize more accurate 3D position estimation, we address ground plane correction in real-time. The efficacy of the proposed method is demonstrated through experimental evaluations that compare our results to ground truth data available from other sensors including Can-Bus and LiDAR.\n",
            "----------------------------------------\n",
            "Title: Causally Colored Reflections on Leo Breiman's \"Statistical Modeling: The Two Cultures\" (2001)\n",
            "Abstract: Abstract:This note provides a re-assessment of Breiman's contributions to the art of statistical modeling, in light of recent advances in machine learning and causal inference. It highlights the crisp separation between the data-fitting and data-interpretation components of statistical modeling.\n",
            "----------------------------------------\n",
            "Title: Bilinear Scoring Function Search for Knowledge Graph Learning\n",
            "Abstract: Learning embeddings for entities and relations in knowledge graph (KG) have benefited many downstream tasks. In recent years, scoring functions, the crux of KG learning, have been human designed to measure the plausibility of triples and capture different kinds of relations in KGs. However, as relations exhibit intricate patterns that are hard to infer before training, none of them consistently perform the best on benchmark tasks. In this paper, inspired by the recent success of automated machine learning (AutoML), we search bilinear scoring functions for different KG tasks through the AutoML techniques. However, it is non-trivial to explore domain-specific information here. We first set up a search space for AutoBLM by analyzing existing scoring functions. Then, we propose a progressive algorithm (AutoBLM) and an evolutionary algorithm (AutoBLM+), which are further accelerated by filter and predictor to deal with the domain-specific properties for KG learning. Finally, we perform extensive experiments on benchmarks in KG completion, multi-hop query, and entity classification tasks. Empirical results show that the searched scoring functions are KG dependent, new to the literature, and outperform the existing scoring functions. AutoBLM+ is better than AutoBLM as the evolutionary algorithm can flexibly explore better structures in the same budget.\n",
            "----------------------------------------\n",
            "Title: Host microbiomes in tumor precision medicine: how far are we?\n",
            "Abstract: The human gut microbiome has received a crescendo of attention in recent years, due to the countless influences on human pathophysiology, including cancer. Research on cancer and anticancer therapy is constantly looking for new hints to improve the response to therapy while reducing the risk of relapse. In this scenario, the gut microbiome and the plethora of microbial-derived metabolites are considered a new opening in the development of innovative anticancer treatments for a better prognosis. This narrative review summarizes the current knowledge on the role of the gut microbiome in the onset and progression of cancer, as well as in response to chemo-immunotherapy. Recent findings regarding the tumor microbiome and its implications for clinical practice are also commented on. Current microbiome-based intervention strategies (i.e., prebiotics, probiotics, live biotherapeutics and fecal microbiota transplantation) are then discussed, along with key shortcomings, including a lack of long-term safety information in patients who are already severely compromised by standard treatments. The implementation of bioinformatic tools applied to microbiomics and other omics data, such as machine learning, has an enormous potential to push research in the field, enabling the prediction of health risk and therapeutic outcomes, for a truly personalized precision medicine.\n",
            "----------------------------------------\n",
            "Title: Research Aligned Analysis on Web Access Behavioral Pattern Mining for User Identificationa\n",
            "Abstract: Human activity understanding includes activity recognition and activity pattern discovery. Monitoring human activity and finding abnormality in their activities used by many field like medical applications, security systems etc. Basically it helps and support in decision making systems. Mining user activity from web logs can helps in finding hidden information about the user access pattern which reveals the web access behaviour of the users. Clustering and Classification techniques are used for web user identification. Clustering is the task of grouping similar patterns for web user identification. Classification is the process of classifying web patterns for user identification. In this paper we have implemented the existing works and discussed the results here to find the limitations. In existing methods, many data mining techniques were introduced for web user behaviour identification. But, the user identification accuracy was not improved and time consumption was not reduced. Our objective is to study the existing work and explore the possibility to improve the identification accuracy and reduce the time consumption using machine learning and deep learning techniques\n",
            "----------------------------------------\n",
            "Title: SAAFEC-SEQ: A Sequence-Based Method for Predicting the Effect of Single Point Mutations on Protein Thermodynamic Stability\n",
            "Abstract: Modeling the effect of mutations on protein thermodynamics stability is useful for protein engineering and understanding molecular mechanisms of disease-causing variants. Here, we report a new development of the SAAFEC method, the SAAFEC-SEQ, which is a gradient boosting decision tree machine learning method to predict the change of the folding free energy caused by amino acid substitutions. The method does not require the 3D structure of the corresponding protein, but only its sequence and, thus, can be applied on genome-scale investigations where structural information is very sparse. SAAFEC-SEQ uses physicochemical properties, sequence features, and evolutionary information features to make the predictions. It is shown to consistently outperform all existing state-of-the-art sequence-based methods in both the Pearson correlation coefficient and root-mean-squared-error parameters as benchmarked on several independent datasets. The SAAFEC-SEQ has been implemented into a web server and is available as stand-alone code that can be downloaded and embedded into other researchers’ code.\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Based Multi-Room Indoor Localization Using Fingerprint Technique\n",
            "Abstract: Nowadays, developing Wi-Fi-based indoor localization systems has become an attractive research topic due to the growing need for pervasive location determination. The fingerprint technique offers higher positioning accuracy in indoor localization than the distance-based technique. Fingerprint-based techniques via machine learning have been proposed for many years to provide high-accuracy indoor localization services. These works attempt to establish the optimal correlation between the user fingerprint and a pre-defined set of grid points on a radio map. In this paper, a comparative analysis of selected machine learning algorithms is conducted within the context of online phase fingerprint techniques for localization, focusing on implementation in a multi-room case. The experiment involves measurements using a Wi-Fi module in a laboratory, an aisle, a lobby, and a typical classroom, resulting in a small-sized fingerprint database covering a total area of 573.71 m2. The results reveal that Naïve Bayes (NB) obtains the highest localization accuracy in the laboratory and classroom. Meanwhile, Support Vector Machine (SVM) outperforms other algorithms in the aisle, while K-Nearest Neighbor (KNN) delivers the best accuracy in the lobby. In summary, NB, KNN, and SVM are suitable pattern-matching algorithms for multi-room indoor localization and relatively small fingerprint databases.\n",
            "----------------------------------------\n",
            "Title: Abstract 060: Association Of Antecedent Statin Use With Outcomes Of People With Covid-19 Admitted At Northwestern Medicine Health System\n",
            "Abstract: \n",
            " Background:\n",
            " Several observational studies have found that antecedent statin use (i.e., use prior to getting admitted) was associated with lower mortality risk in hospitalized COVID-19 patients, but this is not a consistent finding. Differences maybe due to covariate imbalance, model misspecification, or selection bias.\n",
            " \n",
            " \n",
            " Objective:\n",
            " Estimate the association of antecedent statin use with adverse outcomes (in-hospital death, intubation, ICU admission) in patients admitted for COVID-19 in an academic health system in Chicago.\n",
            " \n",
            " \n",
            " Methods:\n",
            " We analyzed electronic health records from an academic health system in Chicago (Mar ‘20-Mar ‘21) comparing rates of adverse events (composite and per outcome) between antecedent users and non-users. Eligible individuals were ≥40 years old in Illinois, admitted for ≥24 hours, and tested positive for COVID-19 in the 30 days before to 7 days after admission. Antecedent use is defined as existence of statins prescription ≥30 days before admission. We used augmented inverse probability weighting (AIPW) with targeted maximum likelihood estimation to improve covariate balance and estimate the risk difference. Compared to standard methods, this approach allowed use of machine learning models and is doubly robust to misspecification.\n",
            " \n",
            " \n",
            " Results:\n",
            " Of 6267 admitted, 1337 (20%) were antecedent users. Users tend to be older, male, White, smoke, and have a comorbidity. Unadjusted analysis showed significantly higher rates of negative outcomes in non-users except in-hospital death. Analysis using AIPW improved covariate balance and showed that users had significantly lower rates of the composite outcome (RD: -3.9%, 95%CI: -6.0, -1.9) and ICU admissions (RD: -4.0, 95%CI: -7.0, -1.0). No differences in intubation and mortality rates were detected.\n",
            " \n",
            " \n",
            " Conclusion:\n",
            " Antecedent statin use is associated with lower risk of ICU admissions but not with intubation or in-hospital mortality. We were not able to confirm the mortality benefit detected by prior studies nor any differences in rates of intubations.\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "----------------------------------------\n",
            "Title: An evaluation of machine learning and latent semantic analysis in text sentiment classification\n",
            "Abstract: Abstract In this paper, we compare the following machine learning methods as classifiers for sentiment analysis: k – nearest neighbours (kNN), artificial neural network (ANN), support vector machine (SVM), random forest. We used a dataset containing 5,000 movie reviews in which 2,500 were marked as positive and 2,500 as negative. We chose 5,189 words which have an influence on sentence sentiment. The dataset was prepared using a term document matrix (TDM) and classical multidimensional scaling (MDS). This is the first time that TDM and MDS have been used to choose the characteristics of text in sentiment analysis. In this case, we decided to examine different indicators of the specific classifier, such as kernel type for SVM and neighbour count in kNN. All calculations were performed in the R language, in the program R Studio v 3.5.2. Our work can be reproduced because all of our data sets and source code are public.\n",
            "----------------------------------------\n",
            "Title: Catastrophic risk management: Stochastic hybrid model to calculate the loss index trigger for catastrophe bonds (cat bonds). Adjustment using evolutionary strategies\n",
            "Abstract: Purpose: This paper develops a stochastic model to calculate the loss index trigger for catastrophe bonds as alternative instruments for the management of major insured risks, such as natural catastrophe. Methodology: The underlying loss index of catastrophe bonds is the aggregate catastrophe losses reported before the end of certain period. The catastrophe severity is defined as the sum of two random variable: the reported loss amount and incurred-but-not-yet-reported loss amount, and the central hypothesis is that the latter decreases proportionally to a linearly increasing function up to a certain time and constant thereafter, called the hybrid claim reporting rate. Randomness in the reporting process is represented by a geometric Brownian motion in the claim reporting rate. The validity of the proposed model is evaluated by estimating its parameters using machine learning techniques (specifically, evolutionary strategies, ES). Findings: The results shows that the model accurately captures the uneven behavior of the claim reporting process over time and therefore correctly describes the catastrophic claims reporting process. Originality: The model proposed allows for an easy calculation of catastrophic loss indexes, thus facilitating the pricing of loss index-triggered Cat bonds. This translates into better catastrophe risk management for both insurance and reinsurance companies, as well as for those companies that diversify their portfolios with this type of financial instruments. The simplicity of the presented model facilitates parameter estimation and simulation.\n",
            "----------------------------------------\n",
            "Title: Combinatorial and Machine Learning Approaches for Improved Somatic Variant Calling From Formalin-Fixed Paraffin-Embedded Genome Sequence Data\n",
            "Abstract: Formalin fixation of paraffin-embedded tissue samples is a well-established method for preserving tissue and is routinely used in clinical settings. Although formalin-fixed, paraffin-embedded (FFPE) tissues are deemed crucial for research and clinical applications, the fixation process results in molecular damage to nucleic acids, thus confounding their use in genome sequence analysis. Methods to improve genomic data quality from FFPE tissues have emerged, but there remains significant room for improvement. Here, we use whole-genome sequencing (WGS) data from matched Fresh Frozen (FF) and FFPE tissue samples to optimize a sensitive and precise FFPE single nucleotide variant (SNV) calling approach. We present methods to reduce the prevalence of false-positive SNVs by applying combinatorial techniques to five publicly available variant callers. We also introduce FFPolish, a novel variant classification method that efficiently classifies FFPE-specific false-positive variants. Our combinatorial and statistical techniques improve precision and F1 scores compared to the results of publicly available tools when tested individually.\n",
            "----------------------------------------\n",
            "Title: Predicting Molecular Phenotypes with Single Cell RNA Sequencing Data: an Assessment of Unsupervised Machine Learning Models\n",
            "Abstract: According to the National Cancer Institute, there were 9.5 million cancer-related deaths in 2018. A challenge in improving treatment is resistance in genetically unstable cells. The purpose of this study is to evaluate unsupervised machine learning on classifying treatment-resistant phenotypes in heterogeneous tumors through analysis of single cell RNA sequencing(scRNAseq) data with a pipeline and evaluation metrics. scRNAseq quantifies mRNA in cells and characterizes cell phenotypes. One scRNAseq dataset was analyzed (tumor/non-tumor cells of different molecular subtypes and patient identifications). The pipeline consisted of data filtering, dimensionality reduction with Principal Component Analysis, projection with Uniform Manifold Approximation and Projection, clustering with nine approaches (Ward, BIRCH, Gaussian Mixture Model, DBSCAN, Spectral, Affinity Propagation, Agglomerative Clustering, Mean Shift, and K-Means), and evaluation. Seven models divided tumor versus non-tumor cells and molecular subtype while six models classified different patient identification (13 of which were presented in the dataset); K-Means, Ward, and BIRCH often ranked highest with ~80% accuracy on the tumor versus non-tumor task and ~60% for molecular subtype and patient ID. An optimized classification pipeline using K-Means, Ward, and BIRCH models was evaluated to be most effective for further analysis. In clinical research where there is currently no standard protocol for scRNAseq analysis, clusters generated from this pipeline can be used to understand cancer cell behavior and malignant growth, directly affecting the success of treatment.\n",
            "----------------------------------------\n",
            "Title: A summary-statistics-based approach to examine the role of serotonin transporter promoter tandem repeat polymorphism in psychiatric phenotypes\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: TeD-Q: a tensor network enhanced distributed hybrid quantum machine learning framework\n",
            "Abstract: TeD-Q is an open-source software framework for quantum machine learning, variational quantum algorithm (VQA), and simulation of quantum computing. It seamlessly integrates classical machine learning libraries with quantum simulators, giving users the ability to leverage the power of classical machine learning while training quantum machine learning models. TeD-Q supports auto-differentiation that provides backpropagation, parameters shift, and finite difference methods to obtain gradients. With tensor contraction, simulation of quantum circuits with large number of qubits is possible. TeD-Q also provides a graphical mode in which the quantum circuit and the training progress can be visualized in real-time.\n",
            "----------------------------------------\n",
            "Title: Transformer-Based Embeddings for Greek Language Categorization\n",
            "Abstract: The Greek School Network (GSN) provides support to students, teachers, and school units in secondary education across Greece. Handling numerous user queries manually can be challenging, necessitating the development of an automated system for accurate categorization of these queries. This paper presents a comparative study of various transformer-based models for multi-class text categorization of Greek language queries submitted to the GSN helpdesk. We introduce a new experimental balanced dataset and extract vector representations from eleven transformer-based models. These representations are evaluated using ten classic machine learning classifiers. Our findings highlight the superior performance of the Multilingual E5 Text Embeddings model, particularly when paired with the extreme gradient-boosting classifier. This combination demonstrates a clear advantage in accurately categorizing user queries, paving the way for more efficient automated helpdesk systems.\n",
            "----------------------------------------\n",
            "Title: A Network Attack Model based on Colored Petri Net\n",
            "Abstract: The researches have shown that not all the Petri Net machines can be used to describe attack behavior. When Petri Net machines adapted for attack behavior modeling are detecting the network, for some event of current status, if there is matching event in the model, it has only one corresponding transition; otherwise that may cause errors. Since sharing synthesis and synchronization synthesis of traditional machines cannot ensure synthetic model reserves original detection capability, we propose the novel concept for synthesis operation and colored synthetic operation. By the analysis on the relation among these operations, the ability to reserve original detection is verified. Then an improved colored judgement Petri Net machine is adopted for modeling and renewing the knowledge repository. The inductive learning method is used to extend the attack modes. It creates a four-layered concept space, which actually provides a depth-first search path for matching. To solve the problems in multi-pattern matching and incremental learning, various modes are generalized by colored operation. We also adopt the decomposition and synthesis operation to handle the pattern matching of distributed attack behavior and attack information fusion. Finally the actual cases verify that our algorithm is feasible\n",
            "----------------------------------------\n",
            "Title: Analysis-ready optical underwater images of Manganese-nodule covered seafloor of the Clarion-Clipperton Zone\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Deep Learning for Time Series Forecasting: The Electric Load Case\n",
            "Abstract: Management and efficient operations in critical infrastructure such as Smart Grids take huge advantage of accurate power load forecasting which, due to its nonlinear nature, remains a challenging task. Recently, deep learning has emerged in the machine learning field achieving impressive performance in a vast range of tasks, from image classification to machine translation. Applications of deep learning models to the electric load forecasting problem are gaining interest among researchers as well as the industry, but a comprehensive and sound comparison among different architectures is not yet available in the literature. This work aims at filling the gap by reviewing and experimentally evaluating on two real-world datasets the most recent trends in electric load forecasting, by contrasting deep learning architectures on short term forecast (one day ahead prediction). Specifically, we focus on feedforward and recurrent neural networks, sequence to sequence models and temporal convolutional neural networks along with architectural variants, which are known in the signal processing community but are novel to the load forecasting one.\n",
            "----------------------------------------\n",
            "Title: Soft electronic material based sensor with optical network in sports application for player movement analysis using machine learning model\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: An Ensemble Machine Learning Model Using Gradient Boosting Identifies Patients with Disease Progression in Newly Diagnosed Multiple Myeloma\n",
            "Abstract: \n",
            " Introduction:\n",
            " In many cases, treatment decisions for multiple myeloma patients must be made in the absence of high quality randomized controlled clinical trials. As a result, many clinicians lean on prognostic models to drive treatment selection. The most widely used of these models incorporate a limited number of patient related factors that reflect tumor burden, cytogenetic features, or gene expression profiling. These prediction scores are derived from regression models that incorporate these variables at the time of diagnosis. They do not account for variables that change dynamically over time, do not explore the relationship between treatment selection and progression, and imperfectly predict survival outcomes. We designed a prognostic model based on an ensemble machine learning platform to predict progression in NDMM using Extreme Gradient Boosting Machine (XGBoost) combined with accelerated failure time modeling for survival analysis.\n",
            " Methods:\n",
            " We utilized a large retrospective data set containing treatment and response information for 1127 patients with newly diagnosed multiple myeloma (NDMM) treated at the Cleveland Clinic Foundation between 2000 and 2023. Following data preprocessing based on data completeness, 953 patient records were included in our training, testing, and cross validation datasets. For the purposes of our analysis, the initial dataset was randomly split into training (70%), testing (15%) and validation (15%) subsets at the patient level. We also defined the lower and upper bounds for each subset, which is critical due to the right-censored nature of survival data. Hyperparameters for XGBoost were optimized using Bayesian search, minimizing the negative log-likelihood. A random forest method was applied for the imputation of missing data (MissForest). We then trained the XGBoost model using GPU acceleration for enhanced computational efficiency. Finally, a log-rank test on predicted survival times was used to test the model's performance on patients with and without known progression.\n",
            " Results:\n",
            " Our preprocessed data set had 953 patients with a mean age at disease onset of 65 years and a slight male predominance (55%). Approximately 27% of patients harbored high cytogenetic risk disease and 3.5% of the cohort presented with extramedullary disease a diagnosis. At a median follow up of 35 months, 47% of patients had experienced disease progression or death. Induction therapy included an immunomodulatory drug in 40% of patients and proteasome inhibitors in 22%. Frontline autologous stem cell transplantation followed induction in 28% of patients. Median progression free survival in the overall data set was 44 months. These features were consistent across the randomly assigned training, testing, and validation cohorts.\n",
            " Following data preprocessing, 34 independent clinical and genomic variables including selection of first line treatment were assessed as model inputs each available record. Under optimized parameters, the model was trained with a maximum tree depth = 7 and a learning rate ~ 0.22 for the desired output of progression free survival (PFS). We then queried PFS for both the training and validation sets and divided patients into those known to have progressed and those without a progression event. Survival analysis was undertaken using predicted PFS values for patients known to have progressed and those who remained progression free. For the validation data set, our model successfully discerned between progressed and non-progressed cases (log-rank test statistic = 22.07, p < 0.005) (Figure 1).\n",
            " Discussion:\n",
            " We present a machine learning approach based on regularized gradient boosting that accurately discerns between patients who experience progression and those who remain progression free at a median ~35 months of follow-up in a large retrospective data set in patients presenting with NDMM. Further elaboration of our model will allow for the incorporation of large amounts data to predict survival outcomes on the basis of dynamic variables such as depth of response and treatment selection. With the ability to parse outcomes among multiple myeloma patients at high resolution, future clinicians and clinical trialists may be able to overcome limitations in trial design and patient-level therapy selection for both newly diagnosed and relapsed patients.\n",
            "----------------------------------------\n",
            "Title: Modelo basado en Machine Learning para el Neurorendimiento Académico de estudiantes en la Universidad José Carlos Mariátegui filial Tacna 2018 – I\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Smart contract based automated cervical cancer prediction using ensemble machine learning\n",
            "Abstract: Cervical cancer is a serious health concern that entails high risks for individuals due to delayed detection and treatment worldwide. Formal screening for the condition is challenging in both developed and developing countries due to a number of factors, including medical costs, access to healthcare facilities, social norms, and delayed symptom manifestation. Bypassing conventional, time-consuming medical procedures, machine learning presents a promising path for the efficient and economical early diagnosis of a variety of diseases, including cervical cancer. However, the fact that existing machine classification techniques for identifying diseases rely heavily on the predictive accuracy of a single classifier poses a significant drawback. Single classification methods alone might not provide the best predictions because of bias, over-fitting, improper handling of noisy data, and outliers, among other issues. Moreover, machine learning algorithms deals with sensitive patient data therefore Security measures are necessary to prevent unauthorized access and safeguard individual and organisations’ privacy, guard against model tampering. This paper proposes a novel framework for cervical cancer automated prediction using ensemble model training and blockchain smart contracts. The research records a noteworthy improvement in prediction test accuracy of 99.7% and train accuracy of 93%, surpassing the accuracy of predictions made by individual categorization techniques.\n",
            "----------------------------------------\n",
            "Title: Modeling Rapport for Conversations About Health with Autonomous Avatars from Video Corpus of Clinician-Client Therapy Sessions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Data science in Asia (for PAKDD 2016)\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Verified perceptron convergence theorem\n",
            "Abstract: Frank Rosenblatt invented the perceptron algorithm in 1957 as part of an early attempt to build ``brain models'', artificial neural networks. In this paper, we apply tools from symbolic logic such as dependent type theory as implemented in Coq to build, and prove convergence of, one-layer perceptrons (specifically, we show that our Coq implementation converges to a binary classifier when trained on linearly separable datasets). Our perceptron and proof are extensible, which we demonstrate by adapting our convergence proof to the averaged perceptron, a common variant of the basic perceptron algorithm. We perform experiments to evaluate the performance of our Coq perceptron vs. an arbitrary-precision C++ implementation and against a hybrid implementation in which separators learned in C++ are certified in Coq. We find that by carefully optimizing the extraction of our Coq perceptron, we can meet -- and occasionally exceed -- the performance of the arbitrary-precision C++ implementation. Our hybrid Coq certifier demonstrates an architecture for building high-assurance machine-learning systems that reuse existing codebases.\n",
            "----------------------------------------\n",
            "Title: Machine Learning and the Re‐Enchantment of the Administrative State\n",
            "Abstract: Machine learning algorithms present substantial promise for more effective decision‐making by administrative agencies. However, some of these algorithms are inscrutable, namely, they produce predictions that humans cannot understand or explain. This trait is in tension with the emphasis on reason‐giving in administrative law. The article explores this tension, advancing two interrelated arguments. First, providing adequate reasons is a significant facet of respecting individuals’ agency. Incorporating inscrutable algorithmic predictions into administrative decision‐making compromises this normative ideal. Second, as a long‐term concern, the use of inscrutable algorithms by administrative agencies may generate systemic effects by gradually reducing the realm of the humanly explainable in public life, a phenomenon Max Weber termed ‘re‐enchantment’. As a result, the use of inscrutable machine learning algorithms might trigger a special kind of re‐enchantment, making us comprehend less rather than more of shared human experience, and consequently altering the way we understand the administrative state and experience public life.\n",
            "----------------------------------------\n",
            "Title: The Method of Machine Learning Considering Tamper of Training Data\n",
            "Abstract: Big data is increasingly used as training data for machine learning. However, large-scale data such as big data is not always appropriate as training data at all times. Particularly when collecting data from Web services such as SNS, unspeciﬁed number of people using the service can indirectly tamper with data. In this research, we propose a learning method and verify its eﬀectiveness so as to obtain a learning result close to the case without tampering even in an environment in which part of the training data has been tampered with. In this method, learning is divided into two stages\n",
            "----------------------------------------\n",
            "Title: IDDF2023-ABS-0074 Pretreatment prediction of T cell-inflamed gene expression profile in hepatocellular carcinoma: a contrast-enhanced ultrasound radiomics-based machine learning model\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Jucazinho Dam Streamflow Prediction: A Comparative Analysis of Machine Learning Techniques\n",
            "Abstract: The centuries-old history of dam construction, from the Saad el-Kafara Dam to global expansion in the 1950s, highlights the importance of these structures in water resource management. The Jucazinho Dam, built in 1998, emerged as a response to the scarcity of water in the Agreste region of Pernambuco, Brazil. After having less than 1% of its water storage capacity in 2016, the dam recovered in 2020 after interventions by the local water utility. In this context, the reliability of influent flow prediction models for dams becomes crucial for managers. This study proposed hydrological models based on artificial intelligence that aim to generate flow series, and we evaluated the adaptability of these models for the operation of the Jucazinho Dam. Data normalization between 0 and 1 was applied to avoid the predominance of variables with high values. The model was based on machine learning and employed support vector regression (SVM), random forest (RF) and artificial neural networks (ANNs), as provided by the Python Sklearn library. The selection of the monitoring stations took place via the Brazilian National Water and Sanitation Agency’s (ANA) HIDROWEB portal, and we used Spearman’s correlation to identify the relationship between precipitation and flow. The evaluation of the performance of the model involved graphical analyses and statistical criteria such as the Nash–Sutcliffe model efficiency coefficient (NSE), the percentage of bias (PBIAS), the coefficient of determination (R2) and the root mean standard deviation ratio (RSR). The results of the statistical coefficients for the test data indicated unsatisfactory performance for long-term predictions (8, 16 and 32 days ahead), revealing a downward trend in the quality of the fit with an increase in the forecast horizon. The SVM model stood out by obtaining the best indices of NSE, PBIAS, R2 and RSR. The graphical results of the SVM models showed underestimation of the flow values with an increase in the forecast horizon due to the sensitivity of the SVM to complex patterns in the time series. On the other hand, the RF and ANN models showed hyperestimation of the flow values as the number of forecast days increased, which was mainly attributed to overfitting. In summary, this study highlights the relevance of artificial intelligence in flow prediction for the efficient management of dams, especially in water scarcity and data-scarce scenarios. A proper choice of models and the ensuring of reliable input data are crucial for obtaining accurate forecasts and can contribute to water security and the effective operation of dams such as Jucazinho.\n",
            "----------------------------------------\n",
            "Title: RESUME ANALYZER\n",
            "Abstract: Resume analysis is the process in which a machine analyses a resume based on given requirements of the job description. With the flood of resumes received by companies, it is not effective and also not possible for a person to go through a number of resumes to select a candidate. They have become very popular among the companies in the process of determining candidate selection. The main objective of the project is to be able to match the requirements and skills from a job description to the resume applied. This gives an instantaneous result on whether the resume is accepted or rejected. The end process allows the company itself to be able to select candidates without the requirement of a third party and thus is also cost effective. A big number of resumes could be used in this project to sort the necessary application using various classifiers. Following classifications, the top n candidates will be sorted in accordance with the job description using content-based recommendation and cosine similarity. The project employs k-NN to determine which CVs are most similar to the supplied job description. Through machine learning, the system evaluates a resume for a particular position using NLP.\n",
            "----------------------------------------\n",
            "Title: Developing Affordable, Portable and Simplistic Diagnostic Sensors to Improve Access to Care\n",
            "Abstract: Ophthalmology is a highly technical specialty, especially in the area of diagnostic equipment. While the field is innovative, the access to cutting-edge technology is limited with reference to the global population. A significant way to improve overall healthcare is to understand the needs and possibilities of all possible consumers when developing sophisticated and accurate medical devices. The Smartphone-based Keratograph (SBK), is an example of a new project that uses real world feedback, addresses an unmet medical need, and implements commercially available components to create a device that is affordable, portable and simplistic to operate. The long-term goal of the SBK is to collect data from users for supervised machine-learning. This machine-learning aspect will ultimately aid in the development of an artificial intelligence device to enable even earlier detection of keratoconus, especially in children and adolescents. Again, the ultimate goal of any medical device should be to improve patient care, and to make a significant improvement on vision healthcare for the global population, providing access to this technology is essential.\n",
            "----------------------------------------\n",
            "Title: Further (Potential) Application Fields\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Offshore field experimentation for novel hybrid condition monitoring approaches\n",
            "Abstract: This study details the development of a fully automated pipeline for the condition monitoring of wind turbine drive trains. Vibration data is collected using hardware designed and manufactured in-house and used directly to monitor the condition of the drive trains. The complex nature of wind turbine vibration signals, due to the large number of components and highly variable operating conditions, makes drive train condition monitoring a challenging task. This paper details the full data measurement and analysis flow from sensor to insights and proposes a hybrid automated pipeline with signal processing and data-driven techniques to address the complexity of dealing with wind turbine vibration data. The vibration signals are directly employed to estimate the wind turbine’s instantaneous angular speed to compensate for any rotation speed fluctuations. Pre-processing is performed on the speed-independent signals to evaluate condition indicators in both the time and spectral domain for the vibration signals and their envelopes. Machine learning is then employed to distinguish the healthy state of the machine from a faulty one using the computed condition indicators. Besides the scalar indicators, also two-dimensional vibration decompositions such as the cyclic spectral correlation maps are used as inputs to the machine learning pipeline. This comprehensive and automated approach ensures both an early and reliable fault detection. Experimental results demonstrate that the fully automated hybrid pipeline can effectively be used for fleet-based health tracking of offshore wind turbine drivetrains.\n",
            "----------------------------------------\n",
            "Title: A Comparative Analysis of Machine Learning Models in Prediction of Mortar Compressive Strength\n",
            "Abstract: Predicting the mechanical properties of cement-based mortars is essential in understanding the life and functioning of structures. Machine learning (ML) algorithms in this regard can be especially useful in prediction scenarios. In this paper, a comprehensive comparison of nine ML algorithms, i.e., linear regression (LR), random forest regression (RFR), support vector regression (SVR), AdaBoost regression (ABR), multi-layer perceptron (MLP), gradient boosting regression (GBR), decision tree regression (DT), hist gradient boosting regression (hGBR) and XGBoost regression (XGB), is carried out. A multi-attribute decision making method called TOPSIS (technique for order of preference by similarity to ideal solution) is used to select the best ML metamodel. A large dataset on cement-based mortars consisting of 424 sample points is used. The compressive strength of cement-based mortars is predicted based on six input parameters, i.e., the age of specimen (AS), the cement grade (CG), the metakaolin-to-total-binder ratio (MK/B), the water-to-binder ratio (W/B), the superplasticizer-to-binder ratio (SP) and the binder-to-sand ratio (B/S). XGBoost regression is found to be the best ML metamodel while simple metamodels like linear regression (LR) are found to be insufficient in handling the non-linearity in the process. This mapping of the compressive strength of mortars using ML techniques will be helpful for practitioners and researchers in identifying suitable mortar mixes.\n",
            "----------------------------------------\n",
            "Title: Identification of Unclassified Ships Implementing AIS Information and SAR Image-Based Ship Detection Results\n",
            "Abstract: Monitoring and detecting ships via machine learning based algorithm were regarded efficient in martial and economic manners. As an algorithm regarding automated training data retrieval from SAR image was proposed, the identification of unclassified ships without AIS information could be raised as another challenging issue of ship surveillance. This study presented the effective identification algorithm of discerning unclassified ships from AIS information and the results of conventional ship detection based on machine learning. The accurately detected ships were selected from the conventional ship detection results, followed by the preprocessing of AIS information corresponding to the SAR images containing the detection results. Superposition of AIS information on accurate detection results was conducted and concluded the ships without AIS information as unclassified ships. From 3 Sentinel-1 SAR images, it obtained the average rate of identification as 85.67%. Additional research implementing the identification algorithm accompanied by rapidly acquired satellite or airborne SAR images could be effective in rendering a ship surveillance system with rapid response.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Based Unpleasant Sound Detection by Electroencephalography\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Machine-Learning-Based Risk Factor Analysis for Hypertension: Korea National Health and Nutrition Examination Survey 2016–2019\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: lociPARSE: a locality-aware invariant point attention model for scoring RNA 3D structures\n",
            "Abstract: A scoring function that can reliably assess the accuracy of a 3D RNA structural model in the absence of experimental structure is not only important for model evaluation and selection but also useful for scoring-guided conformational sampling. However, high-fidelity RNA scoring has proven to be difficult using conventional knowledge-based statistical potentials and currently-available machine learning-based approaches. Here we present lociPARSE, a locality-aware invariant point attention architecture for scoring RNA 3D structures. Unlike existing machine learning methods that estimate superposition-based root mean square deviation (RMSD), lociPARSE estimates Local Distance Difference Test (lDDT) scores capturing the accuracy of each nucleotide and its surrounding local atomic environment in a superposition-free manner, before aggregating information to predict global structural accuracy. Tested on multiple datasets including CASP15, lociPARSE significantly outperforms existing statistical potentials (rsRNASP, cgRNASP, DFIRE-RNA, and RASP) and machine learning methods (ARES and RNA3DCNN) across complementary assessment metrics. lociPARSE is freely available at https://github.com/Bhattacharya-Lab/lociPARSE.\n",
            "----------------------------------------\n",
            "Title: LabelMars: Creating an extremely large Martian image dataset through machine learning\n",
            "Abstract: Introduction: Four landers (Viking 1,2, Phoenix and Insight) and 4 rovers (Sojourner, Spirit, Opportunity, and Curiosity) have successfully operated on the Martian surface since 1976, with the combined operation time of landers exceeding 3680 sols and that of rovers exceeding 9660 sols at the time of writing of this abstract (December 2018)[1]. This has returned a large dataset of images from the cameras on board, with examples of recent image-based research on Curiosity images alone including, but not limited to, studies of aeolian, active bedforms [2,3], conglomerates and river beds [4], sedimentary structures [5,6,7], and erosional features [8], together for a reconstruction of the geology of the site [9,10,11]. This list is clearly not exhaustive but it demonstrates how images are key to understanding of the geologic environment at the site, and thus are basis for operational decisions and an invaluable science data resource. With two missions currently active (Curiosity, InSight) and two more scheduled to launch in 2020 (ESA ExoMars, NASA Mars2020) this data set is a ‘big data’ problem, and growing. In order to facilitate easier access, especially for researchers who do not have the luxury of following the mission on a daily basis, this research has developed an automated terrain labelling and classification system based on state of the art machine/deep learning which enables keyword based search. The project: LabelMars achieved 5000 annotated images from the Spirit, Opportunity and Rover navigation camera data bases. The project was a part of a larger European Space Agency (ESA) project called Novelty or Anomaly Hunter (NOAH) which has a number of other tasks, including the labelling as a citizen science project [12], an AI algorithmic evaluation, and a prototype flight detector developed which ported some of the algorithms to flight C versions in order to enable future on-board operations of the technology. We started with the entire set of available navigation camera images from the MER and MSL rovers sourced from the Analyst’s Notebook [13] and down-selected those by selecting continuous rows of sols from different terrains and subsequently deleting all unsuitable ones from this set of images (e.g., if they were too dark or an exact repeat of another one). This resulted in 5917 images {Spirit (2724), Opportunity (1173) and Curiosity (2020)}, which were further reduced to exactly 5000 by eliminating similar scenes and very dark images. The resulting images were manually labelled. Table 1. Example of the category structure for the labelling.\n",
            "----------------------------------------\n",
            "Title: Global and Local Features Based Classification for Bleed-Through Removal\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Traffic Prediction for Intelligent Transportation System using Machine Learning\n",
            "Abstract: Abstract: Machine learning is a set of algorithms and statistical models that computers use to perform a desired task. Machine learning can be used in many applications such as face detection, speech recognition, medical diagnostics, statistical arbitrage, traffic prediction, etc. The traffic environment includes everything that can affect traffic on the road, whether it is traffic lights, accidents, rallies, or even road repairs that can cause congestion. If we have preconceived information very close to all of the above and the many everyday situations that can affect traffic, the driver or passenger can make an informed decision. It also helps with the future of automotive vehicles. In the present decades, traffic data has been massively generated, and we have moved towards big data concepts for transportation. The to be had site visitors glide forecasting strategies use a few site visitors’ prediction fashions and are nonetheless unsatisfactory to address real-global applications. It is lumbering to figure out the traffic flow precisely since the information accessible for the transportation framework is madly colossal. In this work, we arranged to utilize machine learning, genetic, soft computing, and deep learning algorithms to analyse the big-data for the transportation system with much-reduced complexity. Moreover, Image Processing algorithms are included in traffic sign recognition, which inevitably helps for the right training of autonomous vehicles. In economic years, Mobility GPS has become very popular in big cities in determining traffic percentage with the help of centralized traffic - server management. The data collected can be used to build an idea that displays the current traffic in the city and can be used in the future in predicting traffic and congestion analysis can be done\n",
            "----------------------------------------\n",
            "Title: Bibliometric Analysis of the Journal of Big Data: Trends, Impact, and Future Directions\n",
            "Abstract: The Journal of Big Data, a peer-reviewed publication since 2014, has played a pivotal role in the field of big data research by disseminating a total of 788 papers over its ten years of activity. Of these, 649 papers have garnered citations, with 46 receiving over 100 citations. The journal maintains an average of 37.13 citations per paper, with a higher average of 45.09 citations per cited paper, reflecting its significant impact. An h-index of 70 and a g-index of 158 further underscore its academic influence. The journal’s active year growth rate of 39.88% signifies its consistent expansion, while the average document age of 2.83 years indicates a focus on current developments. Collaborative research is a hallmark of the journal, evident in its 3.47 average authors per paper and 19.67% of papers with international co-authorships. The analysis of year-wise performance and citation trends offers insights into scholarly output and engagement. Visualizing collaborative relationships among authors highlights prominent nodes of interaction, revealing key contributors. Noteworthy institutions such as Florida Atlantic University, USA, and Bina Nusantara University, Indonesia, emerge in the landscape of research productivity. An exploration of keywords and their co-occurrence uncovers thematic clusters, ranging from big data technologies and deep learning to natural language processing and machine learning. In conclusion, the Journal of Big Data stands as a vital platform for disseminating impactful research in the dynamic realm of big data. Its comprehensive analysis emphasizes its academic influence through citation metrics, collaborative research, and thematic explorations. Through its decade-long journey, the journal has solidified its role in advancing the field and fostering global collaboration among researchers.\n",
            "----------------------------------------\n",
            "Title: Detecting foodborne pathogens with darkfield hyperspectral microscopy\n",
            "Abstract: The presence of pathogenic microorganisms such as salmonella, listeria and E. coli in foods is a major threat to consumer safety. The failure to detect these pathogens can result in severe outbreaks of foodborne illness. There are several technologies utilized in food pathogen detection today including plating, nucleic acid-based polymerase chain reaction techniques and immunoassays. While these technologies have their merits, each approach requires significant sample incubation and total time to answer of 18 – 72hrs. HinaLea is working in collaboration with the USDA to develop a system which will significantly accelerate the identification of foodborne pathogens. The system combines darkfield microscopy, hyperspectral imaging, machine learning and automation in a standalone unit. Our vision is to move towards real-time identification of pathogens in the food production environment.\n",
            "----------------------------------------\n",
            "Title: Method and Apparatus for Stock Performance Prediction Using Momentum Strategy along with Social Feedback\n",
            "Abstract: Stock prediction and historical stock data analysis have been of great interest over the decades. The research is wide from classical deterministic algorithms to machine learning models and techniques along with the supply huge amounts of historical data. Volatility and Market Sentiment are key parameters to account for during the construction of any stock prediction model. Commonly used techniques like the n-moving days average is not responsive to swings in the stocks and the information sent and posted online has made a huge effect on investors' opinions on the market, making these the two optimal parameters of prediction. Hence, we present an automatic pipeline that has 2 modules - N-Observation period momentum strategy to identify potential stocks and then a stock holding module that identifies market sentiment using NLP techniques.\n",
            "----------------------------------------\n",
            "Title: ETL-FEXIC Model for Secured Heart Rate Abnormality Healthcare Framework\n",
            "Abstract: In traditional methods, it is critical for an effective continuous pulse monitor for humans prone to heart rate abnormalities. This paper proposes a secured heartrate abnormality detector which continuously monitors human pulse rate and SpO2 level. The current studies proposes that machine learning (ML) models performs well in classification; also, TinyML model shows better performance for data from resource constrained IoT devices. Hence, the research first analyses abnormal heart rate detection and spam data identification using standard ML algorithms such as SVM, Random Forest, Decision Tree, and TinyML. Though ML models are superior in classification, deep learning approaches outperforms them in feature learning. Hence, our proposed framework combines the merits of both ML and DL models. In our approach, the generated healthcare dataset is fed to DL models such as ANN, and autoencoder and also to SHAP XAI (eXplainable Artificial Intelligence) for feature extraction and learning. These learnt features are fed to ML models for classification. In this experiment, the proposed ETL-FEXIC (Enhanced Tiny Machine Learning with Automated Feature Extraction) outperforms the other ML models where the extracted features from XAI is fed to optimized TinyML classification model.\n",
            "----------------------------------------\n",
            "Title: Navigating Industry 4.0 Frontiers: A Scalable and Resilient Next-Generation IoT Framework to Implement Future Advancements in Smart and Adaptive Industrial Systems\n",
            "Abstract: The emergence of Industry 4.0 signifies a paradigm shift in industrial systems, characterized by the amalgamation of digital technologies with tangible operations. The goal of this study is to present a state-of-the-art, scalable, and robust Internet of Things (IoT) framework that will enable future innovations in intelligent and adaptable industrial systems to be seamlessly integrated. Our framework gives scalability first priority in response to Industry 4.0's dynamic nature, which is marked by fast technical evolution and rising connection in order to handle the expanding ecosystem of networked devices. The suggested structure places a strong emphasis on resilience and is designed to resist setbacks and guarantee the continuation of vital industrial processes. Our framework improves industrial systems' intelligence by utilizing edge computing, machine learning techniques, and improved communication protocols. This allows the systems to self-adapt to changing situations. Moreover, it adopts a modular architecture that facilitates interoperability and makes it simple to integrate various devices and technologies. Our IoT framework creates a solid, flexible, and future-proof industrial environment with this all-encompassing strategy, enabling businesses to confidently and effectively traverse Industry 4.0's frontiers.\n",
            "----------------------------------------\n",
            "Title: Complex system health condition estimation using tree-structured simple recurrent unit networks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Measuring Caloric Intake at the Population Level (NOTION): Protocol for an Experimental Study\n",
            "Abstract: Background The monitoring of caloric intake is an important challenge for the maintenance of individual and public health. The instruments used so far for dietary monitoring (eg, food frequency questionnaires, food diaries, and telephone interviews) are inexpensive and easy to implement but show important inaccuracies. Alternative methods based on wearable devices and wrist accelerometers have been proposed, yet they have limited accuracy in predicting caloric intake because analytics are usually not well suited to manage the massive sets of data generated from these types of devices. Objective This study aims to develop an algorithm using recent advances in machine learning methodology, which provides a precise and stable estimate of caloric intake. Methods The study will capture four individual eating activities outside the home over 2 months. Twenty healthy Italian adults will be recruited from the University of Padova in Padova, Italy, with email, flyers, and website announcements. The eligibility requirements include age 18 to 66 years and no eating disorder history. Each participant will be randomized to one of two menus to be eaten on weekdays in a predefined cafeteria in Padova (northeastern Italy). Flows of raw data will be accessed and downloaded from the wearable devices given to study participants and associated with anthropometric and demographic characteristics of the user (with their written permission). These massive data flows will provide a detailed picture of real-life conditions and will be analyzed through an up-to-date machine learning approach with the aim to accurately predict the caloric contribution of individual eating activities. Gold standard evaluation of the energy content of eaten foods will be obtained using calorimetric assessments made at the Laboratory of Dietetics and Nutraceutical Research of the University of Padova. Results The study will last 14 months from July 2017 with a final report by November 2018. Data collection will occur from October to December 2017. From this study, we expect to obtain a series of relevant data that, opportunely filtered, could allow the construction of a prototype algorithm able to estimate caloric intake through the recognition of food type and the number of bites. The algorithm should work in real time, be embedded in a wearable device, and able to match bite-related movements and the corresponding caloric intake with high accuracy. Conclusions Building an automatic calculation method for caloric intake, independent on the black-box processing of the wearable devices marketed so far, has great potential both for clinical nutrition (eg, for assessing cardiovascular compliance or for the prevention of coronary heart disease through proper dietary control) and public health nutrition as a low-cost monitoring tool for eating habits of different segments of the population. International Registered Report Identifier (IRRID) DERR1-10.2196/12116\n",
            "----------------------------------------\n",
            "Title: StockNet: A Multivariate Deep Neural Architecture for stock prices prediction\n",
            "Abstract: Stock price forecasting is an inherently difficult problem. According to the efficient market hypothesis financial prices are unpredictable. However, a great number of machine learning methods have obtained consistent results on anticipating market movements. Most recent time-series prediction methods attempt to predict prices polarity, that is, whether prices have increased or fallen compared to the last time-step. Such approaches are inefficient in real scenarios, as forecasting price polarity alone makes financial planning a hard task, due to the fees and operation costs. Most of these methods use only Recurrent Neural Networks, but recent advances in temporal convolutional networks also may prove to be promising in prediction of general time-series, making better predictions with easier to train models. Recent hybrid architectures have also obtained important results using additional unstructured information from financial news. We propose a novel deep neural architecture to predict stock prices based on Temporal Convolutional Networks and built upon on a state of the art acoustic model for voice synthesis. Experimental results show that our model can consistently improve individual stocks prediction when compared to traditional methods.\n",
            "----------------------------------------\n",
            "Title: Proceedings 44th IEEE Symposium on Foundations of Computer Science - FOCS 2003\n",
            "Abstract: The following topics are discussed: computer science; network performance analysis; algorithms and data structures, computational complexity, cryptography, computational geometry, algorithmic graph theory and combinatorics, parallel and distributed computing, machine learning, applications of logic, algorithmic algebra and coding theory, theoretical aspects of databases, information retrieval, networks, computational biology, robotics, and quantum computing; constraint satisfaction problems; and traveling salesman problem.\n",
            "----------------------------------------\n",
            "Title: Analyzing analytics\n",
            "Abstract: Many organizations today are faced with the challenge of processing and distilling information from huge and growing collections of data. Such organizations are increasingly deploying sophisticated mathematical algorithms to model the behavior of their business processes to discover correlations in the data, to predict trends and ultimately drive decisions to optimize their operations. These techniques, are known collectively as analytics, and draw upon multiple disciplines, including statistics, quantitative analysis, data mining, and machine learning. In this survey paper, we identify some of the key techniques employed in analytics both to serve as an introduction for the non-specialist and to explore the opportunity for greater optimizations for parallelization and acceleration using commodity and specialized multi-core processors. We are interested in isolating and documenting repeated patterns in analytical algorithms, data structures and data types, and in understanding howthese could be most effectively mapped onto parallel infrastructure. To this end, we focus on analytical models that can be executed using different algorithms. For most major model types, we study implementations of key algorithms to determine common computational and runtime patterns. We then use this information to characterize and recommend suitable parallelization strategies for these algorithms, specifically when used in data management workloads.\n",
            "----------------------------------------\n",
            "Title: Abstract 16427: Despite Machine Learning Models, QRS Duration Remains the Superior ECG Criterion for Predicting Left Ventricular Dilation in Patients With Left Bundle Branch Block\n",
            "Abstract: \n",
            " Introduction:\n",
            " The utility of ECG to diagnose left ventricular (LV) dilation in patients with left bundle branch block (LBBB) is not known. We sought to compare the diagnostic yield of ECG using (i) QRS duration, (ii) published LVH criteria, and (iii) machine learning (ML) models to detect increased left ventricular end diastolic volume indexed (LVEDVi) in the setting of LBBB.\n",
            " \n",
            " \n",
            " Hypothesis:\n",
            " ML is superior to QRS duration and LVH criteria to detect increased LVEDVi among LBBB.\n",
            " \n",
            " \n",
            " Methods:\n",
            " 12-lead ECGs were processed to reconstruct orthogonal X, Y, Z leads using Kors’s matrix and obtain root-mean-squared (3D) ECG. R wave, S wave and overall amplitudes, voltage-time-integrals (VTIs), and other ECG features were extracted from all ECG leads. ML algorithms [logistic regression (LR), support vector classifier (SVC), decision trees (DT), random forest (RF), gradient boosted machine (GBM) and boosted trees (BT)] were trained to predict increased LVEDVi (women >61 mL/m\n",
            " 2\n",
            " , men >74 mL/m\n",
            " 2\n",
            " ) from ECG features on a training set of 2668 ECGs with typical LBBB and echocardiogram within 45 days before or after ECG. LVEDV was measured using ASE biplane method of discs. We obtained ROC AUCs for prediction of increased LVEDVi by (i) QRS duration, (ii) published LVH criteria, and (iii) ML models in a separate validation set of adults with typical LBBB.\n",
            " \n",
            " \n",
            " Results:\n",
            " Among the validation set of 413 adults (53% women, age 73±12 yr) with LBBB, QRS duration alone had a higher AUC (women 0.668, men 0.699) for diagnosing increased LVMi compared to standard LVH criteria (Table). The best ML model (RF with overall AUC 0.694) did not substantially outperform QRS duration alone.\n",
            " \n",
            " \n",
            " Conclusions:\n",
            " In patients with LBBB, QRS duration ≥150 in women and ≥160 in men is a superior predictor of LV dilation than traditional ECG-based LVH criteria, with no additional value added by ML methods.\n",
            " \n",
            " \n",
            " \n",
            "\n",
            "----------------------------------------\n",
            "Title: Evaluation of Tree Diameter and Height Measurements in UAV Data by Integrating Remote Sensing and Machine Learning Methods\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: L2 SUPPORT VECTOR MACHINES REVISITED - NOVEL DIRECT LEARNING ALGORITHM AND SOME GEOMETRIC INSIGHTS\n",
            "Abstract: : The paper presents a novel learning algorithm for the class of L2 Support Vector Machines classifiers dubbed Direct L2 SVM. The proposed algorithm avoids solving the quadratic programming problem and yet, it produces both the same exact results as the classic quadratic programming based solution in a significantly shorter CPU time. The connections between various L2 SVM algorithms will be highlighted and some geometric properties of the Direct L2 SVM will be pointed at. All the other known L2 based SVMs can be looked at as the special cases of a Direct L2 SVM. The developed Direct L2 SVM algorithm is posed as the Non-Negative Least Squares problem which solves the comprehensive L2 SVM exactly and, in a striking difference to both the Least Squares SVM and proximal SVM, is able to produce the sparse solutions.\n",
            "----------------------------------------\n",
            "Title: Unsupervised Insider Detection Through Neural Feature Learning and Model Optimisation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Toolbox for Automating Development of Personalized Epileptic Seizure Detection Algorithms\n",
            "Abstract: Objective: A toolbox for automating the development of real-time personalized epileptic seizure detection algorithms is presented. The toolbox contains modules that cover feature extraction, feature selection, classiﬁer training and performance evaluation using cross-validation. Methods: A large pool of features is extracted from the training dataset of a given patient using di ↵ erent signal processing methods. Then, the feature selection modules picks an e � cient subset of features. Next, a high-level machine learning classiﬁer is created to automatically classify EEG data as seizure or non-seizure. Results: The toolbox performance was evaluated using 3-fold cross-validation on multiple patients from three publicly available datasets. The overall sensitivities were between 74 . 2% and 92 . 7% with median false positive rates below 2 per day. Conclusion: The toolbox was able to create individualized detection algorithms with suitable sensitivities and low false positive rates for most of the patients. Signiﬁcance: The performance of the toolbox conﬁrms its potential to be used in clinical settings, raising alarms when patients su ↵ er from seizures. Moreover, it can pre-process EEG recordings by ﬁnding seizure occurrences. The modularity of the toolbox enables its components to be used in the design of new algorithms tailored for di ↵ erent tasks.\n",
            "----------------------------------------\n",
            "Title: Traduction automatique de termes biomédicaux pour la recherche d'information interlingue\n",
            "Abstract: In this article, we present a new method to automatically translate biomedical terms. This method relies on an original machine-learning technique that infers rewriting rules and on the use of language models. Evaluations presented here prove that this method yields good results and allows one to translate between any two languages provided that their differences are regular enough to be learnt. This translation method is applied and evaluated on a interlingual IR task in the biomedical domain with queries in several languages (French, Spanish, Portuguese, Russian, Italian); the good results we obtain prove the interest of such an automatic approach for the information retrieval domain. MOTS-CLES : RI interlingue, traduction artificielle, apprentissage artificiel, termes biomedicaux\n",
            "----------------------------------------\n",
            "Title: Forecasting the Energy Utilization in WSN by Support Vector Regression Model\n",
            "Abstract: Energy management issues in Wireless Sensor Networks (WSNs) are an important research topic because they are widely used to monitor a variety of physical conditions. Though several analytical methods are available, it is still challenging to make a precise model to forecast energy utilization due to the prompting parameters' difficulty. It is critical for an energy manager to accurately predict energy consumption in order to make sound decisions and achieve energy utilization. The dimensionality reduction and efficient feature selection process in WSN is challenging. In many real-time situations, machine learning methods such as Support Vector Regression (SVR) provide greater accuracy. This paper proposes a Support Vector Regression (SVR) model for forecasting the processing energy utilization in WSN. The SVR system maps the input variables to high dimensional feature space and discovers the nonlinear connection between the input and output by reducing the data load. Furthermore, the Boruta algorithm is used to select the feature and improve the forecasting accuracy. The experimental outcomes demonstrate the FSVR method enhances the accuracy and minimizes the processing energy utilization in the WSN.\n",
            "----------------------------------------\n",
            "Title: ANOMALY DETECTION WITH SELF-SUPERVISED AUDIO EMBEDDINGS Technical\n",
            "Abstract: The majority of approaches to machine condition monitoring via anomalous sound detection are based on supervised learning. The metadata of the datasets is used as data labels for training supervised models. However, data labeling is expensive and often impossible for industries with significant amount of equipment. In this case self-supervised methods could solve the problem since they do not require labeled data. In this work we applied the recent self-supervised approach to compute embeddings of audio signals named BYOL-A and classical machine learning method Local Out-lier Factor (LOF) to compute outlier scores for anomalous sounds. The main focus of this work is to not use any labels from the meta-data of the datasets and explore a self-supervised learning approach.\n",
            "----------------------------------------\n",
            "Title: Machine Learning: Frontmatter\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Federated Learning without Full Labels: A Survey\n",
            "Abstract: Data privacy has become an increasingly important concern in real-world big data applications such as machine learning. To address the problem, federated learning (FL) has been a promising solution to building effective machine learning models from decentralized and private data. Existing federated learning algorithms mainly tackle the supervised learning problem, where data are assumed to be fully labeled. However, in practice, fully labeled data is often hard to obtain, as the participants may not have sufficient domain expertise, or they lack the motivation and tools to label data. Therefore, the problem of federated learning without full labels is important in real-world FL applications. In this paper, we discuss how the problem can be solved with machine learning techniques that leverage unlabeled data. We present a survey of methods that combine FL with semi-supervised learning, self-supervised learning, and transfer learning methods. We also summarize the datasets used to evaluate FL methods without full labels. Finally, we highlight future directions in the context of FL without full labels.\n",
            "----------------------------------------\n",
            "Title: Diagnosing Skin Cancer using Machine Learning Techniques\n",
            "Abstract: Melanoma skin cancer is one of the deadly types of skin cancer and Biopsy is the method that is used to detect this cancer and success rate depends on performance of a trained doctor. The biopsy Process is very painful and requires considerable time. So, there is a need for a technique that can detect melanoma cancer that could avoid biopsy and that would be based on looking deep into skin cancer images. This paper has conducted a study on image classification of melanoma skin cancer using machine learning and various neural network techniques. The stages of the cancer image classification process melanoma skin in this study include the preprocessing process, segmentation, feature extraction with ABCD namely Asymmetry, Border Irregularity, Color Variation and Diameter. Subsequently, it's quantified that both the machine learning and neural network can be used for skin cancer diagnostics.\n",
            "----------------------------------------\n",
            "Title: Clean-label Backdoor Attack on Machine Learning-based Malware Detection Models and Countermeasures\n",
            "Abstract: In recent years, machine learning technology has been extensively utilized, leading to increased attention to the security of AI systems. In the field of image recognition, an attack technique called clean-label backdoor attack has been widely studied, and it is more difficult to detect than general backdoor attacks because data labels do not change when tampering with poisoning data during model training. However, there remains a lack of research on malware detection systems. Some of the current work is under the white-box assumption that requires knowledge of machine learning-based models which can be advantageous for attackers. In this study, we focus on clean-label backdoor attacks in malware detection systems and propose a new clean-label backdoor attack under the black-box assumption that does not require knowledge of machine learning-based models, which is riskier. The experimental evaluation of the proposed attack method shows that the attack success rate is up to 80.50% when the poisoning rate is 14.00%, demonstrating the effectiveness of the proposed attack method. In addition, we experimentally evaluated the effectiveness of the dimensionality reduction techniques in preventing clean-label backdoor attacks, and showed that it can reduce the attack success rate by 76.00%.\n",
            "----------------------------------------\n",
            "Title: Response Time Determinism in Healthcare Data Analytics Using Machine Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Rapidly adapting machine learning methods for brain-computer interfaces\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: SENTRI: Jurnal Riset Ilmiah\n",
            "Abstract: : Deteksi warna merupakan salah satu metode yang dapat digunakan untuk tracking objek maupun klasifikasi benda dalam robotic dan aplikasi lainnya. Dalam paper ini dibahas mengenai deteksi warna primer dengan memanfaatkan webcam yang terdapat pada laptop. Inisialisasi awal variable HSV amatlah penting untuk menentukan warna yang diinginkan. Berdasarkan variable warna dapat didefinisikan dan dilakukan deteksi lebih lanjut. Dari hasil percobaan, terdapat non objek yang tedeteksi akibat system yang bersifat real-time sehingga diperlukan tambahan machine learning sebagai penstabil data yang ditangkap kamera\n",
            "----------------------------------------\n",
            "Title: Precision therapy for ulcerative colitis: insights from mitochondrial dysfunction interacting with the immune microenvironment\n",
            "Abstract: Background Accumulating evidence reveals mitochondrial dysfunction exacerbates intestinal barrier dysfunction and inflammation. Despite the growing knowledge of mitochondrial dysfunction and ulcerative colitis (UC), the mechanism of mitochondrial dysfunction in UC remains to be fully explored. Methods We integrated 1137 UC colon mucosal samples from 12 multicenter cohorts worldwide to create a normalized compendium. Differentially expressed mitochondria-related genes (DE-MiRGs) in individuals with UC were identified using the “Limma” R package. Unsupervised consensus clustering was utilized to determine the intrinsic subtypes of UC driven by DE-MiRGs. Weighted gene co-expression network analysis was employed to investigate module genes related to UC. Four machine learning algorithms were utilized for screening DE-MiRGs in UC and construct MiRGs diagnostic models. The models were developed utilizing the over-sampled training cohort, followed by validation in both the internal test cohort and the external validation cohort. Immune cell infiltration was assessed using the Xcell and CIBERSORT algorithms, while potential biological mechanisms were explored through GSVA and GSEA algorithms. Hub genes were selected using the PPI network. Results The study identified 108 DE-MiRGs in the colonic mucosa of patients with UC compared to healthy controls, showing significant enrichment in pathways associated with mitochondrial metabolism and inflammation. The MiRGs diagnostic models for UC were constructed based on 17 signature genes identified through various machine learning algorithms, demonstrated excellent predictive capabilities. Utilizing the identified DE-MiRGs from the normalized compendium, 941 patients with UC were stratified into three subtypes characterized by distinct cellular and molecular profiles. Specifically, the metabolic subtype demonstrated enrichment in epithelial cells, the immune-inflamed subtype displayed high enrichment in antigen-presenting cells and pathways related to pro-inflammatory activation, and the transitional subtype exhibited moderate activation across all signaling pathways. Importantly, the immune-inflamed subtype exhibited a stronger correlation with superior response to four biologics: infliximab, ustekinumab, vedolizumab, and golimumab compared to the metabolic subtype. Conclusion This analysis unveils the interplay between mitochondrial dysfunction and the immune microenvironment in UC, thereby offering novel perspectives on the potential pathogenesis of UC and precision treatment of UC patients, and identifying new therapeutic targets.\n",
            "----------------------------------------\n",
            "Title: Identification of Multimorbidity Patterns in Rheumatoid Arthritis Through Machine Learning\n",
            "Abstract: Recognizing that the interrelationships between chronic conditions that complicate rheumatoid arthritis (RA) are poorly understood, we aimed to identify patterns of multimorbidity and to define their prevalence in RA through machine learning.\n",
            "----------------------------------------\n",
            "Title: Contextual Sentence Decomposition\n",
            "Abstract: In this thesis, we introduce and study contextual sentence decomposition, which, intuitively, decomposes a given sentence into parts that semantically “belong together”. For example, a valid decomposition of the sentence “Usable parts of rhubarb include the edible stalks and the medicinally used roots, however its leaves are toxic” are the sub-sentences “Usable parts of rhubarb include the edible stalks”, “Usable parts of rhubarb include the edible stalks” and “however its leaves are toxic”. Our motivation for this problem comes from semantic full-text search. For a query plant edible leaves, semantic full-text search returns passages where instances of a plant, such as “rhubarb” (and not the word “plant”), are mentioned along with the words “edible” and “leaves”. One of the results this query might erroneously return is the original sentence above. With contextual sentence decomposition we avoid this false-positive, while at the same time maintaining the true factual contents of the original sentence. We propose two approaches for our problem, one based on a set of rules and one using machine learning. On a manually assembled ground truth, we achieve an F-measure of about 65 percent for the former and of 40 percent for the latter. For the semantic full-text search based on these approaches, evaluated on the English Wikipedia (27 GB of raw text), we achieve improvements nearly doubling the F-measure for some queries.\n",
            "----------------------------------------\n",
            "Title: Machine learning for improved dengue diagnosis, Puerto Rico\n",
            "Abstract: Background:Diagnosing dengue accurately, especially in resource-limited settings, remains challenging due to overlapping symptoms with other febrile illnesses and limitations of current diagnostic methods. This study aimed to develop machine learning (ML) models that leverage readily available clinical data to improve diagnostic accuracy for dengue, potentially offering a more accessible and rapid diagnostic tool for healthcare providers. Methods:We used data from the Sentinel Enhanced Dengue Surveillance System (SEDSS) in Puerto Rico (May 2012-June 2024). SEDSS primarily targets acute febrile illness but also includes cases with other symptoms during outbreaks (e.g., Zika and COVID-19). ML models (logistic regression, random forest, support vector machine, artificial neural network, adaptive boosting, light gradient boosting machine [LightGBM], and extreme gradient boosting [XGBoost]) were evaluated across different feature sets, including demographic, clinical, laboratory, and epidemiological variables. Model performance was assessed using the area under the receiver operating characteristic curve (AUC), where higher AUC values indicate better performance in distinguishing dengue cases from non-dengue cases. Results:Among 49,679 patients in SEDSS, 1,640 laboratory-confirmed dengue cases were identified.TheXGBoost and LightGBM models achieved the highest diagnostic accuracy, with AUCs exceeding 90%, particularly with comprehensive feature sets. Incorporating predictors such as monthly dengue incidence, leukopenia, thrombocytopenia, rash, age, and absence of nasal discharge significantly enhanced model sensitivity and specificity for diagnosing dengue. Adding more relevant clinical and epidemiological features consistently improved the models' ability to correctly identify dengue cases. Conclusions:ML models, especially XGBoost and LightGBM, show promise for improving diagnostic accuracy for dengue using widely accessible clinical data, even in resource-limited settings. Future research should focus on developing user-friendly tools, such as mobile apps, web-based platforms, or clinical decision systems integrated into electronic health records, to implement these models in clinical practice and exploring their application for predicting dengue.\n",
            "----------------------------------------\n",
            "Title: Machine learning based algorithms for uncertainty quantification in numerical weather prediction models\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine Learning-Based Price Forecasting for Polypropylene Granules in Thailand\n",
            "Abstract: The plastic industry plays a vital role in Thailand, with a significant dependence on plastic materials for a majority of industrial products. Among the various types of plastics, polypropylene (PP) emerges as the most extensively used, making it indispensable for the country's plastic industry. This research focuses on presenting and comparing forecasting models for the price of PP granules in Thailand. The primary objective is to identify the most accurate forecasting model, with the mean absolute percentage error (MAPE) serving as the criterion for assessing the forecast model's performance. Three machine learning forecasting models, namely Support Vector Regression (SVR), eXtreme Gradient Boosting (XGBoost), and Artificial Neural Network (ANN), are employed in the study. The findings reveal that the ANN model demonstrates the highest accuracy, achieving a MAPE of 5.89% on the test dataset.\n",
            "----------------------------------------\n",
            "Title: Regression Training using Model Parallelism in a Distributed Cloud\n",
            "Abstract: Machine learning requires a relevant amount of computational resources and it is usually executed in high-capacity centralized cloud infrastructures (e.g., data centers). In such infrastructures, resources are shared in a scalable manner through instantiation and orchestration of multiple virtualized services. Emerging trends in machine learning are distribution and parallelization of model training, which allows the execution of model training tasks in multiple distributed computational domains, with the aim of reducing the overall training time. A possible drawback in decentralization of machine learning is that performance latency issues may arise when the computation of training is geographically distributed to nodes with long distance from each other. One way to reduce latency is to utilize edge computing infrastructure, i.e., to distribute computation near the origin of the request. As edge resources can be scarce, it is important to orchestrate the model training in a parallelized manner. To this extent, in order to effectively ease the use of parallelization both in centralized and in distributed scenarios, we propose and implement a concept that we refer to Intelligent Agent (IA). An IA is responsible for instantiating and scheduling of the machine learning tasks (e.g., model training), and deriving inferences. In our solution, model training is distributed to multiple IAs in parallel. Each IA is packaged into a Linux container in order to take advantage of container portability across heterogenous deployments and to reuse existing container orchestration tools. We validate our proposal by deploying and instantiating multiple IAs across a distributed cloud environment, where each IA is accounting for a fixed amount of computational resources. Keywords - Intelligent agent, Model parallelism, Regression training, Intelligent cloud\n",
            "----------------------------------------\n",
            "Title: A Machine Learning Approach for Steel Surface Textural Defect Classification Based on Wavelet Scattering Features and PCA\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Anomaly detection of electricity load data based on MixMatch\n",
            "Abstract: With the development of power industry, electricity has become one of the most important energy sources in our country, related to the lifeline of the country's economy. The electricity system is becoming more and more mature, but abnormal electricity consumption behaviors are also emerging endlessly, causing potential safety hazards in the electricity industry and even the electricity supply system. Considering the lack of abnormal annotations in the electricity load data, this paper proposes a semi-supervised electricity load data anomaly detection method based on MixMatch. Firstly, data cleaning of electricity load data is used to remove incorrect data. Secondly, Convolutional Autoencoder (CAE) is used to extract its time-domain and frequency-domain features separately, and the features are combined through feature fusion. Thirdly, the Borderline Synthetic Minority Oversampling Technique (Borderline-SMOTE) is used to solve the problem of data imbalance. The MixMatch semi-supervised algorithm is used to label the abnormal data to realize the anomaly detection of the electricity load data. Finally, this paper uses the k-means clustering and T-Stochastic neighbour Embedding (T -SNE) to classify the abnormal data and visualize the data. The experimental results show that, compared with traditional machine learning methods, the proposed method has a significant improvement on AUC.\n",
            "----------------------------------------\n",
            "Title: GAN Augmentation: Augmenting Training Data using Generative Adversarial Networks\n",
            "Abstract: One of the biggest issues facing the use of machine learning in medical imaging is the lack of availability of large, labelled datasets. The annotation of medical images is not only expensive and time consuming but also highly dependent on the availability of expert observers. The limited amount of training data can inhibit the performance of supervised machine learning algorithms which often need very large quantities of data on which to train to avoid overfitting. So far, much effort has been directed at extracting as much information as possible from what data is available. Generative Adversarial Networks (GANs) offer a novel way to unlock additional information from a dataset by generating synthetic samples with the appearance of real images. This paper demonstrates the feasibility of introducing GAN derived synthetic data to the training datasets in two brain segmentation tasks, leading to improvements in Dice Similarity Coefficient (DSC) of between 1 and 5 percentage points under different conditions, with the strongest effects seen fewer than ten training image stacks are available.\n",
            "----------------------------------------\n",
            "Title: A Personal Intelligent Information Assistant Based on Web Mining\n",
            "Abstract: Web mining technology and web information service with personalization and initiative are research focus all long. The studies on both problems also have lots of difficulties because the web data with complicated structure is a great deal and changeful. In this paper, we integrate Web mining with agent and machine learning, and design a personal intelligent information assistant based on web mining (PIIA) at the center of user, and design in detail its primary function. lastly the characteristic of the system is expounded.\n",
            "----------------------------------------\n",
            "Title: Novel Hypoxia-related Biomarkers and Targeted Drugs for Acute Myocardial Infarction Revealed by Bioinformatics\n",
            "Abstract: \n",
            "\n",
            "Acute myocardial infarction (MI) is a serious emergency disease with high\n",
            "mortality. Hypoxia is associated with unfavorable outcomes in cancer patients. Nevertheless, there\n",
            "remains a shortage of effective hypoxia-related biomarkers to forecast the prognosis of acute MI\n",
            "patients and to identify targeted therapies.\n",
            "\n",
            "\n",
            "\n",
            "First, data on acute MI patient samples and hypoxia-related genes were obtained based on\n",
            "public databases. Hypoxia-related gene scores were calculated by single sample Gene Set Enrichment\n",
            "Analysis (ssGSEA). Hypoxia-related hub genes in acute MI were screened via weighted correlation\n",
            "network analysis (WGCNA). Acute MI samples were analyzed for differentially expressed\n",
            "genes (DEGs) using the limma package and intersected with hub gene for hypoxia-related DEGs.\n",
            "Then, machine learning methods were used to identify hypoxia-related biomarkers in acute MI. Gene\n",
            "set enrichment analysis (GSEA) and immune infiltration analysis were performed on biomarkers.\n",
            "Targeted drug prediction and molecular docking were conducted based on biomarkers.\n",
            "\n",
            "\n",
            "\n",
            "1) To determine whether there is difference in hypoxia-related gene score between acute MI and control samples. 2) To identify the hypoxia-related hubgene in acute MI. 3) To screen the hypoxia-related biomarkers for acute MI. 4) To assess the correlation between biomarkers and immune cells infiltration. 5) To predict drugs for acute MI based on biomarkers.\n",
            "\n",
            "\n",
            "\n",
            "The hypoxia-related gene score of the acute MI group was higher than the control group,\n",
            "and 319 hypoxia-related hub genes in acute MI were acquired. A total of 7 hypoxia-related DEGs\n",
            "were obtained by WGCNA and DEGs analysis. Then, 2 hypoxia-related biomarkers in acute MI,\n",
            "HAUS3 and SLC2A3, were identified based on machine learning algorithms. Both HAUS3 and\n",
            "SLC2A3 were enriched in the ribosome and spliceosome pathways. The expression levels of SLC2A3\n",
            "and HAUS3 were correlated with immune cell infiltration. Furthermore, 8-hydroxyquinoline, perhexiline,\n",
            "and sotalol were selected as the targeted drugs, which could bind to HAUS3 and SLC2A3.\n",
            "\n",
            "\n",
            "\n",
            "In short, we screened two important hypoxia-related biomarkers and three potential\n",
            "target drugs based on bioinformatics techniques. This provides new ideas and potential drug targets\n",
            "for early diagnosis and targeted therapy of acute MI.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Optimizing the development of contaminated land in China: Exploring machine-learning to identify risk markers.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Cybersecurity enhancement to detect credit card frauds in health care using new machine learning strategies\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Parkinson's disease detection using olfactory loss and REM sleep disorder features\n",
            "Abstract: In Parkinson's disease, there exists a prodromal or a premotor phase characterized by symptoms like olfactory loss and sleep disorders, which may last for years or even decades before the onset of motor clinical symptoms. Diagnostic tools based on machine learning using these features can be very useful as they have the potential in early diagnosis of the disease. In the paper, we use olfactory loss feature from 40-item University of Pennsylvania Smell Identification Test (UPSIT) and Sleep behavior disorder feature from Rapid eye movement sleep Behavior Disorder Screening Questionnaire (RBDSQ), obtained from the Parkinson's Progression Marker's Initiative (PPMI) database, to develop automated diagnostic models using Support Vector Machine (SVM) and classification tree methods. The advantage of using UPSIT and RBDSQ is that they are quick, cheap, and can be self-administered. Results show that the models performed with high accuracy and sensitivity, and that they have the potential to aid in early diagnosis of Parkinson's disease.\n",
            "----------------------------------------\n",
            "Title: K-Local hyperplane distance nearest neighbor algorithm and protein fold recognition\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Leveraging Flask API and Machine Learning to Forecast Multiple Diseases\n",
            "Abstract: The study described in this abstract used machine learning to predict several diseases, and it integrated the model into a Flask API. A user-friendly platform for disease prediction based on patient symptoms and medical history was the goal of the paper. A number of strategies were used to optimize the predictive performance once the machine learning model had been trained on a sizable dataset of patient records. The model was made accessible as a web service through the usage of the Flask API, enabling simple deployment and integration into current healthcare systems. The study's findings demonstrated that the model could accurately forecast diseases with a high degree of precision, and the Flask API gave healthcare professionals an easy way to use the model in real-world settings. The study underscores the significance of developing open and user-friendly platforms for healthcare applications and shows the potential of machine learning and online APIs in improving disease detection. Additionally, the study discovered that the model could correctly identify disorders even in the absence of conclusive diagnostic tests.\n",
            "----------------------------------------\n",
            "Title: Pre-trained deep learning models for brain MRI image classification\n",
            "Abstract: Brain tumors are serious conditions caused by uncontrolled and abnormal cell division. Tumors can have devastating implications if not accurately and promptly detected. Magnetic resonance imaging (MRI) is one of the methods frequently used to detect brain tumors owing to its excellent resolution. In the past few decades, substantial research has been conducted in the field of classifying brain images, ranging from traditional methods to deep-learning techniques such as convolutional neural networks (CNN). To accomplish classification, machine-learning methods require manually created features. In contrast, CNN achieves classification by extracting visual features from unprocessed images. The size of the training dataset had a significant impact on the features that CNN extracts. The CNN tends to overfit when its size is small. Deep CNNs (DCNN) with transfer learning have therefore been developed. The aim of this work was to investigate the brain MR image categorization potential of pre-trained DCNN VGG-19, VGG-16, ResNet50, and Inception V3 models using data augmentation and transfer learning techniques. Validation of the test set utilizing accuracy, recall, Precision, and F1 score showed that the pre-trained VGG-19 model with transfer learning exhibited the best performance. In addition, these methods offer an end-to-end classification of raw images without the need for manual attribute extraction.\n",
            "----------------------------------------\n",
            "Title: Machine learning forecasts of Scandinavian numerical weather prediction wind model residuals with control theory for wind energy\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Information retrieval using machine learning from breast cancer diagnosis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Heat Transport Properties of Au-Nanoparticles Supported by TiO2: Insights from E(3)-Equivariant Machine Learning Potentials.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Novel Statistical Regularized Extreme Learning Algorithm to Address the Multicollinearity in Machine Learning\n",
            "Abstract: The multicollinearity problem is a common phenomenon in data-driven studies, significantly affecting the performance of machine learning algorithms during the process of extracting information from data. Despite its widespread use across various fields, the extreme learning machine (ELM) also suffers from multicollinearity issues. To address this challenge, the ridge and Liu estimators, drawn from statistics literature, have been integrated into ELM theory, resulting in a notable advancement. This study aims to further enhance the capabilities of ridge and Liu estimators within the ELM framework by introducing two innovative two-parameter algorithms (TP1-ELM and TP2-ELM) that simultaneously incorporate both estimators. The proposed algorithms undergo comprehensive benchmarking against ELM, ELM-based algorithms, and other commonly used machine learning techniques across seven diverse datasets. Benchmark results demonstrate that the proposed algorithms consistently outperform both ELM-focused approaches and traditional machine learning algorithms on most datasets, yielding more generalizable and stable results. These findings suggest that the proposed algorithms offer a promising alternative to traditional machine learning techniques for regression and classification tasks, particularly in scenarios where multicollinearity is a concern.\n",
            "----------------------------------------\n",
            "Title: Artificial Intelligence in General\n",
            "Abstract: There are many kinds of uses for artificial intelligence (AI) in almost every field. AI is quite often used for control, computer aided design (CAD) and computer aided manufacturing (CAM), machine control, computer integrated manufacturing (CIM), production spot control, factory control, intelligent control, intelligent systems, deep learning, the cloud, knowledge bases, database, management, production systems, statistics, to assist sales forces, environment examination, agriculture, art, livings, daily life, etc. The present AI uses will be reexamined whether there is any matter to be considered further or not in AI research directions and their purposes behind the current status by looking at the history of AI development.\n",
            "----------------------------------------\n",
            "Title: Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks\n",
            "Abstract: The integration of Machine Learning and Artifi-cial Intelligence (ML/AI) into fifth-generation (5G) networks has made evident the limitations of network intelligence with ever-increasing, strenuous requirements for current and next-generation devices. This transition to ubiquitous intelligence demands high connectivity, synchronicity, and end-to-end communication between users and network operators, and will pave the way towards full network automation without human intervention. Intent-based networking is a key factor in the reduction of human actions, roles, and responsibilities while shifting towards novel extraction and interpretation of automated network management. This paper presents the development of a custom Large Language Model (LLM) for 5G and next-generation intent-based networking and provides insights into future LLM developments and integrations to realize end-to-end intent-based networking for fully automated network intelligence.\n",
            "----------------------------------------\n",
            "Title: Zeroth-Order Online Alternating Direction Method of Multipliers: Convergence Analysis and Applications\n",
            "Abstract: In this paper, we design and analyze a new zeroth-order online algorithm, namely, the zeroth-order online alternating direction method of multipliers (ZOO-ADMM), which enjoys dual advantages of being gradient-free operation and employing the ADMM to accommodate complex structured regularizers. Compared to the first-order gradient-based online algorithm, we show that ZOO-ADMM requires $\\sqrt{m}$ times more iterations, leading to a convergence rate of $O(\\sqrt{m}/\\sqrt{T})$, where $m$ is the number of optimization variables, and $T$ is the number of iterations. To accelerate ZOO-ADMM, we propose two minibatch strategies: gradient sample averaging and observation averaging, resulting in an improved convergence rate of $O(\\sqrt{1+q^{-1}m}/\\sqrt{T})$, where $q$ is the minibatch size. In addition to convergence analysis, we also demonstrate ZOO-ADMM to applications in signal processing, statistics, and machine learning.\n",
            "----------------------------------------\n",
            "Title: Unsupervised Assessment of Balance and Falls Risk Using a Smartphone and Machine Learning\n",
            "Abstract: Assessment of health and physical function using smartphones (mHealth) has enormous potential due to the ubiquity of smartphones and their potential to provide low cost, scalable access to care as well as frequent, objective measurements, outside of clinical environments. Validation of the algorithms and outcome measures used by mHealth apps is of paramount importance, as poorly validated apps have been found to be harmful to patients. Falls are a complex, common and costly problem in the older adult population. Deficits in balance and postural control are strongly associated with falls risk. Assessment of balance and falls risk using a validated smartphone app may lessen the need for clinical assessments which can be expensive, requiring non-portable equipment and specialist expertise. This study reports results for the real-world deployment of a smartphone app for self-directed, unsupervised assessment of balance and falls risk. The app relies on a previously validated algorithm for assessment of balance and falls risk; the outcome measures employed were trained prior to deployment on an independent data set. Results for a sample of 594 smartphone assessments from 147 unique phones show a strong association between self-reported falls history and the falls risk and balance impairment scores produced by the app, suggesting they may be clinically useful outcome measures. In addition, analysis of the quantitative balance features produced seems to suggest that unsupervised, self-directed assessment of balance in the home is feasible.\n",
            "----------------------------------------\n",
            "Title: Review\n",
            "Abstract: Deep Learning is-one of the machine learning areas, applied in recent areas. Various techniques have been proposed depends on varieties of learning, including unsupervised, semi-supervised, and supervised-learning. Some of the experimental results proved that the deep learning systems are performed well compared to conventional machine learning systems in image processing, computer vision and pattern recognition. This paper provides a brief survey, beginning with Deep Neural Network (DNN) in Deep Learning area. The survey moves on-the Convolutional Neural Network (CNN) and its architectures, such as LeNet, AlexNet, GoogleNet, VGG16, VGG19, Resnet50 etc. We have included transfer learning by using the CNN’s pre-trained architectures. These architectures are tested with large ImageNet data sets. The deep learning techniques are analyzed with the help of most popular data sets, which are freely available in web. Based on this survey, conclude the performance of the system depends on the GPU system.\n",
            "----------------------------------------\n",
            "Title: Pre-Processing Data with a Horizontal Tuning Framework Using Microservices and its Impact on Machine Learning Algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Detecting Risk Gene and Pathogenic Brain Region in EMCI Using a Novel GERF Algorithm Based on Brain Imaging and Genetic Data\n",
            "Abstract: Fusion analysis of disease-related multi-modal data is becoming increasingly important to illuminate the pathogenesis of complex brain diseases. However, owing to the small amount and high dimension of multi-modal data, current machine learning methods do not fully achieve the high veracity and reliability of fusion feature selection. In this paper, we propose a genetic-evolutionary random forest (GERF) algorithm to discover the risk genes and disease-related brain regions of early mild cognitive impairment (EMCI) based on the genetic data and resting-state functional magnetic resonance imaging (rs-fMRI) data. Classical correlation analysis method is used to explore the association between brain regions and genes, and fusion features are constructed. The genetic-evolutionary idea is introduced to enhance the classification performance, and to extract the optimal features effectively. The proposed GERF algorithm is evaluated by the public Alzheimer's Disease Neuroimaging Initiative (ADNI) database, and the results show that the algorithm achieves satisfactory classification accuracy in small sample learning. Moreover, we compare the GERF algorithm with other methods to prove its superiority. Furthermore, we propose the overall framework of detecting pathogenic factors, which can be accurately and efficiently applied to the multi-modal data analysis of EMCI and be able to extend to other diseases. This work provides a novel insight for early diagnosis and clinicopathologic analysis of EMCI, which facilitates clinical medicine to control further deterioration of diseases and is good for the accurate electric shock using transcranial magnetic stimulation.\n",
            "----------------------------------------\n",
            "Title: Comprehending Lexical and Affective Ontologies in the Demographically Diverse Spatial Social Media Discourse\n",
            "Abstract: This study aims to comprehend linguistic and sociodemographic features, encompassing English language styles, conveyed sentiments, and lexical diversity within spatial online social media review data. To this end, we undertake a case study that scrutinizes reviews composed by two distinct and demographically diverse groups. Our analysis entails the extraction and examination of various statistical, grammatical, and sentimental features from these two groups. Subsequently, we leverage these features with machine learning (ML) classifiers to discern their potential in effectively differentiating between the groups. Our investigation unveils substantial disparities in certain linguistic attributes between the two groups. When integrated into ML classifiers, these attributes exhibit a marked efficacy in distinguishing the groups, yielding a macro F1 score of approximately 0.85. Furthermore, we conduct a comparative evaluation of these linguistic features with word n-gram-based lexical features in discerning demographically diverse review data. As expected, the n-gram lexical features, coupled with finetuned transformer-based models, show superior performance, attaining accuracies surpassing 95% and macro F1 scores exceeding 0.96. Our meticulous analysis and comprehensive evaluations substantiate the efficacy of linguistic and sentimental features in effectively discerning demographically diverse review data. The findings of this study provide valuable guidelines for future research endeavors concerning the analysis of demographic patterns in textual content across various social media platforms.\n",
            "----------------------------------------\n",
            "Title: A Novel Feature Encoding Scheme for Machine Learning Based Malware Detection Systems\n",
            "Abstract: Malware detection is an ever-evolving area given that the strides in the detection capabilities being matched by radical attempts to bypass the detection. As the sophistication of malware continues to increase, the demand for innovative approaches to improve detection capabilities become paramount. Machine learning/Deep learning models are being increasingly used for Malware Detection, however one of the most important and frequently overlooked aspects of building such models is feature encoding. This research paper explores the importance of feature encoding to improve the efficiency of threat detection and proposes a novel entropy-based encoding scheme for the categorical features present in the data extracted from malicious inputs. The KDDCUP99, UNSW-NB15 and CIC-Evasive-PDFMal2022 datasets have been used to evaluate the effectiveness of the proposed encoding scheme. The results of the proposed encoding scheme are validated against seven other encoding schemes to ascertain the credibility and usability of the proposed scheme. The efficiency of the proposed system evaluated by applying different encoded versions of the datasets to train various machine learning models and determining the classification performance of the models on each dataset. The machine learning models trained with the proposed encoding scheme produced stable classification results and outperformed other encoding schemes when dimensionality reduction was applied on the data. The ensemble classifier trained using the proposed scheme was able to classify the data with an F1 score of 99.99% when the dimension-reduced entropy-encoded KDD Cup99 dataset was used to build the model. On the CIC-Evasive-PDFMal2022 dataset, the entropy encoding has exhibited a slightly improved classification parameters with the ensemble methods yielding a peak F1 score of 99.27%. We have also determined the feature importance values of the features present in the datasets to study the change in the contribution levels of the features when multiple categorical encoding schemes are applied upon the data.\n",
            "----------------------------------------\n",
            "Title: Sistema de sugestão de produtos para e-commerce utilizando Inteligência Artificial\n",
            "Abstract: Resumo. O trabalho trata da implementação de um sistema de recomendação baseado em filtragem colaborativa, utilizando técnicas de Machine Learning e Deep Learning. Esse sistema, diferentemente de outros do tipo, não depende de avaliações de clientes e infere a popularidade dos produtos com base em seu volume e recorrência de venda. Nesse estudo, as recomendações geradas são analisadas a fim de obter insights sobre as lojas virtuais das quais se originaram.\n",
            "----------------------------------------\n",
            "Title: Application of Machine Learning Methods in Inferring Surface Water Groundwater Exchanges using High Temporal Resolution Temperature Measurements\n",
            "Abstract: We examine the ability of machine learning (ML) and deep learning (DL) algorithms to infer surface/ground exchange flux based on subsurface temperature observations. The observations and fluxes are produced from a high-resolution numerical model representing conditions in the Columbia River near the Department of Energy Hanford site located in southeastern Washington State. Random measurement error, of varying magnitude, is added to the synthetic temperature observations. The results indicate that both ML and DL methods can be used to infer the surface/ground exchange flux. DL methods, especially convolutional neural networks, outperform the ML methods when used to interpret noisy temperature data with a smoothing filter applied. However, the ML methods also performed well and they are can better identify a reduced number of important observations, which could be useful for measurement network optimization. Surprisingly, the ML and DL methods better inferred upward flux than downward flux. This is in direct contrast to previous findings using numerical models to infer flux from temperature observations and it may suggest that combined use of ML or DL inference with numerical inference could improve flux estimation beneath river systems.\n",
            "----------------------------------------\n",
            "Title: Telephone-based Dementia Screening I: Automated Semantic Verbal Fluency Assessment\n",
            "Abstract: Dementia has a large economic impact on our society as cost-effective population-wide screening for early signs of dementia is still an unsolved medical supply resource problem. A solution should be fast, require a minimum of external material, and automatically indicate potential persons at risk of cognitive decline. Despite encouraging results, leveraging pervasive sensing technologies for automatic dementia screening, there are still two main issues: significant hardware costs or installation efforts and the challenge of effective pattern recognition. Conversely, automatic speech recognition (ASR) and speech analysis have reached sufficient maturity and allow for low-tech remote telephone-based screening scenarios. Therefore, we examine the technologic feasibility of automatically assessing a neuropsychological test---Semantic Verbal Fluency (SVF)--via a telephone-based solution. We investigate its suitability for inclusion into an automated dementia frontline screening and global risk assessment, based on concise telephone-sampled speech, ASR and machine learning classification. Results are encouraging showing an area under the curve (AUC) of 0.85. We observe a relatively low word error rate of 33% despite phone-quality speech samples and a mean age of 77 years of the participants. The automated classification pipeline performs equally well compared to the classifier trained on manual transcriptions of the same speech data. Our results indicate SVF as a prime candidate for inclusion into an automated telephone-screening system.\n",
            "----------------------------------------\n",
            "Title: Analysis Model of Terrorist Attacks Based on Big Data\n",
            "Abstract: With the continuous deepening of international anti-terrorism movement the anti-terrorism has entered a new stage5 and it is facing new challenges. One of the new challenges is to extract useful and valuable information from massive data efficiently. The anti-terrorism system model based on local shallow information is imperfect, which is not conducive to obtaining accurate prediction results. The shortcomings of existing research are the lack of comprehensive analysis and deeper mining of data. In order to improve the efficiency and accuracy of the present anti-terrorism system5 we propose an effective method for risk assessment and prediction based on machine learning by using Global Terrorism Database (GTD). There are four basic steps: first, we reduce the data dimension through correlation calculation and Singular Value Decomposition(SVD) then the function is established to rank the harmfulness of terrorist attacks; second, the cascaded network with attention mechanism is used to predict suspects; third, k-means is used to cluster the regions of terrorist attacks5 and then we establish a generalized linear regression model to predict the situation of terrorist attacks. We verify the feasibility of the model by comparing with the real data. The experimental results show that the proposed method can analyze and predict the information related to terrorist attacks comprehensively and accurately.\n",
            "----------------------------------------\n",
            "Title: Machine learning-based grassland aboveground biomass estimation and its response to climate variation in Southwest China\n",
            "Abstract: The demand for accurate estimation of aboveground biomass (AGB) at high spatial resolution is increasing in grassland-related research and management, especially for those regions with complex topography and fragmented landscapes, where grass and shrub are interspersed. In this study, based on 519 field AGB observations, integrating Synthetic Aperture Radar (SAR; Sentinel-1) and high-resolution (Sentinel-2) remote sensing images, environmental and topographical data, we estimated the AGB of mountain grassland in Southwest China (Yunnan Province and Guizhou Province) by using remote sensing algorithms ranging from traditional regression to cutting edge machine learning (ML) and deep learning (DL) models. Four models (i.e., multiple stepwise regression (MSR), random forest (RF), support vector machine (SVM) and convolutional neural network (CNN)) were developed and compared for AGB simulation purposes. The results indicated that the RF model performed the best among the four models (testing dataset: decision co-efficient (R2) was 0.80 for shrubland and 0.75 for grassland, respectively). Among all input variables in the RF model, the vegetation indices played the most important role in grassland AGB estimation, with 6 vegetation indices (EVI, EVI2, NDVI, NIRv, MSR and DVI) in the top 10 of input variables. For shrubland, however, topographical factors (elevation, 12.7% IncMSE (increase in mean squared error)) and SAR data (VH band, 11.3% IncMSE) were the variables which contributed the most in the AGB estimation model. By comparing the input variables to the RF model, we found that integrating SAR data has the potential to improve grassland AGB estimation, especially for shrubland (26.7% improvement in the estimation of shrubland AGB). Regional grassland AGB estimation showed a lower mean AGB in Yunnan Province (443.6 g/m2) than that in Guizhou Province (687.6 g/m2) in 2021. Moreover, the correlation between five consecutive years (2018–2022) of AGB data and climatic factors calculated by partial correlation analysis showed that regional AGB was positively related with mean annual precipitation in more than 70% of the grassland and 60% of the shrubland area, respectively. Also, we found a positive relationship with mean annual temperature in 62.8% of the grassland and 55.6% of the shrubland area, respectively. This study demonstrated that integrating SAR into grassland AGB estimation led to a remote sensing estimation model that greatly improved the accuracy of modeled mountain grassland AGB in southwest China, where the grassland consists of a complex mix of grass and shrubs.\n",
            "----------------------------------------\n",
            "Title: Limbic/paralimbic connection weakening in preschool autism-spectrum disorder based on diffusion basis spectrum imaging.\n",
            "Abstract: This study aims to investigate the value of basal ganglia and limbic/paralimbic networks alteration in identifying preschool children with ASD and normal controls using diffusion basis spectrum imaging (DBSI). DBSI data from 31 patients with ASD and 30 NC were collected in Hunan Children's Hospital. All data were imported into the post-processing server. The most discriminative features were extracted from the connection, global and nodal metrics separately using the two-sample t-test. To effectively integrate the multimodal information, we employed the multi-kernel learning support vector machine (MKL-SVM). In ASD group, the value of global efficiency, local efficiency, clustering coefficient and synchronization were lower than NC group, while modularity score, hierarchy, normalized clustering coefficient, normalized characteristic path length, small-world, characteristic path length and assortativity were higher. Significant weaker connections are mainly distributed in the limbic/paralimbic networks. The model combining consensus connection, global and nodal graph metrics features can achieve the best performance in identifying ASD patients, with an accuracy of 96.72%.The most specific brain regions connection weakening associated with preschool ASD are predominantly located in limbic/paralimbic networks, suggesting their involvement in abnormal brain development processes. The effective combination of connection, global and nodal metrics information by MKL-SVM can effectively distinguish patients with ASD.\n",
            "----------------------------------------\n",
            "Title: “Decision tree analysis for assessing the risk of post-traumatic haemorrhage after mild traumatic brain injury in patients on oral anticoagulant therapy”\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Open-Ended Questions\n",
            "Abstract: Natural language processing (NLP) is the field of decoding human written language. This chapter responds to the growing interest in using machine learning–based NLP approaches for analyzing open-ended employee survey responses. These techniques address scalability and the ability to provide real-time insights to make qualitative data collection equally or more desirable in organizations. The chapter walks through the evolution of text analytics in industrial–organizational psychology and discusses relevant supervised and unsupervised machine learning NLP methods for survey text data, such as latent Dirichlet allocation, latent semantic analysis, sentiment analysis, word relatedness methods, and so on. The chapter also lays out preprocessing techniques and the trade-offs of growing NLP capabilities internally versus externally, points the readers to available resources, and ends with discussing implications and future directions of these approaches.\n",
            "----------------------------------------\n",
            "Title: Reinforcement Learning based Scheduling for Spark Jobs in Cloud Environment\n",
            "Abstract: Recently, big data computing paradigm has been gaining proliferation due to wide applications for processing enormous volumes of data to produce meaningful information. The big data computing frameworks perform data processing in cloud computing or physical on-premises. Cloud service providers provide flexible, affordable, and reliable resources that are easier to manage than on-premise physical data centers. So many organization are now moving their big data computing framework over to the cloud computing environment. However, due to several limitations, including the need to reduce costs for using virtual machines, optimize system performance by lowering the Average job completion time, and adhere to service level agreements for the jobs, scheduling Spark jobs efficiently in a cloud environment is a challenging problem. Numerous heuristic-based solutions are available in the literature; however, they do not work well in heterogeneous cloud environments where many constraints are present while scheduling the jobs. So, in this paper, we have optimized the use of computing resources in a cloud environment by analyzing spark job scheduling based on reinforcement learning algorithms. The case study's proposed analysis demonstrates how a reinforcement learning algorithm enables an agent to learn the inherent properties of the computing environment for job scheduling.\n",
            "----------------------------------------\n",
            "Title: Traditional and Machine Learning Methods for Credit Scoring: an introduction\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Research on State of Health Estimation of Lithium Batteries Based on EIS and CNN-VIT Models\n",
            "Abstract: \n",
            " With the development of electric vehicles, the demand for lithium-ion batteries has been increasing annually. Accurately estimating the State of Health (SOH) of lithium-ion batteries is crucial for their efficient and reliable use. Most of the existing research on SOH estimation is based on parameters such as current, voltage, and temperature, which are prone to fluctuations. Estimating the SOH of lithium-ion batteries based on Electrochemical Impedance Spectroscopy (EIS) and data-driven approaches has been proven effective. In this paper, we explore a novel SOH estimation model for lithium batteries based on EIS and Convolutional Neural Network (CNN)-Vision Transformer (VIT). The EIS data is treated as a grayscale image, eliminating the need for manual feature extraction and simultaneously capturing both local and global features in the data. To validate the effectiveness of the proposed model, a series of simulation experiments are conducted, comparing it with various traditional machine learning models in terms of Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Coefficient of Determination (R2). The simulation results demonstrate that the proposed model performs best overall in the testing dataset at three different temperatures. This confirms that the model can accurately and stably estimate the SOH of lithium-ion batteries without requiring manual feature extraction and knowledge of battery aging temperature.\n",
            "----------------------------------------\n",
            "Title: From Big Data to Deep Data to Support People Analytics for Employee Attrition Prediction\n",
            "Abstract: In the era of data science and big data analytics, people analytics help organizations and their human resources (HR) managers to reduce attrition by changing the way of attracting and retaining talent. In this context, employee attrition presents a critical problem and a big risk for organizations as it affects not only their productivity but also their planning continuity. In this context, the salient contributions of this research are as follows. Firstly, we propose a people analytics approach to predict employee attrition that shifts from a big data to a deep data context by focusing on data quality instead of its quantity. In fact, this deep data-driven approach is based on a mixed method to construct a relevant employee attrition model in order to identify key employee features influencing his/her attrition. In this method, we started thinking ‘big’ by collecting most of the common features from the literature (an exploratory research) then we tried thinking ‘deep’ by filtering and selecting the most important features using survey and feature selection algorithms (a quantitative method). Secondly, this attrition prediction approach is based on machine, deep and ensemble learning models and is experimented on a large-sized and a medium-sized simulated human resources datasets and then a real small-sized dataset from a total of 450 responses. Our approach achieves higher accuracy (0.96, 0.98 and 0.99 respectively) for the three datasets when compared previous solutions. Finally, while rewards and payments are generally considered as the most important keys to retention, our findings indicate that ‘business travel’, which is less common in the literature, is the leading motivator for employees and must be considered within HR policies to retention.\n",
            "----------------------------------------\n",
            "Title: Evolutionary machine learning builds smart education big data platform: Data-driven higher education\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Chatbot: A Deep Neural Network Based Human to Machine Conversation Model\n",
            "Abstract: A conversational agent (chatbot) is computer software capable of communicating with humans using natural language processing. The crucial part of building any chatbot is the development of conversation. Despite many developments in Natural Language Processing (NLP) and Artificial Intelligence (AI), creating a good chatbot model remains a significant challenge in this field even today. A conversational bot can be used for countless errands. In general, they need to understand the user's intent and deliver appropriate replies. This is a software program of a conversational interface that allows a user to converse in the same manner one would address a human. Hence, these are used in almost every customer communication platform, like social networks. At present, there are two basic models used in developing a chatbot. Generative based models and Retrieval based models. The recent advancements in deep learning and artificial intelligence, such as the end-to-end trainable neural networks have rapidly replaced earlier methods based on hand-written instructions and patterns or statistical methods. This paper proposes a new method of creating a chatbot using a deep neural learning method. In this method, a neural network with multiple layers is built to learn and process the data.\n",
            "----------------------------------------\n",
            "Title: BlindFL: Vertical Federated Machine Learning without Peeking into Your Data\n",
            "Abstract: Due to the rising concerns on privacy protection, how to build machine learning (ML) models over different data sources with security guarantees is gaining more popularity. Vertical federated learning (VFL) describes such a case where ML models are built upon the private data of different participated parties that own disjoint features for the same set of instances, which fits many real-world collaborative tasks. Nevertheless, we find that existing solutions for VFL either support limited kinds of input features or suffer from potential data leakage during the federated execution. To this end, this paper aims to investigate both the functionality and security of ML modes in the VFL scenario. To be specific, we introduce BlindFL, a novel framework for VFL training and inference. First, to address the functionality of VFL models, we propose the federated source layers to unite the data from different parties. Various kinds of features can be supported efficiently by the federated source layers, including dense, sparse, numerical, and categorical features. Second, we carefully analyze the security during the federated execution and formalize the privacy requirements. Based on the analysis, we devise secure and accurate algorithm protocols, and further prove the security guarantees under the ideal-real simulation paradigm. Extensive experiments show that BlindFL supports diverse datasets and models efficiently whilst achieves robust privacy guarantees.\n",
            "----------------------------------------\n",
            "Title: A Comprehensive Survey on Conflict Detection and Resolution in Unmanned Aircraft System Traffic Management\n",
            "Abstract: The anticipated proliferation of Unmanned Aerial Vehicles (UAVs) in the airspace in the coming years has raised concerns about how to manage their flights to avoid collisions and crashes at various stages of flight. To this end, many Unmanned Aircraft Traffic Management systems (UTM) have been designed. These systems use various methods for managing UAV conflicts. Several surveys have reviewed conflict resolution methods for UAVs. However, to the best of our knowledge, there is no survey specifically addressing conflict detection and resolution methods in UTM, particularly those using AI-based methods. Therefore, this article serves as a comprehensive survey of all UAVs conflicts detection and resolution methods proposed in the literature and their use in the UTM systems. This survey classifies the methods into two categories: classical (non-learning) methods and learning-based methods. Classical methods typically rely on pre-defined algorithms or rules for UAVs to avoid collisions, whereas Artificial Intelligence-based methods, including Machine Learning (ML) and especially Reinforcement Learning (RL), enable UAVs to adapt to their environment, autonomously resolve conflicts, and exhibit intelligent behavior based on their experiences. It also presents their application in the conflict resolution service for UTMs. Additionally, the challenges and issues associated with each type of methods are discussed. This article can serve as a foundational resource for researchers in guiding their selection of methods for conflict resolution, particularly those relevant to UTM systems.\n",
            "----------------------------------------\n",
            "Title: S1417 Comparison of Logistic Regression Model With Machine Learning Models to Predict Acute Liver Injury in Patients Hospitalized With COVID-19\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Fast learning network: a novel artificial neural network with a fast learning speed\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: QGeo: Q-Learning-Based Geographic Ad Hoc Routing Protocol for Unmanned Robotic Networks\n",
            "Abstract: This letter proposes a novel protocol that uses Q-learning-based geographic routing (QGeo) to improve the network performance of unmanned robotic networks. A rapid and reliable network is essential for the remote control and monitoring of mobile robotic devices. However, controlling the network overhead required for route selection and repair is still a notable challenge, owing to high mobility of the devices. To alleviate this problem, we propose a machine-learning-based geographic routing scheme to reduce network overhead in high-mobility scenarios. We evaluate the performance of QGeo in comparison with other methods using the NS-3 simulator. We find that QGeo has a higher packet delivery ratio and a lower network overhead than existing methods.\n",
            "----------------------------------------\n",
            "Title: Development and Validation of a Machine Learning Model for Detection and Classification of Vertigo.\n",
            "Abstract: PURPOSE\n",
            "This study aims to investigate whether artificial intelligence can improve the diagnostic accuracy of vertigo related diseases.\n",
            "\n",
            "\n",
            "EXPERIMENTAL DESIGN\n",
            "Based on the clinical guidelines, clinical symptoms and laboratory test results were extracted from electronic medical records as variables. These variables were then input into a machine learning diagnostic model for classification and diagnosis. This study encompasses two primary objectives: Task 1 to distinguish between patients with Benign Paroxysmal Positional Vertigo (BPPV) and non-BPPV. In Task 2, further classifying non-BPPV patients into Ménière's Disease (MD), Vestibular Migraine (VM), and Sudden Sensorineural Hearing Loss accompanied by Vertigo (SSNHLV). The sensitivity, precision, and area under the curve (AUC) metric is primarily used to assess the performance of the machine learning model development phase in a prospective validation cohort.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "In our study, 1789 patients were recruited as the training cohort and 1148 patients as the prospective validation cohort. The comprehensive diagnostic performance of the XGBoost model surpasses that of traditional models. The sensitivity, accuracy, and AUC in task 1 were 98.32%, 87.03%, and 0.947, respectively. In task 2, the sensitivity values for MD, SSNHLV, and VM were 89.00%, 100.0%, and 79.40%, respectively. The precision values were 88.80%, 100.0%, and 80.00%, respectively. The AUC values were 0.933, 1.000, and 0.931, respectively. The model can significantly improve the accuracy of diagnosing vertigo diseases.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "This system may enhance the accuracy of classification and diagnosis of vertigo diseases. It offers initial therapy or referrals to clinical doctors, particularly in resource-limited settings.\n",
            "\n",
            "\n",
            "LEVEL OF EVIDENCE\n",
            "N/A Laryngoscope, 2024.\n",
            "----------------------------------------\n",
            "Title: Optimization of Power Efficient Spatial Division Multiplexed Submarine Cables Using Adaptive Transponders and Machine Learning\n",
            "Abstract: Historically, undersea systems capacity increases were primarily based on maximizing the total throughput per fiber. Whilst previously designed to operate at optimum launch power of the fiber, subsea systems are now designed for higher optical power efficiency. Next generation of spatial division multiplexed (SDM) cables require operation at lower signal power enabling repeater pump farming and providing higher reliability and efficiency. To adapt to these power constraints, the benefits of adaptive transponders and the application of machine learning to submarine line design are investigated.\n",
            "----------------------------------------\n",
            "Title: Sexual Trauma and Post-Traumatic Stress Disorder Among Warfighters in Army STARRS\n",
            "Abstract: Abstract : The current report presents an update of results from the previous annual report. A great deal of progress has been made over the past year. The most exciting results are those that focus on the association between self-reported risk and protective factors in the Army STARRS New Soldier Survey (NSS), which was administered during reception week, and subsequent administrative records showing that the new soldiers in the NSS either were perpetrators or victims of Military Sexual Trauma (MST) over their first two years of Army service. We used machine learning methods to develop optimal prediction equations from the NSS data. Even though final models have not yet been completed, preliminary results are very positive: showing that the 10% of new male soldiers classified as having highest risk of MST perpetration were responsible for 58.3% of all actual MST perpetration that occurred over the next two years, while the 5% of new female soldiers classified as having highest risk of MST victimization were involved in 32% of all actual MST victimization that occurred over the next two years. These percentages can only increase with model refinements that will be made over the next few months. Concentrations of risk as high as these are actionable, as they can be used to target high-risk new soldiers for enhanced preventive intervention efforts aimed at reducing incidence of MST.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Methods in Statistical Model Checking and System Design - Tutorial\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Deep Illumination: Approximating Dynamic Global Illumination with Generative Adversarial Network\n",
            "Abstract: We present Deep Illumination, a novel machine learning technique for approximating global illumination (GI) in real-time applications using a Conditional Generative Adversarial Network. Our primary focus is on generating indirect illumination and soft shadows with offline rendering quality at interactive rates. Inspired from recent advancement in image-to-image translation problems using deep generative convolutional networks, we introduce a variant of this network that learns a mapping from Gbuffers (depth map, normal map, and diffuse map) and direct illumination to any global illumination solution. Our primary contribution is showing that a generative model can be used to learn a density estimation from screen space buffers to an advanced illumination model for a 3D environment. Once trained, our network can approximate global illumination for scene configurations it has never encountered before within the environment it was trained on. We evaluate Deep Illumination through a comparison with both a state of the art real-time GI technique (VXGI) and an offline rendering GI technique (path tracing). We show that our method produces effective GI approximations and is also computationally cheaper than existing GI techniques. Our technique has the potential to replace existing precomputed and screen-space techniques for producing global illumination effects in dynamic scenes with physically-based rendering quality.\n",
            "----------------------------------------\n",
            "Title: Design and Implementation of Network Security Management System Based on K-Means Algorithm\n",
            "Abstract: With the rapid development of computer technology and Internet worldwide, people are using computers more and more to deal with various affairs. However, due to the late start of information construction and weak foundation, there are still many problems that need to be solved in China: such as unreasonable network structure, unsound network management system and lack of effective network security protection system, which have seriously restricted the rapid and healthy development of China’s economy and society. Therefore, how to strengthen the scientific and rational use of information network resources has become one of the important issues that need to be studied urgently. As an emerging information processing method, cluster analysis is to measure the similarity in a collection of objects and divide them into several categories according to certain criteria, so that the objects in the same category have a greater degree of similarity or similarity. It can discover a large amount of potentially useful knowledge, and thus is widely used in pattern recognition, machine learning, image segmentation and text classification. However, traditional clustering algorithms often need to specify the number of clusters or the initial centroid positions in advance, which leads to the final result may not be the optimal solution; In addition, when the size of the dataset increases, the computational effort also increases dramatically, which is difficult to meet the actual demand. To address the above problems, this paper proposes a new K-Means algorithm-based model for network security management systems, which can automatically determine the number of clusters and their optimal initial values, while using a parallel approach to execute tasks to reduce running time and improve efficiency.\n",
            "----------------------------------------\n",
            "Title: Structured Representations for Coreference Resolution\n",
            "Abstract: Coreference resolution is the task of determining which expressions in a text are used to refer to the same entity. This task is one of the most fundamental problems of natural language understanding. Inherently, coreference resolution is a structured task, as the output consists of sets of coreferring expressions. This complex structure poses several challenges since it is not clear how to account for the structure in terms of error analysis and representation. \n",
            " \n",
            "In this thesis, we present a treatment of computational coreference resolution that accounts for the structure. Our treatment encompasses error analysis and the representation of approaches to coreference resolution. In particular, we propose two frameworks in this thesis. \n",
            " \n",
            "The first framework deals with error analysis. We gather requirements for an appropriate error analysis method and devise a framework that considers a structured graph-based representation of the reference annotation and the system output. Error extraction is performed by constructing linguistically motivated or data-driven spanning trees for the graph-based coreference representations. \n",
            " \n",
            "The second framework concerns the representation of approaches to coreference resolution. We show that approaches to coreference resolution can be understood as predictors of latent structures that are not annotated in the data. From these latent structures, the final output is derived during a post-processing step. We devise a machine learning framework for coreference resolution based on this insight. In this framework, we have a unified representation of approaches to coreference resolution. Individual approaches can be expressed as instantiations of a generic approach. We express many approaches from the literature as well as novel variants in our framework, ranging from simple pairwise classification approaches to complex entity-centric models. Using the uniform representation, we are able to analyze differences and similarities between the models transparently and in detail. \n",
            " \n",
            "Finally, we employ the error analysis framework to perform a qualitative analysis of differences in error profiles of the models on a benchmark dataset. We trace back differences in the error profiles to differences in the representation. Our analysis shows that a mention ranking model and a tree-based mention-entity model with left-to-right inference have the highest performance. We discuss reasons for the improved performance and analyze why more advanced approaches modeled in our framework cannot improve on these models. An implementation of the frameworks discussed in this thesis is publicly available.\n",
            "----------------------------------------\n",
            "Title: Optimization of Crime Scene Reconstruction Based on Bloodstain Patterns and Machine Learning Techniques\n",
            "Abstract: Crime scene reconstruction based on circumstantial evidence and bloodstain patterns at the scene is often affected by unwanted expert bias. Using features such as bloodstain pattern, wound analysis, size of bloodstains on objects etc., predictions could be made about the relative position of the victim/s, bystander/s and perpetrator/s. Supervised learning techniques can be used to make predictions related to the murder weapon used. Gender of an individual could also be estimated from the bloody broken plastic footprint of an individual using a suitable dataset and supervised classifier. These intermediate prediction modules are important for development of event segments. The event segments add up towards the development of the events that transpired at the crime scene. An optimal sequence of events that might have transpired at the crime scene could thereby be developed using event timestamp and logical sequencing of similar incidents that had occurred in the past using probability theory.\n",
            "----------------------------------------\n",
            "Title: Weighted Fuzzy System for Identifying DNA N4-Methylcytosine Sites With Kernel Entropy Component Analysis\n",
            "Abstract: N4-methylcytosine (4mC) is a common DNA methylation that has been implicated in epigenetic regulation and host defense. Accurate prediction of 4mC sites in DNA sequences will help to better explore the biological processes and mechanisms. For this problem, computational methods based on machine learning and deep learning are faster, less complex, and less expensive than experimental detection methods. However, the existing computational methods are still unsatisfactory in terms of prediction accuracy, so we propose a new method with better performance. In this work, we propose a weighted fuzzy system for identifying DNA 4mC sites by kernel entropy component analysis (KECA). We named it as W-TSK-FS-KECA. This model is improved based on the Takagi–Sugeuo–Kang fuzzy system (TSK-FS). We use position-specific trinucleotide propensity to construct feature vectors on representative benchmark datasets. Then we use KECA to get the reconstruct error. Finally, we put the calculated reconstruction error add to the regular term of TSK-FS as the weights to enhance the model performance. Comparative experiments with other methods show that it has good classification perfor- mance.\n",
            "----------------------------------------\n",
            "Title: Gender Aspects in Driving Style and Its Impact on Battery Ageing\n",
            "Abstract: The long and tiring discussion of who are the best drivers, men or women, is not answered in this article. This article, though, sheds some light on the actual differences that can be seen in how men and women drive. In this study, GPS-recorded driving dynamics data from 123 drivers, 48 women and 75 men, are analysed and drivers are categorised as aggressive, normal or gentle. A total of 10% of the drivers was categorised as aggressive, with an even distribution between the genders. For the gentle drivers, 11% of the drivers, the men dominated. The driving style investigation was extended to utilise machine learning, confirming the results from statistical tools. As driving style highly impacts a vehicle’s fuel consumption, while switching over to battery electric vehicles it is important to investigate how the different driving styles impact battery utilisation. Two Li-ion battery cell types were tested utilising the same load cycle with three levels of current amplitude, to represent accelerations for the three drive categories. While one cell type was insensitive to the current amplitude, the highly energy-optimised cell proved to be sensitive to higher current amplitudes, corresponding to a more aggressive driving style. Thus, the amplitude of the dynamic current can for some cells be a factor that needs to be considered for lifetime predictions, while it can be neglected for other cells.\n",
            "----------------------------------------\n",
            "Title: Spin-Current Thermoelectric Conversion — Informatics-Based Materials Development and Scope of Applications\n",
            "Abstract: There are many cases in which the discovery of a material or device possessing new functionality changes not only the structures of individual enterprises but also exerts a very great impact on leading to the reform of the entire society. Some such examples include the neodymium magnet, the high-temperature superconductor and the blue LED. All of which have achieved significant success due to the extensive committed research, as well as the impact of chance events. However, the environments that surround material and device development are changing continually. The need for results has now reached a very high level of urgency in the fields that are experiencing severe competition. Consequently, attention is drawn to approaches that can develop materials and devices more efficiently by the maximum use of advanced technologies. Particularly, the materials informatics (MI) gathers special attention as a new technique for accelerating development by utilizing the knowledge obtained via informatics. In the present paper, section 2 describes the trends of MI technology development, section 3 reports on an Since the energy conversion technology that makes use of a new physical property called the spin current was reported in 2008, conversion efficiencies have been improved significantly, being helped by the discovery of new materials. This improvement has been backed not only by the accumulation of discoveries of new materials and mechanisms but more importantly, by efforts aimed at improving the efficiencies of materials development processes by taking a completely new approach. This paper introduces the creation of a new materials development process that combines an attempt at large-scale data acquisition in the field of materials development and an informatics approach for analyzing the acquired data by using machine learning. The potential benefits of its utilization are also discussed. In addition, the paper discusses the application domains of the spin-current thermoelectric conversion technology that are currently being put into practical use.\n",
            "----------------------------------------\n",
            "Title: Root identification in minirhizotron imagery with multiple instance learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Accurate Multi-Scale Feature Fusion CNN for Time Series Classification in Smart Factory\n",
            "Abstract: Time series classification (TSC) has attracted various attention in the community of machine learning and data mining and has many successful applications such as fault detection and product identification in the process of building a smart factory. However, it is still challenging for the efficiency and accuracy of classification due to complexity, multi-dimension of time series. This paper presents a new approach for time series classification based on convolutional neural networks (CNN). The proposed method contains three parts: short-time gap feature extraction, multi-scale local feature learning, and global feature learning. In the process of short-time gap feature extraction, large kernel filters are employed to extract the features within the short-time gap from the raw time series. Then, a multi-scale feature extraction technique is applied in the process of multi-scale local feature learning to obtain detailed representations. The global convolution operation with giant stride is to obtain a robust and global feature representation. The comprehension features used for classifying are a fusion of short time gap feature representations, local multi-scale feature representations, and global feature representations. To test the efficiency of the proposed method named multi-scale feature fusion convolutional neural networks (MSFFCNN), we designed, trained MSFFCNN on some public sensors, device, and simulated control time series data sets. The comparative studies indicate our proposed MSFFCNN outperforms other alternatives, and we also provided a detailed analysis of the proposed MSFFCNN.\n",
            "----------------------------------------\n",
            "Title: Applications of Machine Learning in Wireless Communication: 5G and Beyond\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: The relationship between students’ interest in bilingual science learning and students’ English competence\n",
            "Abstract: The correlation of students’ interest in bilingual science learning and their English competence was investigated. Forty-six students of elementary-school teacher candidate program participated in this study. The students received five topics of science (Heat, Changes in Matters, Plant Life and Environment, Simple Machine, Animal Life and Environment) with English usage embedded. The students’ interest in science learning involving English was examined. Meanwhile, the students’ mastery of general English was measured. The result shows that the students’ interest in bilingual science learning and their English mastery is not significantly correlated. The finding suggests that the students might still enjoy and get benefit from bilingual science learning despite their English abilities. This leads to the opportunity to have more bilingual science classes to enhance not only students’ science mastery but also their English competence.\n",
            "----------------------------------------\n",
            "Title: Weather Condition Clustering for Improvement of Photovoltaic Power Plant Generation Forecasting Accuracy\n",
            "Abstract: Together with the growing interest towards renewable energy sources within the framework of different strategies of various countries, the number of solar power plants keeps growing. However, managing optimal power generation for solar power plants has its own challenges. First comes the problem of work interruption and reduction in power generation. As the system must be tolerant to the faults, the relevance and significance of short-term forecasting of solar power generation becomes crucial. Within the framework of this research, the applicability of different forecasting methods for short-time forecasting is explained. The main goal of the research is to show an approach regarding how to make the forecast more accurate and overcome the above-mentioned challenges using opensource data as features. The data clustering algorithm based on KMeans is proposed to train unique models for specific groups of data samples to improve the generation forecast accuracy. Based on practical calculations, machine learning models based on Random Forest algorithm are selected which have been proven to have higher efficiency in predicting the generation of solar power plants. The proposed algorithm was successfully tested in practice, with an achieved accuracy near to 90%.\n",
            "----------------------------------------\n",
            "Title: Insights into Ionic Liquids for Flame Retardant: A Study Based on Bibliometric Mapping\n",
            "Abstract: Fire is a typical disaster in the processing industry. Ionic liquids, as a type of green flame retardant, play an important role in process safety. In order to grasp the current research status, hotspots, and frontiers in the field of ionic liquids in flame retardancy, the bibliometric mapping method is applied to study the relevant literature in Web of Science datasets from 2000–2022 in this paper. The results show that the research on ionic liquids in flame retardancy is multidisciplinary and involves some disciplines such as energy science, material science, and environmental protection. Journal of Power Sources, Polymer Degradation and Stability, ACS Applied Materials and Interfaces, and Chemical Engineering Journal are the core journals in the field. The results of keyword co-occurrence indicate that the hotspots of research can be divided into five components: the improvement and application of pure ionic liquids electrolytes, the research of gel polymer electrolytes, applying ionic liquids to enhance the polymer materials’ flame retardancy properties, utilizing ionic liquids and inorganic materials to synergize flame retardant polymers, and using ionic liquids flame retardant to improve material’s multiple properties. The burst terms and time zone diagram’s results point out the combination of computational quantum chemistry to study the flame retardancy mechanism of ionic liquids, the study of fluorinated electrolytes, ionic liquids for smoke suppression, phosphorus-containing ionic liquids for flame retardant, and machine learning-assisted design of ILs flame retardants are the research frontiers and future research trends.\n",
            "----------------------------------------\n",
            "Title: A 3-Tier Architecture for Network Latency Reduction in Healthcare Internet-of-Things Using Fog Computing and Machine Learning\n",
            "Abstract: Healthcare Internet-of-things comprises a huge number of wearable sensors and interconnected computers. The high volume of IoT data is transacted over servers leading to servers overloading with high traffic causing network congestion. These cloud servers are typically for analyzing, retrieving and storing the large data generated from IoT devices. There exist challenges regarding sending real-time healthcare data from cloud servers to end-users. These challenges include the high computational latency, high communication latency, and high network latency. Due to these challenges, IoTs may not be able to send data in real-time to end-users. Fog nodes can be used to play a major role in reducing the high delay and high traffic. It can be a solution to increase system performance. In this paper, we proposed a 3-tier architecture, an analytical model for healthcare IoT using a hybrid approach consisting of fuzzy logic and reinforcement learning in a fog computing environment. The aim is to minimize network latency. The proposed model and 3-tier architecture are simulated using iFogSim simulator.\n",
            "----------------------------------------\n",
            "Title: Artificial Intelligence for Urban Safety: A Case Study for reducing road accident in Genoa\n",
            "Abstract: Abstract. This study explores the application of Machine Learning (ML) and citizen engagement in improving road safety for vulnerable populations (pedestrians, cyclists) in Genoa, Italy. Aligned with the UN's 2030 Agenda for Sustainable Development, the project aims for a 50% reduction in traffic accidents by 2030.The AI4PublicPolicy initiative introduces the Virtual Policy Management Environment (VPME) platform. VPME utilizes ML, Deep Learning (DL), Natural Language Processing (NLP), and chatbots to empower the policy development lifecycle. Citizen feedback is integrated through workshops and surveys, fostering a citizen-centric approach. The Genoa pilot program demonstrates VPME's capabilities. ML models analyse historical accident and Geographic Information Systems (GIS) data to predict future high-risk areas. These predictions inform resource allocation and targeted interventions for pedestrian crossings and school walking routes (\"Pedibus\"). Dashboards visualize the model outputs, allowing users to assess risk levels and predict accident occurrences. Future improvements include incorporating additional data sources (demographics, real-time traffic) for enhanced model accuracy. Citizen engagement played a vital role. Co-creation workshops facilitated stakeholder participation in defining Use Cases, User Stories, and project objectives. Discussions focused on integrating data from environmental, traffic, and citizen reporting systems with VPME solutions. Participants evaluated the project approach and provided valuable feedback. The project highlights the potential of AI and citizen collaboration for data-driven policymaking. This approach empowers municipalities to make informed decisions that prioritize public safety and well-being.\n",
            "\n",
            "----------------------------------------\n",
            "Title: A Fast Interactive Search System for Healthcare Services\n",
            "Abstract: In this paper we describe the design, development, and evaluation of a general human-machine interaction search system, and its potential and use in the context of a collaboration project with SAP and Saffron. The objective of a specialized version of the system is to provide medical and healthcare information services to users via interactive search for personalized patient needs. Patients usually have questions regarding healthcare, including those which concern illness symptoms, duration and types of treatment, possible drug effects, and more. Authorized personnel would often be ideal in responding to such needs; however they could potentially be very expensive, and not easy to support and maintain. If patients could have access to information at their home, by means of i-phone or online access, this could save time, doctor office visit expenses, as well as valuable and restricted medical time. What is more, information concerning other anonymized and similar patient cases provides knowledge and perspective on a wide range of patient issues. From the doctors' perspective, they typically need to spend time on differential analysis about new patient cases: study symptoms, research possible causes, rank results by emergency priority and treat them accordingly. A search system that would direct a doctor (or patient/user) to similar patient cases would save significant amount of manual search time. The powerful new feature of this system is the storage and mining of past patient cases knowledge, to create metadata to be used in the subsequent retrieval of relevant documents. Finally, the interactive search system would speed up identification of rare cases; for instance, symptoms that do not appear commonly in past cases may require special treatment or expert referral. We build a model which dynamically learns medical needs of interacting MDs and patients. The model works on free or unstructured text, allowing disambiguation of vague words and flexibility in describing medical needs. In addition, both experts with an advanced knowledge of medical terminology, and beginning users using basic medical terms, can achieve high search relevance. Furthermore, our approach obviates the need for the assignment of tags or labels, such as treatment, symptoms, causes, to documents, to respond effectively to user queries. In particular, we build a temporal difference algorithm to predict user's information needs by incorporating both current and predicted knowledge into learning the user profile. Our source of information about the user consists of submitted queries and feedback on the returned results. We tested our system on publicly available medical data (OhsuMed TREC dataset 2002) and we achieved a significant improvement in retrieval accuracy, compared to the literature. We provide quantitative results as well as demonstration screenshots which illustrate a) the value of interaction (user time spent with system versus results accuracy), b) the value of using medical terminology understanding, when compared with simple general words, and c) the value of allowing the maximum number of feedback submissions to vary.\n",
            "----------------------------------------\n",
            "Title: Machine Learning Based Technology for Reducing Engine Starting Vibration of Hybrid Vehicles\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Music Classification Model Development Based on Audio Recognition using Transformer Model\n",
            "Abstract: There are several music genres, such as blues, classical, disco, and more. Music genres can be predicted by supervised machine learning using extracted features. This research explores the Transformer deep learning model for audio classification using music genres as labels. The dataset used in this paper is the GTZAN dataset, which contains music in a waveform audio file (WAV) format. The features of this dataset are extracted using Mel-frequency Cepstral Coefficients (MFCC). This study finds that the Transformer model's performance gives higher accuracy than other neural network architectures. Furthermore, the Transformer model's performance is compared with related research results that utilize various traditional machine learning methods with the same dataset. The best result achieved was the accuracy of 75.1% for the Transformer model with the best fine-tune parameters.\n",
            "----------------------------------------\n",
            "Title: Autonomous vehicle control via deep reinforcement learning\n",
            "Abstract: The automotive industry as well as academia are currently conducting a lot of research related to autonomous driving. Autonomous driving is an interesting topic that holds the potential to benefit society in many ways, such as reduce the number of fatalities and reducing the environmental footprint of modern day traffic. In this thesis, we investigate Machine Learning algorithms that can automatically learn to control a vehicle based on its own experience of driving. More specifically we employ two Reinforcement Learning (RL) algorithms called Deterministic Policy Gradient (DDPG), and Actor-Critic with Experience Replay (ACER). The algorithms were trained and evaluated in a synthetic environment. The input to both models are images captured by a front-facing camera and internal states of the ego-vehicle, i.e., velocity, acceleration, and jerk. The results presented in this thesis show that current RL-methods are capable of controlling the vehicle steering, using only images to provide information regarding the position of the ego-vehicle. The results also indicate that a driving policy obtained via RL is more robust towards tricky driving scenarios than policies obtained via supervised learning techniques. However, evaluation of data captured from the real world domain is still needed, to verify the usability of models trained on synthetic data.\n",
            "----------------------------------------\n",
            "Title: A Machine Learning based Preventing the Occurrence of Cyber Bullying Messages on OSN\n",
            "Abstract: The process of threaten or harassment of any user with the help of posting wrong/abused or vulgar messages using the social media in the internet is known as Cyber bullying .These messages may sometime contain a text posted by a teen, or preteen or a child who want to threaten or harassed or embarrassed other child by posting the messages. So in this project, we mainly try to propose another depiction learning strategy to handle this issue known as SEMdae. Here the semantic augmentation comprises of predefined words that contain noise or abused meaning which is posted into the database by the admin and these words are classified based on the five categories that are available in the literature like “HATE, VULGAR, OFFENSIVE, SEX, and VOILENCE”.\n",
            "----------------------------------------\n",
            "Title: Evaluation of a Natural Language Processing Approach to Identify Diagnostic Errors and Analysis of Safety Learning System Case Review Data: Retrospective Cohort Study.\n",
            "Abstract: BACKGROUND\n",
            "Diagnostic errors are an underappreciated cause of preventable mortality in hospitals and pose a risk for severe patient harm and increase hospital length of stay.\n",
            "\n",
            "\n",
            "OBJECTIVE\n",
            "This study aims to explore the potential of machine learning and natural language processing techniques in improving diagnostic safety surveillance. We conducted a rigorous evaluation of the feasibility and potential to use electronic health records clinical notes and existing case review data.\n",
            "\n",
            "\n",
            "METHODS\n",
            "Safety Learning System case review data from 1 large health system composed of 10 hospitals in the mid-Atlantic region of the United States from February 2016 to September 2021 were analyzed. The case review outcome included opportunities for improvement including diagnostic opportunities for improvement. To supplement case review data, electronic health record clinical notes were extracted and analyzed. A simple logistic regression model along with 3 forms of logistic regression models (ie, Least Absolute Shrinkage and Selection Operator, Ridge, and Elastic Net) with regularization functions was trained on this data to compare classification performances in classifying patients who experienced diagnostic errors during hospitalization. Further, statistical tests were conducted to find significant differences between female and male patients who experienced diagnostic errors.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "In total, 126 (7.4%) patients (of 1704) had been identified by case reviewers as having experienced at least 1 diagnostic error. Patients who had experienced diagnostic error were grouped by sex: 59 (7.1%) of the 830 women and 67 (7.7%) of the 874 men. Among the patients who experienced a diagnostic error, female patients were older (median 72, IQR 66-80 vs median 67, IQR 57-76; P=.02), had higher rates of being admitted through general or internal medicine (69.5% vs 47.8%; P=.01), lower rates of cardiovascular-related admitted diagnosis (11.9% vs 28.4%; P=.02), and lower rates of being admitted through neurology department (2.3% vs 13.4%; P=.04). The Ridge model achieved the highest area under the receiver operating characteristic curve (0.885), specificity (0.797), positive predictive value (PPV; 0.24), and F1-score (0.369) in classifying patients who were at higher risk of diagnostic errors among hospitalized patients.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Our findings demonstrate that natural language processing can be a potential solution to more effectively identifying and selecting potential diagnostic error cases for review and therefore reducing the case review burden.\n",
            "----------------------------------------\n",
            "Title: A Probability-Based Close Domain Metric in Lifelong Learning for Multi-label Classification\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Annotated Dataset Creation through General Purpose Language Models for non-English Medical NLP\n",
            "Abstract: Obtaining text datasets with semantic annotations is an effortful process, yet crucial for supervised training in natural language processsing (NLP). In general, developing and applying new NLP pipelines in domain-specific contexts for tasks often requires custom designed datasets to address NLP tasks in supervised machine learning fashion. When operating in non-English languages for medical data processing, this exposes several minor and major, interconnected problems such as lack of task-matching datasets as well as task-specific pre-trained models. In our work we suggest to leverage pretrained language models for training data acquisition in order to retrieve sufficiently large datasets for training smaller and more efficient models for use-case specific tasks. To demonstrate the effectiveness of your approach, we create a custom dataset which we use to train a medical NER model for German texts, GPTNERMED, yet our method remains language-independent in principle. Our obtained dataset as well as our pre-trained models are publicly available at: https://github.com/frankkramer-lab/GPTNERMED\n",
            "----------------------------------------\n",
            "Title: Enabling robust offline active learning for machine learning potentials using simple physics-based priors\n",
            "Abstract: Machine learning surrogate models for quantum mechanical simulations have enabled the field to efficiently and accurately study material and molecular systems. Developed models typically rely on a substantial amount of data to make reliable predictions of the potential energy landscape or careful active learning (AL) and uncertainty estimates. When starting with small datasets, convergence of AL approaches is a major outstanding challenge which has limited most demonstrations to online AL. In this work we demonstrate a Δ-machine learning (ML) approach that enables stable convergence in offline AL strategies by avoiding unphysical configurations with initial datasets as little as a single data point. We demonstrate our framework’s capabilities on a structural relaxation, transition state calculation, and molecular dynamics simulation, with the number of first principle calculations being cut down anywhere from 70%–90%. The approach is incorporated and developed alongside AMPtorch, an open-source ML potential package, along with interactive Google Colab notebook examples.\n",
            "----------------------------------------\n",
            "Title: Modeling of sliding wear characteristics of Polytetrafluoroethylene (PTFE) composite reinforced with carbon fiber against SS304\n",
            "Abstract: Introduction. Over the last decade, composite materials based on polytetrafluoroethylene (PTFE) have been increasingly used as alternative materials for automotive applications. PTFE is characterized by a low coefficient of friction, hardness and corrosion resistance. However, this material has a high wear rate. A group of researchers attempted to improve the wear resistance of PTFE material by reinforcing it with different fillers. The purpose of the work: This study experimentally investigates the dry sliding wear characteristics of a PTFE composite reinforced with carbon fiber (35 wt.%) compared to SS304 stainless steel. In addition, experimental mathematical and ANN models are developed to predict the specific wear rate, taking into account the influence of pressure, sliding speed, and interface temperature. The methods of investigation. Dry sliding experiments were performed on a pin-on-disk wear testing machine with varying the normal load on the pin, disk rotation, and interface temperature. Experiments were planned systematically to investigate the effect of input parameters on specific wear rates with a wide range of design space. In total, fifteen experiments were carried out at a 5-kilometer distance without repeating the central run experiment. Sliding velocities were obtained by selecting the track diameter on the disk and corresponding rotation of the disk. A feedforward back-propagation machine learning algorithm was used to the ANN model. Results and Discussion. This study finds better prediction accuracy with the ANN architecture having two hidden layers with 150 neurons on each layer. This study finds an increase in specific wear rates with normal load, sliding velocity, and interface temperature. However, the increase is more prominent at higher process parameters. The normal load followed by sliding velocity most significantly affects the specific wear rate. The results predicted by the developed models for specific wear rates are in good agreement with the experimental values with an average error close to 10%. This shows that the model could be reliably used to obtain the wear rate of PTFE composite reinforced with carbon fiber (35 wt.%) compared to SS304 stainless steel. This study finds scope for further studies considering the effect of varying ANN architectures, different amount of neurons, and hidden layers on the prediction accuracy of the wear rate.\n",
            "----------------------------------------\n",
            "Title: Remote Health Monitoring IoT Framework using Machine Learning Prediction and Advanced Artificial Intelligence (AI) Model\n",
            "Abstract: Real intervention and treatment standards drew attention to remote health monitoring frameworks. Remote monitoring frameworks for disease detection at an early stage are opposed by most conventional works. Even so, it ran into issues like increased operational complexity, higher resource costs, inaccurate predictions, longer data collection times, and a lower convergence rate. A remote health monitoring framework that uses artificial intelligence (AI) to predict heart disease and diabetes from medical datasets is the goal of this project. Patients' health data is collected via smart devices, and the resulting data is then combined using a variety of nodes, including a detection node, a visualisation node, and a prognostic node. People with long-term illnesses (such as the elderly and disabled) are in such greater demand than ever before that a new approach to healthcare delivery is essential. In the evolved paradigm, conventional physical medical services foundations like clinics, nursing homes, and long haul care offices will be old. Due to recent advancements in modern technology, such as artificial intelligence (AI) and machine learning (ML), the smart healthcare system has become increasingly necessary (ML). This paper will discuss wearable and smartphone technologies, AI for medical diagnostics, and assistive structures, including social robots, that have been created for the surrounding upheld living climate. The review presents programming reconciliation structures that are urgent for consolidating information examination and other man-made consciousness instruments to develop brilliant medical care frameworks (AI).\n",
            "----------------------------------------\n",
            "Title: Computed tomography-based radiomic model predicts radiological response following stereotactic body radiation therapy in early-stage non-small-cell lung cancer and pulmonary oligo-metastases\n",
            "Abstract: Purpose Radiomic models elaborate geometric and texture features of tumors extracted from imaging to develop predictors for clinical outcomes. Stereotactic body radiation therapy (SBRT) has been increasingly applied in the ablative treatment of thoracic tumors. This study aims to identify predictors of treatment responses in patients affected by early stage non-small cell lung cancer (NSCLC) or pulmonary oligo-metastases treated with SBRT and to develop an accurate machine learning model to predict radiological response to SBRT. Materials and Methods Computed tomography (CT) images of 85 tumors (stage I–II NSCLC and pulmonary oligo-metastases) from 69 patients treated with SBRT were analyzed. Gross tumor volumes (GTV) were contoured on CT images. Patients that achieved complete response (CR) or partial response (PR) were defined as responders. One hundred ten radiomic features were extracted using PyRadiomics module based on the GTV. The association of features with response to SBRT was evaluated. A model using support vector machine (SVM) was then trained to predict response based solely on the extracted radiomics features. Receiver operating characteristic curves were constructed to evaluate model performance of the identified radiomic predictors. Results Sixty-nine patients receiving thoracic SBRT from 2008 to 2018 were retrospectively enrolled. Skewness and root mean squared were identified as radiomic predictors of response to SBRT. The SVM machine learning model developed had an accuracy of 74.8%. The area under curves for CR, PR, and non-responder prediction were 0.86 (95% confidence interval [CI], 0.794–0.921), 0.946 (95% CI, 0.873–0.978), and 0.857 (95% CI, 0.789–0.915), respectively. Conclusion Radiomic analysis of pre-treatment CT scan is a promising tool that can predict tumor response to SBRT.\n",
            "----------------------------------------\n",
            "Title: Adaptive Fuzzy Filtering in a Deterministic Setting\n",
            "Abstract: Many real-world applications involve the filtering and estimation of process variables. This study considers the use of interpretable Sugeno-type fuzzy models for adaptive filtering. Our aim in this study is to provide different adaptive fuzzy filtering algorithms in a deterministic setting. The algorithms are derived and studied in a unified way without making any assumptions on the nature of signals (i.e., process variables). The study extends, in a common framework, the adaptive filtering algorithms (usually studied in signal processing literature) and p -norm algorithms (usually studied in machine learning literature) to semilinear fuzzy models. A mathematical framework is provided that allows the development and an analysis of the adaptive fuzzy filtering algorithms. We study a class of nonlinear LMS-like algorithms for the online estimation of fuzzy model parameters. A generalization of the algorithms to the p-norm is provided using Bregman divergences (a standard tool for online machine learning algorithms).\n",
            "----------------------------------------\n",
            "Title: Building Indoor Point Cloud Datasets with Object Annotation for Public Safety\n",
            "Abstract: An accurate model of building interiors with detailed annotations is critical to protecting the first responders’ safety and building occupants during emergency operations. In collaboration with the City of Memphis, we collected extensive LiDAR and image data for the city’s buildings. We apply machine learning techniques to detect and classify objects of interest for first responders and create a comprehensive 3D indoor space database with annotated safety-related objects. This paper documents the challenges we encountered in data collection and processing, and it presents a complete 3D mapping and labeling system for the environments inside and adjacent to buildings. Moreover, we use a case study to illustrate our process and show preliminary evaluation\n",
            "----------------------------------------\n",
            "Title: Forecast and prediction of COVID-19 using machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: STAMP: Lightweight TEE-Assisted MPC for Efficient Privacy-Preserving Machine Learning\n",
            "Abstract: In this paper, we propose S TAMP , an end-to-end 3-party MPC protocol for efﬁcient privacy-preserving machine learning inference assisted by a lightweight TEE (LTEE), which will be far easier to secure and deploy than today’s large TEEs. S TAMP provides three main advantages over the state-of-the-art; (i) S TAMP achieves signiﬁcant performance improvements compared to state-of-the-art MPC protocols, with only a small LTEE that is comparable to a discrete security chip such as the Trusted Platform Module (TPM) or on-chip security subsystems in SoCs similar to the Apple enclave processor. In a semi-honest setting with WAN/GPU, S TAMP is 4 × -63 × faster than Falcon (PoPETs’21) and Ar-iaNN (PoPETs’22) and 3.8 × -12 × more communication ef-ﬁcient. We achieve even higher performance improvements in a malicious setting. (ii) S TAMP guarantees security with abort against malicious adversaries under honest majority assumption. (iii) S TAMP is not limited by the size of secure memory in a TEE and can support high-capacity modern neural networks like ResNet18 and Transformer.\n",
            "----------------------------------------\n",
            "Title: Inhibitors of Calcium Oxalate Crystallization for the Treatment of Oxalate Nephropathies\n",
            "Abstract: Calcium oxalate (CaOx) crystal‐induced nephropathies comprise a range of kidney disorders, for which there are no efficient pharmacological treatments. Although CaOx crystallization inhibitors have been suggested as a therapeutic modality already decades ago, limited progress has been made in the discovery of potent molecules with efficacy in animal disease models. Herein, an image‐based machine learning approach to systematically screen chemically modified myo‐inositol hexakisphosphate (IP6) analogues is utilized, which enables the identification of a highly active divalent inositol phosphate molecule. To date, this is the first molecule shown to completely inhibit the crystallization process in the nanomolar range, reduce crystal–cell interactions, thereby preventing CaOx‐induced transcriptomic changes, and decrease renal CaOx deposition and kidney injury in a mouse model of hyperoxaluria. In conclusion, IP6 analogues based on such a scaffold may represent a new treatment option for CaOx nephropathies.\n",
            "----------------------------------------\n",
            "Title: Statement : Mathematical Foundations of Data Science\n",
            "Abstract: Today’s data deluge is driving a transformation of the world-economy and even the modern way of life. Cutting edge data science challenges are pushing the boundaries of what can be learned from data, giving rise to an array of applications in artificial intelligence, medicine, and social sciences. My past work has provided several major contributions at the front of mathematical statistics and information theory, addressing some of the fundamental theoretical aspects of data science. Among these contributions, my Ph.D. work addressed the effects of data compression on real-world analog data. It provided the first complete characterization of the optimal trade-offs between sampling rate, compression bitrate, and distortion in processing real-world signals digitally. My postdoc work focuses on challenging high-dimensional signal estimation and classification settings. The high-dimensionality here is typically the result of a vast number of features available for inference. These features can represent raw measurements, the result of compression or dimensionality reduction procedures, or the output of data-driven techniques like a neural network’s activations. Arguably, the most pressing issues of modern data-driven inference techniques are their general inability to explain models’ decisions and to generalize to unexpected new situations. Feature-based inference techniques are perfectly suited for resolving this ‘interpretability’ and ‘generalizability’ crises. Interpretability is attained by crafting many meaningful features, while generalizability is attained by using optimal feature selection and inference rules for these features. For this reason, we are witnessing a shift in machine learning and artificial intelligence communities from end-to-end to feature-based approaches. The theoretical tools to handle feature-based inference include multiple hypothesis testing and variable selection in statistics and geometric understanding of high-dimensional distributions from information theory. My research integrates these two disciplines with ambitious computations, validating theoretical results and assessing inference’s performance on real-world datasets. In what follows, I will review in more detail my past achievements and describe my shortand long-term future research plans.\n",
            "----------------------------------------\n",
            "Title: Assessing the Robustness of Cluster Solutions in Emotionally-Annotated Pictures Using Monte-Carlo Simulation Stabilized K-Means Algorithm\n",
            "Abstract: Clustering is a very popular machine-learning technique that is often used in data exploration of continuous variables. In general, there are two problems commonly encountered in clustering: (1) the selection of the optimal number of clusters, and (2) the undecidability of the affiliation of border data points to neighboring clusters. We address both problems and describe how to solve them in application to affective multimedia databases. In the experiment, we used the unsupervised learning algorithm k-means and the Nencki Affective Picture System (NAPS) dataset, which contains 1356 semantically and emotionally annotated pictures. The optimal number of centroids was estimated, using the empirical elbow and silhouette rules, and validated using the Monte-Carlo simulation approach. Clustering with k = 1–50 centroids is reported, along with dominant picture keywords and descriptive statistical parameters. Affective multimedia databases, such as the NAPS, have been specifically designed for emotion and attention experiments. By estimating the optimal cluster solutions, it was possible to gain deeper insight into affective features of visual stimuli. Finally, a custom software application was developed for study in the Python programming language. The tool uses the scikit-learn library for the implementation of machine-learning algorithms, data exploration and visualization. The tool is freely available for scientific and non-commercial purposes.\n",
            "----------------------------------------\n",
            "Title: Intelligent Robotic Perception Systems\n",
            "Abstract: Robotic perception is related to many applications in robotics where sensory data and artificial intelligence/machine learning (AI/ML) techniques are involved. Examples of such applications are object detection, environment representation, scene understand - ing, human/pedestrian detection, activity recognition, semantic place classification, object modeling, among others. Robotic perception, in the scope of this chapter, encom - passes the ML algorithms and techniques that empower robots to learn from sensory data and, based on learned models, to react and take decisions accordingly. The recent developments in machine learning, namely deep-learning approaches, are evident and, consequently, robotic perception systems are evolving in a way that new applications and tasks are becoming a reality. Recent advances in human-robot interaction, complex robotic tasks, intelligent reasoning, and decision-making are, at some extent, the results of the notorious evolution and success of ML algorithms. This chapter will cover recent and emerging topics and use-cases related to intelligent perception systems in robotics.\n",
            "----------------------------------------\n",
            "Title: Physics Guided Machine Learning Significantly Improves Outcomes for Data-Based Production Optimization\n",
            "Abstract: \n",
            " Hydrocarbon production systems generate huge datasets, often with time series going back many years. However, much of the data may be obsolete due to changing reservoir conditions and modification of the asset, and there may be scant data close to optimal operating conditions due to the inadequacy of existing optimization tools. It is widely recognized that data science, artificial intelligence (AI) and machine learning can contribute significantly to the optimization of production operations, and there is a trend towards hybrid AI, which combines data science with traditional physics-based simulators to deliver added value. In our work we show how to make use of physical principles in feature engineering to improve machine learning outcomes. This squeezes additional value from a pure data-based approach while avoiding expensive, time-consuming and often inaccurate simulations. Our toolbox includes energy, mass and force balances; PVT data for production fluids; order-of-magnitude analysis; and dimensional analysis.\n",
            " We illustrate the value of physics guided machine learning with three examples from production optimisation: First example shows a significant improvement in separator operation to achieve environmental limits for safe disposal of produced water using a root-cause analysis to identify bad actors in the production system and recommending operator actions to mitigate oil-in water issues. By physics modeling of key physical processes, such as choke-dispersion and separator efficiency, the predictions were greatly improved. Second example is a data-based VFM using physics-based feature engineering, outperforming a VFM based purely on measured data. Last use-case is a dynamic maximum separator flow capacity calculation that safely allows flow rates above static design limits.\n",
            " We conclude that physics-guided machine learning can add tremendous value to digitalisation rollout across a wide range of production optimisation use cases, and speed up the decision process toward mitigation of production losses in complex industrial phenomena.\n",
            "----------------------------------------\n",
            "Title: Machine learning and multimedia content generation for energy demand reduction\n",
            "Abstract: Domestic energy demand accounts for about 30% of overall energy use. The IDEAL project uses a variety of IT methods to investigate whether, and in which social groups, feedback of personalised, household-specific and behaviour-specific information results in greater reduction in energy use than overall consumption information reported by Smart Meters. It is a sociotechnical study, concentrated on existing housing, with a strong social science component and an experimental design that looks at income levels and household composition as primary factors. Temperature and humidity data related to behaviour is gathered using a small number of wireless sensors in the home, together with data on weather, building factors and household composition. This data is streamed over the internet to servers where it is analysed using Bayesian machine-learning methods to extract household-specific behaviours in near-realtime. Information on the cost, carbon content and amount of energy used for specific behaviours is reported back to the householders via a dedicated wireless tablet. This interactive content is automatically generated using multimedia methods based on natural language generation techniques. The project is in its design phase, with the main project planned (and funded) to run 2013-2016. It is anticipated to demonstrate whether such low-cost sensing, analysis and feedback is significantly more effective than standard Smart Meters in reducing demand, and a business opportunity for green service organisations.\n",
            "----------------------------------------\n",
            "Title: A Novel Generative AI-Based Framework for Anomaly Detection in Multicast Messages in Smart Grid Communications\n",
            "Abstract: Cybersecurity breaches in digital substations can pose significant challenges to the stability and reliability of power system operations. To address these challenges, defense and mitigation techniques are required. Identifying and detecting anomalies in information and communication technology (ICT) is crucial to ensure secure device interactions within digital substations. This paper proposes a task-oriented dialogue (ToD) system for anomaly detection (AD) in datasets of multicast messages e.g., generic object oriented substation event (GOOSE) and sampled value (SV) in digital substations using large language models (LLMs). This model has a lower potential error and better scalability and adaptability than a process that considers the cybersecurity guidelines recommended by humans, known as the human-in-the-loop (HITL) process. Also, this methodology significantly reduces the effort required when addressing new cyber threats or anomalies compared with machine learning (ML) techniques, since it leaves the models complexity and precision unaffected and offers a faster implementation. These findings present a comparative assessment, conducted utilizing standard and advanced performance evaluation metrics for the proposed AD framework and the HITL process. To generate and extract datasets of IEC 61850 communications, a hardware-in-the-loop (HIL) testbed was employed.\n",
            "----------------------------------------\n",
            "Title: Forecasting trends in the cryptocurrency exchange rate through the machine learning theory\n",
            "Abstract: Subject. The study discusses methodological approaches to forecasting trends in the development of the cryptocurrency market (bitcoin).\n",
            "Objectives. The study aims to discover and explain tools and mechanisms for predicting how the cyptocurrency market may evolve in a short run through time series modeling methods and machine learning methods, which are based on artificial neural networks LSTM.\n",
            "Methods. Using Python-based programming methods, we constructed and substantiated a neural network model for the analyzable series describing how the stock exchange rate of bitcoin develops.\n",
            "Results. Matching loss functions, optimizer and parameters for constructing a neural network that predicts the BTC/USD exchange rate for a coming day, we proved its applicability and feasibility, which is confirmed with the lowest number of errors in the test and validation set.\n",
            "Conclusions and Relevance. The findings mainly prove that the above mechanism is feasible for predicting the cryptocurrency market. The mechanism is based on algorithms for constructing LSTM networks. The approach should be used to analyze and evaluate the current and future parameters of the cryptocurrency market development. The tools can be of interest for investors which operate in new markets of e-money.\n",
            "----------------------------------------\n",
            "Title: Integration of Petrophysical Log Data with Computational Intelligence for the Development of a Lithology Predictor\n",
            "Abstract: \n",
            " Wrong manual interpretation from the log data about the formation type and other important information can be catastrophic for the company-operator. With Machine-Learning (ML) (a branch of Artificial Intelligence) algorithms, the interpretation of formation type from the log data has been addressed. As a result, we have successfully developed a program able to accurately predict the type of formation.\n",
            " Using the conventional Machine Learning technique of splitting the data into training, validation and test sets, we tried six different ML algorithms to fit with the training part of the data and then verify their prediction accuracy with cross-validation scores and cross-validation predictions which tests the performance of the classifiers (ML algorithms) on the validation set. The three best performing classifiers were selected and further improved by a search of classifier's best hyperparameters. These improved classifiers are further tested on unseen data to produce a comparative analysis.\n",
            " Our prediction accuracy with Receiver Operating Characteristic (ROC) scores and ROC-Area Under-the-Curve (ROC-AUC) for each type of formation from the log data lies in the range of 95-99%, except for formations such as shaly sandstone and shale (50% and 84% respectively). The reason for this seemed to be under-fitting i.e., during the training, the classifiers did not see enough instances of these types of formation to know exactly what characteristics of the data make the type of formation to be shaly sandstone or shale. The issue of under-fitting was verified by skimming through the data. To resolve this problem, we suggest training classifiers with a larger data with more targets (types of formation). Furthermore, during the data cleaning (prior to classifier training) and data analysis phases we have discovered important relationships between well logs and defined relative importance of each well log for different formations. This observation can be investigated further to help eliminate the use of multiple well logs while dealing with some formations (based on prior geological knowledge) and reduce the cost of the well logging operations. Using our program with a larger well log data consisting of more formation type instances, we can train the classifiers to accurately predict the formation type irrespectively of differences in formation type.\n",
            " Our program is dynamic in the sense that with different targets, i.e., type of formation fluid instead of type of formation or both together, it can successfully predict either or both targets. Increasing the numbers of data instances resulted in a better training and thus, more accurate predictions. Utilization of the program will make the formation-evaluation process easier, faster, automated and more-precise.\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning to Predict Student Success in Undergraduate Engineering Programs\n",
            "Abstract: Undergraduate engineering programs are typically considered some of the most challenging as their curricula require students to have an aptitude for math, science, and engineering. The resources (time, effort, funds) required to finish an engineering degree is substantial. Therefore, it is imperative that the engineering students are supported with well-informed academic guidance as early in their education as possible so that these resources can be used most effectively. Analytical and data-driven methods such as machine learning techniques can be used to inform this guidance process by predicting student success based on features such as individual traits and academic performance. In that direction, we investigated the effectiveness of using machine learning in predicting engineering student success based on academic performance in core math, physics, and engineering courses in three undergraduate engineering programs. The data categories selected for training and testing of the machine learning models in this study are common to most engineering programs nationwide and can be customized in a straightforward manner for other engineering disciplines. The methodology and results outlined in this preliminary study shows promise for predicting degree and cumulative GPA in our three engineering programs.\n",
            "----------------------------------------\n",
            "Title: Images with TensorFlow\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Identification of the Association between Hepatitis B Virus and Liver Cancer using Machine Learning Approaches based on Amino Acid\n",
            "Abstract: Primary liver cancer has been a common reason for death from cancer globally. The most common type of primary liver cancer is the hepatocellular carcinoma (HCC). The major cause of HCC is chronic infections with hepatitis B virus (HBV). In this research, we used next generation sequencing (NGS), which has been very widely used to produce deep, efficient, and high-quality sequence data. NGS was used to sequence the pre-S region of the HBV genome of total 139 patients, which contain 94 HCC patients and 45 chronic HBV (CHB) patients. We generated two types of datasets. Firstly, for the data of amino acid occurrence frequency, we used basic local alignment search tool (BLAST) to map each NGS short read and translated each alignment into amino acid by DNA codon table. The input features are the occurrence frequencies of 20 basic amino acids using Shannon entropy. We picked 40 patients with 27 HCC and 13 CHB as the independent testing set. Then we used machine learning methods including logistic regression, random forest and support vector machine (SVM) to construct the classification models and make the prediction. The AUC values on the independent testing set for those machine learning methods (logistic regression, random forest and SVM) are 0.946, 0.923 and 0.960 respectively. Secondly, for the data of word pattern frequency of amino acids, we calculated word pattern frequencies of amino acids of all individuals and compared them using Euclidean distance. The input features are the frequencies of amino acid word of length 2, which is normalized by dividing the total occurrence number of all words. What's more, word pattern frequencies of amino acids were used to construct the classification models for HCC status using machine learning methods. Principal coordinate analysis (PCoA) was also used to visualize the associations between patient clusters, the HCC disease status of patients, and the fraction of HBV genotypes. We found that word patterns are powerful for the analysis of the HBV sequences from the aspect of amino acids because the AUC values of the classification models for machine learning methods are all above 0.9. Hence, our study showed that word pattern frequencies of amino acids is powerful for revealing the underlying principles of the occurrence of HCC triggered by HBV. Our essential findings consist of three parts. Firstly, all machine learning methods can generate classification models with high AUC values. Then, we can find some certain positions of amino acids or word patterns of amino acids that the mutation occurred on those positions will induce the HCC. Last, PCoA is associated with the disease status (HCC or CHB) and the fraction of genotype B (or C).\n",
            "----------------------------------------\n",
            "Title: Towards Competence in Autonomous Agents\n",
            "Abstract: My thesis aims to contribute towards building autonomous agents that are able to develop what White (1959) called competency over their environment—agents that are able to achieve mastery over their domain and are able to solve new problems as they arise using the knowledge and skills they acquired in the past. While the field of machine learning has made much progress in solving individual, isolated problems, progress has been slow in developing agents that are able to interact effectively with their environment and flexibly deal with new tasks. There is still a large gap between the abilities of humans in this respect and the current capabilities of autonomous agents. My thesis will propose a number of methods for building competence in autonomous agents using the reinforcement learning (RL) framework, a computational approach to learning from interaction that has proved effective in certain types of problems (Sutton & Barto 1998). I expect that the methods I propose will extend the capabilities of RL agents in ways that are more than incremental, essentially allowing an autonomous agent to operate at a qualitatively different level.\n",
            "----------------------------------------\n",
            "Title: Automated Pediatric TMJ articular disk identification and displacement classification in MRI with machine learning.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Optimization of ultrasonic-excited double-pipe heat exchanger with machine learning and PSO\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Finding Optimally Robust Data Mixtures via Concave Maximization\n",
            "Abstract: Machine learning models are often required to perform well across several pre-defined settings, such as a set of user groups. Worst-case performance is a common metric to capture this requirement, and is the objective of group distributionally robust optimization (group DRO). Unfortunately, these methods struggle when the loss is non-convex in the parameters, or the model class is non-parametric. Here, we make a classical move to address this: we reparameterize group DRO from parameter space to function space, which results in a number of advantages. First, we show that group DRO over the space of bounded functions admits a minimax theorem. Second, for cross-entropy and mean squared error, we show that the minimax optimal mixture distribution is the solution of a simple convex optimization problem. Thus, provided one is working with a model class of universal function approximators, group DRO can be solved by a convex optimization problem followed by a classical risk minimization problem. We call our method MixMax. In our experiments, we found that MixMax matched or outperformed the standard group DRO baselines, and in particular, MixMax improved the performance of XGBoost over the only baseline, data balancing, for variations of the ACSIncome and CelebA annotations datasets.\n",
            "----------------------------------------\n",
            "Title: Towards efficient powder quality control in additive manufacturing via an in situ capable device and methodology leveraging multispectral machine learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Editorial: Applying Machine Learning for Combating Fake News and Internet/Media Content Manipulation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Analysing Economic Convergence Across the America: A Survival Analysis Approach to GDP Per Capita Trajectories\n",
            "Abstract: Machine learning algorithms, and economic interpretation, integrated with survival analysis, are used to examine the temporal dynamics associated with achieving a 5% increase in purchasing power parity-adjusted GDP per capita over a period of 120 months (2013-2022). The comparative investigation reveals that DeepSurv effectively captures non-linear interactions, though standard models exhibit comparable performance under certain conditions. The weight matrix evaluates the economic implications of vulnerabilities, risks, and capacities. To meet the GDP per capita objective, the findings emphasize the necessity of a balanced approach to risk-taking, strategic vulnerability reduction, and investment in governmental capacities and social cohesiveness. The policy guidelines advocate for individualized approaches that account for the complex dynamics at play in decision-making processes.\n",
            "----------------------------------------\n",
            "Title: Using AI/ML to gain situational understanding from passive network observations\n",
            "Abstract: The data available in the network traffic fromany Government building contains a significant amount ofinformation. An analysis of the traffic can yield insightsand situational understanding about what is happening inthe building. However, the use of traditional network packet inspection, either deep or shallow, is useful for only a limited understanding of the environment, with applicability limited to some aspects of network and security management. If weuse AI/ML based techniques to understand the network traffic, we can gain significant insights which increase our situational awareness of what is happening in the environment.At IBM, we have created a system which uses a combination of network domain knowledge and machine learning techniques to convert network traffic into actionable insights about the on premise environment. These insights include characterization of the communicating devices, discovering unauthorized devices that may violate policy requirements, identifying hidden components and vulnerability points, detecting leakage of sensitive information, and identifying the presence of people and devices.In this paper, we will describe the overall design of this system, the major use-cases that have been identified for it, and the lessons learnt when deploying this system for some of those use-cases\n",
            "----------------------------------------\n",
            "Title: Differentiating peritoneal tuberculosis and peritoneal carcinomatosis based on a machine learning model with CT: a multicentre study\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Development of an automated manufacturing course with lab for undergraduates\n",
            "Abstract: Many engineering programs at universities across the country have dropped machine shop and manufacturing courses from their curriculum due to budget constraints, accreditation requirements, and concerns about student safety. At the University of Portland, we have resurrected and enhanced a hands-on advanced CAD and automated manufacturing course that introduces students to advanced solid modeling techniques in CAD, such as sweeps, lofts, and surfacing methods. In addition, students learn manual machining and vacuum forming in our machine shop, along with learning how to create tool paths for CNC machining their designed CAD parts out of wax on various three axis end mills, a 3D printer, and a 3D laser scanner. The end mills were all refurbished and/or repaired over a period of four years to get this course up and running. A commercial software package, MasterCAM, was used in conjunction with SolidWorks as the platform from which to learn about automated manufacturing. In addition, a MakerBot 3D printer was built from a kit to give students experience with future manufacturing techniques. The 3D laser scanner was student designed and built and creates CAD surface models of parts, useful for learning about reverse engineering. The machinable wax used for machining is recycled, melted down, and formed into blocks again for reuse. This saves considerable money. Our goal has been to enhance design quality in our curriculum through experiential learning. Prior to taking this course, all mechanical engineering students are required to take a solid modeling CAD course to learn the basics. However, our experience has been that students do not conceptually understand the importance of designing for manufacture. Although emphasized in all courses, without the hands-on experience, it is difficult for students to remember to apply fillet radii to the bottom of pockets, for example. When faced with having to fit a block with sharp corners into a machined pocket with its default small corner radii, however, learning is instantaneous. The early outcomes of this course show students have learned a great deal about design for manufacturing and manufacturing techniques from taking this course.\n",
            "----------------------------------------\n",
            "Title: An Extension of the Gamma Test Statistics to Binary Variables and Some Applications\n",
            "Abstract: In this paper, we discuss the problem of estimating the minimum error reachable by a regression model given a dataset, prior to learning. More specifically, we extend the Gamma Test estimates of the variance of the noise from the continuous case to the binary case. We give some heuristics for further possible extensions of the theory in the continuous case with the [Formula: see text]-norm and conclude with some applications and simulations. From the point of view of machine learning, the result is relevant because it gives conditions under which there is no need to learn the model in order to predict the best possible performance.\n",
            "----------------------------------------\n",
            "Title: Machine learning techniques in bankruptcy prediction: A systematic literature review\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Harnessing the power of promising technologies to transform science education: prospects and challenges to promote adaptive epistemic beliefs in science learning\n",
            "Abstract: ABSTRACT Forming learners’ science concepts and conceptual change entails adaptive epistemic beliefs to support a high degree of interactivity within a coherent knowledge structure. Adaptive epistemic beliefs are characterized by beliefs that knowledge is uncertain and should be justified through experimentation or multiple sources dependent upon the task contexts. Thus, assessing and evaluating learners’ adaptive epistemic beliefs is a complex process that requires laborious analysis of learner artifacts based on reliable and valid coding schemes. This article aims to describe new ways of assessing and applying technologies that can measure and foster adaptive epistemic beliefs. We propose new strategies for a theoretically-based human-and-machine symbiotic Learning Analytics (LA) framework. The application of this LA framework may facilitate the development of real-time detecting and representation of the individual and collective epistemic belief networks as well as diagnosing and providing appropriate scaffolds to promote adaptive epistemic beliefs via the design of personalised pedagogical feedback with experts’ input. The heuristic application of technology infrastructure may propel a movement for more tangible and personalised learning in science education. The current gaps of using AI-based emerging technologies in science learning and implications for science education are discussed to advance science education in new directions.\n",
            "----------------------------------------\n",
            "Title: Long-term evolution of winter habitats in Poyang Lake derived from satellite imagery using machine learning methods\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Gender Identification from Speech Recognition Using Machine Learning Techniques and Convolutional Neural Networks\n",
            "Abstract: Gender identification represents a fundamental component of speech recognition and automatic interacting sound responding systems. Identifying the voice gender minimizes the computational loads of these systems for additional processing. Standard approaches for gender estimation from the speech have broadly relied on the extraction of speech features and classification tasks. This paper proposes a technique for gender identification of speech samples using the speech recognition process. The proposed technique extracts essential voice features like Mean, Zero-Crossing, Standard Deviation, and Amplitude, as well as 12 most significant features from every voice sample, and combines them to create voice feature vectors. The proposed technique uses several machine and deep learning methods such as Random Forest, KNN, Logistic Regression, Decision Tree, and CNNs, in order to classify the voice vectors into Male and Female classes. After comparing the evaluation metrics results of all classifiers, the proposed technique finds out that the CNN model is the best classifier used to classify the voice vectors with a higher precision value of 1.0.\n",
            "----------------------------------------\n",
            "Title: Unification of Machine Learning Features\n",
            "Abstract: In the Information Age, Machine learning (ML) provides a competitive advantage to any business. Machine learning applications are not limited to driverless cars or online recommendations but are widely used in healthcare, social services, government systems, telecommunications, and so on. As many enterprises are trying to step up machine learning applications, it is critical to have a long-term strategy. Most of the enterprises are not able to truly realize the fruits of ML capabilities due to its complexity. It is easier to access a variety of data today due to data democratization, distributed storage, technological advancements, and big data applications. Despite easier data access and recent advancements in ML, developers still spend most of the time in data cleansing, data preparation, and data modeling for ML applications. These steps are often repeated and result in identical features. As identical features can have inconsistent processing while testing and training, more issues pop up at later stages in ML application development. The unification of ML features is an effective way to address these issues. This paper presents details about numerous methods to achieve ML features unification.\n",
            "----------------------------------------\n",
            "Title: Experimental verification and identifying biomarkers related to insomnia\n",
            "Abstract: Introduction Insomnia is the most common form of sleep deprivation (SD) observed in clinics. Although there are differences between insomnia and SD, they have similar symptoms and the same animal model. Currently, there is a lack of microarray data on insomnia. Therefore, for now, we are going to apply the SD data to insomnia. Although many studies have explained the possible mechanisms associated with insomnia, no previous studies have considered the key genes associated with insomnia or the relationship between insomnia and immune cells. In this study, we analyzed the relationship between key genes and immune cells by identifying biomarkers for the diagnosis of insomnia. Next, we verified the efficacy of these biomarkers experimentally. Methods First, we downloaded four microarrays (GSE11755, GSE12624, GSE28750, and GSE48080) from the Gene Expression Omnibus (GEO) database, which included data from 239 normal human blood samples and 365 blood specimens from patients with SD. Then, we analyzed two groups of differentially expressed genes (DEGs) and used Support Vector Machine Recursive Feature Elimination (SVM-RFE) analysis and the Least Absolute Shrinkage and Selection Operator (LASSO) regression model to investigate these key genes. Next, we used CIBERSORT to investigate the composition of 22 immune cell components of key genes in SD patients. Finally, the expression levels of key biomarkers in sleep-deprived patients were examined by quantitative real-time polymerase chain reaction (qRT-PCR). Results A total of 50 DEGs were identified: six genes were significantly upregulated, and 44 genes were significantly downregulated. Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analysis showed that Salmonella infection, NOD-like receptor (NLR) signaling pathway, Kaposi sarcoma-associated herpesvirus infection, and Th17 cell differentiation were significant. Based on machine learning, we identified C2CD2L, SPINT2, APOL3, PKNOX1, and A2M as key genes for SD; these were confirmed by receiver operating characteristic (ROC) analysis. Immune cell infiltration analysis showed that C2CD2L, SPINT2, APOL3, PKNOX1, and A2M were related in different degrees to regulatory T cells (Tregs), follicular T helper cells, CD8 cells, and other immune cells. The qRT-PCR experiments confirmed that the expression levels of C2CD2L concurred with the results derived from machine learning, but PKNOX1 and APOL3 did not. Discussion In summary, we identified a key gene (C2CD2L) that may facilitate the development of biomarkers for insomnia.\n",
            "----------------------------------------\n",
            "Title: Dynamic Patterns: The Self-Organization of Brain and Behavior\n",
            "Abstract: Part 1 How nature handles complexity: what is a pattern? kinds of patterns principles of dynamic pattern formation the messages of self-organized patterns new laws to be expected in the organism matters of mind and matter the mind revealed? or, what this book's about. Part 2 Self-organization of behaviour - the basic picture: some historical remarks about the science of psychology are actions self-organized? if so, how? from synergies to synergetics requirements of a theory of self-organized behaviour. Part 3 Self-organization of behaviour - first steps of generalization: Hubris tempered? on Harvard horses and Russian cats coordination between components of an organism coordination between organisms on coupling. Part 4 Extending the basic picture - breaking away: relative coordination relative coordination explained absolute and relative coordination unified related models - fireflies, lampreys, and lasers instability and the nature of life - the intermittency mechanism exposed postscript. Part 5 Intentional dynamics: goal-directness in biology the second cornerstone of biological self-organization - informational specificity intentional behaviourial change related views - termites, predator-prey cycles, and quantum mechanics summing up. Part 6 Learning dynamics: issues in learning the main concepts the 'seagull effect' - competition and cooperation questions of learning transfer and generalization - symmetry again behaviourial development evolution and morphogenesis summary and conclusions. Part 7 perceptual dynamics: the barrier of meaning - perceptual dynamics I the barrier of meaning - perceptual dynamics II metastability of mind principles of perceiving - calculating, settling, resonating, and twinkling. Part 8 Self-organizing dynamics of the nervous system: microscale events mesoscale events macroscale events extending the basic picture...again postscript on etymology. Part 9 Self-organization of the human brain: prolegomenon obstacles to understanding the brain is not a static machine the 'brain dynamics' approach - fractural dimension spatiotemporal patterns of the brain models of brain behaviour - coupled modes and Sil'nikov chaos summary and conclusions - brain behaviour.\n",
            "----------------------------------------\n",
            "Title: Assessment of Readiness of Croatian Companies to Introduce I4.0 Technologies\n",
            "Abstract: The main topic of this paper is to estimate the possibility and inclination of Croatian companies towards technology and innovation as well as to analyze advantages, limitations and risks involved with this significant technological leap. We analyzed 7147 Croatian business entities operating in different industries in this paper. The starting point in this research is to identify subjects, which could be users of I4.0 or its elements, based on the similarity of indicators with indicators of a sample of 58 identified I4.0 companies. We developed a machine-learning model by using the eXtreme Gradient Boosting algorithm (XGBoost) for this purpose, an approach that has not been used in any similar research. This research shows that the main difference between I4.0 and traditional industry is mostly observable in significantly better business performance of investment indicators, cost efficiency, technical equipment and market competitiveness. We identified 141 companies (1.97% of total analyzed sample) as potential users of I4.0, which makes up around 27% of total assets of the analyzed sample and around 26% of revenues.\n",
            "----------------------------------------\n",
            "Title: Adaptive multi-agent smart academic advising framework\n",
            "Abstract: Abdelaziz A. Abdelhamid, College of Computing & Information Technology, Shaqra University, Saudi Arabia. Email: Abdelaziz@cis.asu.edu.eg Abstract Academic advising is a crucial process in higher education and usually requires better understanding of student capabilities and curriculum structure to achieve its intended goals. Here, the authors propose a framework of integrated environment based on multi‐ agents to automate the full process of academic advising. The proposed framework consists of six agents namely, student agent, instructor agent, administrator agent, performance agent, schedule agent, and smart advisor agent. These agents are interacting together with the help of smart advisor agent, which manages the communication between them and provides smart advice based on machine learning techniques. In addition, the analysis of the proposed framework along with the deployment map is discussed by the authors. Moreover, a case study is presented in terms of a sample part of adaptive multi‐agent smart academic advising framework to demonstrate the workflow of the proposed approach.\n",
            "----------------------------------------\n",
            "Title: Predicting Survival Time of Ball Bearings in the Presence of Censoring\n",
            "Abstract: Ball bearings find widespread use in various manufacturing and mechanical domains, and methods based on machine learning have been widely adopted in the field to monitor wear and spot defects before they lead to failures. Few studies, however, have addressed the problem of censored data, in which failure is not observed. In this paper, we propose a novel approach to predict the time to failure in ball bearings using survival analysis. First, we analyze bearing data in the frequency domain and annotate when a bearing fails by comparing the Kullback-Leibler divergence and the standard deviation between its break-in frequency bins and its break-out frequency bins. Second, we train several survival models to estimate the time to failure based on the annotated data and covariates extracted from the time domain, such as skewness, kurtosis and entropy. The models give a probabilistic prediction of risk over time and allow us to compare the survival function between groups of bearings. We demonstrate our approach on the XJTU and PRONOSTIA datasets. On XJTU, the best result is a 0.70 concordance-index and 0.21 integrated Brier score. On PRONOSTIA, the best is a 0.76 concordance-index and 0.19 integrated Brier score. Our work motivates further work on incorporating censored data in models for predictive maintenance.\n",
            "----------------------------------------\n",
            "Title: PAS: Probably Approximate Safety Verification of Reinforcement Learning Policy Using Scenario Optimization\n",
            "Abstract: With the advancement of machine learning based automation in the current digital world, the problem of safety verification of such systems is becoming crucial, especially in safety-critical domains like self-driving cars, robotics, etc. Reinforcement learning (RL) is an emerging machine learning technique with many applications, including in safety-critical domains. The classical safety verification approach of making a binary decision on determining whether a system is safe or unsafe is particularly challenging for an RL system. Such an approach generally requires prior knowledge about the system, e.g., the transition model of the system, the set of unsafe states in the environment, etc., which are typically unavailable in a standard RL setting. Instead, this paper addresses the safety verification problem from a quantitative safety perspective, i.e., we quantify the safe behavior of the policy in terms of probability. We formulate the safety verification problem as a chance-constrained optimization using the technique of barrier certificate. We then use a sampling based approach called scenario optimization to solve the chance-constrained problem, which gives the desired probabilistic guarantee on the safe behavior of the policy. Our extensive empirical evaluation shows the validity and robustness of our approach in three RL domains.\n",
            "----------------------------------------\n",
            "Title: Constructing and predicting school advice for academic achievement: a comparison of item response theory and machine learning techniques\n",
            "Abstract: Educational tests can be used to estimate pupils' abilities and thereby give an indication of whether their school type is suitable for them. However, tests in education are usually conducted for each content area separately which makes it difficult to combine these results into one single school advice. To help with school advice, we provide a comparison between both domain-specific and domain-agnostic methods for predicting school types. Both use data from a pupil monitoring system in the Netherlands, a system that keeps track of pupils' educational progress over several years by a series of tests measuring multiple skills. A domain-specific item response theory (IRT) model is calibrated from which an ability score is extracted and is subsequently plugged into a multinomial log-linear regression model. Second, we train domain-agnostic machine learning (ML) models. These are a random forest (RF) and a shallow neural network (NN). Furthermore, we apply case weighting to give extra attention to pupils who switched between school types. When considering the performance of all pupils, RFs provided the most accurate predictions followed by NNs and IRT respectively. When only looking at the performance of pupils who switched school type, IRT performed best followed by NNs and RFs. Case weighting proved to provide a major improvement for this group. Lastly, IRT was found to be much easier to explain in comparison to the other models. Thus, while ML provided more accurate results, this comes at the cost of a lower explainability in comparison to IRT.\n",
            "----------------------------------------\n",
            "Title: IPC Multi-label Classification Applying the Characteristics of Patent Documents\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Predicting Citation Counts Using Text and Graph Mining\n",
            "Abstract: As the volume of scientific literature grows faster it becomes more difficult for researchers to identify promising papers that are likely to become influential in their field. We study the problem of predicting future citation counts of papers given information available at the time of publication (five years forward in our pilot study). We apply machine learning techniques on a dataset of millions of academic papers from several research domains to identify predictive features including venue reputation, authors and institutions, citation networks and content measures. We identify how these features are differentially predictive in various domains and identify possible reasons where citation behaviors might lead to these differences.\n",
            "----------------------------------------\n",
            "Title: Predicting Cyber Risks through National Vulnerability Database\n",
            "Abstract: ABSTRACT Software vulnerabilities are the major cause of cyber security problems. The National Vulnerability Database (NVD) is a public data source that maintains standardized information about reported software vulnerabilities. Since its inception in 1997, NVD has published information about more than 43,000 software vulnerabilities affecting more than 17,000 software applications. This information is potentially valuable in understanding trends and patterns in software vulnerabilities so that one can better manage the security of computer systems that are pestered by the ubiquitous software security flaws. In particular, one would like to be able to predict the likelihood that a piece of software contains a yet-to-be-discovered vulnerability, which must be taken into account in security management due to the increasing trend in zero-day attacks. We conducted an empirical study on applying data-mining techniques on NVD data with the objective of predicting the time to next vulnerability for a given software application. We experimented with various features constructed using the information available in NVD and applied various machine learning algorithms to examine the predictive power of the data. Our results show that the data in NVD generally have poor prediction capability, with the exception of a few vendors and software applications. We suggest possible reasons for why the NVD data have not produced a reasonable prediction model for time to next vulnerability with our current approach, and suggest alternative ways in which the data in NVD can be used for the purpose of risk estimation.\n",
            "----------------------------------------\n",
            "Title: Potential of Artificial Intelligence in Improving Speed and Efficiency of Clinical Trials\n",
            "Abstract: \n",
            " In recent years, artificial intelligence (AI) has demonstrated its ability to improve many facets of health care. Clinical trials are no exception. There s enormous potential in the use of AI in all stages of clinical trials – planning, conduct, and analysis. However, clinical trials are highly regulated, and the guidance on the use of AI in trials has not yet been developed. Once these challenges are overcome or in the appropriate setting, AI can offer significant speed and cost advantage across all stages of clinical trials. In the planning stage, AI can simulate patient journey to enable patient-centric study design and identify the patient pool and investigational sites based on eligibility criteria. The tools can run multiple scenarios on timeline, cost, and complexity to determine feasibility. Generative AI can be used to create study documents. During study conduct, AI can be deployed to identify risks for data quality and integrity enabling reduction in monitoring visits and potentially reducing carbon footprint. AI can predict event accrual and data cleaning using machine learning. During study closeout, AI can accelerate data query resolution by bots and reduce site burden. The generative AI applied during the creation of study documents can be efficiently used to write study reports and generate tables and figures. In summary, AI has the potential to improve the efficiency of clinical trials, and if development is successful, AI can even potentially reduce the cost of drug to the patient.\n",
            "----------------------------------------\n",
            "Title: Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification\n",
            "Abstract: Chronic kidney disease (CKD) is a significant public health challenge, often progressing to end-stage renal disease (ESRD) if not detected and managed early. Early intervention, warranted by silent disease progression, can significantly reduce associated morbidity, mortality, and financial burden. In this study, we propose a novel approach to modeling CKD progression using a combination of machine learning techniques and classical statistical models. Building on the work of Liu et al. (2023), we evaluate linear models, tree-based methods, and deep learning models to extract novel predictors for CKD progression, with feature importance assessed using Shapley values. These newly identified predictors, integrated with established clinical features from the Kidney Failure Risk Equation, are then applied within the framework of Cox proportional hazards models to predict CKD progression.\n",
            "----------------------------------------\n",
            "Title: Predicting stock movement direction with machine learning: An extensive study on S&P 500 stocks\n",
            "Abstract: Stocks movement direction forecasting has received a lot of attention. Indeed, being able to make accurate forecasts has strong implications on trading strategies. Surprisingly enough little has been published, relatively to the importance of the topic. In this paper, we reviewed how well four classic classification algorithms: random forest, gradient boosted trees, artificial neural network and logistic regression perform in predicting 463 stocks of the S&P 500. Several experiments were conduced to thoroughly study the predictability of these stocks. To validate each prediction algorithm, three schemes we compared: standard cross validation, sequential validation and single validation. As expected, we were not able to predict stocks future prices from their past. However, unexpectedly, we were able to show that taking into account recent information — such as recently closed European and Asian indexes — to predict S&P 500 can lead to a vast increase in predictability. Moreover, we also found out that, among various sectors, financial sector stocks are comparatively more easy to predict than others.\n",
            "----------------------------------------\n",
            "Title: A survey of ontology learning techniques and applications\n",
            "Abstract: Abstract Ontologies have gained a lot of popularity and recognition in the semantic web because of their extensive use in Internet-based applications. Ontologies are often considered a fine source of semantics and interoperability in all artificially smart systems. Exponential increase in unstructured data on the web has made automated acquisition of ontology from unstructured text a most prominent research area. Several methodologies exploiting numerous techniques of various fields (machine learning, text mining, knowledge representation and reasoning, information retrieval and natural language processing) are being proposed to bring some level of automation in the process of ontology acquisition from unstructured text. This paper describes the process of ontology learning and further classification of ontology learning techniques into three classes (linguistics, statistical and logical) and discusses many algorithms under each category. This paper also explores ontology evaluation techniques by highlighting their pros and cons. Moreover, it describes the scope and use of ontology learning in several industries. Finally, the paper discusses challenges of ontology learning along with their corresponding future directions.\n",
            "----------------------------------------\n",
            "Title: Design of Badminton Technical Movement Recognition System Based on Improved Agnes Algorithm\n",
            "Abstract: The Badminton Technical Movement Recognition System is a technology-driven solution aimed at identifying and analyzing various technical movements performed by badminton players during gameplay. Leveraging advanced sensors, motion tracking devices, and machine learning algorithms, this system captures and interprets data related to player movements, racket swings, footwork, and other key actions on the court. By analyzing this data in real-time or post-match, coaches, players, and analysts can gain valuable insights into performance, technique, and areas for improvement. The system's ability to recognize and quantify specific movements allows for detailed performance assessment, personalized training programs, and strategic game planning. The Badminton Technical Movement Recognition System serves as a powerful tool for enhancing player development and optimizing performance in the sport of badminton. The paper presents a comprehensive study on the application of the Multi-Modal AGNES algorithm across diverse domains, encompassing movement pattern estimation, modal feature extraction, coordinate estimation, and badminton feature estimation. Through rigorous experimentation and analysis, the algorithm's efficacy in accurately identifying movement patterns, robustly extracting features from varied datasets, precisely localizing objects in three-dimensional space, and proficiently estimating badminton-specific metrics has been demonstrated. Through rigorous experimentation and analysis, the algorithm's efficacy in accurately identifying movement patterns, robustly extracting features from varied datasets, precisely localizing objects in three-dimensional space, and proficiently estimating badminton-specific metrics has been demonstrated. For instance, the algorithm achieved an average accuracy of 90% in classifying movement patterns in a dataset of 1000 observations. Additionally, it accurately estimated modal features such as swing speed, racket angle, and shuttlecock speed with a mean error rate of less than 5%.    \n",
            "----------------------------------------\n",
            "Title: 基于认知算法的中文本体自动构建工具研究与实现 Research and implementation of automatic Chinese ontology-building tools based on cognitive algorithms 云南民族大学学报：自然科学版，2018，27（3）：234-242\n",
            "Abstract: 本体广泛应用于语义网、自然语言处理、数字图书馆等领域，而自动构建本体是这些领域的难点之一.全自动的本体构建以及如何令机器自己不断学习并更新已有的本体知识的研究仍然缺乏.提出了一种基于认知算法的中文本体自动构建方法，建立了自动构建本体的概念和物理模型，并根据此模型实现了一个初步的自动构建本体的工具，在此基础上基于某些公理化算子来实现对已有本体的扩充、缩减、修正等操作，实验证明该模型和系统很大程度上降低了在构建本体过程中的人力投入. Ontology is widely used in the fields of semantic network, natural language processing, digital library and so on, while the automatic construction of ontology is one of the difficult points in these fields. There is a lack of research on fully automatic ontology construction and the approaches to maintaining the machine learning or updating the existing knowledge ontology. Research and implementation of automatic Chinese ontology-building tools based on cognitive algorithms creates a model of automatic Chinese ontology-building tool; meanwhile, a system is programmed to simulate this kind of ontology-learning. This system can do basic ontology-operations like ontology-expansion, ontology-reduction, ontology-correction and so on. And the results of all the above-mentioned experiments show that this model and system can reduce manpower on ontology engineering effectively.\n",
            "----------------------------------------\n",
            "Title: Combining phylogeny and coevolution improves the inference of interaction partners among paralogous proteins\n",
            "Abstract: Predicting protein-protein interactions from sequences is an important goal of computational biology. Various sources of information can be used to this end. Starting from the sequences of two interacting protein families, one can use phylogeny or residue coevolution to infer which paralogs are specific interaction partners within each species. We show that these two signals can be combined to improve the performance of the inference of interaction partners among paralogs. For this, we first align the sequence-similarity graphs of the two families through simulated annealing, yielding a robust partial pairing. We next use this partial pairing to seed a coevolution-based iterative pairing algorithm. This combined method improves performance over either separate method. The improvement obtained is striking in the difficult cases where the average number of paralogs per species is large or where the total number of sequences is modest. Author summary When two protein families interact, their sequences feature statistical dependencies. First, interacting proteins tend to share a common evolutionary history. Second, maintaining structure and interactions through the course of evolution yields coevolution, detectable via correlations in the amino-acid usage at contacting sites. Both signals can be used to computationally predict which proteins are specific interaction partners among the paralogs of two interacting protein families, starting just from their sequences. We show that combining them improves the performance of interaction partner inference, especially when the average number of potential partners is large and when the total data set size is modest. The resulting paired multiple-sequence alignments might be used as input to machine-learning algorithms to improve protein-complex structure prediction, as well as to understand interaction specificity in signaling pathways.\n",
            "----------------------------------------\n",
            "Title: Machine learning and brain imaging in psychosis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Recent trends in marine microplastic modeling and machine learning tools: Potential for long-term microplastic monitoring\n",
            "Abstract: The increase in the global demand for plastics, and more recently during the pandemic, is a major concern for the future of plastic waste pollution and microplastics. Efficient microplastic monitoring is imperative to understanding the long-term effects and progression of microplastic effects in the environment. Numerical models are valuable in studying microplastic transport as they can be used to examine the effects of different parameters systematically to help elucidate the fate and transport processes of microplastics, thus providing a holistic view of microplastics in the ocean environment. By incorporating physical parameters (such as size, shape, density, and identity of microplastics), numerical models have gained better understanding of the physics of microplastic transport, predicted sinking velocities more accurately, and estimated microplastic pathways in marine environments. However, availability of large amounts of information about microplastic physical and chemical parameters is sparse. Machine learning and computer-vision tools can aid in acquiring environmental information and provide input to develop more accurate models and verify their predictions. More accurate models can further the understanding of microplastic transport, facilitate monitoring efforts, and thus optimize where more data collection can take place to ultimately improve machine learning tools. This review offers a perspective on how image-based machine learning can be exploited to help uncover the physics of microplastic transport behaviors. Additionally, the authors hope the review inspires studies that can bridge the gap between numerical modeling and machine learning for microplastic analysis to exploit their joined potential.\n",
            "----------------------------------------\n",
            "Title: Global output on artificial intelligence in the field of nursing: A bibliometric analysis and science mapping.\n",
            "Abstract: PURPOSE\n",
            "To analyze the AI research in the field of nursing, to explore the current situation, hot topics, and prospects of AI research in the field of nursing, and to provide a reference for researchers to carry out related studies.\n",
            "\n",
            "\n",
            "METHODS\n",
            "We used the VOSviewer 1.6.17, SciMAT, and CiteSpace 5.8.R3 to generate visual cooperation network maps for the country, organizations, authors, citations, and keywords and perform burst detection, theme evolution, and so forth.\n",
            "\n",
            "\n",
            "FINDINGS\n",
            "A total of 9318 articles were obtained from the Web of Science Core Collection database. Four hundred and thirty-one AI research related to the field of nursing was published by 855 institutions from 54 countries. CIN-Computers Informatics Nursing was the top productive journal. The United States was the dominant country. The transnational cooperation between authors from developed countries was closer than that between authors from developing countries. The main hot topics included nurse rostering, nursing diagnosis, nursing decision support, disease risk factor prediction, nursing big data management, expert system, support vector machine, decision tree, deep learning, natural language processing, and nursing education. Machine learning represented one of the cutting-edge and most applicable branches of artificial intelligence in the field of nursing, and deep learning was the hottest technology among many machine learning methods in recent years. One of the most cited papers was published by Burke in 2004 and cited 500 times, which critically evaluated AI methods to deal with nurse scheduling problems.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "Although AI has been paid more and more attention to the field of nursing, there is still a lack of high-yielding authors who have been engaged in this field for a long time. Most of the high contribution authors and institutions came from developed countries; therefore, more transnational and multi-disciplinary cooperation is needed to promote the development of AI in the nursing field. This bibliometric analysis not only provided a comprehensive overview to help researchers to understand the important articles, journals, potential collaborators, and institutions in this field but also analyzed the history, hot spots, and future trends of the research topic to provide inspiration for researchers to choose research directions.\n",
            "----------------------------------------\n",
            "Title: Intelligence-led policing in the 21st Century: How increased mobility requires new paradigms of information sharing\n",
            "Abstract: The challenge posed by mobile criminality to law enforcement has increased in the 21st Century, as technology and digital communication have accelerated. This study examines the threat by analysing foreign national suspects data (arrested in a UK police force, n = 293) and UK-based practitioner interviews (n = 36). The evidence reveals the threat from offenders who travel between countries is growing, in quantity and sophistication. To keep pace with this evolution, law enforcement must develop new paradigms of information sharing, using technological advances and machine learning to their benefit and relying less on resource-intensive human practice. It suggests such a change will create cultural challenges.\n",
            "----------------------------------------\n",
            "Title: AirDraw: Leveraging smart watch motion sensors for mobile human computer interactions\n",
            "Abstract: Wearable computing is one of the fastest growing technology markets today, with smart watches poised to take over at least of half the wearable device market. Approaches to text entry on smart watches and other wrist worn systems, independent of the small screen, is of importance to the further growth of wearable systems. The consistent user interaction and hands-free, heads-up operation of smart watches paves the way for gesture recognition methods for text entry. This paper proposes a new text input method for smart watches, which utilizes motion sensor data and machine learning approaches to detect letters written in the air by a user. This method is less computationally intensive, less expensive, and unaffected by lighting factors, when compared to computer vision approaches. The AirDraw system prototype developed to test this approach is presented, along with experimental results with close to 71% accuracy in letter recognition.\n",
            "----------------------------------------\n",
            "Title: Research and Application of Feature Extraction and Multi-objective Machine Learning\n",
            "Abstract: A feature extraction and multi-objective machine learning algorithm is proposed based on multi-objective coevolutionary algorithm.Training samples core attributes are found by feature extraction and attribute groups are composed of core attributes and non-core attributes,so the classified accuracy is improved.All attribute groups are supervised clustering by attribute similarity and class tags.The number and center of class families can automatically determined by using the fitness function in machine learning as the goal;in this way,they can avoid the effect of subjective factors and the two key elements owning optimization nature are guaranteed.The class tag using the nearest neighbor method determines a genus of the unclassified samples.At last,the algorithm is demonstrated by the UCI data sets of Liver Disorders,Hepatitis data sets and summery abnormal megathermal forecast in the north area of Zhejiang province.The experiment results indicate that feature extraction and multi-objective machine learning algorithm is better than the well-known NBC,C4.5 and SVM.\n",
            "----------------------------------------\n",
            "Title: Design and Development of a Personality Traits Classifier based on Machine Learning Techniques\n",
            "Abstract: Recently, during the last few years the use of digital devices, with Internet access, such as smartphones or tablets, has been increasing considerably in people's day after day. Because of this, Internet usage and therefore social networks usage has also increased. In social networks, users share personal data to broadcast content between users and this also implicitly convey useful information for companies studies. This makes interesting the task of characterizing users (in this case using personality) through their activity in social networks. \n",
            "In previous studies, there has been seen that personality can affect users in different aspects: preferences for interaction styles in the digital world or musical genres, for example. \n",
            "Consequently, the design of customized user interfaces and music recommender systems can help us to provide better experiences to users. \n",
            "This thesis is the result of a project whose main aim has been to obtain a personality traits classifier, whose task was set in a workshop in 2014, working on a YouTube dataset, using Python as programming language and deploying the system as a Senpy plug-in. \n",
            "During the development phase, there have been used supervised machine learning tools, natural language processing techniques (NLP) and queries to the sentiments and emotions analysis platform, Senpy. \n",
            "Regarding the workshop, there have been obtained similar results, what means that predicting personality can be seen as a real possibility.\n",
            "----------------------------------------\n",
            "Title: Mapping the daily nitrous acid (HONO) concentrations across China during 2006-2017 through ensemble machine-learning algorithm.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Method for reducing dimensions of hyper-spectral data on basis of pairwise constraint discriminate analysis and non-negative sparse divergence\n",
            "Abstract: The invention discloses a method for reducing dimensions of hyper-spectral data on the basis of pairwise constraint discriminate analysis and non-negative sparse divergence, and belongs to methods for processing hyper-spectral remote sensing images. The method aims to solve the problem of deterioration of the classification performance of most advanced algorithms for classifying hyper-spectral data on the basis of machine learning when source hyper-spectral data and target hyper-spectral data are distributed differently. The method includes firstly, performing pairwise constraint discriminate analysis according to pairwise constraint samples; secondly, designing a non-negative sparse divergence criterion to create a bridge among source-field hyper-spectral data and target-field hyper-spectral data which are distributed differently; thirdly, combining the pairwise constraint discriminate analysis with the bridge to transfer knowledge from the source hyper-spectral data to the target hyper-spectral data. The pairwise constraint samples containing discriminate information can be automatically acquired. The method has the advantages that the knowledge can be transferred among the hyper-spectral data acquired at different moments, in different areas or by different sensors; the information of the source-field hyper-spectral data can be effectively utilized to analyze the target-field hyper-spectral data, and high integral classification precision and a high Kappa coefficient can be acquired.\n",
            "----------------------------------------\n",
            "Title: Explainable Supervised Method for Genetics Ancestry Estimation\n",
            "Abstract: Ancestry estimation is one crucial stage in genomic research. It generates scores that represent the admixed genetics profile as the result of human evolution. In the previous research, we implemented multiple unsupervised methods to estimate these scores from large genomics data obtained from the 1000 Genome Project. These methods were limited to only cluster the samples to the five global populations in the dataset. The main challenge arose when implementing these methods to cluster the samples into more specific subpopulations. In this paper, we proposed a supervised approach to answer this challenge. Two state-of-the-art supervised machine learning methods, XGBoost and Deep Neural Network (DNN), were applied to the same dataset. These methods were aimed to classify samples, both into five main populations and also into 26 sub-populations. In the first classification task, both methods achieved similar results to our previous unsupervised approach. Interestingly, for the second classification task, which posses a relatively higher difficulty, DNN yielded better performance in the train, validation, and test dataset, despite its overfitting problem. Furthermore, the feature importance scores from each model were calculated using Shapley Additive Explanations (SHAP) method. Finally, 11 overlapped SNPs from all models were evaluated based on the reported Minor Allele Frequency (MAF) from the 1000 Genome Project. Overall, only using these 11 SNPs, we could differentiate each population in regards to its average MAF.\n",
            "----------------------------------------\n",
            "Title: Optimisation of System Configuration Using Machine Learning as a Surrogate Model\n",
            "Abstract: Complex mechanical systems provide a degree of reliability through redundancy. That is, they have duplicate systems, either similar or dissimilar, performing the same function. These duplicate systems will vary in their dynamic properties and may have different vibration transmission\n",
            " paths due to their connections within the overall system. Therefore, the use of redundancy gives rise to different vibrational behaviour of the overall system depending on the machines selected to deliver the intended system output. In some circumstances, it is necessary to minimise vibration\n",
            " levels by selecting a particular system configuration. In large complex systems consisting of multiple sources, this is not a trivial task, and virtually impossible to investigate all possible machinery combinations leading to the lowest vibration levels, whilst delivering the desired output.\n",
            " To address this, a machine learning model has been trained to provide predictions of machinery vibration levels. Data are obtained using an experimental vibration rig, emulating a complex, multi-source mechanical system. The machine learning model is subsequently utilised within a genetic\n",
            " algorithm optimisation routine in order to obtain the system configuration producing the lowest vibration levels at a number of observer locations for a specified system output.\n",
            "----------------------------------------\n",
            "Title: Learning Algorithm of Boltzmann Machine Based on Spatial Monte Carlo Integration Method\n",
            "Abstract: The machine learning techniques for Markov random fields are fundamental in various fields involving pattern recognition, image processing, sparse modeling, and earth science, and a Boltzmann machine is one of the most important models in Markov random fields. However, the inference and learning problems in the Boltzmann machine are NP-hard. The investigation of an effective learning algorithm for the Boltzmann machine is one of the most important challenges in the field of statistical machine learning. In this paper, we study Boltzmann machine learning based on the (first-order) spatial Monte Carlo integration method, referred to as the 1-SMCI learning method, which was proposed in the author’s previous paper. In the first part of this paper, we compare the method with the maximum pseudo-likelihood estimation (MPLE) method using a theoretical and a numerical approaches, and show the 1-SMCI learning method is more effective than the MPLE. In the latter part, we compare the 1-SMCI learning method with other effective methods, ratio matching and minimum probability flow, using a numerical experiment, and show the 1-SMCI learning method outperforms them.\n",
            "----------------------------------------\n",
            "Title: Performance Analysis of Multilayer Perceptron Neural Network Models in Week-Ahead Rainfall Forecasting\n",
            "Abstract: Multilayer perceptron neural network (MLPNN) is considered as one of the most efficient forecasting techniques which can be implemented for the prediction of weather occurrence. As with any machine learning implementation, the challenge on the utilization of MLPNN in rainfall forecasting lies in the development and evaluation of MLPNN models which delivers optimal forecasting performance. This research conducted performance analysis of MLPNN models through data preparation, model designing, and model evaluation in order to determine which parameters are the best-fit configurations for MLPNN model implementation in rainfall forecasting. During rainfall data preparation, imputation process and spatial correlation evaluation of weather variables from various weather stations showed that the geographical location of the chosen weather stations did not have a direct correlation between stations with respect to rainfall behavior leading to the decision of utilizing the weather station having the most complete weather data to be fed in the MLPNN. By conducting performance analysis of MLPNN models with different combinations of training algorithms, activation functions, learning rate, and momentum, it was found out that MLPNN model having 100 hidden neurons with Scaled Conjugate Gradient training algorithm and Sigmoid activation function delivered the lowest RMSE of 0.031537 while another MLPNN model having the same number of hidden neurons, the same activation function but Resilient Propagation as training algorithm had the lowest MAE of 0.0209. The results of this research showed that performance analysis of MLPNN models is a crucial process in model implementation of MLPNN for week-ahead rainfall forecasting.\n",
            "----------------------------------------\n",
            "Title: Transcriptomic analysis of immune cells in a multi-ethnic cohort of systemic lupus erythematosus patients identifies ethnicity- and disease-specific expression signatures\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Multiple Machine Learning Algorithms for Cancer Prognosis in Lung Adenocarcinoma\n",
            "Abstract: Lung cancer is the most prevailing source of death due to cancer, accounting for over 25% of death in the United States. Being able to predict the survival time for patients will provide valuable information for the choice of their treatment plans and benefit patient management. With the advancement of next-generation sequencing, many high-throughput sequencing data for DNA and RNA becomes available for cancer patients. Here we present the results for using multiple machine learning algorithms in predicting the survivorship of patients with Lung cancer adenocarcinoma. Using the publicly available datasets in TCGA with the overall survival length, and transcriptomic information, we evaluated our ability to predict prognosis. We found that using the expression level of a few candidate genes alone generates significant statistical power from a very limited number of patients, suggesting more future studies to be conducted on collecting such data to facilitate personalized medicine.\n",
            "----------------------------------------\n",
            "Title: Spatiotemporal estimation of the PM2.5 concentration and human health risks combining the three-dimensional landscape pattern index and machine learning methods to optimize land use regression modeling in Shaanxi, China.\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: 6G-SECUREIDS: Blockchain-Enhanced Secure Knowledge Transfer for Distributed Intrusion Detection Systems in Advanced Networks\n",
            "Abstract: As the development of wireless networks advances towards the deployment of 6G technology, ensuring robust security measures becomes crucial. In this paper, we propose 6G-SECUREIDS, a novel intrusion detection system designed specifically for 6G wireless networks. The system leverages machine learning techniques and blockchain technology to detect and mitigate security threats, safeguard data privacy, and ensure efficient and optimized training. Our experimental results demonstrate the effectiveness and reliability of the system, with the clients achieving high accuracy scores across different model architectures. The promising results highlight the potential of 6G-SECUREIDS as a valuable security solution for future 6G networks, contributing to the overall protection and integrity of the wireless communication ecosystem.\n",
            "----------------------------------------\n",
            "Title: Machine learning algorithm for ventilator mode selection, pressure and volume control\n",
            "Abstract: Mechanical ventilation techniques are vital for preserving individuals with a serious condition lives in the prolonged hospitalization unit. Nevertheless, an imbalance amid the hospitalized people demands and the respiratory structure could cause to inconsistencies in the patient’s inhalation. To tackle this problem, this study presents an Iterative Learning PID Controller (ILC-PID), a unique current cycle feedback type controller that helps in gaining the correct pressure and volume. The paper also offers a clear and complete examination of the primarily efficient neural approach for generating optimal inhalation strategies. Moreover, machine learning-based classifiers are used to evaluate the precision and performance of the ILC-PID controller. These classifiers able to forecast and choose the perfect type for various inhalation modes, eliminating the likelihood that patients will require mechanical ventilation. In pressure control, the suggested accurate neural categorization exhibited an average accuracy rate of 88.2% in continuous positive airway pressure (CPAP) mode and 91.7% in proportional assist ventilation (PAV) mode while comparing with the other classifiers like ensemble classifier has reduced accuracy rate of 69.5% in CPAP mode and also 71.7% in PAV mode. An average accuracy of 78.9% rate in other classifiers compared to neutral network in CPAP. The neural model had an typical range of 81.6% in CPAP mode and 84.59% in PAV mode for 20 cm H2O of volume created by the neural network classifier in the volume investigation. Compared to the other classifiers, an average of 72.17% was in CPAP mode, and 77.83% was in PAV mode in volume control. Different approaches, such as decision trees, optimizable Bayes trees, naive Bayes trees, nearest neighbour trees, and an ensemble of trees, were also evaluated regarding the accuracy by confusion matrix concept, training duration, specificity, sensitivity, and F1 score.\n",
            "----------------------------------------\n",
            "Title: Geometric Data Analysis Across Scales via Laplacian Eigenvector Cascading.\n",
            "Abstract: We develop here an algorithmic framework for constructing consistent multiscale Laplacian eigenfunctions (vectors) on data. Consequently, we address the unsupervised machine learning task of finding scalar functions capturing consistent structure across scales in data, in a way that encodes intrinsic geometric and topological features. This is accomplished by two algorithms for eigenvector cascading. We show via examples that cascading accelerates the computation of graph Laplacian eigenvectors, and more importantly, that one obtains consistent bases of the associated eigenspaces across scales. Finally, we present an application to TDA mapper, showing that our multiscale Laplacian eigenvectors identify stable flair-like structures in mapper graphs of varying granularity.\n",
            "----------------------------------------\n",
            "Title: Assessing responses to climate stressors in two contrasting pine species\n",
            "Abstract: \n",
            " <p>Climate conditions in which tree species are able to grow are determined by their ecophysiological traits. The genus Pinus spp. is widespread across Eurasia, so that the different Pinus species have evolved to live within diverse climate envelops, from the boreal Scots pine (Pinus sylvestris L.) to the Mediterranean Aleppo pine (Pinus halepensis Mill.). Therefore, the different pine species are expected to present contrasting responses to environmental stressors, depending on the ones that populations had faced in the past.</p><p>Here we analyze the impact of climate on stand carbon fluxes in two contrasting stands -i.e. a boreal Finnish Scots pine stand and a Mediterranean Israeli Aleppo pine stand. We use a machine learning approach -i.e. Random Forest algorithm- to evaluate seasonal changes in the most limiting environmental driver (MLED) for forest productivity. Then, we use data from controlled experiments with Aleppo and Scots pine saplings, in which we evaluated their response to drought and heat stresses, in order to assess if differences in their ecophysiological traits may explain their ability to grow in such contrasting climate conditions.</p><p>Our results suggest that the MLED of forest productivity during all year in the boreal stand are low temperatures. Conversely but not surprisingly, the MLED in the Mediterranean stand is soil water availability, especially during summer. Therefore, we expect P. halepensis to be better adapted to heat and drought stresses, whereas we expect P. sylvestris to present higher photosynthetic rates at lower temperatures. Controlled experiments confirm these expectations, with a remarkable isohydric behavior of P. halepensis during drought, and different species responses of photosynthesis thermal optimum to heat and drought stress. Our results highlight the need to understand how traits determine tree species&#8217; responses to different environmental stressors, in order to anticipate their performance in a warmer world.</p>\n",
            "\n",
            "----------------------------------------\n",
            "Title: SOUNDLAB AI Tool – Machine Learning zur Bestimmung des bewerteten Schalldämmmaßes\n",
            "Abstract: Die moderne Architektur strebt nach transparenten Gebäudehüllen und insbesondere nach nachhaltigen und bauphysikalisch adäquaten Glasfassaden. Typischerweise werden Glasfassaden entworfen, um eine Vielzahl von Zielen zu erfüllen, eines davon sind die Anforderungen an den Schallschutz. Eine zuverlässige Abschätzung der Schalldämmeigenschaften beliebiger Glasaufbauten ist aufgrund der Komplexität experimenteller Tests oder numerischer Simulationen zeitaufwendig und kostenintensiv. Daher wird in dieser Arbeit ein maschineller Lern‐Ansatz zur Prädiktion der akustischen Eigenschaften beliebiger Glasaufbauten vorgestellt.\n",
            "----------------------------------------\n",
            "Title: Consensus models to predict oral rat acute toxicity and validation on a dataset coming from the industrial context\n",
            "Abstract: ABSTRACT We report predictive models of acute oral systemic toxicity representing a follow-up of our previous work in the framework of the NICEATM project. It includes the update of original models through the addition of new data and an external validation of the models using a dataset relevant for the chemical industry context. A regression model for LD50 and multi-class classification model for toxicity classes according to the Global Harmonized System categories were prepared. ISIDA descriptors were used to encode molecular structures. Machine learning algorithms included support vector machine (SVM), random forest (RF) and naïve Bayesian. Selected individual models were combined in consensus. The different datasets were compared using the generative topographic mapping approach. It appeared that the NICEATM datasets were lacking some relevant chemotypes for chemical industry. The new models trained on enlarged data sets have applicability domains (AD) sufficiently large to accommodate industrial compounds. The fraction of compounds inside the models’ AD increased from 58% (NICEATM model) to 94% (new model). The increase of training sets improved models’ prediction performance: RMSE values decreased from 0.56 to 0.47 and balanced accuracies increased from 0.69 to 0.71 for NICEATM and new models, respectively.\n",
            "----------------------------------------\n",
            "Title: Using machine learning to develop a clinical prediction model for SSRI-associated bleeding: a feasibility study\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Social Credibility Incorporating Semantic Analysis and Machine Learning: A Survey of the State-of-the-Art and Future Research Directions\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Armor Guard: Revolutionizing Motorcycle Safety with Smart Helmet\n",
            "Abstract: Motorcycle accidents continue to be a significant concern worldwide, with riders facing various risks on the road. In response to these challenges, The design and development of a smart helmet system, intended to improve rider safety and encourage responsible riding, is presented in this study. The smart helmet integrates cutting-edge technologies and innovative features to provide a comprehensive safety solution for motorcycle riders. Key functionalities of the smart helmet include advanced navigation assistance, seamless call management, proactive accident detection, real-time alcohol detection, fog removal, and backlight indicators. These features are designed to improve visibility, prevent accidents, and ensure compliance with safety protocols. The smart helmet has a safety feature that prevents the vehicle from turning on unless the person wearing the helmet follows specific safety requirements. Additionally, an LED stripe integrated into the helmet's visor assists in fog removal, while a backlight indicator at the back of the helmet enhances visibility to fellow riders. Testing and evaluation of the smart helmet system demonstrate its functionality, reliability, and effectiveness in real-world scenarios. Response time testing confirms the system's prompt detection and response to various events, such as helmet activation and accident detection. The research also identifies areas for future work, including the integration of advanced sensor technologies, enhanced communication and connectivity, AI and machine learning applications, and improvements in energy efficiency and user experience.\n",
            "----------------------------------------\n",
            "Title: Extracting normative relationships from business contracts\n",
            "Abstract: The normative concepts offer a principled basis for engineering flexible multiagent systems for business and other cross-organizational settings. However, producing suitable specifications is nontrivial: the difficulty is an obstacle to the adoption of multiagent systems in industry. This paper considers normative relationships of six main types, namely, commitments (both practical and dialectical), authorizations, powers, prohibitions, and sanctions. It applies natural language processing and machine learning to extract these relationships from business contracts, establishing that they are realistic and their encoding can assist modelers, thereby lowering a barrier to adoption. A ten-fold cross-validation over more than 800 sentences randomly drawn from a corpus of real-life contracts (and manually labeled) yields promising results for the viability of this approach.\n",
            "----------------------------------------\n",
            "Title: Design of a recommendation system based on collaborative filtering and machine learning considering personal needs of the user\n",
            "Abstract: The paper reports a study into recommendation algorithms and determination of their advantages and disadvantages. The method for developing recommendations based on collaborative filtering such as Content-Based Filtering (CBF), Collaborative Filtering (CF), and hybrid methods of Machine Learning (ML) has been improved. The paper describes the design principles and functional requirements to a recommendation system in the form of a Web application for choosing the content required by user using movies as an example. The research has focused on solving issues related to cold start and scalability within the method of collaborative filtering. To effectively address these tasks, we have used hybrid training methods. A hybrid recommendation system (HRS) has been practically implemented for providing relevant content recommendations using movies as an example, taking into consideration the user's personal preferences based on the constructed hybrid method. We have improved an algorithm for developing content recommendations based on the collaborative filtering and Machine Learning for the combined filtration of similarity indicators among users or goods. The hybrid algorithm receives initial information in a different form, normalizes it, and generates relevant recommendations based on a combination of CF and CBF methods. Machine Learning is capable of defining those factors that influence the selection of relevant films, which improves development of recommendations specific to the user. To solve these tasks, a new improved method has been proposed, underlying which, in contrast to existing systems of recommendations, are the hybrid methods and Machine Learning. Machine Learning data for the designed HRS were borrowed from MovieLens. We have analyzed methods for developing recommendations to the user; existing recommendation systems have been reviewed. Our experimental results demonstrate that the operational indicators for the proposed HRS, based on the technology of CF+CBF+ML, outperform those for two individual models, CF and CBF, and such their combinations as CF CBF, CF+ML, and CBF+ML. We recommend using HRS to collect data on people's preferences in selecting goods and to providing relevant recommendations.\n",
            "----------------------------------------\n",
            "Title: Establishment and interpretation of the gamma pass rate prediction model based on radiomics for different intensity-modulated radiotherapy techniques in the pelvis\n",
            "Abstract: Backgroundand objectives: Implementation of patient-specific quality assurance (PSQA) is a crucial aspect of precise radiotherapy. Various machine learning-based models have showed potential as virtual quality assurance tools, being capable of accurately predicting the dose verification results of fixed-beam intensity-modulated radiation therapy (IMRT) or volumetric modulated arc therapy (VMAT) plans, thereby ensuring safe and efficient treatment for patients. However, there has been no research yet that simultaneously integrates different IMRT techniques to predict the gamma pass rate (GPR) and explain the model.Methods: Retrospective analysis of the 3D dosimetric verification results based on measurements with gamma pass rate criteria of 3%/2 mm and 10% dose threshold of 409 pelvic IMRT and VMAT plans was carried out. Radiomics features were extracted from the dose files, from which the XGBoost algorithm based on SHapley Additive exPlanations (SHAP) values was used to select the optimal feature subset as the input for the prediction model. The study employed four different machine learning algorithms, namely, random forest (RF), adaptive boosting (AdaBoost), extreme gradient boosting (XGBoost), and light gradient boosting machine (LightGBM), to construct predictive models. Sensitivity, specificity, F1 score, and AUC value were calculated to evaluate the classification performance of these models. The SHAP values were utilized to perform a related interpretive analysis on the best performing model.Results: The sensitivities and specificities of the RF, AdaBoost, XGBoost, and LightGBM models were 0.96, 0.82, 0.93, and 0.89, and 0.38, 0.54, 0.62, and 0.62, respectively. The F1 scores and area under the curve (AUC) values were 0.86, 0.81, 0.88, and 0.86, and 0.81, 0.77, 0.85, and 0.83, respectively. The explanation of the model output based on SHAP values can provide a reference basis for medical physicists when adjusting the plan, thereby improving the efficiency and quality of treatment plans.Conclusion: It is feasible to use a machine learning method based on radiomics to establish a gamma pass rate classification prediction model for IMRT and VMAT plans in the pelvis. The XGBoost model performs better in classification than the other three tree-based ensemble models, and global explanations and single-sample explanations of the model output through SHAP values may offer reference for medical physicists to provide high-quality plans, promoting the clinical application and implementation of GPR prediction models, and providing safe and efficient personalized QA management for patients.\n",
            "----------------------------------------\n",
            "Title: M3ICRO: Machine Learning-Enabled Compact Photonic Tensor Core based on PRogrammable Multi-Operand Multimode Interference\n",
            "Abstract: Photonic computing shows promise for transformative advancements in machine learning (ML) acceleration, offering ultrafast speed, massive parallelism, and high energy efficiency. However, current photonic tensor core (PTC) designs based on standard optical components hinder scalability and compute density due to their large spatial footprint. To address this, we propose an ultracompact PTC using customized programmable multi-operand multimode interference (MOMMI) devices, named M3ICRO. The programmable MOMMI leverages the intrinsic light propagation principle, providing a single-device programmable matrix unit beyond the conventional computing paradigm of one multiply-accumulate operation per device. To overcome the optimization difficulty of customized devices that often requires time-consuming simulation, we apply ML for optics to predict the device behavior and enable differentiable optimization flow. We thoroughly investigate the reconfigurability and matrix expressivity of our customized PTC and introduce a novel block unfolding method to fully exploit the computing capabilities of a complex-valued PTC for near-universal real-valued linear transformations. Extensive evaluations demonstrate that M3ICRO achieves a 3.5–8.9× smaller footprint, 1.6–4.4× higher speed, 9.9–38.5× higher compute density, 3.7–12× higher system throughput, and superior noise robustness compared to state-of-the-art coherent PTC designs. It also outperforms electronic digital A100 graphics processing unit by 34.8–403× higher throughput while maintaining close-to-digital task accuracy across various ML benchmarks.\n",
            "----------------------------------------\n",
            "Title: A Right to a Human Decision\n",
            "Abstract: Recent advances in computational technologies have spurred anxiety about a shift of power from human to machine decision-makers. From prison sentences to loan approvals to college applications, corporate and state actors increasingly lean on machine learning tools (a subset of artificial intelligence) to allocate goods and to assign coercion. Machine-learning tools are perceived to be eclipsing, even extinguishing, human agency in ways that sacrifice important individual interests. An emerging legal response to such worries is a right to a human decision. European law has already embraced the idea in the General Data Protection Regulation. American law, especially in the criminal justice domain, is already moving in the same direction. But no jurisdiction has defined with precision what that right entails, or furnished a clear justification for its creation. This Article investigates the legal possibilities of a right to a human decision. I first define the conditions of technological plausibility for that right as applied against state action. To understand its technological predicates, I specify the margins along which machine decisions are distinct from human ones. Such technological contextualization enables a nuanced exploration of why, or indeed whether, the gaps that do separate human and machine decisions might have normative import. Based on this technological accounting, I then analyze the normative stakes of a right to a human decision. I consider three potential normative justifications: (a) an appeal to individual interests to participation and reason-giving; (b) worries about the insufficiently reasoned or individuated quality of state action; and (c) arguments based on negative externalities. A careful analysis of these three grounds suggests that there is no general justification for adopting a right to a human decision by the state. Normative concerns about insufficiently reasoned or accurate decisions, which have a particularly powerful hold on the legal imagination, are best addressed in other ways. Similarly, concerns about the ways that algorithmic tools create asymmetries of social power are not parried by a right to a human decision. Indeed, rather than firmly supporting a right to a human decision, available evidence tentatively points toward a countervailing ‘right to a well-calibrated machine decision’ as ultimately more normatively wellgrounded. * Frank and Bernice J. Greenberg Professor of Law, University of Chicago Law School. Thanks to Faith Laken for terrific research aid. Thanks to Tony Casey, David Driesen, Lauryn Gouldin, Daniel Hemel, Darryl Li, Anup Malani, Richard McAdams, Eric Posner, Julie Roin, and Lior Strahilevitz for thoughtful conversation. Workshop participants at the University of Chicago, the University of Houston, and Syracuse University School of Law also provided thoughtful feedback. All errors are mine. Electronic copy available at: https://ssrn.com/abstract=3382521\n",
            "----------------------------------------\n",
            "Title: Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing\n",
            "Abstract: The ACL 2005 Workshop on Feature Engineering for Machine Learning in Natural Language Processing is an opportunity to explore the various dimensions of feature engineering for problems that are of interest to the ACL community. Feature Engineering encompasses feature design, feature selection, feature induction, studies of feature impact (including feature ablation studies), and related topics. In 2003, there was a NIPS workshop on feature engineering (\"Feature Extraction and Feature Selection\"), but the focus was not on NLP problems specifically. Also, although the various aspects of feature engineering have been dealt with at times in various ACL forums, until now, to our knowledge, the spotlight has never been shone directly on this topic specifically for NLP and language technology problems. We feel that now is the time to look more closely. \n",
            " \n",
            "As experience with machine learning for solving natural language processing tasks accumulates in the field, practitioners are finding that feature engineering is as critical as the choice of machine learning algorithm, if not more so. Feature engineering significantly affects the performance of systems and deserves greater attention. Also, in the wake of the shift in our field away from knowledge engineering and of the successes of data-driven and statistical methods, researchers are likely to make further progress by incorporating additional, sometimes familiar, sources of knowledge as features. Feature design may benefit from expert insight even where the relative merits of features must be assessed through empirical techniques from data. Although some experience in the area of feature engineering is to be found in the theoretical machine learning community, the particular demands of natural language processing leave much to be discovered. \n",
            " \n",
            "In the call for papers, we expressed our intent of bringing together practitioners of NLP, machine learning, information extraction, speech processing, and related fields with the goal of sharing experimental evidence for successful approaches to feature engineering. Judging by the quality and diversity of the submissions received, we believe we have succeeded, and the resulting program should be of great interest to many researchers in the ACL community. We hope that the workshop will contribute to the distillation of best practices and to the discovery of new sources of knowledge and features previously untapped.\n",
            "----------------------------------------\n",
            "Title: Mixed state entanglement classification using artificial neural networks\n",
            "Abstract: Reliable methods for the classification and quantification of quantum entanglement are fundamental to understanding its exploitation in quantum technologies. One such method, known as separable neural network quantum states (SNNS), employs a neural network inspired parameterization of quantum states whose entanglement properties are explicitly programmable. Combined with generative machine learning methods, this ansatz allows for the study of very specific forms of entanglement which can be used to infer/measure entanglement properties of target quantum states. In this work, we extend the use of SNNS to mixed, multipartite states, providing a versatile and efficient tool for the investigation of intricately entangled quantum systems. We illustrate the effectiveness of our method through a number of examples, such as the computation of novel tripartite entanglement measures, and the approximation of ultimate upper bounds for qudit channel capacities.\n",
            "----------------------------------------\n",
            "Title: English -Malayalam Vision aid with Multi Modal Machine Learning Technologies\n",
            "Abstract: Most of the blind assistive devices accessible in the market operate in the English language. This narrow downs the product’s scope in multilingual countries. To deal with this, some assistive devices make use of translation APIs and modules to make an interpretation of English into the regional language, but these translations are not up to the mark when comparing with the original text. Most of the translation APIs make use of traditional machine translation models that intakes single context as input and produce translations out of it. Linguistic ambiguity is very common among such models. This is mainly because of the morphological and syntactical divergence between the languages. This makes English-Indic language translation a challenging task. This research work proposes an efficient translation algorithm exclusively for blind assistive devices. This approach employs an image-guided multi-modal machine translation methodology, in which an image is used as an additional input to generate more accurate translations/scene distributions on Malayalam.\n",
            "----------------------------------------\n",
            "Title: Recent advances in feature selection and its applications\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Automata Learning from Preference and Equivalence Queries\n",
            "Abstract: Active automata learning from membership and equivalence queries is a foundational problem with numerous applications. We propose a novel variant of the active automata learning problem: actively learn finite automata using preference queries -- i.e., queries about the relative position of two sequences in a total order -- instead of membership queries. Our solution is REMAP, a novel algorithm which leverages a symbolic observation table along with unification and constraint solving to navigate a space of symbolic hypotheses (each representing a set of automata), and uses satisfiability-solving to construct a concrete automaton from a symbolic hypothesis. REMAP is guaranteed to correctly infer the minimal automaton with polynomial query complexity under exact equivalence queries, and achieves PAC-identification ($\\varepsilon$-approximate, with high probability) of the minimal automaton using sampling-based equivalence queries. Our empirical evaluations of REMAP on the task of learning reward machines for two reinforcement learning domains indicate REMAP scales to large automata and is effective at learning correct automata from consistent teachers, under both exact and sampling-based equivalence queries.\n",
            "----------------------------------------\n",
            "Title: Identification of blood-based transcriptomics biomarkers for Alzheimer's disease using statistical and machine learning classifier\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Active sonar target classification using a physics-cognizant feature representation\n",
            "Abstract: Active sonar target classification is challenging due to the non-linear overlap of changing oceanic and target parameters, creating entangled acoustic color spectra that should be disentangled prior to classification. A physics-cognizant feature extraction algorithm, used before interfacing with three machine learning techniques for active sonar target classification of experimental field data, is presented. The feature extraction algorithm convolves a two-dimensional Gabor wavelet across acoustic color spectra prior to threshold-based binarization, feature culling, and dimensional reduction. The optimal two-dimensional Gabor wavelet parameters are chosen through sensitivity analysis by a support vector machine (SVM) on a disjoint subset of data. Classification is performed on the second subset of data with an SVM, random forest tree, and neural network on the Gabor filtered spectra and unfiltered spectra to show the increased classification accuracy of the application of the geometric wavelet. Classification results are presented as confusion matrices for four targets of two public domain experiments. Ongoing and future work will include extending this feature extraction technique using various geometric feature representations to capture and describe far-field large scattering mechanisms from targets such as oil rigs, tankers, and shipwrecks. [This research is funded by the Office of Naval Research under Grant No. N00014-19-1-2436.]\n",
            "----------------------------------------\n",
            "Title: Enhancing Comparative Effectiveness Research With Automated Pediatric Pneumonia Detection in a Multi-Institutional Clinical Repository: A PHIS+ Pilot Study\n",
            "Abstract: Background Community-acquired pneumonia is a leading cause of pediatric morbidity. Administrative data are often used to conduct comparative effectiveness research (CER) with sufficient sample sizes to enhance detection of important outcomes. However, such studies are prone to misclassification errors because of the variable accuracy of discharge diagnosis codes. Objective The aim of this study was to develop an automated, scalable, and accurate method to determine the presence or absence of pneumonia in children using chest imaging reports. Methods The multi-institutional PHIS+ clinical repository was developed to support pediatric CER by expanding an administrative database of children’s hospitals with detailed clinical data. To develop a scalable approach to find patients with bacterial pneumonia more accurately, we developed a Natural Language Processing (NLP) application to extract relevant information from chest diagnostic imaging reports. Domain experts established a reference standard by manually annotating 282 reports to train and then test the NLP application. Findings of pleural effusion, pulmonary infiltrate, and pneumonia were automatically extracted from the reports and then used to automatically classify whether a report was consistent with bacterial pneumonia. Results Compared with the annotated diagnostic imaging reports reference standard, the most accurate implementation of machine learning algorithms in our NLP application allowed extracting relevant findings with a sensitivity of .939 and a positive predictive value of .925. It allowed classifying reports with a sensitivity of .71, a positive predictive value of .86, and a specificity of .962. When compared with each of the domain experts manually annotating these reports, the NLP application allowed for significantly higher sensitivity (.71 vs .527) and similar positive predictive value and specificity . Conclusions NLP-based pneumonia information extraction of pediatric diagnostic imaging reports performed better than domain experts in this pilot study. NLP is an efficient method to extract information from a large collection of imaging reports to facilitate CER.\n",
            "----------------------------------------\n",
            "Title: ADAPTIVE SCHEDULING THROUGH MACHINE LEARNING-BASED PROCESS PARAMETER PREDICTION\n",
            "Abstract: Detailed manufacturing process data and sensor signals are typically disregarded in production scheduling. However, they have strong relations since a longer processing time triggers a change in schedule. Although promising approaches already exist for mapping the influence of manufacturing processes on production scheduling, the variability of the production environment, including changing process conditions, technological parameters and the status of current orders, is usually ignored. For this reason, this paper presents a novel, data-driven approach that adaptively refines the production schedule by applying Machine Learning (ML)-models during the manufacturing process in order to predict the process-dependent parameters that influence the schedule. With the proper prediction of these parameters based on the process conditions, the production schedule is proactively adjusted to changing conditions not only to ensure the sufficient product quality but also to reduce the negative effects and losses that delayed rescheduling would cause. The proposed approach aims on minimizing the overall lateness by utilizing an active data exchange between the scheduling system and the predictive ML-models on the process level. The efficiency of the solution is demonstrated by a realistic case study using discrete event simulation.\n",
            "----------------------------------------\n",
            "Title: Factorial models and refiltering for speech separation and denoising\n",
            "Abstract: This paper proposes the combination of several ideas, some old and some new, from machine learning and speech processing. We review the max approximation to log spectrograms of mixtures, show why this motivates a “refiltering” approach to separation and denoising, and then describe how the process of inference in factorial probabilistic models performs a computation useful for deriving the masking signals needed in refiltering. A particularly simple model, factorial-max vector quantization (MAXVQ), is introduced along with a branch-and-bound technique for efficient exact inference and applied to both denoising and monaural separation. Our approach represents a return to the ideas of Ephraim, Varga and Moore but applied to auditory scene analysis rather than to speech recognition. 1. Sparsity & Redundancy in Spectrograms 1.1. The Log-MaxApproximation When two clean speech signals are mixed additively in the time domain, what is the relationship between the individual log spectrograms of the sources and the log spectrogram of the mixture? Unless the sources are highly dependent (synchronized), the spectrogram of the mixture is almost exactly the maximum of the individual spectrograms, with the maximum operating over small time-frequency regions (fig. 2). This amazing fact, first noted by Roger Moore in 1983, comes from the fact that unless e1 and e2 are both large and almost equal, log(e1 + e2) ≈ max(log e1, log e2) (fig. 1a). The sparse nature of the speech code across time and frequency is the key to the practical usefulness of this approximation: most narrow frequency bands carry substantial energy only a small fraction of the time and thus it is rare that two independent sources inject large amounts of energy into the same subband at the same time. (Figure 1b shows a plot of the relative energy of two simultaneous speakers in a narrow subband; most of the time at least one of the two sources shows negligible power.) 1.2. Masking and Refiltering Fortunately, the speech code is also redundant across timefrequency. Different frequency bands carry, to a certain extent, independent information and so if information in some bands is suppressed or masked, even for significant durations, other bands can fill in. (A similar effect occurs over time: if brief sections of the signal are obscured, even across all bands, the speech is still intelligible; while also useful, we do not exploit this here.) This is partly why humans perform so well on many monaural speech separation and denoising tasks. When we solve the cocktail party problem or recognize degraded speech, we are doing structural analysis, or a kind of “perceptual grouping” on the incoming sound. There is substantial evidence that the appropriate subparts of an audio signal for use in grouping may be narrow frequency bands over short times. To generate these parts computationally, we can perform multiband analysis – break the original speech signal y(t) into many subband signals bi(t) each lo g e2 ma\n",
            "----------------------------------------\n",
            "Title: Aircraft Fleet Health Monitoring with Anomaly Detection Techniques\n",
            "Abstract: Predictive maintenance has received considerable attention in the aviation industry where costs, system availability and reliability are major concerns. In spite of recent advances, effective health monitoring and prognostics for the scheduling of condition-based maintenance operations is still very challenging. The increasing availability of maintenance and operational data along with recent progress made in machine learning has boosted the development of data-driven prognostics and health management (PHM) models. In this paper, we describe the data workflow in place at an airline for the maintenance of an aircraft system and highlight the difficulties related to a proper labelling of the health status of such systems, resulting in a poor suitability of supervised learning techniques. We focus on investigating the feasibility and the potential of semi-supervised anomaly detection methods for the health monitoring of a real aircraft system. roposed methods are evaluated on large volumes of real sensor data from a cooling unit system on a modern wide body aircraft from a major European airline. For the sake of confidentiality, data has been anonymized and only few technical and operational details about the system had been made available. We trained several deep neural network autoencoder architectures on nominal data and used the anomaly scores to calculate a health indicator. Results suggest that high anomaly scores are correlated with identified failures in the maintenance logs. Also, some situations see an increase in the anomaly score for several flights prior to the system’s failure, which paves a natural way for early fault identification.\n",
            "----------------------------------------\n",
            "Title: Active machine learning-driven experimentation to determine compound effects on protein patterns\n",
            "Abstract: High throughput screening determines the effects of many conditions on a given biological target. Currently, to estimate the effects of those conditions on other targets requires either strong modeling assumptions (e.g. similarities among targets) or separate screens. Ideally, data-driven experimentation could be used to learn accurate models for many conditions and targets without doing all possible experiments. We have previously described an active machine learning algorithm that can iteratively choose small sets of experiments to learn models of multiple effects. We now show that, with no prior knowledge and with liquid handling robotics and automated microscopy under its control, this learner accurately learned the effects of 48 chemical compounds on the subcellular localization of 48 proteins while performing only 29% of all possible experiments. The results represent the first practical demonstration of the utility of active learning-driven biological experimentation in which the set of possible phenotypes is unknown in advance. DOI: http://dx.doi.org/10.7554/eLife.10047.001\n",
            "----------------------------------------\n",
            "Title: Fault Diagnosis of Rolling Bearing Based on Improved LeNet-5 CNN\n",
            "Abstract: To solve the problem of fault diagnosis of rolling bearing caused by large amount of data and difficulties of processing those data on to bearing set, based on Convolution Neural Network, a new method of data processing is proposed in this paper. With this method, one-dimensional time domain signal can be transformed into two-dimensional images, which is more suitable for Convolutional Neural Network processing. Meanwhile, the traditional machine learning method has the disadvantage of low robustness and low recognition rate with noise interference. Therefore, based on the feature extraction of Convolution Neural Network, in this paper we proposed an improved LeNet-5 Convolution Neural Network model, that is, adding a convolution layer and a pooling layer to the classic LeNet-5 model. The hidden layer features are extracted by using the trainable convolution kernel, while the extracted implicit features are reduced by the pooling layer, the Softmax classifier is used for classification and recognition of rolling bearing faults. In this paper we verified the effectiveness of the improved LeNet-5 model for fault diagnosis of rolling bearing by using the rolling bearing data to train the classic LeNet-5 model and the improved model.\n",
            "----------------------------------------\n",
            "Title: Can machine learning make naturalism about health truly naturalistic? A reflection on a data-driven concept of health\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Population subset selection for the use of a validation dataset for overfitting control in genetic programming\n",
            "Abstract: ABSTRACT Genetic Programming (GP) is a technique which is able to solve different problems through the evolution of mathematical expressions. However, in order to be applied, its tendency to overfit the data is one of its main issues. The use of a validation dataset is a common alternative to prevent overfitting in many Machine Learning (ML) techniques, including GP. But, there is one key point which differentiates GP and other ML techniques: instead of training a single model, GP evolves a population of models. Therefore, the use of the validation dataset has several possibilities because any of those evolved models could be evaluated. This work explores the possibility of using the validation dataset not only on the training-best individual but also in a subset with the training-best individuals of the population. The study has been conducted with 5 well-known databases performing regression or classification tasks. In most of the cases, the results of the study point out to an improvement when the validation dataset is used on a subset of the population instead of only on the training-best individual, which also induces a reduction on the number of nodes and, consequently, a lower complexity on the expressions.\n",
            "----------------------------------------\n",
            "Title: Interactive tools for the transcription of handwritten documents\n",
            "Abstract: Public and private archives contain hundreds of precious ancient documents for historic and genealogical research: Civil records, church records, military records, population censuses. These archives are regularly scanned for preservation and sharing. However accessing information is tedious when the corpus is not indexed nor transcribed. Several project aim at indexing and transcribing such documents automatically, such as Transkribus [6] or Himanis [5]. Despite their efforts, transcribing documents automatically remain complicated and unsatisfactory for historians [4]. Automatic methods are not able to interpret complex writings (irregular, with overlaps, bad scan quality) [3]. Moreover these algorithms require hand-made learning database and machine learning experts to adapt the tool to a specific document corpus.\n",
            "----------------------------------------\n",
            "Title: A Bag of Strings Representation for Image Categorization\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Computational challenges for multimodal astrophysics\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Malware Detection Using Machine Learning Models\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Copyright lessons on Machine Learning: what impact on algorithmic art?\n",
            "Abstract: JIPITEC 10 (2020) 3 - Nowadays, Artificial Intelligence (AI) is described as “the new electricity”. Current algorithmic innovation allowed the development of software which enables machines to learn and to achieve autonomous decision making, with limited or no human involvement, in a vast number of applications, such as speech recognition, machine translation and algorithmic creation of works (computer generated art), on the basis of a process widely known as Machine Learning (ML). Within the ML context, machines are repeatedly trained by means of specifically designed learning algorithms that use a corpus of examples in the form of data sets as training material. Very often and, especially in the context of algorithmic creativity, the training material is mainly composed by copyrighted works, such as texts, images, paintings, musical compositions, and others. Machine Learning workflow typically involves the realization of (multiple) reproductions of any protected work used as training material. The present paper aims to assess the extent to which the use of copyrighted works for Machine Learning purposes in the field of algorithmic creativity is controlled by the monopolistic power of the copyright rightholder on that work. The answer to this question will be researched in the context of EU copyright law, by examining the content of reproduction right and exceptions possibly applicable in a typical ML workflow in the field of algorithmic art, before making an overall assessment of the current EU regulatory framework for artistic ML projects, as it is shaped after the DSM Directive 2019/790.\n",
            "----------------------------------------\n",
            "Title: Wind turbine drivetrains condition monitoring through SCADA data on farm level\n",
            "Abstract: The offshore wind industry has grown rapidly over the last decade and drivetrains are increasing in size to reduce the cost of energy. These turbines are operating in a harsh environment. Adopting a preventive maintenance strategy is important to achieve an as high as possible availability of the farm and reduce the cost of maintenance. A well performing condition monitoring system that utilizes SCADA data from the wind farm can enable this strategy without the need in additional cost in hardware. This master thesis focusses on the development of a framework that can be utilized for this task. This framework can process raw operational SCADA data collected at the Egmond aan Zee offshore wind farm to create a clean dataset to train supervised machine learning models on. This work provides an insight in the correlation between different SCADA signals using a mathematical approach and from a understanding of the system integration of drivetrain components. Bearing temperatures are modelled using a data driven approach to describe the temperatures under healthy conditions. Several models are evaluated for this task and it was concluded that a decision tree supervised machine learning regression model resulted in the lowest error between predicted and measured values. Anomalies are detected and tracked with a normal behaviour model and a Sherward and CUSUM control chart that are applied on the residual error between modelled and measured temperature signals. 4 anomalies could be identified in the gearbox bearings using the developed framework. Abnormal behaviour of the drivetrain could be identified as early as 1 month before the turbine was taken out of productions. This highlights that temperature based condition monitoring that utilizes SCADA data can be used for early detection of faults by combining the accuracy of supervised machine learning methods with different fault detection methods like the CUSUM control chart. This work also investigates the relation between experienced wake of a wind turbine and the influence on the drivetrain component temperatures. The wake conditions at Egmond aan Zee, modelled with an Ishahara wake model, and the component temperature measurements from the SCADA data are used for this analysis. The bearing temperature distributions under different operational and wake conditions can be compared by clustering over the wind speed and the velocity deficit or turbulence intensity at turbine level. It is concluded from this work that wake effects do not result in a change in drivetrain component temperatures. The effects of asymmetric wake conditions opposed to wake experienced over the entire rotor is analysed by comparing the temperature distributions under these conditions in a cluster where the turbine is partially waked. A small shift towards higher component temperatures can observed on a limited amount of data for turbines under asymmetric loading conditions.\n",
            "----------------------------------------\n",
            "Title: Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles\n",
            "Abstract: Ensemble deep learning has been shown to achieve high predictive accuracy and uncertainty estimation in a wide variety of medical imaging contexts. However, perturbations in the input images at test time (e.g. noise, domain shifts) can still lead to significant performance degradation, posing challenges for trustworthy clinical deployment. In order to address this, we propose LaDiNE, a novel and robust probabilistic method that is capable of inferring informative and invariant latent variables from the input images. These latent variables are then used to recover the robust predictive distribution without relying on a predefined functional-form. This results in improved (i) generalization capabilities and (ii) calibration of prediction confidence. Extensive experiments were performed on the task of disease classification based on the Tuberculosis chest X-ray and the ISIC Melanoma skin cancer datasets. Here the performance of LaDiNE was analysed under a range of challenging covariate shift conditions, where training was based on\"clean\"images, and unseen noisy inputs and adversarial perturbations were presented at test time. Results show that LaDiNE outperforms existing state-of-the-art baseline methods in terms of accuracy and confidence calibration. This increases the feasibility of deploying reliable medical machine learning models in real clinical settings, where accurate and trustworthy predictions are crucial for patient care and clinical decision support.\n",
            "----------------------------------------\n",
            "Title: Using Machine Learning to Determine Morphologies of z < 1 AGN Host Galaxies in the Hyper Suprime-Cam Wide Survey\n",
            "Abstract: We present a machine-learning framework to accurately characterize the morphologies of active galactic nucleus (AGN) host galaxies within z < 1. We first use PSFGAN to decouple host galaxy light from the central point source, then we invoke the Galaxy Morphology Network (GaMorNet) to estimate whether the host galaxy is disk-dominated, bulge-dominated, or indeterminate. Using optical images from five bands of the HSC Wide Survey, we build models independently in three redshift bins: low (0 < z < 0.25), mid (0.25 < z < 0.5), and high (0.5 < z < 1.0). By first training on a large number of simulated galaxies, then fine-tuning using far fewer classified real galaxies, our framework predicts the actual morphology for ∼60%–70% of the host galaxies from test sets, with a classification precision of ∼80%–95%, depending on the redshift bin. Specifically, our models achieve a disk precision of 96%/82%/79% and bulge precision of 90%/90%/80% (for the three redshift bins) at thresholds corresponding to indeterminate fractions of 30%/43%/42%. The classification precision of our models has a noticeable dependency on host galaxy radius and magnitude. No strong dependency is observed on contrast ratio. Comparing classifications of real AGNs, our models agree well with traditional 2D fitting with GALFIT. The PSFGAN+GaMorNet framework does not depend on the choice of fitting functions or galaxy-related input parameters, runs orders of magnitude faster than GALFIT, and is easily generalizable via transfer learning, making it an ideal tool for studying AGN host galaxy morphology in forthcoming large imaging surveys.\n",
            "----------------------------------------\n",
            "Title: Projecting the Thermal Response in a HTGR-Type System during Conduction Cooldown Using Graph-Laplacian Based Machine Learning\n",
            "Abstract: Accurate prediction of an off-normal event in a nuclear reactor is dependent upon the availability of sensory data, reactor core physical condition, and understanding of the underlying phenomenon. This work presents a method to project the data from some discrete sensory locations to the overall reactor domain during conduction cooldown scenarios similar to High Temperature Gas-cooled Reactors (HTGRs). The existing models for conductive cooldown in a heterogeneous multi-body system, such as an assembly of prismatic blocks or pebble beds relies on knowledge of the thermal contact conductance, requiring significant knowledge of local thermal contacts and heat transport possibilities across those contacts. With a priori knowledge of bulk geometry features and some discrete sensors, a machine learning approach was devised. The presented work uses an experimental facility to mimic conduction cooldown with an assembly of 68 cylindrical rods initially heated to 1200 K. High-fidelity temperature data were collected using an infrared (IR) camera to provide training data to the model and validate the predicted temperature data. The machine learning approach used here first converts the macroscopic bulk geometry information into Graph-Laplacian, and then uses the eigenvectors of the Graph-Laplacian to develop Kernel functions. Support vector regression (SVR) was implemented on the obtained Kernels and used to predict the thermal response in a packed rod assembly during a conduction cooldown experiment. The usage of SVR modeling differs from most models today because of its representation of thermal coupling between rods in the core. When trained with thermographic data, the average normalized error is less than 2% over 400 s, during which temperatures of the assembly have dropped by more than 500 K. The rod temperature prediction performance was significantly better for rods in the interior of the assembly compared to those near the exterior, likely due to the model simplification of the surroundings.\n",
            "----------------------------------------\n",
            "Title: Sensitivity study using machine learning algorithms on simulated r-mode gravitational wave signals from newborn neutron stars\n",
            "Abstract: This is a follow-up sensitivity study on $r$-mode gravitational wave signals from newborn neutron stars illustrating the applicability of machine learning algorithms for the detection of long-lived gravitational wave transients. In this sensitivity study, we examine three machine learning algorithms (MLAs): artificial neural networks, support vector machines, and constrained subspace classifiers. The objective of this study is to compare the detection efficiencies that MLAs can achieve to the efficiency of the conventional (seedless clustering) detection algorithm discussed in an earlier paper. Comparisons are made using two distinct $r$-mode waveforms. For the training of the MLAs, we assumed that some information about the distance to the source is given so that the training was performed over distance ranges not wider than half an order of magnitude. The results of this study suggest that we can use the machine learning algorithms as part of an investigative stage in the pipeline that would be able to provide very fast and solid triggers for further, and more intense, investigation.\n",
            "----------------------------------------\n",
            "Title: Prediction of Blood Glucose Concentration Based on CEEMD and Improved Particle Swarm Optimization LSSVM.\n",
            "Abstract: Aiming at the difficulty of accurate prediction due to the randomness and nonstationary nature of blood glucose concentration series, a blood glucose concentration prediction model based on complementary ensemble empirical mode decomposition (CEEMD) and least squares support vector machine (LSSVM) is proposed. Firstly, CEEMD is used to convert the blood glucose concentration sequence into a series of intrinsic mode functions (IMFs) to reduce the impact of randomness and nonstationary signals on prediction performance. Then, a LSSVM prediction model is established for each mode IMF. The comprehensive learning particle swarm optimization (CLPSO) algorithm is used to optimize the kernel parameters of LSSVM. Finally, the prediction results of all IMFs are superimposed to yield the final blood glucose concentration prediction value. The experimental results show that the proposed prediction model has higher prediction accuracy in short-term blood glucose concentration values.\n",
            "----------------------------------------\n",
            "Title: Modality Influence in Multimodal Machine Learning\n",
            "Abstract: Multimodal Machine Learning has emerged as a prominent research direction across various applications such as Sentiment Analysis, Emotion Recognition, Machine Translation, Hate Speech Recognition, and Movie Genre Classification. This approach has shown promising results by utilizing modern deep learning architectures. Despite the achievements made, challenges remain in data representation, alignment techniques, reasoning, generation, and quantification within multimodal learning. Additionally, assumptions about the dominant role of textual modality in decision-making have been made. However, limited investigations have been conducted on the influence of different modalities in Multimodal Machine Learning systems. This paper aims to address this gap by studying the impact of each modality on multimodal learning tasks. The research focuses on verifying presumptions and gaining insights into the usage of different modalities. The main contribution of this work is the proposal of a methodology to determine the effect of each modality on several Multimodal Machine Learning models and datasets from various tasks. Specifically, the study examines Multimodal Sentiment Analysis, Multimodal Emotion Recognition, Multimodal Hate Speech Recognition, and Multimodal Disease Detection. The study objectives include training SOTA MultiModal Machine Learning models with masked modalities to evaluate their impact on performance. Furthermore, the research aims to identify the most influential modality or set of modalities for each task and draw conclusions for diverse multimodal classification tasks. By undertaking these investigations, this research contributes to a better understanding of the role of individual modalities in multi-modal learning and provides valuable insights for future advancements in this field.\n",
            "----------------------------------------\n",
            "Title: SAFFIRRE: Selective Aggregate Filtering Through Filter Rule Refinement\n",
            "Abstract: Volumetric Distributed Denial of Service attacks send unsolicited high-volume traffic to overwhelm network infrastructures and disrupt service availability. To counteract such attacks, we introduce Selective Aggregate Filtering through Filter Rule Refinement. This novel approach monitors traffic aggregates over the IP address hierarchy with hierarchical heavy hitter algorithms. Based on this, it builds effective droplists for upstream filtering to protect network infrastructures. By estimating attack traffic volumes in traffic aggregates with machine learning, filter rule refinement compensates several drawbacks of hierarchical heavy hitters to achieve low false positive and false negative rates. Furthermore, it enables adaptation to dynamic traffic by tracking filter rule precision over time. We evaluate mitigation effectiveness in dynamic situations with challenging mixed legitimate and attack traffic distributions.\n",
            "----------------------------------------\n",
            "Title: Benchmarking Invasive Alien Species Image Recognition Models for a Citizen Science Based Spatial Distribution Monitoring\n",
            "Abstract: Abstract. Recent developments in image recognition technology including artificial intelligence and machine learning led to an intensified research in computer vision models. This progress also allows advances for the collection of spatio-temporal data on Invasive Alien Species (IAS), in order to understand their geographical distribution and impact on the biodiversity loss. Citizen Science (CS) approaches already show successful solutions how the public can be involved in collecting spatio-temporal data on IAS, e.g. by using mobile applications for monitoring. Our work analyzes recently developed image-based species recognition models suitable for the monitoring of IAS in CS applications. We demonstrate how computer vision models can be benchmarked for such a use case and how their accuracy can be evaluated by testing them with IAS of European Union concern. We found out that available models have different strengths. Depending on which criteria (e.g. high species coverage, costs, maintenance, high accuracies) are considered as most important, it needs to be decided individually which model fits best. Using only one model alone may not necessarily be the best solution, thus combining multiple models or developing a new custom model can be desirable. Generally, cooperation with the model providers can be advantageous.\n",
            "\n",
            "----------------------------------------\n",
            "Title: Real‐time recognition of power quality disturbance‐based deep belief network using embedded parallel computing platform\n",
            "Abstract: This paper proposes a novel integrated solution for real‐time power quality (PQ) disturbance analysis. Traditionally, the recognitions are based on the feature extraction and are implemented offline or on the advanced reduced instruction set computer machine/digital signal processor platforms. In this paper, the optimized deep belief network (DBN) analyzes the PQ signals by learning knowledge from raw data of signals directly, which maximizes the features of original signals, and runs on an embedded parallel computing platform (EPCP). In simulation studies, eight types of common PQ disturbances are divided into 17 classes of data frame models according to the PQ disturbances that may occur during a fixed period of time. These samples of data frame models are utilized to train and optimize the DBNs on a central server. Compared with the existing classifiers, the simulation results demonstrate that the proposed approach has higher accuracy and stronger robustness. Then, the optimized DBN is sent to EPCP, and the previous DBN model is updated. The EPCPs are used to recognize the signals of PQ disturbances from a real time digital system (RTDS). The proposed integrated solution has excellent performance regarding accuracy but is time consuming. © 2020 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc.\n",
            "----------------------------------------\n",
            "Title: MindMiner: A Mixed-Initiative Interface for Interactive Distance Metric Learning\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Using Kernel Perceptrons to Learn Action Effects for Planning\n",
            "Abstract: We investigate the problem of learning action effects in STRIPS and ADL planning domains. Our approach is based on a kernel perceptron learning model, where action and state information is encoded in a compact vector representation as input to the learning mechanism, and resulting state changes are produced as output. Empirical results of our approach indicate efficient training and prediction times, with low average error rates (< 3%) when tested on STRIPS and ADL versions of an object manipulation scenario. This work is part of a project to integrate machine learning techniques with a planning system, as part of a larger cognitive architecture linking a high- level reasoning component with a low-level robot/vision system.\n",
            "----------------------------------------\n",
            "Title: ASSIMILATION OF PASSIVE MICROWAVE BRIGHTNESS TEMPERATURES FOR SNOW WATER EQUIVALENT ESTIMATION USING THE NASA CATCHMENT LAND SURFACE MODEL AND MACHINE LEARNING ALGORITHMS IN NORTH AMERICA\n",
            "Abstract: Title of dissertation: ASSIMILATION OF PASSIVE MICROWAVE BRIGHTNESS TEMPERATURES FOR SNOW WATER EQUIVALENT ESTIMATION USING THE NASA CATCHMENT LAND SURFACE MODEL AND MACHINE LEARNING ALGORITHMS IN NORTH AMERICA Yuan Xue, Doctor of Philosophy, 2017 Dissertation directed by: Assistant Professor Barton A. Forman Department of Civil and Environmental Engineering Snow is a critical component in the global energy and hydrologic cycle. It is important to know the mass of snow because it serves as the dominant source of drinking water for more than one billion people worldwide. To accurately estimate the depth of snow and mass of water within a snow pack across regional or continental scales is a challenge, especially in the presence of dense vegetations since direct quantification of SWE is complicated by spatial and temporal variability. To overcome some of the limitations encountered by traditional SWE retrieval algorithms or radiative transfer-based snow emission models, this study explores the use of a welltrained support vector machine to merge an advanced land surface model within a variant of radiance emission (i.e., brightness temperature) assimilation experiments. In general, modest improvements in snow depth, and SWE predictability were witnessed as a result of the assimilation procedure over snow-covered terrain in North America when compared against available snow products as well as ground-based observations. These preliminary findings are encouraging and suggest the potential for global-scale snow estimation via the proposed assimilation procedure.\n",
            "----------------------------------------\n",
            "Title: The Discovery and Interpretation of Evidence Accumulation Stages\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: A deep learning based solution for imperfect CSI problem in correlated FSO communication channel.\n",
            "Abstract: Imperfect channel state information (CSI) at the receiver, which is due to channel estimation error, is one of the main problems toward achieving optimum detection. This paper presents a deep learning based structure for combating this issue. In order to show the effect of using deep learning, the symbol error rate of a simple free space optical (FSO) communication system is simulated over correlated and un-correlated log-normal channel with write/ wrong CSI. Novelties and contributions of this paper, which are done for the first in machine learning for FSO communication include considering deep learning, considering Log-normal channel, considering correlated channel, considering imperfect CSI. The proposed deep learning based structure is compared with maximum likelihood detector, it is shown that in perfect CSI, both perform the same (because maximum likelihood is optimum), but in imperfect CSI, proposed deep learning based structure outperforms maximum likelihood in channels with un-correlation or desired correlation lengths.\n",
            "----------------------------------------\n",
            "Title: Accurate Solubility Prediction with Error Bars for Electrolytes: A Machine Learning Approach\n",
            "Abstract: Accurate in silico models for predicting aqueous solubility are needed in drug design and discovery and many other areas of chemical research. We present a statistical modeling of aqueous solubility based on measured data, using a Gaussian Process nonlinear regression model (GPsol). We compare our results with those of 14 scientific studies and 6 commercial tools. This shows that the developed model achieves much higher accuracy than available commercial tools for the prediction of solubility of electrolytes. On top of the high accuracy, the proposed machine learning model also provides error bars for each individual prediction.\n",
            "----------------------------------------\n",
            "Title: Prediction-Driven Knowledge Discovery from Data and Prior Knowledge\n",
            "Abstract: This paper presents a novel approach to knowledge discovery. As opposed to the vast majority of existing approaches that use statistical machine learning to discover knowledge from data, we synergistically integrate ideas from artificial intelligence, machine learning, science of evidence, logic and probabilities to use both existing incomplete domain knowledge and imperfect data to discover new knowledge. We illustrate this approach in the precision agriculture domain considering the practices associated with cover crops, and learning how abiotic and biotic factors and cover crops management practices (planting and termination dates and methods) influence cereal cover crop biomass accumulation across corn-growing, soybean-growing, and cotton-growing regions of the U.S.\n",
            "----------------------------------------\n",
            "Title: The Role of Declarative Querying in Bioinformatics\n",
            "Abstract: THE RECENT PUBLICATION of a draft of the entire human genome (McPherson et al., 2001; Venter et al., 2001) has served to fuel an already explosive area of research in bioinformatics that is involved in deriving meaningful knowledge from proteins and DNA sequences (Alberts et al., 2002). Even with the full human genome sequence now in hand, scientists still face the challenges of determining exact gene locations and functions, observing interactions between proteins in complex molecular machines, and learning the structure and function of proteins, just to name a few. The progress of this scientific research is closely connected to the research in the database community in that analyzing large volumes of biological data sets involves being able to maintain and query large databases (Moussouni et al., 1999; Davidson, 2002). Database management systems (DBMSs) could help support life sciences applications, in a number of different ways. A partial list of tasks that such applications require is: querying large structured databases (such as sequence and graph databases), querying semi-structured (such as published manuscripts), managing data replication, querying distributed data sources, and managing parallelism in high-throughput bioinformatics. Unfortunately, current DBMSs have largely ignored supporting life sciences applications, and consequently, the life sciences researches have been forced to write tools and scripts to perform these tasks. An interesting parallel can be drawn between the state of data management tools in life sciences, and the state of data management tools for business applications, such as a banking application, about three decades ago. Prior to the advent of the relational data model, business data was managed and queried using customized programs/scripts that were developed for each application. Reusing programs, and the algorithms for querying the data, involved rewriting application program and logic, which was very time consuming and expensive. In addition, the querying programs were closely tied to the format that was used to represent the data. Any change in the format of the data representation often would break the querying programs. Furthermore, writing complex queries, such as querying over multiple data sets or posing complex analytical queries, was a daunting task. One of the critical contributions of the relational data model (Codd, 1970) was the introduction of a declarative querying paradigm for business data management, instead of the previously used procedural paradigm. In a declarative querying paradigm, the user expresses the query in a high-level language, like SQL, and the DBMS determines the best strategy for evaluating the query. In addition, the DBMS only presents to the user a logical view of the data against which queries are posed. The physical representation of the data, either on disk or in-memory, can be very different from the logical view. For example, in a relational database management system (RDBMS), indices may be created, and the user doesn’t have to query against the index. The user still queries against logical relations, and the system automatically determines if it is faster to use the indices to answer a query. The user is thus insulated from worrying about various details such as physical organization of data on disk, the exact location of the data, tuning the representation for better performance, and choosing the best plan for evaluating a query. This declarative querying paradigm has been a huge success for relational DBMSs, and today commercial RDBMSs manage terabytes of data, and allow very complex querying on these databases. Database management systems can provide similar benefits to the life sciences community, just as it did three decades ago to the business data management community. Many of the data sets that are used in life sciences are growing at an astonishing rate (such as sequence data at NCBI’s GenBank (NCBI, 2002)), and the queries\n",
            "----------------------------------------\n",
            "Title: Mechanisms and pathology of protein misfolding and aggregation\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: The Intersection of Machine Learning, Zakat, and Transportation for a Healthy Society\n",
            "Abstract: . The recent Covid-19 pandemic has shown that transportation has a significant role in creating a healthy society. Human mobility can be tracked and traced to map the spread of infectious diseases using screening, tracing, and tracking methods through policies and applications. This momentum has accelerated the massive application of technology, one of which is using Machine Learning. Zakat also has an essential role during the pandemic quarantine policy. The potential of the combination of Machine Learning, Zakat, and transportation should now be increased to improve the Quality of Life to achieve a healthy society. The intersection of these three topics was researched using data scraping from the web dimension as one of the platforms that accommodates a collection of research publications. Data is limited to abstracts of research results within the last five years. Next, the data obtained was preprocessed, text-processed, and analyzed using the FP-Growth Algorithm for Association Rule. Research published so far shows that there is an intersection between Machine Learning, Zakat, and Transportation to achieve a healthy society, even with varying intersection probability values. Machine learning and transportation have the most potent intersection with health, while zakat is still lower. The results of this research can open up collaborative research topics between these domains. The results of this research can also be used as suggestions for policy-making by stakeholders to explore the existing potentials of various journals that have been published.\n",
            "----------------------------------------\n",
            "Title: ROTEX: space telerobotic flight experiment\n",
            "Abstract: In early 1993 the space robot technology experiment ROTEX flew with the space-shuttle Columbia (spacelab mission D2 on flight STS-55 from April 26 to May 6). A multisensory robot on board the space-craft successfully worked in autonomous modes, teleoperated by astronauts, as well as in different telerobotic ground control modes. These include on-line teleoperation and tele-sensor-programming, a task-level oriented programming technique involving `learning by showing' concepts in a virtual environment. The robot's key features were its multisensory gripper and the local sensory feedback schemes which are the basis for shared autonomy. The corresponding man-machine interface concepts using a 6 dof non-force- reflecting control ball and visual feedback to the human operator are explained. Stereographic simulation on ground was used to predict not only the robot's free motion but even the sensor based path refinement on board; prototype tasks performed by this space robot were the assembly of a truss structure, connecting/disconnecting an electric plug (orbit replaceable unit exchange ORU), and grasping free-floating objects.\n",
            "----------------------------------------\n",
            "Title: Surface water detection and delineation using remote sensing images: a review of methods and algorithms\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Review: Synergy between mechanistic modelling and data-driven models for modern animal production systems in the era of big data.\n",
            "Abstract: Mechanistic models (MMs) have served as causal pathway analysis and 'decision-support' tools within animal production systems for decades. Such models quantitatively define how a biological system works based on causal relationships and use that cumulative biological knowledge to generate predictions and recommendations (in practice) and generate/evaluate hypotheses (in research). Their limitations revolve around obtaining sufficiently accurate inputs, user training and accuracy/precision of predictions on-farm. The new wave in digitalization technologies may negate some of these challenges. New data-driven (DD) modelling methods such as machine learning (ML) and deep learning (DL) examine patterns in data to produce accurate predictions (forecasting, classification of animals, etc.). The deluge of sensor data and new self-learning modelling techniques may address some of the limitations of traditional MM approaches - access to input data (e.g. sensors) and on-farm calibration. However, most of these new methods lack transparency in the reasoning behind predictions, in contrast to MM that have historically been used to translate knowledge into wisdom. The objective of this paper is to propose means to hybridize these two seemingly divergent methodologies to advance the models we use in animal production systems and support movement towards truly knowledge-based precision agriculture. In order to identify potential niches for models in animal production of the future, a cross-species (dairy, swine and poultry) examination of the current state of the art in MM and new DD methodologies (ML, DL analytics) is undertaken. We hypothesize that there are several ways via which synergy may be achieved to advance both our predictive capabilities and system understanding, being: (1) building and utilizing data streams (e.g. intake, rumination behaviour, rumen sensors, activity sensors, environmental sensors, cameras and near IR) to apply MM in real-time and/or with new resolution and capabilities; (2) hybridization of MM and DD approaches where, for example, a ML framework is augmented by MM-generated parameters or predicted outcomes and (3) hybridization of the MM and DD approaches, where biological bounds are placed on parameters within a MM framework, and the DD system parameterizes the MM for individual animals, farms or other such clusters of data. As animal systems modellers, we should expand our toolbox to explore new DD approaches and big data to find opportunities to increase understanding of biological systems, find new patterns in data and move the field towards intelligent, knowledge-based precision agriculture systems.\n",
            "----------------------------------------\n",
            "Title: Preventing Watermark Forging Attacks in a MLaaS Environment\n",
            "Abstract: With the development of machine learning models for task automation, watermarking appears to be a suitable solution to protect one’s own intellectual property. Indeed, by embedding secret specific markers into the model, the model owner is able to analyze the behavior of any model on these markers, called trigger instances and hence claim its ownership if this is the case. However, in the context of a Machine Learning as a Service (MLaaS) platform where models are available for inference, an attacker could forge such proofs in order to steal the ownership of these watermarked models in order to make a profit out of it. This type of attacks, called watermark forging attacks, is a serious threat against the intellectual property of models owners. Current work provides limited solutions to this problem: They constrain model owners to disclose either their models or their trigger set to a third party. In this paper, we propose counter-measures against watermark forging attacks, in a black-box environment and compatible with privacy-preserving machine learning where both the model weights and the inputs could be kept private. We show that our solution successfully prevents two different types of watermark forging attacks with minimalist assumptions regarding either the access to the model’s weight or the content of the trigger set.\n",
            "----------------------------------------\n",
            "Title: Multimedia Technology Supporting Manufacturing Education\n",
            "Abstract: Accredited programs in manufacturing engineering technology stress hands on applications and problem solving using the computer as a tool. The computers found in technology laboratories come in many different forms directed at solving a particular problem, developing and documenting a product design, controlling a process or machine, or even helping to manage the business side of the operation. Students learn to program and operate many different computer based applications. The computer is rarely used in manufacturing classes as a teaching tool or as an aid to the instructor, other than in the basic applications of word processing and spreadsheet programs. The powerful computers in manufacturing labs are not often used to improve the teaching or learning activities of manufacturing technology classes.\n",
            "----------------------------------------\n",
            "Title: An Intelligent Approach for Prediction of Liver Disease using Machine Learning Models\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Machine-learning methods for inferring vocal-tract articulation from speech acoustics\n",
            "Abstract: This research explores an inverse mapping from speech acoustics to vocal-tract articulatory trajectories. Such a mapping has the potential to improve speech recognition, speaker verification, low-bit-rate speech coding, and teaching speech production to the hearing impaired. Previous attempts to construct a vocal-tract inverse mapping have been limited by the use of primarily vowel data, a lack of real articulatory data for validation, and the use of homoscedastic (unimodal with constant variance) least-mean-squared regression techniques. Instead, this project considers continuous speech, real articulatory data from five subjects, and multimodal regression models designed to capture the nonuniqueness of the instantaneous inverse that causes homoscedastic regressions to fail. We introduce Maximum-Likelihood Articulator Trajectories (MALAT) in a theoretical speech recognition framework. After discretely partitioning the speech acoustic data, the articulatory data corresponding to each acoustic centroid are modeled using some probability density function (pdf). The MALAT algorithm takes a time series of these pdfs and, using a physiologically based smoothness constraint, estimates those articulatory trajectories that maximize the likelihood of the observed acoustic data. The model is trained using one set of data, and performance is measured on an independent test set using root-mean-squared error (rmse) and the correlation between inferred and actual trajectories. MALAT with multimodal pdfs produces correlations averaged over articulators of 0.90-0.92 and rmses of 1.3-1.5 mm compared to correlations of only 0.79-0.84 and rmses of 1.7-1.9 mm using unimodal pdfs. We then use Maximum-Likelihood Continuity Mapping (MALCOM), an unsupervised method previously demonstrated by Hogden (1995) to accurately infer articulatory information for vowels, and obtain correlations only 0.05-0.21 lower than using MALAT. To find paths that maximize both the likelihood of the phoneme sequence as well as of the acoustics, we extend MALCOM to the Two-Observable case (TO-MALCOM) to incorporate phonetic labels into training. TO-MALCOM and MALCOM perform comparably at capturing articulatory information, but TO-MALCOM produces paths with greater phoneme discriminability. Because it does not require measured articulatory data--only acoustics--TO-MALCOM has the potential to be applied to speech processing tasks as an articulation-based alternative to hidden Markov models.\n",
            "----------------------------------------\n",
            "Title: Identification of high likelihood of dementia in population-based surveys using unsupervised clustering: a longitudinal analysis\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Modelo de agrupamiento de precios en el autoservicio\n",
            "Abstract: . Nowadays, the retail in Mexico presents a great dynamism since most of the retailers try to o(cid:27)er the best prices to their clients in order to increase their sales volume, which leads to lost large amounts in pro(cid:28)t margin in order to achieve this target. For this reason, we decided to apply the following machine learning models that allow us to create groups of items according to their mean range price and similar patterns with the di(cid:27)erence between their price and the competitor’s price, this will let us develop unique strategies for each group of products, increasing the pro(cid:28)t of their investments by applying speci(cid:28)c price reductions to each group. The models used in this article are Hierarchical Grouping\n",
            "----------------------------------------\n",
            "Title: Predicting Industry Sectors from Financial Statements: An Illustration of Machine Learning in Accounting Research\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Handling CHD Classifier Based on Machine Learning and Fuzzy Logic Techniques\n",
            "Abstract: Developing a high performance classifier requires understanding the complex relationships hidden within statistical information. Machine learning algorithms and rule based fuzzy logic approaches can help handle classification problems due to their efficient learning capabilities. Several approaches have been defined in both categories to classify discrete class labels. Selection of appropriate techniques and algorithms can help in developing high performance classifiers. In this paper, coronary heart disease (CHD) is taken as the classification problem whose objective is to find out whether an individual is suffering from CHD or not. To handle the CHD problem, four machine learning based classifiers and two fuzzy logic based classifiers have been developed. Accuracy, precision, recall and Fl-score evaluation metrics have been used to evaluate the performance of the developed classifier. The results obtained from the developed classifiers showed that Support Vector Machine and Wang-Mendel based classifiers perform with 92.32% and 98.48% accuracy in their respective category.\n",
            "----------------------------------------\n",
            "Title: scTenifoldKnk: a machine learning workflow performing virtual knockout experiments on single-cell gene regulatory networks\n",
            "Abstract: Gene knockout (KO) experiments are a proven approach for studying gene function. A typical KO experiment usually involves the phenotypic characterization of KO organisms. The recent advent of single-cell technology has greatly boosted the resolution of cellular phenotyping, providing unprecedented insights into cell-type-specific gene function. However, the use of single-cell technology in large-scale, systematic KO experiments is prohibitive due to the vast resources required. Here we present scTenifoldKnk—a machine learning workflow that performs virtual KO experiments using single-cell RNA sequencing (scRNA-seq) data. scTenifoldKnk first uses data from wild-type (WT) samples to construct a single-cell gene regulatory network (scGRN). Then, a gene is knocked out from the constructed scGRN by setting weights of the gene’s outward edges to zeros. ScTenifoldKnk then compares this “pseudo-KO” scGRN with the original scGRN to identify differentially regulated (DR) genes. These DR genes, also called virtual-KO perturbed genes, are used to assess the impact of the gene KO and reveal the gene’s function in analyzed cells. Using existing data sets, we demonstrate that the scTenifoldKnk analysis recapitulates the main findings of three real-animal KO experiments and confirms the functions of genes underlying three Mendelian diseases. We show the power of scTenifoldKnk as a predictive method to successfully predict the outcomes of two KO experiments that involve intestinal enterocytes in Ahr-/mice and pancreatic islet cells in Malat1-/mice, respectively. Finally, we demonstrate the use of scTenifoldKnk to perform systematic KO analyses, in which a large number of genes are virtually deleted, allowing gene functions to be revealed in a cell type-specific manner.\n",
            "----------------------------------------\n",
            "Title: Radiology Decision Support System for Selecting Appropriate CT Imaging Titles Using Machine Learning Techniques Based on Electronic Medical Records\n",
            "Abstract: Radiologists use an imaging order from the ordering physician, which includes a radiology title, to select the most suitable imaging protocol. Inappropriate radiology titles can disrupt protocol selection and result in mistaken or delayed diagnosis. The objective of this work is to develop an algorithm to predict correct radiology titles from incoming exam order data. The proposed instrument is an ensemble of five decision tree-based machine learning (ML) techniques (Light Gradient Boosting Machine, eXtreme Gradient Boosting Machine, Random Forest, Adaptive Boosting, and Random UnderSampling Boosting Model) trained to recommend radiology titles of computed tomography imaging examinations based on electronic medical records. Issues of imbalanced data and generalization were addressed. The tuned models were used to predict the top three radiology titles for the radiologist revision. The models were evaluated using a 10-fold cross-validation method, yielding an approximate average accuracy of $80.5\\% \\pm 2.02\\%$ and F1-score of $80.3\\% \\pm 1.67\\%$ for all models, while the ensemble classifier (~83% F1-score) outperformed individual models. An accumulated average accuracy of ~92% was obtained for the top three predictions. ML techniques can predict radiology titles and identify highly important features. The proposed system can guide physicians toward selecting appropriate radiology titles and alert radiologists to inconsistencies between the radiology title in the exam order and the patient’s underlying conditions, thereby improving imaging utility and increasing diagnostic accuracy, which favors better patient outcomes.\n",
            "----------------------------------------\n",
            "Title: Association of Machine Learning–Based Predictions of Medial Knee Contact Force With Cartilage Loss Over 2.5 Years in Knee Osteoarthritis\n",
            "Abstract: The relationship between in vivo knee load predictions and longitudinal cartilage changes has not been investigated. We undertook this study to develop an equation to predict the medial tibiofemoral contact force (MCF) peak during walking in persons with instrumented knee implants, and to apply this equation to determine the relationship between the predicted MCF peak and cartilage loss in patients with knee osteoarthritis (OA).\n",
            "----------------------------------------\n",
            "Title: How does image quality affect computer-aided diagnosis of colorectal polyps?\n",
            "Abstract: Colorectal cancer (CRC) is one of the leading causes of cancer-related deaths with rising incidence. Since the survival rate of CRC is correlated with the cancer stage at diagnosis, timely detection and adequate treatment strategies are of utmost importance. Technical innovations such as machine learning (ML) and its application in endoscopy show promising results, but the trust of medical doctors in ML is lacking and the ‘black box’ nature complicates the understanding of such systems in clinical practice. In contrast to CT and MRI, image quality is a limiting factor in especially endoscopic imaging, as it is very operator dependent. However, the influence of image quality on convolutional (deep) neural networks (CNNs) is insufficiently studied in relation to clinical practice and the usage of medical image data for computer-aided detection and diagnosis (CADx) systems. This paper explores the influence of degraded image quality on the performance of CNNs applied to colorectal polyp (CRP) characterization. Five commonly used CNN architectures, from simple to more complex, are employed with a custom classification head for common CRP characterization. To degrade the quality of images, distortions such as noise, blur, and contrast changes are imposed on the data and their influence on the performance degradation is studied for the mentioned CNN architectures. A large prospectively collected in vivo data set, gathered from four Dutch, both academic and community, hospitals is employed. Results for CRP characterization show that promising CNN-based methods are rather susceptible to noise and blur distortions but reasonably resilient to changes in contrast. This implies that image quality needs monitoring and control prior to directly using image data in CNN models, in order to gain trustworthy use of deep learning (DL) models in a clinical setting. We propose that incorporating an image quality indicator in CADx systems will lead to better acceptance of such systems, and is necessary for the safe implementation of DL applications in clinical practice.\n",
            "----------------------------------------\n",
            "Title: Estimating Value of Customer through Store Check-in Histories and its Application for Visitor Promotion\n",
            "Abstract: : This paper proposes a method to estimate value of customers based on store check-in histories. The proposed method enables to distinguish possible loyal customers whose purchase histories are not available. Machine learning process is employed for model acquisition. The outcomes of estimation are able to improve eﬃciency of visitor promotions and new customer acquisition events. The result of actual visitor promotion trial conﬁrms eﬀectiveness of the proposed method.\n",
            "----------------------------------------\n",
            "Title: Machine-learning enabled construction of temperature-strain phase diagrams of ferroelectric thin films\n",
            "Abstract: Ferroelectric thin films have been explored for many applications such as microelectronics or system-on-a-chip prototypes. It is well established that stability of ferroelectric states of thin films are determined by both temperature and strain between the film and its underlying substrate and the chemical composition for solid solution thin films. A complexity associated with ferroelectric thin films constrained by a substrate is that often the multidomain states of multiple ferroelectric domain variants become stable. Using a combination of high-throughput calculations, classification machine-learning algorithms, and phase-field simulations, we systematically investigate the phase diagrams of (Ba_ x , Ca_1- x )TiO_3 (BCTO) solid solution thin films. We examine several machine-learning techniques to understand the differences in their accuracies and capabilities for the construction of phase diagrams of ferroelectric thin films. We demonstrate that a computational scheme consisting of high-throughput calculations, machine-learning, and phase-field simulations, can be employed to obtain accurate phase-stability diagrams of ferroelectric films. Graphical abstract\n",
            "----------------------------------------\n",
            "Title: Can Machine-learning Techniques Be Used for 5-year Survival Prediction of Patients With Chondrosarcoma?\n",
            "Abstract: Background Several studies have identified prognostic factors for patients with chondrosarcoma, but there are few studies investigating the accuracy of computationally intensive methods such as machine learning. Machine learning is a type of artificial intelligence that enables computers to learn from data. Studies using machine learning are potentially appealing, because of its possibility to explore complex patterns in data and to improve its models over time. Questions/purposes The purposes of this study were (1) to develop machine-learning algorithms for the prediction of 5-year survival in patients with chondrosarcoma; and (2) to deploy the best algorithm as an accessible web-based app for clinical use. Methods All patients with a microscopically confirmed diagnosis of conventional or dedifferentiated chondrosarcoma were extracted from the Surveillance, Epidemiology, and End Results (SEER) Registry from 2000 to 2010. SEER covers approximately 30% of the US population and consists of demographic, tumor characteristic, treatment, and outcome data. In total, 1554 patients met the inclusion criteria. Mean age at diagnosis was 52 years (SD 17), ranging from 7 to 102 years; 813 of the 1554 patients were men (55%); and mean tumor size was 8 cm (SD 6), ranging from 0.1 cm to 50 cm. Exact size was missing in 340 of 1544 patients (22%), grade in 88 of 1544 (6%), tumor extension in 41 of 1544 (3%), and race in 16 of 1544 (1%). Data for 1-, 3-, 5-, and 10-year overall survival were available for 1533 (99%), 1512 (98%), 1487 (96%), and 977 (63%) patients, respectively. One-year survival was 92%, 3-year survival was 82%, 5-year survival was 76%, and 10-year survival was 54%. Missing data were imputed using the nonparametric missForest method. Boosted decision tree, support vector machine, Bayes point machine, and neural network models were developed for 5-year survival. These models were chosen as a result of their capability of predicting two outcomes based on prior work on machine-learning models for binary classification. The models were assessed by discrimination, calibration, and overall performance. The c-statistic is a measure of discrimination. It ranges from 0.5 to 1.0 with 1.0 being perfect discrimination and 0.5 that the model is no better than chance at making a prediction. The Brier score measures the squared difference between the predicted probability and the actual outcome. A Brier score of 0 indicates perfect prediction, whereas a Brier score of 1 indicates the poorest prediction. The Brier scores of the models are compared with the null model, which is calculated by assigning each patient a probability equal to the prevalence of the outcome. Results Four models for 5-year survival were developed with c-statistics ranging from 0.846 to 0.868 and Brier scores ranging from 0.117 to 0.135 with a null model Brier score of 0.182. The Bayes point machine was incorporated into a freely available web-based application. This application can be accessed through https://sorg-apps.shinyapps.io/chondrosarcoma/. Conclusions Although caution is warranted, because the prediction model has not been validated yet, healthcare providers could use the online prediction tool in daily practice when survival prediction of patients with chondrosarcoma is desired. Future studies should seek to validate the developed prediction model. Level of Evidence Level III, prognostic study.\n",
            "----------------------------------------\n",
            "Title: BRAIN STROKE PREDICTION USING SUPERVISED MACHINE LEARNING\n",
            "Abstract: : A Stroke is a medical disorder that damages the brain by rupturing blood vessels. It can also happen when the brain's blood flow and other nutrients are interrupted. Stroke is the greatest cause of death and disability worldwide, according to the World Health Organization (WHO). The majority of research has focused on the prediction of heart stroke, while just a few studies have looked at the likelihood of a brain stroke. With this in mind, various machine learning models are being developed to forecast the likelihood of a brain stroke. This article employed machine learning techniques like K-Nearest and Nave Bayes Classification to model many physiological parameters for accurate prediction and discover the optimum approach\n",
            "----------------------------------------\n",
            "Title: Learning event representation: As sparse as possible, but not sparser\n",
            "Abstract: Selecting an optimal event representation is essential for event classification in real world contexts. In this paper, we investigate the application of qualitative spatial reasoning (QSR) frameworks for classification of human-object interaction in three dimensional space, in comparison with the use of quantitative feature extraction approaches for the same purpose. In particular, we modify QSRLib, a library that allows computation of Qualitative Spatial Relations and Calculi, and employ it for feature extraction, before inputting features into our neural network models. Using an experimental setup involving motion captures of human-object interaction as three dimensional inputs, we observe that the use of qualitative spatial features significantly improves the performance of our machine learning algorithm against our baseline, while quantitative features of similar kinds fail to deliver similar improvement. We also observe that sequential representations of QSR features yield the best classification performance. A result of our learning method is a simple approach to the qualitative representation of 3D activities as compositions of 2D actions that can be visualized and learned using 2-dimensional QSR.\n",
            "----------------------------------------\n",
            "Title: Applications in cognitive neuroscience: electroencephalography-based prediction of treatment response in schizophrenia and the effect of authenticity on emotion perception\n",
            "Abstract: Background Cognitive neuroscience is a field of science that explores the neural basis of cognition. The field is vast and includes studies from a micro-level, such as studies of individual synapses to the organisation-level studies that are interested in how specific brain regions interact with each other. For such a wide variety of applications, there is a high demand in new methods and techniques to integrate the knowledge from different parts of cognitive neuroscience. Here, we will introduce two different studies that involve different techniques and areas of cognitive neuroscience. The first study (Chapter 2) is a clinical neuroimaging study showcasing how neuroimaging techniques such as electroencephalography (EEG) could be in principle be used to predict the treatment outcomes in a group of patients with refractory schizophrenia. The second study (Chapter 3) is a behavioural investigation of authenticity of facial expressions run on an online platform. We investigated whether emotion authenticity of unseen faces can bias emotion perception of subsequent faces and whether authenticity of seen faces can affect the intensity ratings of those images.MethodsFor the clinical neuroimaging study, the data was collected by a laboratory at UCSD. Forty-five treatment-refractory patients with schizophrenia participated in the study (Hochberger et al., 2019). Two randomised groups of patients were exposed to either computer games, referred to as treatment as usual (TAU), or a novel auditory treatment, called auditory-based targeted cognitive training (TCT). In addition to the treatment, every participant completed two cognitive assessments and three EEG recordings. The goal of our study was to predict the outcome of the TCT treatment in patients with refractory schizophrenia by training a machine learning classifier on EEG data collected after the initial hour of treatment. First of all, we attempted to replicate the UCSD group’s results with a similar single-channel analysis procedure. For the single-channel analysis, we preprocessed data in two ways. The initial preprocessing was done according to standard protocols in our group. In contrast, the second preprocessing was performed in an attempt to replicate the preprocessing steps done by the group at UCSD. In addition to the single-channel analysis, we used whole spatiotemporal data (i.e. all EEG channels at all time points). For the behavioural study, the stimuli were fist validated in a separate experiment to ensure that the stimuli selection was unbiased and to confirm the emotion of each stimulus. Fifty participants (13 females) participated in the Validation task where they were asked to match authentic to posed images of the same actor. The best matching images, according to participants’ responses on the Validation task, were selected for the Subliminal Priming task. For the Subliminal Priming task, 94 people (40 females) aged 18-65 were recruited. There were two types of trial structure. The first type included a fixation cross, forward mask, prime (happy, disgust, or neutral), backward mask, and a neutral target image. The second type did not contain primes and targets were either happy or disgust images. For both types of trials, participants were asked to rate the emotion of seen target images. We examined 1) the effect of emotion and authenticity in primes on perceived emotion intensity in neutral targets and, 2) the effect of emotion and authenticity on perceived emotion intensity in the emotion targets. We also used inverted images to control for different physical features, such as an eye gaze direction.ResultsThe clinical neuroimaging study revealed that predicting cognitive outcome following initial TCT treatment in schizophrenia with EEG from these data was not viable, as the basic analysis from our group and the UCSD group using the same dataset produced strikingly different results. It is likely that these differences were due to slight changes in the eyeblink preprocessing corrections. In addition to the single-channel analysis, the spatiotemporal analysis also did not produce any significant results. Given the influence of the differences in preprocessing strategies on the results, and the limited sample size, we decided not to proceed to with the goal of using machine learning to predict treatment response. In the behavioural study, we found opposing results to previous literature about authenticity in consciously perceived faces, in that authentic emotion faces were rated as less intense than posed emotion faces. For the unconsciously perceived primes, only posed primes had an effect of neutral targets. Contrary to upward primes, inverted subliminal primes showed no effect of emotion on neutral targets. We suggest that the physical properties of primes did not bias emotion intensity ratings on neutral facial expressions. Indeed, we did find significant effects of emotion and authenticity on emotion intensity ratings for the inverted emotion targets. Suggesting that consciously perceived different physical properties in authentic versus posed and also happy versus disgust expressions influence emotion processing.ConclusionThe two studies demonstrate different areas and techniques used in cognitive neuroscience. Both studies also expose some of the important issues in the field. The lack of reproducibility of the results in the first study parallels the recent concern of the scientific community on reproducibility crisis. Our results show that when two labs perform slightly different analyses on the same data, the outcomes might be strikingly different. The second study highlights the importance of authentic emotions in research. We found that people rate the intensity of consciously perceived authentic emotions differently to posed emotions. However, as the same inverted images also had an effect of emotion, future work is needed in order to disentangle whether the effect of authenticity was due to physical features or holistic processing of authentic emotion. The effect of authenticity was not found in subliminal primes. This might suggest that authenticity is processed at the conscious level rather than at the subconscious level as was hypothesised. We also highlight the importance of developing new databases with authentic stimuli as currently, only a few such databases exist.\n",
            "----------------------------------------\n",
            "Title: Ensemble learning in the estimation of flow types and velocities of individual phases in multiphase flow using non-intrusive accelerometers' and process pressure data\n",
            "Abstract: in oil and gas industries. Accurately identifying flow types and estimating flow velocities of the individual phases are crucial for different purposes, such as observing the process status and providing inputs to control systems. This paper presents a solution for identifying flow contents and estimating flow rates in single-phase or each phase in multiphase flows by using pressure measurements and pipe vibrations caused by the flows. The necessary experiments were performed using the multiphase flow rig with three-inch diameter pipelines transporting natural gas, water, and crude oil in a closed loop with a separator tank as source and sink. A series of tree-based ensemble machine learning models have been developed and tested with the data collected from accelerometers, differential pressure transmitters, and upstream- and downstream pressure transmitters. With these inputs, the developed models can identify volume ratios of individual phases (such as water cut) and can estimate the flow velocity of each phase in the flow loop, including the open/close status of the choke valve. After describing briefly, the P&ID diagram of the multiphase flow rig, the paper focuses on exploratory data analysis of the data from three accelerometers and three pressure sensors using three submodels cascaded to perform ensemble learning.\n",
            "----------------------------------------\n",
            "Title: Invention of 3Mint for feature grouping and scoring in multi-omics\n",
            "Abstract: Advanced genomic and molecular profiling technologies accelerated the enlightenment of the regulatory mechanisms behind cancer development and progression, and the targeted therapies in patients. Along this line, intense studies with immense amounts of biological information have boosted the discovery of molecular biomarkers. Cancer is one of the leading causes of death around the world in recent years. Elucidation of genomic and epigenetic factors in Breast Cancer (BRCA) can provide a roadmap to uncover the disease mechanisms. Accordingly, unraveling the possible systematic connections between-omics data types and their contribution to BRCA tumor progression is crucial. In this study, we have developed a novel machine learning (ML) based integrative approach for multi-omics data analysis. This integrative approach combines information from gene expression (mRNA), microRNA (miRNA) and methylation data. Due to the complexity of cancer, this integrated data is expected to improve the prediction, diagnosis and treatment of disease through patterns only available from the 3-way interactions between these 3-omics datasets. In addition, the proposed method bridges the interpretation gap between the disease mechanisms that drive onset and progression. Our fundamental contribution is the 3 Multi-omics integrative tool (3Mint). This tool aims to perform grouping and scoring of groups using biological knowledge. Another major goal is improved gene selection via detection of novel groups of cross-omics biomarkers. Performance of 3Mint is assessed using different metrics. Our computational performance evaluations showed that the 3Mint classifies the BRCA molecular subtypes with lower number of genes when compared to the miRcorrNet tool which uses miRNA and mRNA gene expression profiles in terms of similar performance metrics (95% Accuracy). The incorporation of methylation data in 3Mint yields a much more focused analysis. The 3Mint tool and all other supplementary files are available at https://github.com/malikyousef/3Mint/.\n",
            "----------------------------------------\n",
            "Title: XAI Human-Machine collaboration applied to network security\n",
            "Abstract: Cyber attacking is easier than cyber defending—attackers only need to find one breach, while the defenders must successfully repel all attacks. This research demonstrates how cyber defenders can increase their capabilities by joining forces with eXplainable-AI (XAI) utilizing interactive human-machine collaboration. With a global shortfall of cyber defenders there is a need to amplify their skills using AI. Cyber asymmetries make propositional machine learning techniques impractical. Human reasoning and skill is a key ingredient in defense and must be embedded in the AI framework. For Human-Machine collaboration to work requires that the AI is an ultra-strong machine learner and can explain its models. Unlike Deep Learning, Inductive Logic Programming can communicate what it learns to a human. An empirical study was undertaken using six months of eavesdropped network traffic from an organization generating up-to 562K network events daily. Easier-to-defend devices were identified using a form of the Good-Turing Frequency estimator which is a promising form of volatility measure. A behavioral cloning grammar in explicit symbolic form was then produced from a single device's network activity using the compression algorithm SEQUITUR. A novel visualization was generated to allow defenders to identify network sequences they wish to explain. Interactive Inductive Logic Programming (the XAI) is supplied the network traffic meta data, sophisticated pre-existing cyber security background knowledge, and one recurring sequence of events from a single device to explain. A co-inductive process between the human cyber defender and the XAI where the human is able to understand, then refute and shape the XAI's developing model, to produce a model that conforms with the data as well as the original device designers programming. The acceptable model is in a form that can be deployed as an ongoing active cyber defense.\n",
            "----------------------------------------\n",
            "Title: ML-SPAs: Fortifying Healthcare Cybersecurity Leveraging Varied Machine Learning Approaches against Spear Phishing Attacks\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Classifying drivers using electronic logging devices\n",
            "Abstract: In the era of personalization, being able to determine the risk of individual drivers and hence provide suitable insurance coverage to them would be a logical step. This paper proposes risk scoring for motor insurance using logged data of the drivers that are collected electronically. The proposed method uses machine learning to create a model that can be applied using the logged data. Initial studies conducted were able to achieve up to an accuracy of 79.4%. With further improvement, it can provide a suitable individual risk scoring for insurance premium computation.\n",
            "----------------------------------------\n",
            "Title: Machine learning designs new GCGR/GLP-1R dual agonists with enhanced biological potency\n",
            "Abstract: None\n",
            "----------------------------------------\n",
            "Title: Unravelling the atomistic mechanisms underpinning the morphological evolution of Al-alloyed hematite.\n",
            "Abstract: Hydrothermal synthesis based upon the use of Al3+ as the dopant and/or ethanol as the solvent is effective in promoting the growth of hematite into nanoplates rich in the (001) surface, which is highly active for a broad range of catalytic applications. However, the underpinning mechanism for the flattening of hematite crystals is still poorly comprehended. To close this knowledge gap, in this work, we have attempted intensive computational modelling to construct a binary phase diagram for Fe2O3-Al2O3 under typical hydrothermal conditions, as well as to quantify the surface energy of hematite crystal upon coverage with Al3+ and ethanol molecules. An innovative coupling of density functional theory calculation, cluster expansion and Monte Carlo simulations in analogy to machine learning and prediction was attempted. Upon successful validation by experimental observation, our simulation results suggest an optimum atomic dispersion of Al3+ within hematite in cases when its concentration is below 4 at% otherwise phase separation occurs, and discrete Al2O3 nano-clusters can be preferentially formed. Computations also revealed that the adsorption of ethanol molecules alone can reduce the specific surface energy of the hematite (001) surface from 1.33 to 0.31 J m-2. The segregation of Al3+ on the (001) surface can further reduce the specific surface energy to 0.18 J m-2. Consequently, the (001) surface growth is inhibited, and it becomes dominant after the disappearance of other surfaces upon their continual growth. This work provides atomistic insights into the synergistic effect between the aluminium textural promoter and the ethanol capping agent in determining the morphology of hematite nanoparticles. The established computation approach also applies to other oxide-based catalysts in controlling their surface growth and morphology, which are critical for their catalytic applications.\n",
            "----------------------------------------\n",
            "Finished fetching papers.\n"
          ]
        }
      ],
      "source": [
        "# defining the search query\n",
        "query = 'machine learning'\n",
        "\n",
        "# API URL for searching research paper\n",
        "url = 'https://api.semanticscholar.org/graph/v1/paper/search/bulk'\n",
        "\n",
        "# setting query parameters for API request\n",
        "query_params = {\n",
        "    'query': query,  # searching research papers related to machine learning\n",
        "    'offset': 0,  # starting index for fetching results\n",
        "    'limit': 100,  # fetching 100 papers at a time\n",
        "    'fields': 'paperId,title,abstract'  # specifying the fields to include in the response\n",
        "}\n",
        "\n",
        "# creating an empty list to store research paper details\n",
        "all_papers = []\n",
        "\n",
        "# using loop function to fetch multipl several batches of results\n",
        "for batch in range(100): # running loop for 100 times to collect more papers\n",
        "    print(f'\\nFetching Batch {batch + 1}...') # showing batch number\n",
        "\n",
        "    # making the get request to API with query parameters\n",
        "    response = requests.get(url, params=query_params)\n",
        "\n",
        "    # checking if the response status is successful\n",
        "    if response.status_code == 200:  # checking if the request is successful\n",
        "        data = response.json()  # converting response to JSON format\n",
        "        papers = data.get('data', [])  # extracting paper list from the response\n",
        "\n",
        "        # looping through each paper and extracting required details\n",
        "        for paper in papers:\n",
        "            title = paper.get(\"title\", \"No Title\") # getting title of the paper\n",
        "            abstract = paper.get(\"abstract\", \"No Abstract\") # getting abstract of the paper\n",
        "\n",
        "            # adding paper details to the list\n",
        "            all_papers.append({\n",
        "                'Title': title,\n",
        "                'Abstract': abstract\n",
        "            })\n",
        "\n",
        "            # printing the paper details\n",
        "            print(f'Title: {title}')\n",
        "            print(f'Abstract: {abstract}')\n",
        "            print('-' * 40)\n",
        "\n",
        "        # updating the offset for fetching the next batch of research papers\n",
        "        query_params['offset'] += 100  # increasing offset by 100 to get results\n",
        "\n",
        "        # adding a small delay to avoid hitting API rate limit\n",
        "        time.sleep(5) # pausing run time for 5 seconds\n",
        "\n",
        "    elif response.status_code == 429:  # if API returns too many requests error\n",
        "        print('Too many requests! Waiting for 10 seconds before retrying...')\n",
        "        time.sleep(10)  # waiting for 10 seconds before retrying\n",
        "\n",
        "    else:\n",
        "        print(f'Request failed with status code {response.status_code}: {response.text}')\n",
        "        break  # stopping further details if there is an error\n",
        "\n",
        "# displaying that script has been completed\n",
        "print('Finished fetching papers.')\n",
        "\n",
        "# changing data to a CSV file\n",
        "df = pd.DataFrame(all_papers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (15 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "BLQN4qkdNd2X",
        "outputId": "e37b09ff-7e65-44b5-8042-f9bbd66e076a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       Cleaned_title  \\\n",
              "0  insight household electr vehicl charg behavior...   \n",
              "1  person predict respons smartphonedeliv medit t...   \n",
              "2  machin learn method quantifi role vulner hurri...   \n",
              "3  abstract text summar lowresourc languag use de...   \n",
              "4  detect ddo attack cloud comput environ use mac...   \n",
              "\n",
              "                                    Cleaned_Abstract  \n",
              "0  era burgeon electr vehicl ev popular understan...  \n",
              "1  background medit app surg popular recent year ...  \n",
              "2                                                     \n",
              "3  background human must abl cope huge amount inf...  \n",
              "4  grow number cloudbas servic led rise threat di...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddbcf394-5a38-4826-9351-e268348a0cd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cleaned_title</th>\n",
              "      <th>Cleaned_Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>insight household electr vehicl charg behavior...</td>\n",
              "      <td>era burgeon electr vehicl ev popular understan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>person predict respons smartphonedeliv medit t...</td>\n",
              "      <td>background medit app surg popular recent year ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machin learn method quantifi role vulner hurri...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abstract text summar lowresourc languag use de...</td>\n",
              "      <td>background human must abl cope huge amount inf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>detect ddo attack cloud comput environ use mac...</td>\n",
              "      <td>grow number cloudbas servic led rise threat di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddbcf394-5a38-4826-9351-e268348a0cd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddbcf394-5a38-4826-9351-e268348a0cd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddbcf394-5a38-4826-9351-e268348a0cd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5b092f4-a550-436d-9947-b5379231b93a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5b092f4-a550-436d-9947-b5379231b93a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5b092f4-a550-436d-9947-b5379231b93a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['Cleaned_title', 'Cleaned_Abstract']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Cleaned_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"person predict respons smartphonedeliv medit train random control trial\",\n          \"detect ddo attack cloud comput environ use machin learn techniqu\",\n          \"machin learn method quantifi role vulner hurrican damag\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"background medit app surg popular recent year increas number individu turn app cope stress includ covid pandem medit app commonli use mental health app depress anxieti howev littl known well suit app object studi aim develop test datadriven algorithm predict individu like benefit appbas medit train method use random control trial data compar week medit app healthi mind program hmp assessmentonli control condit school system employe n develop algorithm predict like benefit hmp baselin clinic demograph characterist submit machin learn model develop person advantag index pai reflect individu expect reduct distress primari outcom hmp versu control result signific group pai interact emerg p indic pai score moder group differ outcom regress model includ repetit neg think sole baselin predictor perform compar well final demonstr translat predict model person recommend expect benefit conclus overal result reveal potenti datadriven algorithm inform individu like benefit medit app algorithm could use object commun expect benefit individu allow make inform decis whether medit app appropri trial registr clinicaltrialsgov nct httpsclinicaltrialsgovctshownct\",\n          \"grow number cloudbas servic led rise threat distribut denial servic ddo attack attack caus signific harm busi organ overwhelm network resourc result unavail critic servic tradit defens mechan firewal system becom insuffici cope scale complex ddo attack research propos new machin learn approach base ensembl learn detect ddo attack cloud environ propos method util variou featur extract network traffic train machin learn algorithm propos solut expect effect detect ddo attack realtim high accuraci\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# loading the data from the previously collected research papers\n",
        "df = pd.DataFrame(all_papers) # creating a df\n",
        "\n",
        "# downloading necessary NLTK resources\n",
        "nltk.download('stopwords') # downloading stopwords dataset\n",
        "nltk.download('wordnet')  # downloading wordnet for lemmatization\n",
        "nltk.download('punkt') # downloading tokenizer dataset\n",
        "\n",
        "# initializing the porterstemmer and wordnet lemmatizer\n",
        "stemmer = PorterStemmer() # creating an instance of porterstemmer\n",
        "lemmatizer = WordNetLemmatizer() # creating an instance of wordnet lemmatizer\n",
        "\n",
        "# defining stopwords to remove common words that do not have any meaning\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# defining a function to clean the text\n",
        "def clean_text_remove_stopwords_stem_and_lemmatize(text):\n",
        "    if text is None:\n",
        "        return ''  # if the text is none, return an empty string\n",
        "\n",
        "    # removing special characters and punctuation using regex\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Keep only letters, numbers, and spaces\n",
        "\n",
        "    # removing numbers using regex\n",
        "    text = re.sub(r'\\d+', '', text)  # removing all digits\n",
        "\n",
        "    # converting text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # removing stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "    # applying stemming to each word\n",
        "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "    # applying lemmatization to each word\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "# applying the cleaning, stemming, and lemmatization function to title and abstract\n",
        "df['Cleaned_title'] = df['Title'].apply(clean_text_remove_stopwords_stem_and_lemmatize)\n",
        "df['Cleaned_Abstract'] = df['Abstract'].apply(clean_text_remove_stopwords_stem_and_lemmatize)\n",
        "\n",
        "# showing few rows of the cleaned data\n",
        "df[['Cleaned_title', 'Cleaned_Abstract']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tLgIBMWmNBRA"
      },
      "outputs": [],
      "source": [
        "# exporting to csv\n",
        "abstract_paper = df[['Cleaned_title', 'Cleaned_Abstract']]\n",
        "abstract_paper.to_csv('cleaned_papers.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (15 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkOh11Q_X8tb",
        "outputId": "f544aaa9-d3d9-4def-bca3-1b6ac841d024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting benepar\n",
            "  Downloading benepar-0.2.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.11/dist-packages (from benepar) (3.9.1)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.11/dist-packages (from benepar) (3.7.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from benepar) (2.5.1+cu124)\n",
            "Collecting torch-struct>=0.5 (from benepar)\n",
            "  Downloading torch_struct-0.5-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in /usr/local/lib/python3.11/dist-packages (from benepar) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.2.2 in /usr/local/lib/python3.11/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (4.48.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from benepar) (4.25.6)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from benepar) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (0.15.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.26.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.9.4->benepar) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->benepar) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (0.5.2)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[tokenizers,torch]>=4.2.2->benepar) (5.9.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.0.9->benepar) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.0.9->benepar) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=2.0.9->benepar) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_struct-0.5-py3-none-any.whl (34 kB)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.2.0-py3-none-any.whl size=37626 sha256=77c5d5635cf87026024f24774df1da147a647fa3788f07a140498d03883dbcca\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/06/97/846995c0825bbc92825ce41675b6d5477213b25e167115223f\n",
            "Successfully built benepar\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-struct, benepar\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed benepar-0.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-struct-0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install benepar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install benepar torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0siqMPCOBCC",
        "outputId": "463f5714-edf4-4c0b-da24-2c487d9770b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: benepar in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.11/dist-packages (from benepar) (3.9.1)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.11/dist-packages (from benepar) (3.7.5)\n",
            "Requirement already satisfied: torch-struct>=0.5 in /usr/local/lib/python3.11/dist-packages (from benepar) (0.5)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in /usr/local/lib/python3.11/dist-packages (from benepar) (0.21.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from benepar) (4.25.6)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from benepar) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (1.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.10.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[tokenizers,torch]>=4.2.2->benepar) (5.9.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (2.27.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.0.9->benepar) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.0.9->benepar) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (7.1.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b1_8QLN-3Oae"
      },
      "outputs": [],
      "source": [
        "# importing data libraries\n",
        "import nltk # importing NLTK for natural language processing\n",
        "import os # importing os to manage file paths\n",
        "import spacy  # importing spacy for NLP tasks\n",
        "import benepar # importing benepar for parsing sentences\n",
        "from spacy import displacy # importing displacy for visualizing NLP structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d0VwQkOgHTo",
        "outputId": "2299a6a7-01a0-4489-f770-c13399a715d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# setting directory for storing NLTK data\n",
        "nltk_data_path = os.path.expanduser(\"~\") + \"/nltk_data\" # creating a path for NLTK data\n",
        "os.makedirs(nltk_data_path, exist_ok=True) # creating the directory if it does not exist\n",
        "nltk.data.path.append(nltk_data_path) # adding the directory to NLTK’s data path\n",
        "\n",
        "# downloading necessary packages\n",
        "nltk.download('punkt', download_dir=nltk_data_path) # downloading tokenizer dataset\n",
        "nltk.download('averaged_perceptron_tagger', download_dir=nltk_data_path) # downloading POS tagging dataset\n",
        "nltk.download('punkt_tab') # downloading additional tokenizer dataset\n",
        "nltk.download('averaged_perceptron_tagger_eng') # downloading english POS tagger dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dpN5w_k5e4T8"
      },
      "outputs": [],
      "source": [
        "# reading cleaned data from CSV file\n",
        "cleaned_dataframe = pd.read_csv('/content/cleaned_papers.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QRwyac0VezCj",
        "outputId": "903a5443-2c7f-4b83-d010-65a20270f1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       0    1   2   3  4\n",
              "0      [(era, NN), (burgeon, NN), (electr, NN), (vehi...   70  10  17  1\n",
              "1      [(background, NN), (medit, NN), (app, NN), (su...  105  22  26  4\n",
              "2                                                     []    0   0   0  0\n",
              "3      [(background, NN), (human, JJ), (must, MD), (a...   87  12  33  2\n",
              "4      [(grow, VB), (number, NN), (cloudbas, NN), (se...   52   9  12  0\n",
              "...                                                  ...  ...  ..  .. ..\n",
              "99995  [(cyber, VB), (attack, NN), (easier, JJR), (cy...  121  17  31  1\n",
              "99996                                                 []    0   0   0  0\n",
              "99997  [(era, NN), (person, NN), (abl, JJ), (determin...   43   6   3  0\n",
              "99998                                                 []    0   0   0  0\n",
              "99999  [(hydrotherm, NN), (synthesi, NN), (base, NN),...  110  14  27  5\n",
              "\n",
              "[100000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eaedf8b-af5d-4c5c-a7a7-6a77cc208cd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(era, NN), (burgeon, NN), (electr, NN), (vehi...</td>\n",
              "      <td>70</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(background, NN), (medit, NN), (app, NN), (su...</td>\n",
              "      <td>105</td>\n",
              "      <td>22</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(background, NN), (human, JJ), (must, MD), (a...</td>\n",
              "      <td>87</td>\n",
              "      <td>12</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(grow, VB), (number, NN), (cloudbas, NN), (se...</td>\n",
              "      <td>52</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>[(cyber, VB), (attack, NN), (easier, JJR), (cy...</td>\n",
              "      <td>121</td>\n",
              "      <td>17</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>[(era, NN), (person, NN), (abl, JJ), (determin...</td>\n",
              "      <td>43</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>[(hydrotherm, NN), (synthesi, NN), (base, NN),...</td>\n",
              "      <td>110</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eaedf8b-af5d-4c5c-a7a7-6a77cc208cd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8eaedf8b-af5d-4c5c-a7a7-6a77cc208cd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8eaedf8b-af5d-4c5c-a7a7-6a77cc208cd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7711b599-1ae1-41f7-bb4a-9745b4ac83fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7711b599-1ae1-41f7-bb4a-9745b4ac83fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7711b599-1ae1-41f7-bb4a-9745b4ac83fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5504a626-be59-468d-b94a-5e3e0f4b1e58\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cleaned_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5504a626-be59-468d-b94a-5e3e0f4b1e58 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cleaned_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cleaned_df",
              "summary": "{\n  \"name\": \"cleaned_df\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 0,\n        \"max\": 759,\n        \"num_unique_values\": 175,\n        \"samples\": [\n          1,\n          115,\n          130\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          34,\n          21,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 334,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          12,\n          41,\n          37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          1,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# defining a function to perform POS tagging\n",
        "def pos_tagging(text):\n",
        "    if pd.isna(text) or not isinstance(text, str):  # handling missing values or non-string values\n",
        "        return [], 0, 0, 0, 0 # returning empty values for missing text\n",
        "\n",
        "    words = word_tokenize(text)  # tokenizing the text\n",
        "    tagged_words = pos_tag(words)  # assigning POS tagging to words\n",
        "\n",
        "    # counting occurrences of various POS categories\n",
        "    pos_counts = Counter(tag for _, tag in tagged_words)# counting occurrences of each tag\n",
        "\n",
        "   # defining sets of POS tags for different categories\n",
        "    noun_tags = {'NN', 'NNS', 'NNP', 'NNPS'} # noun tags\n",
        "    verb_tags = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'} # verb tags\n",
        "    adj_tags = {'JJ', 'JJR', 'JJS'} #adjective tags\n",
        "    adv_tags = {'RB', 'RBR', 'RBS'} # adverb tags\n",
        "\n",
        "    # counting the number of nouns, verbs, adjectives, and adverbs\n",
        "    noun_count = sum(pos_counts[tag] for tag in noun_tags if tag in pos_counts)\n",
        "    verb_count = sum(pos_counts[tag] for tag in verb_tags if tag in pos_counts)\n",
        "    adj_count = sum(pos_counts[tag] for tag in adj_tags if tag in pos_counts)\n",
        "    adv_count = sum(pos_counts[tag] for tag in adv_tags if tag in pos_counts)\n",
        "\n",
        "    return tagged_words, noun_count, verb_count, adj_count, adv_count\n",
        "\n",
        "#  applying POS tagging to 'cleaned_title' column\n",
        "cleaned_df = cleaned_dataframe[['title_tags', 'title_nouns', 'title_verbs', 'title_adjs', 'title_advs']] = cleaned_dataframe['Cleaned_title'].apply(\n",
        "    lambda text: pd.Series(pos_tagging(text))\n",
        ")\n",
        "\n",
        "# applying POS tagging to 'Cleaned_Abstract' column (Adjusted column name)\n",
        "cleaned_df = cleaned_dataframe[['abstract_tags', 'abstract_nouns', 'abstract_verbs', 'abstract_adjs', 'abstract_advs']] = cleaned_dataframe['Cleaned_Abstract'].apply(\n",
        "    lambda text: pd.Series(pos_tagging(text))\n",
        ")\n",
        "\n",
        "cleaned_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PD1_FCnTY0xQ",
        "outputId": "f1a26000-7a4f-4294-ec95-970dbc802ce5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/benepar_en3.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/benepar/parse_chart.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "# downloading necessary models\n",
        "nltk.download('punkt')\n",
        "benepar.download('benepar_en3')\n",
        "\n",
        "# loading spacy model with dependency parsing\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# loading constituency parser\n",
        "parser = benepar.Parser(\"benepar_en3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8BUEZxBfY9q7",
        "outputId": "a95b6ec5-6df5-49e7-f33b-82a66cecbc09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Sentence: era burgeon electr vehicl ev popular understand pattern ev user behavior imper paper examin trend household charg session time durat energi consumpt analyz realworld residenti charg data leverag inform collect session novel framework introduc effici realtim predict import charg characterist util histor data userspecif featur machin learn model train predict connect durat charg durat charg demand time next session model enhanc understand ev user behavior provid practic tool optim ev charg infrastructur effect manag charg demand transport sector becom increasingli electrifi work aim empow stakehold insight reliabl model enabl anticip local demand contribut sustain integr electr vehicl grid\n"
          ]
        }
      ],
      "source": [
        "# extracting a sample sentence from the dataset\n",
        "sample_sentence = df['Cleaned_Abstract'].dropna().iloc[0]  # First non-empty abstract\n",
        "\n",
        "print(\"Sample Sentence:\", sample_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load English NLP model with NER capabilities\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Increase the max length limit\n",
        "nlp.max_length = 15000000  # Adjust this value if needed\n",
        "\n",
        "# Extracting text data (combining title and abstract for richer entity extraction)\n",
        "text_data = \" \".join(df['Cleaned_title'].dropna().astype(str)) + \" \" + \" \".join(df['Cleaned_Abstract'].dropna().astype(str))\n",
        "\n",
        "# Function to process text in chunks\n",
        "def process_text_in_chunks(text, chunk_size=1000000):\n",
        "    entities = []\n",
        "    for i in range(0, len(text), chunk_size):\n",
        "        chunk = text[i:i + chunk_size]\n",
        "        doc = nlp(chunk)\n",
        "        entities.extend([(ent.text, ent.label_) for ent in doc.ents])\n",
        "    return entities\n",
        "\n",
        "# Process the text in chunks\n",
        "entities = process_text_in_chunks(text_data)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "entity_df = pd.DataFrame(entities, columns=['Entity', 'Category'])\n",
        "\n",
        "# Counting occurrences of each entity category\n",
        "entity_counts = entity_df['Category'].value_counts()\n",
        "\n",
        "print(entity_counts.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdRx3D7dEgy3",
        "outputId": "39af2e9c-a610-4c53-bf05-4b38e3175b3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category\n",
            "PERSON      222815\n",
            "ORG         169905\n",
            "CARDINAL     60300\n",
            "GPE          49400\n",
            "NORP         38301\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcVqy1yj3wja"
      },
      "source": [
        "# **Following Questions must answer using AI assitance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEdcyHX8VaDB"
      },
      "source": [
        "#Question 4 (20 points)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ung5_YW3C6y"
      },
      "source": [
        "Q4. (PART-1)\n",
        "Web scraping data from the GitHub Marketplace to gather details about popular actions. Using Python, the process begins by sending HTTP requests to multiple pages of the marketplace (1000 products), handling pagination through dynamic page numbers. The key details extracted include the product name, a short description, and the URL.\n",
        "\n",
        " The extracted data is stored in a structured CSV format with columns for product name, description, URL, and page number. A time delay is introduced between requests to avoid server overload. ChatGPT can assist by helping with the parsing of HTML, error handling, and generating reports based on the data collected.\n",
        "\n",
        " The goal is to complete the scraping within a specified time limit, ensuring that the process is efficient and adheres to GitHub’s usage guidelines.\n",
        "\n",
        "(PART -2)\n",
        "\n",
        "1.   **Preprocess Data**: Clean the text by tokenizing, removing stopwords, and converting to lowercase.\n",
        "\n",
        "2. Perform **Data Quality** operations.\n",
        "\n",
        "\n",
        "Preprocessing:\n",
        "Preprocessing involves cleaning the text by removing noise such as special characters, HTML tags, and unnecessary whitespace. It also includes tasks like tokenization, stopword removal, and lemmatization to standardize the text for analysis.\n",
        "\n",
        "Data Quality:\n",
        "Data quality checks ensure completeness, consistency, and accuracy by verifying that all required columns are filled and formatted correctly. Additionally, it involves identifying and removing duplicates, handling missing values, and ensuring the data reflects the true content accurately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTOfUpatronW"
      },
      "source": [
        "Github MarketPlace page:\n",
        "https://github.com/marketplace?type=actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vCRsSOrw4luc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from random import choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ohxwZooD4qYw"
      },
      "outputs": [],
      "source": [
        "# storaging for extracted data\n",
        "product_data = []\n",
        "\n",
        "# listing of different user-agentt strings to avoid detection\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rIL4WYyD4s-9"
      },
      "outputs": [],
      "source": [
        "# creating a session to maintain cookies & headers\n",
        "session = requests.Session()\n",
        "\n",
        "# adding extra headers to mimic a real browser\n",
        "headers = {\n",
        "    'User-Agent': choice(user_agents),\n",
        "    'Accept-Language': 'en-US,en;q=0.5',\n",
        "    'Referer': 'https://github.com/',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "    'Connection': 'keep-alive',\n",
        "    'Cache-Control': 'no-cache',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mTytXEov3_4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf01b5dd-e749-4caa-eaad-306d8cbe0ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping: https://github.com/marketplace?page=1&type=actions\n",
            "Scraping: https://github.com/marketplace?page=2&type=actions\n",
            "Scraping: https://github.com/marketplace?page=3&type=actions\n",
            "Scraping: https://github.com/marketplace?page=4&type=actions\n",
            "Scraping: https://github.com/marketplace?page=5&type=actions\n",
            "Scraping: https://github.com/marketplace?page=6&type=actions\n",
            "Scraping: https://github.com/marketplace?page=7&type=actions\n",
            "Scraping: https://github.com/marketplace?page=8&type=actions\n",
            "Scraping: https://github.com/marketplace?page=9&type=actions\n",
            "Scraping: https://github.com/marketplace?page=10&type=actions\n",
            "Scraping: https://github.com/marketplace?page=11&type=actions\n",
            "Scraping: https://github.com/marketplace?page=12&type=actions\n",
            "Scraping: https://github.com/marketplace?page=13&type=actions\n",
            "Scraping: https://github.com/marketplace?page=14&type=actions\n",
            "Scraping: https://github.com/marketplace?page=15&type=actions\n",
            "Scraping: https://github.com/marketplace?page=16&type=actions\n",
            "Scraping: https://github.com/marketplace?page=17&type=actions\n",
            "Scraping: https://github.com/marketplace?page=18&type=actions\n",
            "Scraping: https://github.com/marketplace?page=19&type=actions\n",
            "Scraping: https://github.com/marketplace?page=20&type=actions\n",
            "Scraping: https://github.com/marketplace?page=21&type=actions\n",
            "Scraping: https://github.com/marketplace?page=22&type=actions\n",
            "Scraping: https://github.com/marketplace?page=23&type=actions\n",
            "Scraping: https://github.com/marketplace?page=24&type=actions\n",
            "Scraping: https://github.com/marketplace?page=25&type=actions\n",
            "Scraping: https://github.com/marketplace?page=26&type=actions\n",
            "Scraping: https://github.com/marketplace?page=27&type=actions\n",
            "Scraping: https://github.com/marketplace?page=28&type=actions\n",
            "Scraping: https://github.com/marketplace?page=29&type=actions\n",
            "Scraping: https://github.com/marketplace?page=30&type=actions\n",
            "Scraping: https://github.com/marketplace?page=31&type=actions\n",
            "Scraping: https://github.com/marketplace?page=32&type=actions\n",
            "Scraping: https://github.com/marketplace?page=33&type=actions\n",
            "Scraping: https://github.com/marketplace?page=34&type=actions\n",
            "Scraping: https://github.com/marketplace?page=35&type=actions\n",
            "Scraping: https://github.com/marketplace?page=36&type=actions\n",
            "Scraping: https://github.com/marketplace?page=37&type=actions\n",
            "Scraping: https://github.com/marketplace?page=38&type=actions\n",
            "Scraping: https://github.com/marketplace?page=39&type=actions\n",
            "Scraping: https://github.com/marketplace?page=40&type=actions\n",
            "Scraping: https://github.com/marketplace?page=41&type=actions\n",
            "Scraping: https://github.com/marketplace?page=42&type=actions\n",
            "Scraping: https://github.com/marketplace?page=43&type=actions\n",
            "Scraping: https://github.com/marketplace?page=44&type=actions\n",
            "Scraping: https://github.com/marketplace?page=45&type=actions\n",
            "Scraping: https://github.com/marketplace?page=46&type=actions\n",
            "Scraping: https://github.com/marketplace?page=47&type=actions\n",
            "Scraping: https://github.com/marketplace?page=48&type=actions\n",
            "Scraping: https://github.com/marketplace?page=49&type=actions\n",
            "Scraping: https://github.com/marketplace?page=50&type=actions\n",
            "Scraping: https://github.com/marketplace?page=51&type=actions\n",
            "Scraping: https://github.com/marketplace?page=52&type=actions\n",
            "Scraping: https://github.com/marketplace?page=53&type=actions\n",
            "Scraping: https://github.com/marketplace?page=54&type=actions\n"
          ]
        }
      ],
      "source": [
        "# fetching multiple pages\n",
        "for i in range(1, 55):  # adjusting range for more pages\n",
        "    time.sleep(3)  # delay to avoid getting blocked\n",
        "\n",
        "    base_url = f'https://github.com/marketplace?page={i}&type=actions'\n",
        "    print(f\"Scraping: {base_url}\")\n",
        "\n",
        "    # retrying logic\n",
        "    for attempt in range(3):  # Retrying up to 3 times\n",
        "        try:\n",
        "            response = session.get(base_url, headers=headers, timeout=10)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                break  # exiting loop if successful\n",
        "            else:\n",
        "                print(f\"Attempt {attempt+1}: Failed with status {response.status_code}\")\n",
        "                time.sleep(2)  # waiting before retrying\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Skipping page {i} due to failure\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # finding all marketplace items\n",
        "    github_actions = soup.find_all('div', class_='position-relative border rounded-2 d-flex marketplace-common-module__marketplace-item--MohVH gap-3 p-3')\n",
        "\n",
        "    for actions in github_actions:\n",
        "\n",
        "        # handling exception error\n",
        "        try:\n",
        "            # extracting product details\n",
        "            product_name_tag = actions.find('a', class_='marketplace-common-module__marketplace-item-link--jrIHf line-clamp-1')\n",
        "            product_name = product_name_tag.text.strip() if product_name_tag else 'N/A'\n",
        "\n",
        "            # extracting product URL\n",
        "            url = product_name_tag['href'] if product_name_tag else 'N/A'\n",
        "            if url.startswith('/'):\n",
        "                url = f'https://github.com{url}'\n",
        "\n",
        "            # extracting action description\n",
        "            action_description_tag = actions.find('p', class_='mt-1 mb-0 text-small fgColor-muted line-clamp-2')\n",
        "            action_description = action_description_tag.text.strip() if action_description_tag else 'N/A'\n",
        "\n",
        "            # storing in a structured dictionary\n",
        "            product_data.append({\n",
        "                'Product Name': product_name,\n",
        "                'URL': url,\n",
        "                'Description': action_description,\n",
        "                'Page Number': i\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting data on page {i}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "idf1PteL4xvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63533d8b-ffe1-4984-ea35-e9133cb6950b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping Completed. Data saved to github_marketplace_actions.csv.\n"
          ]
        }
      ],
      "source": [
        "# converting to a dataframe\n",
        "df_products = pd.DataFrame(product_data)\n",
        "\n",
        "# saving to csv\n",
        "df_products.to_csv('github_marketplace_actions.csv', index=False)\n",
        "\n",
        "print(\"Scraping Completed. Data saved to github_marketplace_actions.csv.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "H5ZImuE1_Y02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "39f0dddf-f5fc-4976-a75a-3dbd4110cbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Product Name  \\\n",
              "0               trufflehog os   \n",
              "1                metric embed   \n",
              "2  yq portable yaml processor   \n",
              "3                 superlinter   \n",
              "4      gosec security checker   \n",
              "\n",
              "                                         Description  \\\n",
              "0                      scan github action trufflehog   \n",
              "1  infographics generator 40 plugins 300 option d...   \n",
              "2      create read update delete merge validate yaml   \n",
              "3  superlinter readytorun collection linters code...   \n",
              "4                         run gosec security checker   \n",
              "\n",
              "                                                 URL  Page Number  \n",
              "0  https://github.com/marketplace/actions/truffle...            1  \n",
              "1  https://github.com/marketplace/actions/metrics...            1  \n",
              "2  https://github.com/marketplace/actions/yq-port...            1  \n",
              "3  https://github.com/marketplace/actions/super-l...            1  \n",
              "4  https://github.com/marketplace/actions/gosec-s...            1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2451fecd-c6b6-47b7-916b-3a71fd5a3da0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>URL</th>\n",
              "      <th>Page Number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trufflehog os</td>\n",
              "      <td>scan github action trufflehog</td>\n",
              "      <td>https://github.com/marketplace/actions/truffle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metric embed</td>\n",
              "      <td>infographics generator 40 plugins 300 option d...</td>\n",
              "      <td>https://github.com/marketplace/actions/metrics...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yq portable yaml processor</td>\n",
              "      <td>create read update delete merge validate yaml</td>\n",
              "      <td>https://github.com/marketplace/actions/yq-port...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>superlinter</td>\n",
              "      <td>superlinter readytorun collection linters code...</td>\n",
              "      <td>https://github.com/marketplace/actions/super-l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gosec security checker</td>\n",
              "      <td>run gosec security checker</td>\n",
              "      <td>https://github.com/marketplace/actions/gosec-s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2451fecd-c6b6-47b7-916b-3a71fd5a3da0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2451fecd-c6b6-47b7-916b-3a71fd5a3da0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2451fecd-c6b6-47b7-916b-3a71fd5a3da0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e4b2d82-0e76-4b31-81e0-f94b1f607b12\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e4b2d82-0e76-4b31-81e0-f94b1f607b12')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e4b2d82-0e76-4b31-81e0-f94b1f607b12 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_action_products[['Product Name', 'Description', 'URL', 'Page Number']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Product Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"metric embed\",\n          \"gosec security checker\",\n          \"yq portable yaml processor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"infographics generator 40 plugins 300 option display stats github account\",\n          \"run gosec security checker\",\n          \"create read update delete merge validate yaml\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://github.com/marketplace/actions/metrics-embed\",\n          \"https://github.com/marketplace/actions/gosec-security-checker\",\n          \"https://github.com/marketplace/actions/yq-portable-yaml-processor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Page Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# loading the data from the previously collected github_action (replace with your actual dataframe)\n",
        "df_action_products = pd.read_csv('/content/github_marketplace_actions.csv')\n",
        "\n",
        "# downloading the necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# defining a function to clean the text\n",
        "def clean_text_remove_stopword(text):\n",
        "    # handling missing values (NaN) or non-string values\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "     # removing special characters and punctuation using regex\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Keep only alphabets, numbers, and spaces\n",
        "\n",
        "    # converting text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # tokenizing the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # removing stopwords and perform lemmatization\n",
        "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(cleaned_tokens)\n",
        "\n",
        "# applying the cleaning function to 'Product Name' and 'Description' columns\n",
        "df_action_products['Product Name'] = df_action_products['Product Name'].apply(clean_text_remove_stopword)\n",
        "df_action_products['Description'] = df_action_products['Description'].apply(clean_text_remove_stopword)\n",
        "\n",
        "# showing the first few rows of the cleaned data (output)\n",
        "df_action_products[['Product Name', 'Description', 'URL', 'Page Number']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HYhlU_AxLiQT"
      },
      "outputs": [],
      "source": [
        "# droping missing value\n",
        "df_action_products = df_action_products.dropna(subset=['Description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8cqTDvWhOo1e"
      },
      "outputs": [],
      "source": [
        "# selecting specifice column\n",
        "df_actions = df_action_products[['Product Name', 'Description', 'URL', 'Page Number']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CgJXGlpRVDKX"
      },
      "outputs": [],
      "source": [
        "# storing data to csv\n",
        "df_actions.to_csv('cleaned_github_actions_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WeD70ty3Gui"
      },
      "source": [
        "#Question 5 (20 points)\n",
        "\n",
        "PART 1:\n",
        "Web Scrape  tweets from Twitter using the Tweepy API, specifically targeting hashtags related to subtopics (machine learning or artificial intelligence.)\n",
        "The extracted data includes the tweet ID, username, and text.\n",
        "\n",
        "Part 2:\n",
        "Perform data cleaning procedures\n",
        "\n",
        "A final data quality check ensures the completeness and consistency of the dataset. The cleaned data is then saved into a CSV file for further analysis.\n",
        "\n",
        "\n",
        "**Note**\n",
        "\n",
        "1.   Follow tutorials provided in canvas to obtain api keys. Use ChatGPT to get the code. Make sure the file is downloaded and saved.\n",
        "2.   Make sure you divide GPT code as shown in tutorials, dont make multiple requestes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qYRO5Cn8bYwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d478fb3-0709-4fea-e64e-577d13984439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.11/dist-packages (4.15.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# installing tweepy for twitter scraping\n",
        "!pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CU267af2cGZI"
      },
      "outputs": [],
      "source": [
        "# importing tweepy for twitter api\n",
        "import tweepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "z5TcFX8bcMde"
      },
      "outputs": [],
      "source": [
        "# twitter API credentials\n",
        "API_KEY_SECRET = \"****0u4kku\"\n",
        "ACCESS_TOKEN = \"764834168291201028-5sCwhkbhEIjWBaUzlnPfTmd1lYx8ECc\"\n",
        "ACCESS_TOKEN_SECRET = \"5zOsd3Ge94bDtF3NsliM9gMsT56D0pC9QeFtV1h74DI6a\"\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAFtkzQEAAAAAUlrwWEz4%2Bp9GMK8GnHMogUWozvQ%3DhIFbaccUYhoovuO8MMINeFrxE1XSbIK8FSDVgkiDz5WpqKbXOQ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2ShRSwDqcRyN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e5323641-9240-40a2-f1ff-efa2b61c15e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Tweet ID             Username  \\\n",
              "0  1891724106434854973   940823377765371905   \n",
              "1  1891724100957061308  1878701904462831616   \n",
              "2  1891724092471980087  1891306202753355776   \n",
              "3  1891724090056245288           2476684130   \n",
              "4  1891724086704734611  1871092295854116864   \n",
              "\n",
              "                                                Text  \n",
              "0  Alice: The Last return to Wonderland\\nhttps://...  \n",
              "1  @lmarena_ai @xai Wow, Grok-3 crushing it! 🏆  1...  \n",
              "2  💡 58% of customers ghost businesses after ONE ...  \n",
              "3  🚀🔍 Say hello to \"Pearl\", the AI search engine ...  \n",
              "4  ♬ Buffering... Please Wait... https://t.co/sc4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c576cea-75a9-40a5-b6b6-c9a5adfa30ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet ID</th>\n",
              "      <th>Username</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1891724106434854973</td>\n",
              "      <td>940823377765371905</td>\n",
              "      <td>Alice: The Last return to Wonderland\\nhttps://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1891724100957061308</td>\n",
              "      <td>1878701904462831616</td>\n",
              "      <td>@lmarena_ai @xai Wow, Grok-3 crushing it! 🏆  1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1891724092471980087</td>\n",
              "      <td>1891306202753355776</td>\n",
              "      <td>💡 58% of customers ghost businesses after ONE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1891724090056245288</td>\n",
              "      <td>2476684130</td>\n",
              "      <td>🚀🔍 Say hello to \"Pearl\", the AI search engine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1891724086704734611</td>\n",
              "      <td>1871092295854116864</td>\n",
              "      <td>♬ Buffering... Please Wait... https://t.co/sc4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c576cea-75a9-40a5-b6b6-c9a5adfa30ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c576cea-75a9-40a5-b6b6-c9a5adfa30ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c576cea-75a9-40a5-b6b6-c9a5adfa30ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52475f69-964a-4d82-a1ec-fe9c03a95c19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52475f69-964a-4d82-a1ec-fe9c03a95c19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52475f69-964a-4d82-a1ec-fe9c03a95c19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "twitter_df",
              "summary": "{\n  \"name\": \"twitter_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Tweet ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 351594789285,\n        \"min\": 1891722920046584211,\n        \"max\": 1891724106434854973,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          1891723178700870028,\n          1891723500093636974,\n          1891723321885995228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Username\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 646741884554992512,\n        \"min\": 16556756,\n        \"max\": 1891374958019792896,\n        \"num_unique_values\": 85,\n        \"samples\": [\n          1858878417669943298,\n          940823377765371905,\n          1857428478158585856\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"How China\\u2019s \\u2018six little dragons\\u2019 are disrupting AI as we know it.\\n\\n#China @DrewPavlou @badiucao @nyrola @AbduwelA @tengbiao @HKokbore #AI #dragons @jenniferzeng97 @Jkylebass @robert_spalding @AndrewJWHaynes @bobpickettsr @mrbcyber @aadilbrar @songpinganq \\nhttps://t.co/CexmK1qteL\",\n          \"Just discovered #Mozo, an innovative Web3 #AI project. Lead the change! @Mozo_xyz\\n https://t.co/gYUB3K23bd\",\n          \"@lexfridman I've just subscribed to Premium+ for a year after that epic demo! Still waiting for the live access, but I'm beyond excited to dive in and try out Grok 3. #Grok3  #AI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# authenticating using OAuth2\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "\n",
        "# defining search query and parameters\n",
        "query = \"(#MachineLearning OR #AI) -is:retweet lang:en\"\n",
        "tweets = client.search_recent_tweets(query=query, tweet_fields=[\"id\", \"text\", \"author_id\"], max_results=100)\n",
        "\n",
        "# extracting relevant data\n",
        "data = []\n",
        "if tweets.data:\n",
        "    for tweet in tweets.data:\n",
        "        data.append({\n",
        "            \"Tweet ID\": tweet.id,\n",
        "            \"Username\": tweet.author_id,\n",
        "            \"Text\": tweet.text\n",
        "        })\n",
        "\n",
        "# converting to dataframe and display\n",
        "twitter_df = pd.DataFrame(data)\n",
        "twitter_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9gisqaEGjdcO"
      },
      "outputs": [],
      "source": [
        "# storing twitter_df to csv\n",
        "twitter_df.to_csv('twitter_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "p48zOh7KiccD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26b510a-42a2-4733-c2ab-41ed500e3800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            " Tweet ID    0\n",
            "Username    0\n",
            "Text        0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate Rows: 0\n"
          ]
        }
      ],
      "source": [
        "# performing data quality checks\n",
        "missing_values = twitter_df.isnull().sum()\n",
        "duplicate_rows = twitter_df.duplicated().sum()\n",
        "\n",
        "# printing data quality report\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "print(\"\\nDuplicate Rows:\", duplicate_rows)\n",
        "\n",
        "# removing duplicates (if any)\n",
        "df_twitter_cleaned = twitter_df.drop_duplicates()\n",
        "\n",
        "# saving the cleaned data to a new CSV file\n",
        "df_twitter_cleaned.to_csv('twitter_cleaned_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8BFCvWp32cf"
      },
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCsv6gZ75Aah"
      },
      "source": [
        "I find this assignment really challenging and difficult at the same time. While running 10000 data for the question number1, it took me forever to run the code and get the output which was really frustating.I even got google colab pro and tried running code for several times but still couldn't get the whole result beacause of large datasets. I tried scrapping the data first from IMDB but coundn't scrap more than 25 data and had to change to another one.It took me whole 4 days to work on this assignment though I took help from Canvas guidelines and Chatgpt.But at the same time, I learned about lots of data libraries, toolkits and webscraping from different websites."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CSV_files**\n",
        "\n",
        "https://1drv.ms/f/c/b7ab9e17013cc096/EuUHJWPPWjxDk654ltSrfRkBCR_hBQIP4I3gw_Gyc95coQ?e=z9wb1r"
      ],
      "metadata": {
        "id": "cBwXPr4ryJKe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbTa-jDS-KFI"
      },
      "source": [
        "# Write your response below\n",
        "Fill out survey and provide your valuable feedback.\n",
        "\n",
        "https://docs.google.com/forms/d/e/1FAIpQLSd_ObuA3iNoL7Az_C-2NOfHodfKCfDzHZtGRfIker6WyZqTtA/viewform?usp=dialog"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}